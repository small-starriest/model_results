{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.8818024676640639,
            "accuracy_threshold": 0.8850439786911011,
            "ap": 0.7975166561618918,
            "f1": 0.7339333248827481,
            "f1_threshold": 0.8724502325057983,
            "precision": 0.7062698219077824,
            "recall": 0.7638522427440633
        },
        "dot": {
            "accuracy": 0.8818024676640639,
            "accuracy_threshold": 0.8850439786911011,
            "ap": 0.7975164867975405,
            "f1": 0.7339333248827481,
            "f1_threshold": 0.8724502325057983,
            "precision": 0.7062698219077824,
            "recall": 0.7638522427440633
        },
        "euclidean": {
            "accuracy": 0.8818024676640639,
            "accuracy_threshold": 0.47949135303497314,
            "ap": 0.7975167629543484,
            "f1": 0.7339333248827481,
            "f1_threshold": 0.5050737857818604,
            "precision": 0.7062698219077824,
            "recall": 0.7638522427440633
        },
        "evaluation_time": 18.48,
        "manhattan": {
            "accuracy": 0.8819812839005782,
            "accuracy_threshold": 10.732342720031738,
            "ap": 0.7973240690920731,
            "f1": 0.7363973882985533,
            "f1_threshold": 11.107664108276367,
            "precision": 0.7152449639393186,
            "recall": 0.7588390501319261
        },
        "max": {
            "accuracy": 0.8819812839005782,
            "ap": 0.7975167629543484,
            "f1": 0.7363973882985533
        }
    },
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}