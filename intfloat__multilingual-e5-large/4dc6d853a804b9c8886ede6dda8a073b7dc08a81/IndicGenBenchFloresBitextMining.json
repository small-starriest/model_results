{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 323.10643315315247,
  "kg_co2_emissions": 0.05780573930321449,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433466,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433466,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300394,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300394,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433466,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433466,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.9973649538866931,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9973649538866931,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034255,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9907773386034255,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.989459815546772,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.989459815546772,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.989459815546772,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.989459815546772,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034255,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9907773386034255,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9950592885375494,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9950592885375494,
        "precision": 0.9945652173913043,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9950592885375494,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9950592885375494,
        "precision": 0.9945652173913043,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034257,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9907773386034257,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9792490118577075,
        "f1": 0.9724967061923583,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9724967061923583,
        "precision": 0.9692028985507246,
        "recall": 0.9792490118577075
      },
      {
        "accuracy": 0.9762845849802372,
        "f1": 0.9691040843214757,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9691040843214757,
        "precision": 0.9656620553359684,
        "recall": 0.9762845849802372
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9876482213438735,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9876482213438735,
        "precision": 0.9864953886693018,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9871541501976284,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9871541501976284,
        "precision": 0.9856719367588933,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.07806324110671936,
        "f1": 0.06571352418539118,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.06571352418539118,
        "precision": 0.06228022121063359,
        "recall": 0.07806324110671936
      },
      {
        "accuracy": 0.13142292490118576,
        "f1": 0.0855156582083872,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.0855156582083872,
        "precision": 0.07656682209186448,
        "recall": 0.13142292490118576
      },
      {
        "accuracy": 0.3231225296442688,
        "f1": 0.2917264236551538,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2917264236551538,
        "precision": 0.28305876534646246,
        "recall": 0.3231225296442688
      },
      {
        "accuracy": 0.3883399209486166,
        "f1": 0.31686386955161655,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.31686386955161655,
        "precision": 0.2958001932316246,
        "recall": 0.3883399209486166
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.9894598155467721,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9894598155467721,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9436758893280632,
        "f1": 0.9277558190601669,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9277558190601669,
        "precision": 0.9207427536231885,
        "recall": 0.9436758893280632
      },
      {
        "accuracy": 0.9555335968379447,
        "f1": 0.9421466214944476,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.9421466214944476,
        "precision": 0.9357707509881423,
        "recall": 0.9555335968379447
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9909420289855072,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9909420289855072,
        "precision": 0.9899538866930171,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.989459815546772,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.989459815546772,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.5316205533596838,
        "f1": 0.48983191492918227,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.48983191492918227,
        "precision": 0.47840843383207965,
        "recall": 0.5316205533596838
      },
      {
        "accuracy": 0.6719367588932806,
        "f1": 0.6049454169019386,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.6049454169019386,
        "precision": 0.5797509254030992,
        "recall": 0.6719367588932806
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.989459815546772,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.989459815546772,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9861660079051383,
        "f1": 0.9818840579710144,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9818840579710144,
        "precision": 0.9799077733860342,
        "recall": 0.9861660079051383
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.014695145214987168,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.014695145214987168,
        "precision": 0.014182516708306052,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.014125933976810114,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.014125933976810114,
        "precision": 0.011641188759066133,
        "recall": 0.03260869565217391
      }
    ],
    "validation": [
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305584,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9986626546305584,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611167,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9973253092611167,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527916,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9933132731527916,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444667,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9893012370444667,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444667,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9893012370444667,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9923102641257104,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9923102641257104,
        "precision": 0.9914744232698094,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9882982280173854,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9882982280173854,
        "precision": 0.9869608826479438,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305584,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305584,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9856235372785022,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9856235372785022,
        "precision": 0.9841190237378804,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9769307923771314,
        "f1": 0.9694082246740221,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9694082246740221,
        "precision": 0.9657305249080576,
        "recall": 0.9769307923771314
      },
      {
        "accuracy": 0.9679037111334002,
        "f1": 0.9580407890337679,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9580407890337679,
        "precision": 0.9533600802407222,
        "recall": 0.9679037111334002
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9939819458375125,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9939819458375125,
        "precision": 0.993480441323972,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9916415914409897,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9916415914409897,
        "precision": 0.9909729187562688,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222335,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9946506185222335,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.10230692076228685,
        "f1": 0.08525055213507228,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.08525055213507228,
        "precision": 0.08081610973412641,
        "recall": 0.10230692076228685
      },
      {
        "accuracy": 0.1424272818455366,
        "f1": 0.09928823067549294,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.09928823067549294,
        "precision": 0.08965501747746171,
        "recall": 0.1424272818455366
      },
      {
        "accuracy": 0.32898696088264795,
        "f1": 0.2993131507512839,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2993131507512839,
        "precision": 0.2911029111571916,
        "recall": 0.32898696088264795
      },
      {
        "accuracy": 0.4312938816449348,
        "f1": 0.36376611044733054,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.36376611044733054,
        "precision": 0.3431543190220538,
        "recall": 0.4312938816449348
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9894684052156469,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9894684052156469,
        "precision": 0.9882982280173855,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9852892009361417,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9852892009361417,
        "precision": 0.9834503510531595,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9458375125376128,
        "f1": 0.9313105984620528,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9313105984620528,
        "precision": 0.9250847781439557,
        "recall": 0.9458375125376128
      },
      {
        "accuracy": 0.9368104312938816,
        "f1": 0.9179204279505182,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.9179204279505182,
        "precision": 0.908893346706787,
        "recall": 0.9368104312938816
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.9812771648278167,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9812771648278167,
        "precision": 0.9789368104312939,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.5416248746238717,
        "f1": 0.5018817213379395,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.5018817213379395,
        "precision": 0.4900614444621466,
        "recall": 0.5416248746238717
      },
      {
        "accuracy": 0.6710130391173521,
        "f1": 0.6076882885308161,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.6076882885308161,
        "precision": 0.5841325563993567,
        "recall": 0.6710130391173521
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527916,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9933132731527916,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9881310598462052,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9881310598462052,
        "precision": 0.9867937144767636,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611167,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611167,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9866265463055833,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9866265463055833,
        "precision": 0.9849548645937813,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.0160481444332999,
        "f1": 0.011590664994360398,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.011590664994360398,
        "precision": 0.01115010128572555,
        "recall": 0.0160481444332999
      },
      {
        "accuracy": 0.02106318956870612,
        "f1": 0.006950419116178099,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.006950419116178099,
        "precision": 0.005836749183622123,
        "recall": 0.02106318956870612
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}