{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 77.73728823661804,
  "kg_co2_emissions": 0.04070579714501048,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.5703125,
        "f1": 0.5264508928571429,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.5264508928571429,
        "precision": 0.5094746291035354,
        "recall": 0.5703125
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9217936197916667,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9217936197916667,
        "precision": 0.9142020089285714,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9638671875,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9638671875,
        "precision": 0.95947265625,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.8701171875,
        "f1": 0.8405924479166667,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8405924479166667,
        "precision": 0.8273437499999999,
        "recall": 0.8701171875
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8584309895833333,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8584309895833333,
        "precision": 0.8452962239583333,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9752604166666666,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9752604166666666,
        "precision": 0.97216796875,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.92626953125,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.92626953125,
        "precision": 0.9181315104166666,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.7088875642586581,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.7088875642586581,
        "precision": 0.6903506324404762,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.95556640625,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.95556640625,
        "precision": 0.95068359375,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.755859375,
        "f1": 0.7073776971726191,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.7073776971726191,
        "precision": 0.6873790922619047,
        "recall": 0.755859375
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9508463541666667,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9508463541666667,
        "precision": 0.9454752604166667,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0055886141823641815,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0055886141823641815,
        "precision": 0.00430746458147653,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9847005208333333,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9847005208333333,
        "precision": 0.98291015625,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6871186755952381,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.6871186755952381,
        "precision": 0.6645290798611111,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.7763671875,
        "f1": 0.7267926897321428,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.7267926897321428,
        "precision": 0.7059283544146825,
        "recall": 0.7763671875
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9632161458333333,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9632161458333333,
        "precision": 0.9591471354166667,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0050543969903259975,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0050543969903259975,
        "precision": 0.0039510955624236874,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.80595703125,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.80595703125,
        "precision": 0.7913411458333333,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8185546874999999,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8185546874999999,
        "precision": 0.8031412760416667,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.865234375,
        "f1": 0.8339192708333334,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8339192708333334,
        "precision": 0.8201497395833333,
        "recall": 0.865234375
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.962890625,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.962890625,
        "precision": 0.95849609375,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666666,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.9791666666666666,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.603515625,
        "f1": 0.5529506138392857,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.5529506138392857,
        "precision": 0.5334565662202381,
        "recall": 0.603515625
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9676106770833334,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9676106770833334,
        "precision": 0.9637044270833333,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9189453125,
        "f1": 0.8967122395833333,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8967122395833333,
        "precision": 0.8863118489583334,
        "recall": 0.9189453125
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9265950520833333,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9265950520833333,
        "precision": 0.9186197916666667,
        "recall": 0.943359375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.96875,
        "f1": 0.95947265625,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.95947265625,
        "precision": 0.955078125,
        "recall": 0.96875
      },
      {
        "accuracy": 0.8212890625,
        "f1": 0.7824079241071429,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.7824079241071429,
        "precision": 0.7658799913194445,
        "recall": 0.8212890625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333333,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9925130208333333,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.7920758928571429,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.7920758928571429,
        "precision": 0.7747395833333333,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005533337466931216,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.005533337466931216,
        "precision": 0.00419880141559829,
        "recall": 0.013671875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.771484375,
        "f1": 0.7198939732142857,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.7198939732142857,
        "precision": 0.6971028645833333,
        "recall": 0.771484375
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8067568824404763,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8067568824404763,
        "precision": 0.7896647135416668,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.006248615295994328,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.006248615295994328,
        "precision": 0.0046419139834350245,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8805989583333333,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8805989583333333,
        "precision": 0.869384765625,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9322916666666666,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9322916666666666,
        "precision": 0.92431640625,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9080078125,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9080078125,
        "precision": 0.8982747395833333,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.505859375,
        "f1": 0.46138335134150343,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.46138335134150343,
        "precision": 0.44764979168533003,
        "recall": 0.505859375
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.48918784798796594,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.48918784798796594,
        "precision": 0.47248130287681067,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.5966796875,
        "f1": 0.5549838623934465,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5549838623934465,
        "precision": 0.5414366834524431,
        "recall": 0.5966796875
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.5067053733324988,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5067053733324988,
        "precision": 0.49237650691787127,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.5830078125,
        "f1": 0.5364526729882337,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5364526729882337,
        "precision": 0.5210101787132837,
        "recall": 0.5830078125
      },
      {
        "accuracy": 0.455078125,
        "f1": 0.4003431347681118,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.4003431347681118,
        "precision": 0.38251411345196223,
        "recall": 0.455078125
      },
      {
        "accuracy": 0.564453125,
        "f1": 0.5185602744885833,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5185602744885833,
        "precision": 0.5029511973372479,
        "recall": 0.564453125
      },
      {
        "accuracy": 0.4638671875,
        "f1": 0.405083177169287,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.405083177169287,
        "precision": 0.38574533241281284,
        "recall": 0.4638671875
      },
      {
        "accuracy": 0.49609375,
        "f1": 0.4517899542629552,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.4517899542629552,
        "precision": 0.43746598414052146,
        "recall": 0.49609375
      },
      {
        "accuracy": 0.57421875,
        "f1": 0.5298747764593776,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5298747764593776,
        "precision": 0.5150582896920788,
        "recall": 0.57421875
      },
      {
        "accuracy": 0.435546875,
        "f1": 0.3784987969366591,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3784987969366591,
        "precision": 0.36084015376984124,
        "recall": 0.435546875
      },
      {
        "accuracy": 0.513671875,
        "f1": 0.4702509703158315,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4702509703158315,
        "precision": 0.4547859616698855,
        "recall": 0.513671875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005839195654223228,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005839195654223228,
        "precision": 0.004607810808982684,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.5400390625,
        "f1": 0.4960888573394318,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4960888573394318,
        "precision": 0.4820237227095584,
        "recall": 0.5400390625
      },
      {
        "accuracy": 0.3798828125,
        "f1": 0.3190185953369547,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3190185953369547,
        "precision": 0.2992880299018282,
        "recall": 0.3798828125
      },
      {
        "accuracy": 0.443359375,
        "f1": 0.38747937871456267,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.38747937871456267,
        "precision": 0.370353940764097,
        "recall": 0.443359375
      },
      {
        "accuracy": 0.533203125,
        "f1": 0.4843871252331367,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.4843871252331367,
        "precision": 0.4693980185923546,
        "recall": 0.533203125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008636526776175213,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008636526776175213,
        "precision": 0.007642080269607843,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.6123046875,
        "f1": 0.5774825136885684,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5774825136885684,
        "precision": 0.5651088618355786,
        "recall": 0.6123046875
      },
      {
        "accuracy": 0.423828125,
        "f1": 0.3756496400734682,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3756496400734682,
        "precision": 0.3593503600540595,
        "recall": 0.423828125
      },
      {
        "accuracy": 0.4912109375,
        "f1": 0.44065195680544944,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.44065195680544944,
        "precision": 0.4235435548258676,
        "recall": 0.4912109375
      },
      {
        "accuracy": 0.505859375,
        "f1": 0.4575877015124131,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4575877015124131,
        "precision": 0.4427836775493025,
        "recall": 0.505859375
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9045247395833333,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9045247395833333,
        "precision": 0.8946126302083334,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.96240234375,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.96240234375,
        "precision": 0.9578450520833334,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.6328125,
        "f1": 0.5925547542735043,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5925547542735043,
        "precision": 0.5770689352964744,
        "recall": 0.6328125
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9719075520833333,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9719075520833333,
        "precision": 0.9688313802083334,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8758463541666666,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8758463541666666,
        "precision": 0.864697265625,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.85546875,
        "f1": 0.8191592261904762,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8191592261904762,
        "precision": 0.802880859375,
        "recall": 0.85546875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833333,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9793294270833333,
        "precision": 0.9768880208333334,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8854895213293651,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8854895213293651,
        "precision": 0.8765706380208333,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.8212890625,
        "f1": 0.7868598090277777,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7868598090277777,
        "precision": 0.7722079190340909,
        "recall": 0.8212890625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9802083333333333,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9802083333333333,
        "precision": 0.978271484375,
        "recall": 0.984375
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6888726128472222,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6888726128472222,
        "precision": 0.6678397042410714,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9360026041666667,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9360026041666667,
        "precision": 0.9295247395833333,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009157539870430496,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009157539870430496,
        "precision": 0.007957016941391941,
        "recall": 0.015625
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9754231770833334,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9754231770833334,
        "precision": 0.9729817708333334,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.6171875,
        "f1": 0.5475004650297619,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5475004650297619,
        "precision": 0.5199335007440475,
        "recall": 0.6171875
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7875325520833334,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7875325520833334,
        "precision": 0.7695963541666667,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9417317708333333,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9417317708333333,
        "precision": 0.9360677083333334,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.009095840970251404,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009095840970251404,
        "precision": 0.007317076640807109,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.90087890625,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.90087890625,
        "precision": 0.8919596354166668,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.8515625,
        "f1": 0.8173549107142857,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8173549107142857,
        "precision": 0.8025987413194444,
        "recall": 0.8515625
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8320824032738094,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8320824032738094,
        "precision": 0.8181966145833334,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9557291666666667,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9557291666666667,
        "precision": 0.9510416666666667,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9713541666666666,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9713541666666666,
        "precision": 0.9677734375,
        "recall": 0.978515625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.6025390625,
        "f1": 0.5396011594742063,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.5396011594742063,
        "precision": 0.5162473648313493,
        "recall": 0.6025390625
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.97412109375,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.97412109375,
        "precision": 0.9710286458333334,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.91650390625,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.91650390625,
        "precision": 0.9075520833333333,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.91650390625,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.91650390625,
        "precision": 0.9069010416666667,
        "recall": 0.9365234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.8515625,
        "f1": 0.8127752130681818,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.8127752130681818,
        "precision": 0.7951822916666667,
        "recall": 0.8515625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8109561011904761,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8109561011904761,
        "precision": 0.794140625,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9884440104166666,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9884440104166666,
        "precision": 0.9871419270833333,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004662459935897436,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.004662459935897436,
        "precision": 0.0037272135416666664,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.712890625,
        "f1": 0.6565173921130952,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6565173921130952,
        "precision": 0.6343300471230159,
        "recall": 0.712890625
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.8005766369047619,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8005766369047619,
        "precision": 0.7845811631944445,
        "recall": 0.83984375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007808751755910697,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.007808751755910697,
        "precision": 0.006147961738782051,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9073567708333334,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.9073567708333334,
        "precision": 0.89794921875,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.95791015625,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.95791015625,
        "precision": 0.9532063802083333,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.9365234375,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9365234375,
        "precision": 0.9295247395833333,
        "recall": 0.951171875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.8525390625,
        "f1": 0.8221702938988096,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8221702938988096,
        "precision": 0.8095307849702381,
        "recall": 0.8525390625
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.8939336867559524,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8939336867559524,
        "precision": 0.8844982328869047,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.615234375,
        "f1": 0.5716843377976191,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5716843377976191,
        "precision": 0.5550347222222223,
        "recall": 0.615234375
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8716006324404761,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8716006324404761,
        "precision": 0.8609537760416667,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9122907366071429,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9122907366071429,
        "precision": 0.9047925544507576,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.8056640625,
        "f1": 0.7638392857142857,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7638392857142857,
        "precision": 0.7457868303571429,
        "recall": 0.8056640625
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9149600074404762,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9149600074404762,
        "precision": 0.9077473958333333,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8309787326388889,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8309787326388889,
        "precision": 0.8169677734375,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.7392578125,
        "f1": 0.6982414829094516,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6982414829094516,
        "precision": 0.6824098021119505,
        "recall": 0.7392578125
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9095400855654762,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9095400855654762,
        "precision": 0.9015066964285714,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.6904296875,
        "f1": 0.6371899801587302,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6371899801587302,
        "precision": 0.6158063616071427,
        "recall": 0.6904296875
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9351236979166666,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9351236979166666,
        "precision": 0.928466796875,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005220540364583333,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005220540364583333,
        "precision": 0.004353953653033794,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9102539062499999,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9102539062499999,
        "precision": 0.9015299479166667,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.5693359375,
        "f1": 0.501762462797619,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.501762462797619,
        "precision": 0.47480003720238095,
        "recall": 0.5693359375
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6467122395833333,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6467122395833333,
        "precision": 0.626380363343254,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.9033203125,
        "f1": 0.87822265625,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.87822265625,
        "precision": 0.8670572916666667,
        "recall": 0.9033203125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.009474875710227273,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009474875710227273,
        "precision": 0.007287353337796208,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8233398437499999,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8233398437499999,
        "precision": 0.8104492187500001,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.7734375,
        "f1": 0.7306764632936507,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7306764632936507,
        "precision": 0.7136800130208334,
        "recall": 0.7734375
      },
      {
        "accuracy": 0.81640625,
        "f1": 0.7796712239583333,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7796712239583333,
        "precision": 0.7638439360119047,
        "recall": 0.81640625
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8686360677083333,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8686360677083333,
        "precision": 0.858310081845238,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8664574032738096,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8664574032738096,
        "precision": 0.8546875,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9101236979166667,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.9101236979166667,
        "precision": 0.9012044270833334,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.498046875,
        "f1": 0.4561059816919192,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.4561059816919192,
        "precision": 0.44224053127861723,
        "recall": 0.498046875
      },
      {
        "accuracy": 0.84375,
        "f1": 0.8095145089285714,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.8095145089285714,
        "precision": 0.7951923076923078,
        "recall": 0.84375
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.8986328125,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.8986328125,
        "precision": 0.8899251302083333,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.810546875,
        "f1": 0.7695498511904761,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.7695498511904761,
        "precision": 0.7525716145833333,
        "recall": 0.810546875
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9086588541666666,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9086588541666666,
        "precision": 0.8995768229166666,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.8996744791666667,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.8996744791666667,
        "precision": 0.890625,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.640625,
        "f1": 0.5957992311507937,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.5957992311507937,
        "precision": 0.5775409405048078,
        "recall": 0.640625
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8559105282738095,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.8559105282738095,
        "precision": 0.8445149739583333,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.7890625,
        "f1": 0.7429873511904762,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.7429873511904762,
        "precision": 0.72314453125,
        "recall": 0.7890625
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8914085751488094,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.8914085751488094,
        "precision": 0.8827892485119047,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007957598850754762,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.007957598850754762,
        "precision": 0.006789476418382669,
        "recall": 0.015625
      },
      {
        "accuracy": 0.9375,
        "f1": 0.919140625,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.919140625,
        "precision": 0.9107259114583334,
        "recall": 0.9375
      },
      {
        "accuracy": 0.7783203125,
        "f1": 0.7341145833333333,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.7341145833333333,
        "precision": 0.71494140625,
        "recall": 0.7783203125
      },
      {
        "accuracy": 0.873046875,
        "f1": 0.8386067708333333,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.8386067708333333,
        "precision": 0.8234375,
        "recall": 0.873046875
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8823567708333333,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.8823567708333333,
        "precision": 0.8707194010416667,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.008273991126702525,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.008273991126702525,
        "precision": 0.006956152291204264,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7436407180059523,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.7436407180059523,
        "precision": 0.7291271391369047,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7931857638888888,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.7931857638888888,
        "precision": 0.7774495442708333,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.8480794270833334,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.8480794270833334,
        "precision": 0.83447265625,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.921875,
        "f1": 0.8993350074404761,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.8993350074404761,
        "precision": 0.8893229166666666,
        "recall": 0.921875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9733072916666667,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9733072916666667,
        "precision": 0.9703776041666667,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.615234375,
        "f1": 0.5575520833333334,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5575520833333334,
        "precision": 0.535218253968254,
        "recall": 0.615234375
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9817708333333333,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9817708333333333,
        "precision": 0.9794921875,
        "recall": 0.986328125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9239908854166667,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9239908854166667,
        "precision": 0.91552734375,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.92265625,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.92265625,
        "precision": 0.9143880208333333,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9659830729166666,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9659830729166666,
        "precision": 0.96240234375,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.7943359375,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7943359375,
        "precision": 0.7774600074404763,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7808291480654762,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7808291480654762,
        "precision": 0.7639904203869048,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006012834821428572,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006012834821428572,
        "precision": 0.004915364583333333,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6593982514880952,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6593982514880952,
        "precision": 0.63203125,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8218098958333333,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8218098958333333,
        "precision": 0.8052571614583333,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9949544270833333,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.9949544270833333,
        "precision": 0.9944661458333334,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00574136066408222,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00574136066408222,
        "precision": 0.004324988588062739,
        "recall": 0.015625
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9138671875,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9138671875,
        "precision": 0.90576171875,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.94873046875,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.94873046875,
        "precision": 0.9427083333333333,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.9191080729166666,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9191080729166666,
        "precision": 0.9109700520833334,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.91591796875,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.91591796875,
        "precision": 0.907470703125,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.9535807291666667,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9535807291666667,
        "precision": 0.9490559895833334,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.533203125,
        "f1": 0.48381645752251223,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.48381645752251223,
        "precision": 0.46560872395833336,
        "recall": 0.533203125
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8810081845238095,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.8810081845238095,
        "precision": 0.8702311197916667,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9742838541666666,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9742838541666666,
        "precision": 0.9713541666666667,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.857719494047619,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.857719494047619,
        "precision": 0.8453287760416667,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8952985491071428,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8952985491071428,
        "precision": 0.8861490885416666,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9694010416666667,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.9694010416666667,
        "precision": 0.9659830729166666,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.661548119848901,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.661548119848901,
        "precision": 0.6411295572916667,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9210611979166666,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9210611979166666,
        "precision": 0.9134765625,
        "recall": 0.9375
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7923177083333333,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.7923177083333333,
        "precision": 0.7761881510416666,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9521158854166667,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.9521158854166667,
        "precision": 0.9472981770833333,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006169314663724685,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.006169314663724685,
        "precision": 0.0049857012185052264,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9642578125,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9642578125,
        "precision": 0.960205078125,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.7158203125,
        "f1": 0.6583542596726191,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.6583542596726191,
        "precision": 0.6348725818452381,
        "recall": 0.7158203125
      },
      {
        "accuracy": 0.8046875,
        "f1": 0.7590246775793651,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7590246775793651,
        "precision": 0.7393798828125,
        "recall": 0.8046875
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9772135416666666,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9772135416666666,
        "precision": 0.9748046875,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.007926903825341326,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.007926903825341326,
        "precision": 0.006169580060426824,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.828125,
        "f1": 0.7949893043154761,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.7949893043154761,
        "precision": 0.7806896391369048,
        "recall": 0.828125
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9138997395833333,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9138997395833333,
        "precision": 0.9044596354166666,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9446614583333333,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.9446614583333333,
        "precision": 0.9388346354166667,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9450520833333332,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.9450520833333332,
        "precision": 0.9388834635416667,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.7255859375,
        "f1": 0.6782063802083333,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6782063802083333,
        "precision": 0.6594702714819902,
        "recall": 0.7255859375
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7417163403003246,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7417163403003246,
        "precision": 0.7215750558035714,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.5380859375,
        "f1": 0.4936384559833549,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.4936384559833549,
        "precision": 0.4764219626402244,
        "recall": 0.5380859375
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7793185763888888,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7793185763888888,
        "precision": 0.7644938151041667,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.7908893623737374,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7908893623737374,
        "precision": 0.7765838138640873,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6978918650793651,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6978918650793651,
        "precision": 0.6805931454613094,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.6396484375,
        "f1": 0.5772530691964286,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5772530691964286,
        "precision": 0.553089770472583,
        "recall": 0.6396484375
      },
      {
        "accuracy": 0.8125,
        "f1": 0.7721400669642857,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.7721400669642857,
        "precision": 0.7559268043154762,
        "recall": 0.8125
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6624496217757936,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.6624496217757936,
        "precision": 0.6441980139001623,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.8078690786210317,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8078690786210317,
        "precision": 0.7943208240327381,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.5576171875,
        "f1": 0.49283411435502666,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.49283411435502666,
        "precision": 0.4688711191152597,
        "recall": 0.5576171875
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7119436967495332,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7119436967495332,
        "precision": 0.6954467773437499,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006842719184027778,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.006842719184027778,
        "precision": 0.005662237383192525,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.8076171875,
        "f1": 0.7674851190476191,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7674851190476191,
        "precision": 0.7513020833333333,
        "recall": 0.8076171875
      },
      {
        "accuracy": 0.451171875,
        "f1": 0.3856387929019765,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.3856387929019765,
        "precision": 0.36277571310018386,
        "recall": 0.451171875
      },
      {
        "accuracy": 0.6025390625,
        "f1": 0.5388245597718254,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5388245597718254,
        "precision": 0.5151317161571067,
        "recall": 0.6025390625
      },
      {
        "accuracy": 0.76171875,
        "f1": 0.7156277479031385,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7156277479031385,
        "precision": 0.6976795014880952,
        "recall": 0.76171875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009413780231295417,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.009413780231295417,
        "precision": 0.00819165101391664,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.775390625,
        "f1": 0.7394238554796919,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7394238554796919,
        "precision": 0.7247843424479167,
        "recall": 0.775390625
      },
      {
        "accuracy": 0.6298828125,
        "f1": 0.5727911790900072,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.5727911790900072,
        "precision": 0.5512462797619048,
        "recall": 0.6298828125
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.6134029327876984,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.6134029327876984,
        "precision": 0.5919065445188492,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8904017857142857,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.8904017857142857,
        "precision": 0.8804524739583334,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9493815104166667,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9493815104166667,
        "precision": 0.94384765625,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9860026041666666,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9860026041666666,
        "precision": 0.984375,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.5622512722035929,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5622512722035929,
        "precision": 0.543619597904266,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9768880208333333,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9768880208333333,
        "precision": 0.97412109375,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.9073893229166667,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9073893229166667,
        "precision": 0.8984375,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.8595052083333333,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8595052083333333,
        "precision": 0.8458984375,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9136393229166666,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9136393229166666,
        "precision": 0.9053548177083334,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.805224609375,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.805224609375,
        "precision": 0.7892020089285715,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.7392578125,
        "f1": 0.687159894142316,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.687159894142316,
        "precision": 0.6664426773313492,
        "recall": 0.7392578125
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9761393229166666,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9761393229166666,
        "precision": 0.9737141927083333,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006346209490740741,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006346209490740741,
        "precision": 0.004916353314836449,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.6650390625,
        "f1": 0.6015997023809524,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6015997023809524,
        "precision": 0.5753526475694444,
        "recall": 0.6650390625
      },
      {
        "accuracy": 0.8076171875,
        "f1": 0.76162109375,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.76162109375,
        "precision": 0.741650390625,
        "recall": 0.8076171875
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.97412109375,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.97412109375,
        "precision": 0.9710286458333334,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009120304154011312,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009120304154011312,
        "precision": 0.007864993007647297,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9049479166666666,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9049479166666666,
        "precision": 0.89599609375,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8813802083333333,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8813802083333333,
        "precision": 0.8701985677083333,
        "recall": 0.90625
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8689019097222223,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8689019097222223,
        "precision": 0.8569742838541666,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666667,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9791666666666667,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.724609375,
        "f1": 0.6690700954861111,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.6690700954861111,
        "precision": 0.6468354724702381,
        "recall": 0.724609375
      },
      {
        "accuracy": 0.759765625,
        "f1": 0.7119380890376985,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.7119380890376985,
        "precision": 0.6940395514858406,
        "recall": 0.759765625
      },
      {
        "accuracy": 0.4697265625,
        "f1": 0.4311354750233426,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.4311354750233426,
        "precision": 0.41816425626240084,
        "recall": 0.4697265625
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6505271041892136,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.6505271041892136,
        "precision": 0.633151476658621,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.794921875,
        "f1": 0.7536838812229437,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.7536838812229437,
        "precision": 0.7388226573773449,
        "recall": 0.794921875
      },
      {
        "accuracy": 0.6591796875,
        "f1": 0.6097191220238095,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.6097191220238095,
        "precision": 0.5912787543402778,
        "recall": 0.6591796875
      },
      {
        "accuracy": 0.7734375,
        "f1": 0.7320460464015152,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.7320460464015152,
        "precision": 0.7143880208333333,
        "recall": 0.7734375
      },
      {
        "accuracy": 0.7744140625,
        "f1": 0.7293898809523809,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.7293898809523809,
        "precision": 0.7126488095238095,
        "recall": 0.7744140625
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.756640625,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.756640625,
        "precision": 0.7393880208333333,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.53125,
        "f1": 0.4830501546835839,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.4830501546835839,
        "precision": 0.4670851338331807,
        "recall": 0.53125
      },
      {
        "accuracy": 0.705078125,
        "f1": 0.6540831726866883,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.6540831726866883,
        "precision": 0.6358100395698052,
        "recall": 0.705078125
      },
      {
        "accuracy": 0.705078125,
        "f1": 0.6536676051812771,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.6536676051812771,
        "precision": 0.6343781001984128,
        "recall": 0.705078125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007338750930059524,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.007338750930059524,
        "precision": 0.005759094449681914,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.7015531994047619,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.7015531994047619,
        "precision": 0.6820607018849206,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.671875,
        "f1": 0.6159870186237374,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.6159870186237374,
        "precision": 0.5925048828124999,
        "recall": 0.671875
      },
      {
        "accuracy": 0.685546875,
        "f1": 0.6303803943452382,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.6303803943452382,
        "precision": 0.6088216145833334,
        "recall": 0.685546875
      },
      {
        "accuracy": 0.7802734375,
        "f1": 0.73578857123779,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.73578857123779,
        "precision": 0.7188655176204004,
        "recall": 0.7802734375
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.01001278342214518,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.01001278342214518,
        "precision": 0.008207889396433308,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.6337890625,
        "f1": 0.5849416317189755,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.5849416317189755,
        "precision": 0.5674250527033731,
        "recall": 0.6337890625
      },
      {
        "accuracy": 0.73046875,
        "f1": 0.6831844045711233,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.6831844045711233,
        "precision": 0.6640590122767858,
        "recall": 0.73046875
      },
      {
        "accuracy": 0.8046875,
        "f1": 0.7646483182615995,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.7646483182615995,
        "precision": 0.7476318359374999,
        "recall": 0.8046875
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7107987661210318,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.7107987661210318,
        "precision": 0.6934444876840539,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9444986979166666,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9444986979166666,
        "precision": 0.9378255208333334,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5300509982638889,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5300509982638889,
        "precision": 0.5117710658482142,
        "recall": 0.578125
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9484049479166666,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9484049479166666,
        "precision": 0.94287109375,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.98974609375,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.98974609375,
        "precision": 0.9886067708333334,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.94775390625,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.94775390625,
        "precision": 0.9423828125,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9017578125,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9017578125,
        "precision": 0.8915201822916666,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9521484375,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9521484375,
        "precision": 0.9471028645833334,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.783203125,
        "f1": 0.7373635912698413,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7373635912698413,
        "precision": 0.7177978515625,
        "recall": 0.783203125
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9650065104166666,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9650065104166666,
        "precision": 0.96162109375,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.775390625,
        "f1": 0.7269066220238095,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7269066220238095,
        "precision": 0.7062174479166666,
        "recall": 0.775390625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006829985948532144,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006829985948532144,
        "precision": 0.005449418631213451,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.6689453125,
        "f1": 0.6066297743055555,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6066297743055555,
        "precision": 0.5804606119791667,
        "recall": 0.6689453125
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.7543968563988095,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7543968563988095,
        "precision": 0.7351492745535714,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006252953714975281,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006252953714975281,
        "precision": 0.0053917000779263,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8720865885416667,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8720865885416667,
        "precision": 0.8617931547619048,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.8971028645833333,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8971028645833333,
        "precision": 0.8878580729166667,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.91015625,
        "f1": 0.887109375,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.887109375,
        "precision": 0.8765462239583333,
        "recall": 0.91015625
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166666,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9767252604166666,
        "precision": 0.9739583333333334,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006294135737303852,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.006294135737303852,
        "precision": 0.005296379921680804,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003434904548799778,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.003434904548799778,
        "precision": 0.0032212043415314265,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004949686412031128,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.004949686412031128,
        "precision": 0.003932776506003093,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0043047070802005,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0043047070802005,
        "precision": 0.003618093739154954,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011291243361101647,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0011291243361101647,
        "precision": 0.001055541913656833,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.00562541216777343,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.00562541216777343,
        "precision": 0.0044913485726822775,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006954305398999511,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.006954305398999511,
        "precision": 0.006302922408773292,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003977735023100495,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.003977735023100495,
        "precision": 0.0036407606206719763,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0033526063141156807,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0033526063141156807,
        "precision": 0.0028143794776508886,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031623406234017387,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0031623406234017387,
        "precision": 0.0027536264439568204,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005917557586702026,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.005917557586702026,
        "precision": 0.0052256201126581366,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0040425144987502465,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0040425144987502465,
        "precision": 0.0036083871697700325,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004019289060213897,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.004019289060213897,
        "precision": 0.003671969897344949,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004642953357022709,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.004642953357022709,
        "precision": 0.004438401718773193,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005085896443318319,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.005085896443318319,
        "precision": 0.0041337824192176865,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004282353594954535,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.004282353594954535,
        "precision": 0.0034910169177456785,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0022236592060810812,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0022236592060810812,
        "precision": 0.0021060114970645792,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.017575434361239983,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.017575434361239983,
        "precision": 0.015543943940893354,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0036802215399944316,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0036802215399944316,
        "precision": 0.003032078148941563,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0019644199612721056,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0019644199612721056,
        "precision": 0.0015610159077775777,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002751239466854177,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.002751239466854177,
        "precision": 0.0024489117441207024,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003423641434312833,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.003423641434312833,
        "precision": 0.002885718194702173,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9835611979166667,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9835611979166667,
        "precision": 0.9817708333333334,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.60546875,
        "f1": 0.5558872767857143,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5558872767857143,
        "precision": 0.5372884114583334,
        "recall": 0.60546875
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9744466145833334,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9744466145833334,
        "precision": 0.9715169270833333,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9127278645833334,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9127278645833334,
        "precision": 0.9041341145833334,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9263346354166667,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9263346354166667,
        "precision": 0.918212890625,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333333,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9778645833333333,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.7932400173611112,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7932400173611112,
        "precision": 0.7767252604166666,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.98974609375,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.98974609375,
        "precision": 0.9886067708333333,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7785536024305555,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7785536024305555,
        "precision": 0.7612804594494047,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006924078525641026,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006924078525641026,
        "precision": 0.0052327051204004325,
        "recall": 0.015625
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6767950148809524,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6767950148809524,
        "precision": 0.653857421875,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8289899553571428,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8289899553571428,
        "precision": 0.8138671875000001,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007641711415172733,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007641711415172733,
        "precision": 0.006212480460591583,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.9071800595238095,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9071800595238095,
        "precision": 0.89794921875,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9356119791666666,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9356119791666666,
        "precision": 0.9286295572916666,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9146158854166666,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9146158854166666,
        "precision": 0.905517578125,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.6298828125,
        "f1": 0.5766951039411976,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.5766951039411976,
        "precision": 0.5595772879464286,
        "recall": 0.6298828125
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.5903003246753247,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.5903003246753247,
        "precision": 0.5732024575787426,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.353515625,
        "f1": 0.31094093894386865,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.31094093894386865,
        "precision": 0.2973966272520022,
        "recall": 0.353515625
      },
      {
        "accuracy": 0.5146484375,
        "f1": 0.4630188467058475,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.4630188467058475,
        "precision": 0.44601313685106775,
        "recall": 0.5146484375
      },
      {
        "accuracy": 0.611328125,
        "f1": 0.5544169162012282,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.5544169162012282,
        "precision": 0.5349410887697882,
        "recall": 0.611328125
      },
      {
        "accuracy": 0.4775390625,
        "f1": 0.42161314705260017,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.42161314705260017,
        "precision": 0.403900084832702,
        "recall": 0.4775390625
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6779415660677149,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.6779415660677149,
        "precision": 0.6615981064833605,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.611328125,
        "f1": 0.5540320763221154,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.5540320763221154,
        "precision": 0.5357716854543026,
        "recall": 0.611328125
      },
      {
        "accuracy": 0.63671875,
        "f1": 0.5863192336092726,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.5863192336092726,
        "precision": 0.5696390839170021,
        "recall": 0.63671875
      },
      {
        "accuracy": 0.345703125,
        "f1": 0.2987643013777924,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.2987643013777924,
        "precision": 0.2849236978118814,
        "recall": 0.345703125
      },
      {
        "accuracy": 0.58203125,
        "f1": 0.5257751831884414,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.5257751831884414,
        "precision": 0.5069804756218972,
        "recall": 0.58203125
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5439770895337301,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.5439770895337301,
        "precision": 0.5231290302579366,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.5625,
        "f1": 0.5065885213259983,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.5065885213259983,
        "precision": 0.4883415101066468,
        "recall": 0.5625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007112295873210395,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.007112295873210395,
        "precision": 0.00568983831923285,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.6279296875,
        "f1": 0.5679973625932381,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.5679973625932381,
        "precision": 0.5473249415679995,
        "recall": 0.6279296875
      },
      {
        "accuracy": 0.6630859375,
        "f1": 0.6078168133195307,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.6078168133195307,
        "precision": 0.588367467493444,
        "recall": 0.6630859375
      },
      {
        "accuracy": 0.59375,
        "f1": 0.5372390061110764,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.5372390061110764,
        "precision": 0.5182714068700397,
        "recall": 0.59375
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.011677640045358054,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.011677640045358054,
        "precision": 0.010068863157242064,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.4482421875,
        "f1": 0.4033005396626321,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.4033005396626321,
        "precision": 0.38875796706491605,
        "recall": 0.4482421875
      },
      {
        "accuracy": 0.4873046875,
        "f1": 0.424451652405754,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.424451652405754,
        "precision": 0.40378940264322666,
        "recall": 0.4873046875
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5534193996108058,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.5534193996108058,
        "precision": 0.5348453954899267,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.5014964657738095,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.5014964657738095,
        "precision": 0.47919682128795,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.7353515625,
        "f1": 0.6872550843253968,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.6872550843253968,
        "precision": 0.669718036954365,
        "recall": 0.7353515625
      },
      {
        "accuracy": 0.791015625,
        "f1": 0.7468036954365079,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.7468036954365079,
        "precision": 0.7301699683779762,
        "recall": 0.791015625
      },
      {
        "accuracy": 0.4658203125,
        "f1": 0.4322226276327839,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.4322226276327839,
        "precision": 0.419632316468254,
        "recall": 0.4658203125
      },
      {
        "accuracy": 0.80078125,
        "f1": 0.76562255561279,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.76562255561279,
        "precision": 0.7515256851438492,
        "recall": 0.80078125
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.795463634672619,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.795463634672619,
        "precision": 0.7801932198660714,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.67578125,
        "f1": 0.628014167906746,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.628014167906746,
        "precision": 0.6104060959542559,
        "recall": 0.67578125
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8258029513888889,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.8258029513888889,
        "precision": 0.8120361328125,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.7868233816964285,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.7868233816964285,
        "precision": 0.7709263392857143,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.7626953125,
        "f1": 0.7190941220238095,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.7190941220238095,
        "precision": 0.7012881324404762,
        "recall": 0.7626953125
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.5339839874751984,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.5339839874751984,
        "precision": 0.5170172785821139,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.77734375,
        "f1": 0.7345689033189033,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.7345689033189033,
        "precision": 0.7182779947916667,
        "recall": 0.77734375
      },
      {
        "accuracy": 0.6845703125,
        "f1": 0.6355500456574674,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.6355500456574674,
        "precision": 0.616313666801948,
        "recall": 0.6845703125
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7105227292239011,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.7105227292239011,
        "precision": 0.6927199590773809,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009791976686507935,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.009791976686507935,
        "precision": 0.007761475901124339,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.7540783110119047,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.7540783110119047,
        "precision": 0.7360351562499999,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.70703125,
        "f1": 0.6543215573489011,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.6543215573489011,
        "precision": 0.6328450520833333,
        "recall": 0.70703125
      },
      {
        "accuracy": 0.77734375,
        "f1": 0.7303509424603174,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7303509424603174,
        "precision": 0.7128034319196428,
        "recall": 0.77734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009554255965388777,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.009554255965388777,
        "precision": 0.007873560429606625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.6806640625,
        "f1": 0.6364583333333333,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.6364583333333333,
        "precision": 0.6202280195932539,
        "recall": 0.6806640625
      },
      {
        "accuracy": 0.689453125,
        "f1": 0.6331969246031746,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.6331969246031746,
        "precision": 0.6110456194196427,
        "recall": 0.689453125
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6961495535714286,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.6961495535714286,
        "precision": 0.6786690848214286,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7953822544642857,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.7953822544642857,
        "precision": 0.7792317708333334,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9551432291666666,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9551432291666666,
        "precision": 0.9506022135416667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.5849609375,
        "f1": 0.5320311307615995,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5320311307615995,
        "precision": 0.5113145616319444,
        "recall": 0.5849609375
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9466145833333333,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9466145833333333,
        "precision": 0.9407552083333333,
        "recall": 0.958984375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.892875744047619,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.892875744047619,
        "precision": 0.8828938802083334,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8667317708333333,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8667317708333333,
        "precision": 0.8535970052083333,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.962890625,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.962890625,
        "precision": 0.9586588541666667,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.78515625,
        "f1": 0.741725570436508,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.741725570436508,
        "precision": 0.7243733723958334,
        "recall": 0.78515625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7657110305059525,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7657110305059525,
        "precision": 0.7487723214285714,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9794921875,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9794921875,
        "precision": 0.97705078125,
        "recall": 0.984375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004961607403013653,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004961607403013653,
        "precision": 0.003581952929197995,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6508998325892856,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6508998325892856,
        "precision": 0.626376488095238,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.8046875,
        "f1": 0.7600120907738095,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7600120907738095,
        "precision": 0.7414984809027778,
        "recall": 0.8046875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0047040764951159384,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0047040764951159384,
        "precision": 0.003742587542987843,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.8535807291666666,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8535807291666666,
        "precision": 0.8410101996527778,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.92080078125,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.92080078125,
        "precision": 0.9125162760416666,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9079427083333333,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9079427083333333,
        "precision": 0.898681640625,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004948726718509985,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.004948726718509985,
        "precision": 0.0045192487273411595,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.006026853109903382,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.006026853109903382,
        "precision": 0.00565754921720229,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0067389685581386635,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0067389685581386635,
        "precision": 0.005800061666031934,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.006288960420296167,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.006288960420296167,
        "precision": 0.005847542676756304,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0035532294352743354,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0035532294352743354,
        "precision": 0.0032855071290822224,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004918471143505314,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.004918471143505314,
        "precision": 0.004518796967527988,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004948330514825237,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.004948330514825237,
        "precision": 0.0045067650287065174,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0047154518247847915,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0047154518247847915,
        "precision": 0.004384533509370285,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005382639316502463,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.005382639316502463,
        "precision": 0.004606835222069597,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005134690452713245,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.005134690452713245,
        "precision": 0.004674937610641227,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004856939655837806,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.004856939655837806,
        "precision": 0.0042634745351404785,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00588134765625,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.00588134765625,
        "precision": 0.005483975974462365,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00483967335731714,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.00483967335731714,
        "precision": 0.00450362068053492,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.026416071250569606,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.026416071250569606,
        "precision": 0.023732364460864505,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0073952285921625545,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0073952285921625545,
        "precision": 0.007170758928571428,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005413640985871061,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.005413640985871061,
        "precision": 0.004881769186354124,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0031982147102268,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0031982147102268,
        "precision": 0.0027056872149645588,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003259252070393375,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.003259252070393375,
        "precision": 0.0031270260632780085,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005672795278149139,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.005672795278149139,
        "precision": 0.005373598308849944,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003739402304425217,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.003739402304425217,
        "precision": 0.0035008996999370944,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006880089278333722,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.006880089278333722,
        "precision": 0.006122834097407079,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0031307585995086,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0031307585995086,
        "precision": 0.003039189865985079,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7941080729166666,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7941080729166666,
        "precision": 0.7787923177083333,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8720075334821428,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8720075334821428,
        "precision": 0.8622977120535715,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.6416015625,
        "f1": 0.5978004092261905,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5978004092261905,
        "precision": 0.5806764036744505,
        "recall": 0.6416015625
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.8955729166666666,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8955729166666666,
        "precision": 0.8868652343750001,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.9248046875,
        "f1": 0.9061414930555556,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9061414930555556,
        "precision": 0.8985107421875,
        "recall": 0.9248046875
      },
      {
        "accuracy": 0.85546875,
        "f1": 0.8250674293154763,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8250674293154763,
        "precision": 0.812544177827381,
        "recall": 0.85546875
      },
      {
        "accuracy": 0.7802734375,
        "f1": 0.7375434027777779,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7375434027777779,
        "precision": 0.7205264136904762,
        "recall": 0.7802734375
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9097516741071429,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9097516741071429,
        "precision": 0.9022135416666667,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.814453125,
        "f1": 0.7756155303030303,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7756155303030303,
        "precision": 0.7593587239583334,
        "recall": 0.814453125
      },
      {
        "accuracy": 0.7763671875,
        "f1": 0.7379278273809524,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7379278273809524,
        "precision": 0.7220703125,
        "recall": 0.7763671875
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.9054385230654762,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9054385230654762,
        "precision": 0.897763206845238,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.5865869915674604,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5865869915674604,
        "precision": 0.5649739583333333,
        "recall": 0.64453125
      },
      {
        "accuracy": 0.884765625,
        "f1": 0.8590599423363094,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8590599423363094,
        "precision": 0.8482096354166666,
        "recall": 0.884765625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006265345982142857,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006265345982142857,
        "precision": 0.0044228205605158725,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8933919270833334,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8933919270833334,
        "precision": 0.8845703125,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.5478515625,
        "f1": 0.4814600384424603,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.4814600384424603,
        "precision": 0.45659613010687233,
        "recall": 0.5478515625
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6569606012477106,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6569606012477106,
        "precision": 0.6357297867063492,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.8504417782738094,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.8504417782738094,
        "precision": 0.8383951822916667,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009226873185670108,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009226873185670108,
        "precision": 0.008292371961805555,
        "recall": 0.015625
      },
      {
        "accuracy": 0.7568359375,
        "f1": 0.7155265687003969,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7155265687003969,
        "precision": 0.698828547754329,
        "recall": 0.7568359375
      },
      {
        "accuracy": 0.78125,
        "f1": 0.743102904040404,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.743102904040404,
        "precision": 0.7282090928819445,
        "recall": 0.78125
      },
      {
        "accuracy": 0.91015625,
        "f1": 0.8881696428571428,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8881696428571428,
        "precision": 0.8787272135416666,
        "recall": 0.91015625
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8339053199404762,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.8339053199404762,
        "precision": 0.8210797991071428,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9289388020833333,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.9289388020833333,
        "precision": 0.9217936197916667,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.462890625,
        "f1": 0.41949625352945663,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.41949625352945663,
        "precision": 0.4039008598823052,
        "recall": 0.462890625
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8157738095238095,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.8157738095238095,
        "precision": 0.80244140625,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.9525390625,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9525390625,
        "precision": 0.9471842447916667,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.77734375,
        "f1": 0.7369814918154762,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.7369814918154762,
        "precision": 0.7205008370535715,
        "recall": 0.77734375
      },
      {
        "accuracy": 0.822265625,
        "f1": 0.7808756510416666,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7808756510416666,
        "precision": 0.762655784970238,
        "recall": 0.822265625
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9353841145833333,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.9353841145833333,
        "precision": 0.9283854166666667,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9063151041666666,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.9063151041666666,
        "precision": 0.8955891927083333,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.6474609375,
        "f1": 0.5942879548836579,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5942879548836579,
        "precision": 0.5730561755952381,
        "recall": 0.6474609375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8685872395833334,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.8685872395833334,
        "precision": 0.8580314867424242,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6698156932043651,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.6698156932043651,
        "precision": 0.6492222377232143,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8831938244047619,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.8831938244047619,
        "precision": 0.8736165364583334,
        "recall": 0.90625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005512243960084033,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.005512243960084033,
        "precision": 0.003906738354138677,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9334309895833333,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.9334309895833333,
        "precision": 0.9265950520833334,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.556640625,
        "f1": 0.4929594494047619,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.4929594494047619,
        "precision": 0.4690398685515873,
        "recall": 0.556640625
      },
      {
        "accuracy": 0.7138671875,
        "f1": 0.6577008928571428,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.6577008928571428,
        "precision": 0.6347679501488095,
        "recall": 0.7138671875
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.92626953125,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.92626953125,
        "precision": 0.9182942708333334,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0050210618911639615,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0050210618911639615,
        "precision": 0.0038140106352278916,
        "recall": 0.015625
      },
      {
        "accuracy": 0.75,
        "f1": 0.7091238839285714,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.7091238839285714,
        "precision": 0.6930989583333333,
        "recall": 0.75
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8250162760416666,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8250162760416666,
        "precision": 0.8102632068452381,
        "recall": 0.859375
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9249674479166667,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.9249674479166667,
        "precision": 0.9168294270833333,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8374999999999999,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8374999999999999,
        "precision": 0.82392578125,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8888020833333333,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8888020833333333,
        "precision": 0.8779622395833333,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.5556640625,
        "f1": 0.5169902851055195,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.5169902851055195,
        "precision": 0.5021523127480159,
        "recall": 0.5556640625
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.826860119047619,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.826860119047619,
        "precision": 0.813720703125,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.91171875,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.91171875,
        "precision": 0.9043945312499999,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.8173828125,
        "f1": 0.787109375,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.787109375,
        "precision": 0.7744954427083334,
        "recall": 0.8173828125
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.8493489583333333,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8493489583333333,
        "precision": 0.8350423177083333,
        "recall": 0.880859375
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9190755208333333,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9190755208333333,
        "precision": 0.9104817708333333,
        "recall": 0.9375
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.9376627604166666,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.9376627604166666,
        "precision": 0.9313151041666667,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.6611328125,
        "f1": 0.6146206061733406,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6146206061733406,
        "precision": 0.5969571868210426,
        "recall": 0.6611328125
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8487521701388888,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8487521701388888,
        "precision": 0.8352457682291667,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.8115234375,
        "f1": 0.7717633928571428,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.7717633928571428,
        "precision": 0.7547037760416667,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8612630208333333,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8612630208333333,
        "precision": 0.84921875,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005818297371031746,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.005818297371031746,
        "precision": 0.004759227317821068,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9084309895833333,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9084309895833333,
        "precision": 0.899169921875,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.671875,
        "f1": 0.6129061259920634,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.6129061259920634,
        "precision": 0.589404296875,
        "recall": 0.671875
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.6998124379960318,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.6998124379960318,
        "precision": 0.6786322699652778,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.9177083333333333,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.9177083333333333,
        "precision": 0.9094889322916666,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.0056782960261246105,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0056782960261246105,
        "precision": 0.004499929366936974,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.7890625,
        "f1": 0.7513695126488096,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.7513695126488096,
        "precision": 0.7360681310876623,
        "recall": 0.7890625
      },
      {
        "accuracy": 0.857421875,
        "f1": 0.8240745907738095,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.8240745907738095,
        "precision": 0.8094889322916667,
        "recall": 0.857421875
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8841471354166667,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.8841471354166667,
        "precision": 0.8731608072916667,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9724934895833333,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9724934895833333,
        "precision": 0.9695638020833334,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.578125,
        "f1": 0.526163349454365,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.526163349454365,
        "precision": 0.5070316375248016,
        "recall": 0.578125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9749348958333333,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9749348958333333,
        "precision": 0.9723307291666666,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8957356770833333,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.8957356770833333,
        "precision": 0.8853352864583333,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.9306640625,
        "f1": 0.9097981770833333,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9097981770833333,
        "precision": 0.89990234375,
        "recall": 0.9306640625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9611002604166667,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.9611002604166667,
        "precision": 0.9570638020833333,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.89453125,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.89453125,
        "precision": 0.8834635416666667,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.8095703125,
        "f1": 0.7661783854166666,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.7661783854166666,
        "precision": 0.7470865885416667,
        "recall": 0.8095703125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.97802734375,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.97802734375,
        "precision": 0.9754231770833333,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005657897133665142,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.005657897133665142,
        "precision": 0.0046361031098032714,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.6669921875,
        "f1": 0.5970757378472222,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.5970757378472222,
        "precision": 0.5667817615327381,
        "recall": 0.6669921875
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.8438802083333333,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8438802083333333,
        "precision": 0.8288411458333333,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006714482206618308,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.006714482206618308,
        "precision": 0.005315332073144574,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9169921875,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.9169921875,
        "precision": 0.9085286458333333,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9352213541666666,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.9352213541666666,
        "precision": 0.9278971354166666,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9028971354166667,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9028971354166667,
        "precision": 0.8926595052083333,
        "recall": 0.923828125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}