{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 23.379340887069702,
  "kg_co2_emissions": 0.009336464274097558,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8316288848637148,
        "cosine_spearman": 0.8207127771962973,
        "euclidean_pearson": 0.8074400871938258,
        "euclidean_spearman": 0.8207127771962973,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.8207127771962973,
        "manhattan_pearson": 0.8033341360696495,
        "manhattan_spearman": 0.8201548829457295,
        "pearson": 0.8316288848637148,
        "spearman": 0.8207127771962973
      },
      {
        "cosine_pearson": 0.7602469194714804,
        "cosine_spearman": 0.7393736490729479,
        "euclidean_pearson": 0.7504581128370947,
        "euclidean_spearman": 0.7393251908533987,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7393736490729479,
        "manhattan_pearson": 0.7505696252172399,
        "manhattan_spearman": 0.741059718234171,
        "pearson": 0.7602469194714804,
        "spearman": 0.7393736490729479
      },
      {
        "cosine_pearson": 0.6088779749115342,
        "cosine_spearman": 0.6036585092481668,
        "euclidean_pearson": 0.6004519201896782,
        "euclidean_spearman": 0.6036585092481668,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.6036585092481668,
        "manhattan_pearson": 0.5873829336278172,
        "manhattan_spearman": 0.5878463713142922,
        "pearson": 0.6088779749115342,
        "spearman": 0.6036585092481668
      },
      {
        "cosine_pearson": 0.5105640971295108,
        "cosine_spearman": 0.44023886777214094,
        "euclidean_pearson": 0.5147847241815009,
        "euclidean_spearman": 0.44023886777214094,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.44023886777214094,
        "manhattan_pearson": 0.5143609256869025,
        "manhattan_spearman": 0.4372321350858606,
        "pearson": 0.5105640971295108,
        "spearman": 0.44023886777214094
      },
      {
        "cosine_pearson": 0.4609293519056133,
        "cosine_spearman": 0.44120018018054574,
        "euclidean_pearson": 0.44901617111547887,
        "euclidean_spearman": 0.44120018018054574,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.44120018018054574,
        "manhattan_pearson": 0.44991042073166376,
        "manhattan_spearman": 0.44319223354110365,
        "pearson": 0.4609293519056133,
        "spearman": 0.44120018018054574
      },
      {
        "cosine_pearson": 0.8382169756370181,
        "cosine_spearman": 0.8236320261850499,
        "euclidean_pearson": 0.8318909792166626,
        "euclidean_spearman": 0.8236321928062059,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8236320261850499,
        "manhattan_pearson": 0.827170887064081,
        "manhattan_spearman": 0.8160203797158253,
        "pearson": 0.8382169756370181,
        "spearman": 0.8236320261850499
      },
      {
        "cosine_pearson": 0.5594615775865004,
        "cosine_spearman": 0.535398294888641,
        "euclidean_pearson": 0.5497713833462058,
        "euclidean_spearman": 0.535398294888641,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.535398294888641,
        "manhattan_pearson": 0.5525529863013251,
        "manhattan_spearman": 0.5405671193994988,
        "pearson": 0.5594615775865004,
        "spearman": 0.535398294888641
      },
      {
        "cosine_pearson": 0.7639720546635224,
        "cosine_spearman": 0.7741418646736029,
        "euclidean_pearson": 0.7386015574854793,
        "euclidean_spearman": 0.7741418646736029,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7741418646736029,
        "manhattan_pearson": 0.7327739651973915,
        "manhattan_spearman": 0.7669239908834878,
        "pearson": 0.7639720546635224,
        "spearman": 0.7741418646736029
      },
      {
        "cosine_pearson": 0.5544874138688813,
        "cosine_spearman": 0.5531173668671336,
        "euclidean_pearson": 0.5608704705584884,
        "euclidean_spearman": 0.5531173668671336,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5531173668671336,
        "manhattan_pearson": 0.5591082908041798,
        "manhattan_spearman": 0.5499311731959354,
        "pearson": 0.5544874138688813,
        "spearman": 0.5531173668671336
      },
      {
        "cosine_pearson": 0.5663727392176783,
        "cosine_spearman": 0.5575413475858422,
        "euclidean_pearson": 0.5691329625278138,
        "euclidean_spearman": 0.5575413475858422,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5575413475858422,
        "manhattan_pearson": 0.5715460233089485,
        "manhattan_spearman": 0.5603610795197628,
        "pearson": 0.5663727392176783,
        "spearman": 0.5575413475858422
      },
      {
        "cosine_pearson": 0.8066696518845167,
        "cosine_spearman": 0.773320896681836,
        "euclidean_pearson": 0.7942608836384825,
        "euclidean_spearman": 0.773320896681836,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.773320896681836,
        "manhattan_pearson": 0.7953695079901638,
        "manhattan_spearman": 0.776959621034474,
        "pearson": 0.8066696518845167,
        "spearman": 0.773320896681836
      },
      {
        "cosine_pearson": 0.8176099199510173,
        "cosine_spearman": 0.8050993094819546,
        "euclidean_pearson": 0.7926192622737378,
        "euclidean_spearman": 0.8050993094819546,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.8050993094819546,
        "manhattan_pearson": 0.7920966475010264,
        "manhattan_spearman": 0.8055893128204226,
        "pearson": 0.8176099199510173,
        "spearman": 0.8050993094819546
      }
    ]
  },
  "task_name": "SemRel24STS"
}