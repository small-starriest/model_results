{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8058055671454968,
      "accuracy_threshold": 0.8443454504013062,
      "ap": 0.5324970865163429,
      "f1": 0.5173392570652844,
      "f1_threshold": 0.7920330762863159,
      "precision": 0.4859726408532344,
      "recall": 0.5530343007915567
    },
    "dot": {
      "accuracy": 0.7794003695535555,
      "accuracy_threshold": 122.6197280883789,
      "ap": 0.4229762758821821,
      "f1": 0.48235409130902335,
      "f1_threshold": 106.84265899658203,
      "precision": 0.3831340270228296,
      "recall": 0.6509234828496042
    },
    "euclidean": {
      "accuracy": 0.8066996483280682,
      "accuracy_threshold": 6.519073486328125,
      "ap": 0.5335087250337931,
      "f1": 0.5196501457725947,
      "f1_threshold": 7.786074638366699,
      "precision": 0.4656217345872518,
      "recall": 0.5878627968337731
    },
    "evaluation_time": 9.19,
    "manhattan": {
      "accuracy": 0.807653334922811,
      "accuracy_threshold": 142.654541015625,
      "ap": 0.5383192511193553,
      "f1": 0.5255102040816326,
      "f1_threshold": 169.3843536376953,
      "precision": 0.46876292925113777,
      "recall": 0.5978891820580475
    },
    "max": {
      "accuracy": 0.807653334922811,
      "ap": 0.5383192511193553,
      "f1": 0.5255102040816326
    }
  }
}