{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 30.10549783706665,
  "kg_co2_emissions": 0.006510804173075455,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8779,
        "ap": 0.7213995123151237,
        "ap_weighted": 0.7213995123151237,
        "f1": 0.8593266123560606,
        "f1_weighted": 0.8772069752920508,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8779,
        "scores_per_experiment": [
          {
            "accuracy": 0.877,
            "ap": 0.71917429406037,
            "ap_weighted": 0.71917429406037,
            "f1": 0.858802299111832,
            "f1_weighted": 0.8765437902284302
          },
          {
            "accuracy": 0.879,
            "ap": 0.7238461538461538,
            "ap_weighted": 0.7238461538461538,
            "f1": 0.8599276022499562,
            "f1_weighted": 0.8780179524193744
          },
          {
            "accuracy": 0.877,
            "ap": 0.7189388437649308,
            "ap_weighted": 0.7189388437649308,
            "f1": 0.8594913587185612,
            "f1_weighted": 0.8768512013488831
          },
          {
            "accuracy": 0.877,
            "ap": 0.7190880503144654,
            "ap_weighted": 0.7190880503144654,
            "f1": 0.8590340278104087,
            "f1_weighted": 0.8766477260354982
          },
          {
            "accuracy": 0.876,
            "ap": 0.7167687631517419,
            "ap_weighted": 0.7167687631517419,
            "f1": 0.859136369626166,
            "f1_weighted": 0.8761949552644374
          },
          {
            "accuracy": 0.878,
            "ap": 0.7240114161456916,
            "ap_weighted": 0.7240114161456916,
            "f1": 0.8558492135511191,
            "f1_weighted": 0.8756267014519056
          },
          {
            "accuracy": 0.878,
            "ap": 0.7217163618140816,
            "ap_weighted": 0.7217163618140816,
            "f1": 0.858890369383374,
            "f1_weighted": 0.8770652898067954
          },
          {
            "accuracy": 0.877,
            "ap": 0.71917429406037,
            "ap_weighted": 0.71917429406037,
            "f1": 0.858802299111832,
            "f1_weighted": 0.8765437902284302
          },
          {
            "accuracy": 0.879,
            "ap": 0.7231291727140784,
            "ap_weighted": 0.7231291727140784,
            "f1": 0.8613261574395079,
            "f1_weighted": 0.8786534540674413
          },
          {
            "accuracy": 0.881,
            "ap": 0.7281477732793522,
            "ap_weighted": 0.7281477732793522,
            "f1": 0.8620064265578489,
            "f1_weighted": 0.8799248920693122
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}