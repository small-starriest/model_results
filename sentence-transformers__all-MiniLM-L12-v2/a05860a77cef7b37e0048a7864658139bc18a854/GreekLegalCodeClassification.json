{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "evaluation_time": 199.00023365020752,
  "kg_co2_emissions": 0.029684679270593047,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.040087890625,
        "f1": 0.018918344848794254,
        "f1_weighted": 0.028783192890977027,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.040087890625,
        "scores_per_experiment": [
          {
            "accuracy": 0.037109375,
            "f1": 0.016012739857867213,
            "f1_weighted": 0.02298564322300926
          },
          {
            "accuracy": 0.044921875,
            "f1": 0.025208224879292526,
            "f1_weighted": 0.029231380222744692
          },
          {
            "accuracy": 0.03759765625,
            "f1": 0.01858482912763901,
            "f1_weighted": 0.024177831352750995
          },
          {
            "accuracy": 0.0400390625,
            "f1": 0.019179124189573415,
            "f1_weighted": 0.02986453407466688
          },
          {
            "accuracy": 0.03662109375,
            "f1": 0.01895982680973167,
            "f1_weighted": 0.02937483011761592
          },
          {
            "accuracy": 0.03955078125,
            "f1": 0.01720569213178192,
            "f1_weighted": 0.03020992474171379
          },
          {
            "accuracy": 0.048828125,
            "f1": 0.020157896609213445,
            "f1_weighted": 0.03461523199461357
          },
          {
            "accuracy": 0.04296875,
            "f1": 0.02174147701810062,
            "f1_weighted": 0.03532113020506328
          },
          {
            "accuracy": 0.0361328125,
            "f1": 0.015391420514898549,
            "f1_weighted": 0.02535954218489726
          },
          {
            "accuracy": 0.037109375,
            "f1": 0.016742217349844175,
            "f1_weighted": 0.02669188079269462
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.043115234375,
        "f1": 0.019882239040607853,
        "f1_weighted": 0.03228757117158018,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.043115234375,
        "scores_per_experiment": [
          {
            "accuracy": 0.04248046875,
            "f1": 0.018674481438183545,
            "f1_weighted": 0.030536472399468263
          },
          {
            "accuracy": 0.04638671875,
            "f1": 0.02015907275039918,
            "f1_weighted": 0.032363729885298224
          },
          {
            "accuracy": 0.04345703125,
            "f1": 0.01992717259932085,
            "f1_weighted": 0.0356402066776633
          },
          {
            "accuracy": 0.0478515625,
            "f1": 0.026239104360005417,
            "f1_weighted": 0.0404854630815262
          },
          {
            "accuracy": 0.03662109375,
            "f1": 0.016336302299153154,
            "f1_weighted": 0.028024328099157253
          },
          {
            "accuracy": 0.03857421875,
            "f1": 0.016249884821424757,
            "f1_weighted": 0.02698468802616171
          },
          {
            "accuracy": 0.0517578125,
            "f1": 0.01853002723075107,
            "f1_weighted": 0.034485720424434076
          },
          {
            "accuracy": 0.04443359375,
            "f1": 0.0189855239725308,
            "f1_weighted": 0.03309647860980238
          },
          {
            "accuracy": 0.0400390625,
            "f1": 0.018913669054310234,
            "f1_weighted": 0.029644252558089883
          },
          {
            "accuracy": 0.03955078125,
            "f1": 0.024807151879999486,
            "f1_weighted": 0.03161437195420053
          }
        ]
      }
    ]
  },
  "task_name": "GreekLegalCodeClassification"
}