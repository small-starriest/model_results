{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 25.269612550735474,
  "kg_co2_emissions": 0.003990031995972368,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.912656169143195,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.912656169143195,
        "precision": 0.9047183410955867,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.1596806387225549,
        "f1": 0.10705677590845336,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.10705677590845336,
        "precision": 0.09477286474460318,
        "recall": 0.1596806387225549
      },
      {
        "accuracy": 0.6793080505655356,
        "f1": 0.6187545543832969,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6187545543832969,
        "precision": 0.5945247071993579,
        "recall": 0.6793080505655356
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.9333000665335994,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9333000665335994,
        "precision": 0.9275734245794126,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.6606786427145709,
        "f1": 0.6022666307596448,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.6022666307596448,
        "precision": 0.5792452372791693,
        "recall": 0.6606786427145709
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9204036371701043,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9204036371701043,
        "precision": 0.9133399866932801,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9119242995490501,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9119242995490501,
        "precision": 0.9047737857618097,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.8369926813040586,
        "f1": 0.8044112832535987,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.8044112832535987,
        "precision": 0.7907961854069638,
        "recall": 0.8369926813040586
      },
      {
        "accuracy": 0.36127744510978044,
        "f1": 0.287543206948514,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.287543206948514,
        "precision": 0.2642450896035831,
        "recall": 0.36127744510978044
      },
      {
        "accuracy": 0.7744510978043913,
        "f1": 0.7339590659949939,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.7339590659949939,
        "precision": 0.7173605170611158,
        "recall": 0.7744510978043913
      },
      {
        "accuracy": 0.8795741849634066,
        "f1": 0.854424484364604,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.854424484364604,
        "precision": 0.8432801064537591,
        "recall": 0.8795741849634066
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9053448658239076,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9053448658239076,
        "precision": 0.8975049900199601,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.003312494598703338,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.003312494598703338,
        "precision": 0.002765478265135691,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.919107816113804,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.919107816113804,
        "precision": 0.9129740518962076,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9112790292431011,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9112790292431011,
        "precision": 0.9038035041029052,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8888667110223997,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8888667110223997,
        "precision": 0.879618540696385,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.5881570192947438,
        "f1": 0.5201089883724614,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.5201089883724614,
        "precision": 0.49550929406218824,
        "recall": 0.5881570192947438
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.001880877561528643,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.001880877561528643,
        "precision": 0.0012074714731330897,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.4665526090675791,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.4665526090675791,
        "precision": 0.44134244738037154,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.8276779773785762,
        "f1": 0.7943794949782972,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.7943794949782972,
        "precision": 0.7796074517631404,
        "recall": 0.8276779773785762
      },
      {
        "accuracy": 0.8962075848303394,
        "f1": 0.8730332984824002,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8730332984824002,
        "precision": 0.8635570129582105,
        "recall": 0.8962075848303394
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9166017172005196,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9166017172005196,
        "precision": 0.9103459747172322,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8939454424484364,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.8939454424484364,
        "precision": 0.8849190507873143,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.08675514165642326,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.08675514165642326,
        "precision": 0.07838010006459584,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.6620093147039254,
        "f1": 0.6006062430214126,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6006062430214126,
        "precision": 0.5788824061279151,
        "recall": 0.6620093147039254
      },
      {
        "accuracy": 0.9647371922821024,
        "f1": 0.9554668440895986,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9554668440895986,
        "precision": 0.9512641383898869,
        "recall": 0.9647371922821024
      },
      {
        "accuracy": 0.6360612109115104,
        "f1": 0.5739062919267727,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.5739062919267727,
        "precision": 0.551171537333424,
        "recall": 0.6360612109115104
      },
      {
        "accuracy": 0.9441117764471058,
        "f1": 0.9337103570636506,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9337103570636506,
        "precision": 0.9289753825681969,
        "recall": 0.9441117764471058
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.9416056775338213,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9416056775338213,
        "precision": 0.9372033710357063,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.8522954091816367,
        "f1": 0.8199062193074168,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.8199062193074168,
        "precision": 0.8058993124861387,
        "recall": 0.8522954091816367
      },
      {
        "accuracy": 0.3333333333333333,
        "f1": 0.2675477786308756,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.2675477786308756,
        "precision": 0.25012848968766327,
        "recall": 0.3333333333333333
      },
      {
        "accuracy": 0.7884231536926147,
        "f1": 0.7502296180938895,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.7502296180938895,
        "precision": 0.7351109949413343,
        "recall": 0.7884231536926147
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8966844089598581,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8966844089598581,
        "precision": 0.8874536641003707,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9387890884896873,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9387890884896873,
        "precision": 0.933932135728543,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0017520562179415091,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0017520562179415091,
        "precision": 0.001563299945864039,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.9426923929917943,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9426923929917943,
        "precision": 0.9382900864936793,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.9394544244843646,
        "f1": 0.9259702816589044,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9259702816589044,
        "precision": 0.9197715679751608,
        "recall": 0.9394544244843646
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9181969394544245,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9181969394544245,
        "precision": 0.9107182460475874,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.4719765615474198,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.4719765615474198,
        "precision": 0.45106993403227025,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00039918895360186693,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.00039918895360186693,
        "precision": 0.00021914568878935096,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.4976713240186294,
        "f1": 0.4309329915958763,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.4309329915958763,
        "precision": 0.4099622955693423,
        "recall": 0.4976713240186294
      },
      {
        "accuracy": 0.8769128409846972,
        "f1": 0.8509869150587713,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8509869150587713,
        "precision": 0.8393989798181416,
        "recall": 0.8769128409846972
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9217564870259481,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9217564870259481,
        "precision": 0.914781548015081,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.9418052783322244,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9418052783322244,
        "precision": 0.9368485251718784,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.1656686626746507,
        "f1": 0.12272898340714354,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.12272898340714354,
        "precision": 0.11183264720585874,
        "recall": 0.1656686626746507
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.13105906604722523,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.13105906604722523,
        "precision": 0.11914995691557317,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.18762475049900199,
        "f1": 0.14697373333585897,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.14697373333585897,
        "precision": 0.1359909356419533,
        "recall": 0.18762475049900199
      },
      {
        "accuracy": 0.20093147039254824,
        "f1": 0.15600100547118248,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.15600100547118248,
        "precision": 0.14417529274706772,
        "recall": 0.20093147039254824
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.14441849887589986,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.14441849887589986,
        "precision": 0.13483334214158932,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.18097139055222888,
        "f1": 0.13299685330563674,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.13299685330563674,
        "precision": 0.12068979654015465,
        "recall": 0.18097139055222888
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.15692107108361286,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.15692107108361286,
        "precision": 0.1456306124420661,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.16101131071190952,
        "f1": 0.12298327815768957,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.12298327815768957,
        "precision": 0.11273401501501804,
        "recall": 0.16101131071190952
      },
      {
        "accuracy": 0.13506320691949433,
        "f1": 0.1063678250745293,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1063678250745293,
        "precision": 0.09878940049688924,
        "recall": 0.13506320691949433
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.1330000462609889,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1330000462609889,
        "precision": 0.123341674342157,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.1656686626746507,
        "f1": 0.12187069022211672,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.12187069022211672,
        "precision": 0.11138210158926591,
        "recall": 0.1656686626746507
      },
      {
        "accuracy": 0.16966067864271456,
        "f1": 0.12414578596686641,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.12414578596686641,
        "precision": 0.11303206712724159,
        "recall": 0.16966067864271456
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005604286731709306,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005604286731709306,
        "precision": 0.004310698821867327,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.1322838761860615,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1322838761860615,
        "precision": 0.11983852031137508,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.16833000665335995,
        "f1": 0.12414218430332653,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.12414218430332653,
        "precision": 0.11337003338510233,
        "recall": 0.16833000665335995
      },
      {
        "accuracy": 0.18363273453093812,
        "f1": 0.14307978155834167,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.14307978155834167,
        "precision": 0.13241372971289328,
        "recall": 0.18363273453093812
      },
      {
        "accuracy": 0.1536926147704591,
        "f1": 0.1236003264387672,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.1236003264387672,
        "precision": 0.11529086738618656,
        "recall": 0.1536926147704591
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.00305356312045196,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00305356312045196,
        "precision": 0.002183671363269195,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.17498336660013306,
        "f1": 0.1397312095599731,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1397312095599731,
        "precision": 0.1306601333179684,
        "recall": 0.17498336660013306
      },
      {
        "accuracy": 0.1703260146373919,
        "f1": 0.12955467432108161,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.12955467432108161,
        "precision": 0.12011994444487895,
        "recall": 0.1703260146373919
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.13365414022187078,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.13365414022187078,
        "precision": 0.12392650305586338,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.17964071856287425,
        "f1": 0.13760866235694202,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.13760866235694202,
        "precision": 0.1272322202681767,
        "recall": 0.17964071856287425
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6810078256186041,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6810078256186041,
        "precision": 0.6586224376643538,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.7850964737192282,
        "f1": 0.7391676963533251,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7391676963533251,
        "precision": 0.7201844987274129,
        "recall": 0.7850964737192282
      },
      {
        "accuracy": 0.21889554224883567,
        "f1": 0.1603890917504866,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1603890917504866,
        "precision": 0.14249289893921682,
        "recall": 0.21889554224883567
      },
      {
        "accuracy": 0.8409846972721224,
        "f1": 0.8040416521454447,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8040416521454447,
        "precision": 0.7882734530938125,
        "recall": 0.8409846972721224
      },
      {
        "accuracy": 0.5914836992681304,
        "f1": 0.533150197920657,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.533150197920657,
        "precision": 0.509690671566919,
        "recall": 0.5914836992681304
      },
      {
        "accuracy": 0.7924151696606786,
        "f1": 0.7495591308964561,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7495591308964561,
        "precision": 0.7314933624813864,
        "recall": 0.7924151696606786
      },
      {
        "accuracy": 0.801729873586161,
        "f1": 0.7632353526565103,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7632353526565103,
        "precision": 0.7467675759591925,
        "recall": 0.801729873586161
      },
      {
        "accuracy": 0.6852960745176314,
        "f1": 0.6348113297215094,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6348113297215094,
        "precision": 0.6146732989048358,
        "recall": 0.6852960745176314
      },
      {
        "accuracy": 0.39454424484364603,
        "f1": 0.3293343715499404,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3293343715499404,
        "precision": 0.30640445899926944,
        "recall": 0.39454424484364603
      },
      {
        "accuracy": 0.7119095143047239,
        "f1": 0.6644298704178944,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6644298704178944,
        "precision": 0.644992842597633,
        "recall": 0.7119095143047239
      },
      {
        "accuracy": 0.7278775781769794,
        "f1": 0.677107080101092,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.677107080101092,
        "precision": 0.6561210911510312,
        "recall": 0.7278775781769794
      },
      {
        "accuracy": 0.7884231536926147,
        "f1": 0.7462387394523122,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7462387394523122,
        "precision": 0.7281326236416056,
        "recall": 0.7884231536926147
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0025612001337935804,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0025612001337935804,
        "precision": 0.0016712382837339877,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.7957418496340652,
        "f1": 0.752243132782055,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.752243132782055,
        "precision": 0.7343191923032243,
        "recall": 0.7957418496340652
      },
      {
        "accuracy": 0.7777777777777778,
        "f1": 0.7332847532448331,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7332847532448331,
        "precision": 0.7147833961706217,
        "recall": 0.7777777777777778
      },
      {
        "accuracy": 0.780439121756487,
        "f1": 0.7375418955259275,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7375418955259275,
        "precision": 0.7194618699109716,
        "recall": 0.780439121756487
      },
      {
        "accuracy": 0.5129740518962076,
        "f1": 0.4455866045686405,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4455866045686405,
        "precision": 0.4212429638078341,
        "recall": 0.5129740518962076
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0011751729896773623,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011751729896773623,
        "precision": 0.0006546301202405124,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.5801729873586161,
        "f1": 0.5192589610694577,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5192589610694577,
        "precision": 0.4950420587396635,
        "recall": 0.5801729873586161
      },
      {
        "accuracy": 0.6766467065868264,
        "f1": 0.6200535437062383,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6200535437062383,
        "precision": 0.5969251972245985,
        "recall": 0.6766467065868264
      },
      {
        "accuracy": 0.7584830339321357,
        "f1": 0.7126778189652442,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7126778189652442,
        "precision": 0.6941144166693068,
        "recall": 0.7584830339321357
      },
      {
        "accuracy": 0.8077178975382568,
        "f1": 0.7683796428307407,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7683796428307407,
        "precision": 0.7520712543167632,
        "recall": 0.8077178975382568
      },
      {
        "accuracy": 0.9534264803725881,
        "f1": 0.9420935905965846,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9420935905965846,
        "precision": 0.9370148591705477,
        "recall": 0.9534264803725881
      },
      {
        "accuracy": 0.9687292082501663,
        "f1": 0.9605899312486139,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9605899312486139,
        "precision": 0.9570858283433133,
        "recall": 0.9687292082501663
      },
      {
        "accuracy": 0.20891550232867598,
        "f1": 0.1465290229364823,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.1465290229364823,
        "precision": 0.12970603653824414,
        "recall": 0.20891550232867598
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7721942358668906,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.7721942358668906,
        "precision": 0.7526114437791084,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.7671324018629407,
        "f1": 0.7178895843566502,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.7178895843566502,
        "precision": 0.6974289516205685,
        "recall": 0.7671324018629407
      },
      {
        "accuracy": 0.9707252162341983,
        "f1": 0.9630516744289199,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9630516744289199,
        "precision": 0.9596362829895765,
        "recall": 0.9707252162341983
      },
      {
        "accuracy": 0.9727212242182302,
        "f1": 0.965890441339543,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.965890441339543,
        "precision": 0.9627966289642937,
        "recall": 0.9727212242182302
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8811836644171974,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.8811836644171974,
        "precision": 0.8705034375693059,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.4597471723220226,
        "f1": 0.37932055682207555,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.37932055682207555,
        "precision": 0.3526900743966612,
        "recall": 0.4597471723220226
      },
      {
        "accuracy": 0.8815701929474384,
        "f1": 0.8562705277276135,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8562705277276135,
        "precision": 0.8458028387669108,
        "recall": 0.8815701929474384
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9322244400088712,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9322244400088712,
        "precision": 0.9261698824573076,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.9727212242182302,
        "f1": 0.9658239077400753,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9658239077400753,
        "precision": 0.9629629629629629,
        "recall": 0.9727212242182302
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0011879147422975014,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0011879147422975014,
        "precision": 0.0009498693256178286,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.9747172322022621,
        "f1": 0.9676424927921935,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9676424927921935,
        "precision": 0.9645708582834331,
        "recall": 0.9747172322022621
      },
      {
        "accuracy": 0.9680638722554891,
        "f1": 0.9603681525837214,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9603681525837214,
        "precision": 0.9570858283433133,
        "recall": 0.9680638722554891
      },
      {
        "accuracy": 0.9607451763140386,
        "f1": 0.9506320691949436,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9506320691949436,
        "precision": 0.946218673763584,
        "recall": 0.9607451763140386
      },
      {
        "accuracy": 0.6952761144377911,
        "f1": 0.6307438514025341,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.6307438514025341,
        "precision": 0.6057097445320998,
        "recall": 0.6952761144377911
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.00199406674909096,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00199406674909096,
        "precision": 0.0014268372300478217,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.6593479707252162,
        "f1": 0.5947501821753318,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.5947501821753318,
        "precision": 0.5697266841977421,
        "recall": 0.6593479707252162
      },
      {
        "accuracy": 0.9041916167664671,
        "f1": 0.883987580394766,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.883987580394766,
        "precision": 0.8744954535373697,
        "recall": 0.9041916167664671
      },
      {
        "accuracy": 0.9534264803725881,
        "f1": 0.9423153692614772,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9423153692614772,
        "precision": 0.9374805943668219,
        "recall": 0.9534264803725881
      },
      {
        "accuracy": 0.9773785761809713,
        "f1": 0.9714792636948325,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9714792636948325,
        "precision": 0.9689509869150588,
        "recall": 0.9773785761809713
      },
      {
        "accuracy": 0.7072521623419827,
        "f1": 0.656089408484618,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.656089408484618,
        "precision": 0.6351471659854894,
        "recall": 0.7072521623419827
      },
      {
        "accuracy": 0.7544910179640718,
        "f1": 0.7101057144969319,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7101057144969319,
        "precision": 0.6922506838175501,
        "recall": 0.7544910179640718
      },
      {
        "accuracy": 0.18695941450432468,
        "f1": 0.13664884313586909,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.13664884313586909,
        "precision": 0.12155161316837963,
        "recall": 0.18695941450432468
      },
      {
        "accuracy": 0.6047904191616766,
        "f1": 0.5486808637507241,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5486808637507241,
        "precision": 0.5252003928650635,
        "recall": 0.6047904191616766
      },
      {
        "accuracy": 0.7877578176979375,
        "f1": 0.7487495907655589,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7487495907655589,
        "precision": 0.7330291797357665,
        "recall": 0.7877578176979375
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.7198539429078351,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7198539429078351,
        "precision": 0.7015366093210404,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.7664670658682635,
        "f1": 0.7256471664655296,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7256471664655296,
        "precision": 0.7094873744574344,
        "recall": 0.7664670658682635
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.6393562082184837,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6393562082184837,
        "precision": 0.6190890945381964,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.3479707252162342,
        "f1": 0.2866341391291491,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2866341391291491,
        "precision": 0.264963987369177,
        "recall": 0.3479707252162342
      },
      {
        "accuracy": 0.6553559547571524,
        "f1": 0.6069501209221768,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6069501209221768,
        "precision": 0.587461848789194,
        "recall": 0.6553559547571524
      },
      {
        "accuracy": 0.7085828343313373,
        "f1": 0.6596077685898045,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6596077685898045,
        "precision": 0.6389295483107859,
        "recall": 0.7085828343313373
      },
      {
        "accuracy": 0.7744510978043913,
        "f1": 0.7287477954144621,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7287477954144621,
        "precision": 0.7104914103417098,
        "recall": 0.7744510978043913
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0016935605975484998,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0016935605975484998,
        "precision": 0.0013287419247203533,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7158529501842874,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7158529501842874,
        "precision": 0.6977659060963042,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.7471723220226214,
        "f1": 0.6995279282704432,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6995279282704432,
        "precision": 0.6801376083811214,
        "recall": 0.7471723220226214
      },
      {
        "accuracy": 0.7411842980705257,
        "f1": 0.694446028577765,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.694446028577765,
        "precision": 0.6760347030806112,
        "recall": 0.7411842980705257
      },
      {
        "accuracy": 0.5129740518962076,
        "f1": 0.44908011335157044,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.44908011335157044,
        "precision": 0.42408624309821913,
        "recall": 0.5129740518962076
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.001678146487507001,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001678146487507001,
        "precision": 0.001099389960694587,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.500998003992016,
        "f1": 0.4393108444006647,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4393108444006647,
        "precision": 0.4143289733110092,
        "recall": 0.500998003992016
      },
      {
        "accuracy": 0.6606786427145709,
        "f1": 0.6077986883376104,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6077986883376104,
        "precision": 0.5860121027785699,
        "recall": 0.6606786427145709
      },
      {
        "accuracy": 0.7285429141716567,
        "f1": 0.6845916632343778,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6845916632343778,
        "precision": 0.6670619079301714,
        "recall": 0.7285429141716567
      },
      {
        "accuracy": 0.7471723220226214,
        "f1": 0.7026603358938689,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7026603358938689,
        "precision": 0.6849660467424938,
        "recall": 0.7471723220226214
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8945569179102113,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8945569179102113,
        "precision": 0.8855067642492791,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.9395431359503215,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.9395431359503215,
        "precision": 0.9340208471944998,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.1330671989354624,
        "f1": 0.08990469563163309,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.08990469563163309,
        "precision": 0.08040239876124947,
        "recall": 0.1330671989354624
      },
      {
        "accuracy": 0.6560212907518297,
        "f1": 0.5888761345847174,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.5888761345847174,
        "precision": 0.5649629552823165,
        "recall": 0.6560212907518297
      },
      {
        "accuracy": 0.9700598802395209,
        "f1": 0.9621867376358393,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9621867376358393,
        "precision": 0.9586826347305389,
        "recall": 0.9700598802395209
      },
      {
        "accuracy": 0.6500332667997338,
        "f1": 0.5878825419113264,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.5878825419113264,
        "precision": 0.5664142614242416,
        "recall": 0.6500332667997338
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.9424167537939994,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9424167537939994,
        "precision": 0.937680195165225,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.8396540252827678,
        "f1": 0.8053279684018206,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.8053279684018206,
        "precision": 0.7904542766319215,
        "recall": 0.8396540252827678
      },
      {
        "accuracy": 0.3286759813705922,
        "f1": 0.2658504607017487,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.2658504607017487,
        "precision": 0.24990798618085255,
        "recall": 0.3286759813705922
      },
      {
        "accuracy": 0.7950765136393879,
        "f1": 0.752733158022579,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.752733158022579,
        "precision": 0.7357161338698265,
        "recall": 0.7950765136393879
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8940674207141273,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.8940674207141273,
        "precision": 0.8849364762538415,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.9426480372588159,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9426480372588159,
        "precision": 0.9381459303614992,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0004820117628697989,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0004820117628697989,
        "precision": 0.00026674602464390307,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.9560878243512974,
        "f1": 0.9468840097582611,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9468840097582611,
        "precision": 0.9429474384564205,
        "recall": 0.9560878243512974
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9179418939897982,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.9179418939897982,
        "precision": 0.9111443779108449,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.9328802712036246,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.9328802712036246,
        "precision": 0.9263694832557109,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.5322687957418496,
        "f1": 0.4672876284652732,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.4672876284652732,
        "precision": 0.44589941366388475,
        "recall": 0.5322687957418496
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0007060487412669328,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.0007060487412669328,
        "precision": 0.0003839442919538435,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.4916833000665336,
        "f1": 0.4259433736319758,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.4259433736319758,
        "precision": 0.4058461499805299,
        "recall": 0.4916833000665336
      },
      {
        "accuracy": 0.8695941450432468,
        "f1": 0.8412096442036562,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.8412096442036562,
        "precision": 0.8284763805721889,
        "recall": 0.8695941450432468
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9074295852738966,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.9074295852738966,
        "precision": 0.8999223774672876,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9580838323353293,
        "f1": 0.9486043785444983,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.9486043785444983,
        "precision": 0.9444444444444444,
        "recall": 0.9580838323353293
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8907740075404748,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8907740075404748,
        "precision": 0.8808050565535595,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9477489465513418,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9477489465513418,
        "precision": 0.9427811044577512,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.1370592149035263,
        "f1": 0.09447176307533772,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.09447176307533772,
        "precision": 0.08514836419802506,
        "recall": 0.1370592149035263
      },
      {
        "accuracy": 0.6620093147039254,
        "f1": 0.6010540727107594,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6010540727107594,
        "precision": 0.5806714686954207,
        "recall": 0.6620093147039254
      },
      {
        "accuracy": 0.9634065202927479,
        "f1": 0.9535595475715235,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9535595475715235,
        "precision": 0.949268130405855,
        "recall": 0.9634065202927479
      },
      {
        "accuracy": 0.6280771789753826,
        "f1": 0.5699055576865175,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5699055576865175,
        "precision": 0.5500878061589971,
        "recall": 0.6280771789753826
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9388112663561765,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9388112663561765,
        "precision": 0.9337436238633843,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8108782435129741,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8108782435129741,
        "precision": 0.7957666677227555,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.3147039254823686,
        "f1": 0.2553381323926416,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2553381323926416,
        "precision": 0.2402816529276303,
        "recall": 0.3147039254823686
      },
      {
        "accuracy": 0.7791084497671324,
        "f1": 0.7344094879025018,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7344094879025018,
        "precision": 0.7165074612679403,
        "recall": 0.7791084497671324
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8847638057218897,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8847638057218897,
        "precision": 0.874517631403859,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9388777999556441,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9388777999556441,
        "precision": 0.9342869815923707,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.001112572109757025,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001112572109757025,
        "precision": 0.0007183590362940981,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.935041029053005,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.935041029053005,
        "precision": 0.9299955644267022,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9183632734530938,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9183632734530938,
        "precision": 0.9115324905744068,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9191173209137281,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9191173209137281,
        "precision": 0.9120647593701487,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.5096473719228211,
        "f1": 0.44392133820119956,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.44392133820119956,
        "precision": 0.42314754434024665,
        "recall": 0.5096473719228211
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0008377148047192364,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008377148047192364,
        "precision": 0.0005402536453715984,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.490352628077179,
        "f1": 0.4297410227108141,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4297410227108141,
        "precision": 0.41126661956712385,
        "recall": 0.490352628077179
      },
      {
        "accuracy": 0.8682634730538922,
        "f1": 0.8372144599689509,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8372144599689509,
        "precision": 0.8234752716788646,
        "recall": 0.8682634730538922
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9087951081963058,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9087951081963058,
        "precision": 0.9009758261255266,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9409625194056331,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9409625194056331,
        "precision": 0.936127744510978,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8149383772138262,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.8149383772138262,
        "precision": 0.8009536482590375,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.871168773563983,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.871168773563983,
        "precision": 0.8602683521845199,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.15568862275449102,
        "f1": 0.10628799241050439,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.10628799241050439,
        "precision": 0.09359994498589906,
        "recall": 0.15568862275449102
      },
      {
        "accuracy": 0.6400532268795742,
        "f1": 0.583903621328771,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.583903621328771,
        "precision": 0.5613946709755093,
        "recall": 0.6400532268795742
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8843899502582137,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8843899502582137,
        "precision": 0.8754380128631626,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.6300731869594145,
        "f1": 0.5718032189589076,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.5718032189589076,
        "precision": 0.5485785043669276,
        "recall": 0.6300731869594145
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8507334537274658,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8507334537274658,
        "precision": 0.8400310490130849,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8684424801191268,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.8684424801191268,
        "precision": 0.8586002597978647,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.34530938123752497,
        "f1": 0.2734785507240597,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.2734785507240597,
        "precision": 0.2519779220818319,
        "recall": 0.34530938123752497
      },
      {
        "accuracy": 0.7312042581503659,
        "f1": 0.6884374108925007,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.6884374108925007,
        "precision": 0.6711455396086135,
        "recall": 0.7312042581503659
      },
      {
        "accuracy": 0.8556220891550232,
        "f1": 0.8272011532490574,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.8272011532490574,
        "precision": 0.8144552165510249,
        "recall": 0.8556220891550232
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8688527706491779,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8688527706491779,
        "precision": 0.8593036149922377,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.000877226118848138,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.000877226118848138,
        "precision": 0.0004915114417162951,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8619332763045338,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.8619332763045338,
        "precision": 0.8510645375914836,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.8709248170326015,
        "f1": 0.8418844849982574,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.8418844849982574,
        "precision": 0.8291417165668662,
        "recall": 0.8709248170326015
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.8332499023117785,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.8332499023117785,
        "precision": 0.8217620314925704,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.5535595475715236,
        "f1": 0.48655814873379744,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.48655814873379744,
        "precision": 0.46267837101170434,
        "recall": 0.5535595475715236
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0012975555842408342,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0012975555842408342,
        "precision": 0.0008956013977737928,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.5262807717897539,
        "f1": 0.45736573990067003,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.45736573990067003,
        "precision": 0.432322392252532,
        "recall": 0.5262807717897539
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.7980927034819251,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.7980927034819251,
        "precision": 0.7817365269461076,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8743956531381681,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8743956531381681,
        "precision": 0.8639451256217723,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.8835662009314704,
        "f1": 0.8593828216582708,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8593828216582708,
        "precision": 0.8488689288090485,
        "recall": 0.8835662009314704
      },
      {
        "accuracy": 0.3805721889554225,
        "f1": 0.331374727051794,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.331374727051794,
        "precision": 0.3146816295082642,
        "recall": 0.3805721889554225
      },
      {
        "accuracy": 0.4038589487691284,
        "f1": 0.35979134997549783,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.35979134997549783,
        "precision": 0.3453173841405575,
        "recall": 0.4038589487691284
      },
      {
        "accuracy": 0.1536926147704591,
        "f1": 0.11683970276784647,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.11683970276784647,
        "precision": 0.10538079684786272,
        "recall": 0.1536926147704591
      },
      {
        "accuracy": 0.38323353293413176,
        "f1": 0.33919622429269797,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.33919622429269797,
        "precision": 0.3231998029245639,
        "recall": 0.38323353293413176
      },
      {
        "accuracy": 0.4457751164337991,
        "f1": 0.39684497834668075,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.39684497834668075,
        "precision": 0.3808635930637979,
        "recall": 0.4457751164337991
      },
      {
        "accuracy": 0.3366600133067199,
        "f1": 0.298431953655445,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.298431953655445,
        "precision": 0.2852918095433065,
        "recall": 0.3366600133067199
      },
      {
        "accuracy": 0.41783100465735196,
        "f1": 0.3680477416347781,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.3680477416347781,
        "precision": 0.3522917487987348,
        "recall": 0.41783100465735196
      },
      {
        "accuracy": 0.42847638057218895,
        "f1": 0.38021296451032727,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.38021296451032727,
        "precision": 0.3640597526885946,
        "recall": 0.42847638057218895
      },
      {
        "accuracy": 0.3666001330671989,
        "f1": 0.3254466270618177,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.3254466270618177,
        "precision": 0.311364617948509,
        "recall": 0.3666001330671989
      },
      {
        "accuracy": 0.39654025282767796,
        "f1": 0.352148747227707,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.352148747227707,
        "precision": 0.33659680383217183,
        "recall": 0.39654025282767796
      },
      {
        "accuracy": 0.37192282102461743,
        "f1": 0.32490588007886745,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.32490588007886745,
        "precision": 0.3086586520586045,
        "recall": 0.37192282102461743
      },
      {
        "accuracy": 0.4151696606786427,
        "f1": 0.36491297504922426,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.36491297504922426,
        "precision": 0.34820847260967025,
        "recall": 0.4151696606786427
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0035892297618844524,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0035892297618844524,
        "precision": 0.0027517430567000306,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.42980705256154356,
        "f1": 0.3775159587882529,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3775159587882529,
        "precision": 0.36036937642230077,
        "recall": 0.42980705256154356
      },
      {
        "accuracy": 0.39454424484364603,
        "f1": 0.33966090463096454,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.33966090463096454,
        "precision": 0.32167217705388507,
        "recall": 0.39454424484364603
      },
      {
        "accuracy": 0.4138389886892881,
        "f1": 0.3590794268937982,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.3590794268937982,
        "precision": 0.341855171661951,
        "recall": 0.4138389886892881
      },
      {
        "accuracy": 0.32667997338656024,
        "f1": 0.2777194205413239,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.2777194205413239,
        "precision": 0.2607191193518539,
        "recall": 0.32667997338656024
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.002721969975330089,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.002721969975330089,
        "precision": 0.0019274024258909286,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.34331337325349304,
        "f1": 0.29922686170191154,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.29922686170191154,
        "precision": 0.28336993542600125,
        "recall": 0.34331337325349304
      },
      {
        "accuracy": 0.3313373253493014,
        "f1": 0.2826681351316292,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.2826681351316292,
        "precision": 0.26755117922489063,
        "recall": 0.3313373253493014
      },
      {
        "accuracy": 0.3978709248170326,
        "f1": 0.3513549768040786,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.3513549768040786,
        "precision": 0.3354348092704713,
        "recall": 0.3978709248170326
      },
      {
        "accuracy": 0.4471057884231537,
        "f1": 0.3944402504833858,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.3944402504833858,
        "precision": 0.37859728763841594,
        "recall": 0.4471057884231537
      },
      {
        "accuracy": 0.7957418496340652,
        "f1": 0.7527310458448182,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7527310458448182,
        "precision": 0.7343376738586319,
        "recall": 0.7957418496340652
      },
      {
        "accuracy": 0.8396540252827678,
        "f1": 0.8072109748756455,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8072109748756455,
        "precision": 0.7933577289864715,
        "recall": 0.8396540252827678
      },
      {
        "accuracy": 0.19228210246174318,
        "f1": 0.13303205498227222,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.13303205498227222,
        "precision": 0.11708640218494584,
        "recall": 0.19228210246174318
      },
      {
        "accuracy": 0.709913506320692,
        "f1": 0.6490542724075659,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6490542724075659,
        "precision": 0.6234752716788644,
        "recall": 0.709913506320692
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8692282102461744,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8692282102461744,
        "precision": 0.8591547064600957,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.6407185628742516,
        "f1": 0.5774730148981646,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5774730148981646,
        "precision": 0.5524929458063191,
        "recall": 0.6407185628742516
      },
      {
        "accuracy": 0.8702594810379242,
        "f1": 0.8422298260621615,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8422298260621615,
        "precision": 0.8303060545575516,
        "recall": 0.8702594810379242
      },
      {
        "accuracy": 0.8616101131071191,
        "f1": 0.8339057335065319,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8339057335065319,
        "precision": 0.8224828121534707,
        "recall": 0.8616101131071191
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.7218742409361171,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7218742409361171,
        "precision": 0.7039595412349905,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.3985362608117099,
        "f1": 0.320053246450452,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.320053246450452,
        "precision": 0.29459680926746795,
        "recall": 0.3985362608117099
      },
      {
        "accuracy": 0.7930805056553559,
        "f1": 0.7498051516015587,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7498051516015587,
        "precision": 0.7312153470836106,
        "recall": 0.7930805056553559
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8170785413300384,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8170785413300384,
        "precision": 0.803953996768368,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.000526929843390555,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.000526929843390555,
        "precision": 0.0002933386095958065,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8271599657827202,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8271599657827202,
        "precision": 0.8144441276177803,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.8296739853626082,
        "f1": 0.7921078477964705,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7921078477964705,
        "precision": 0.7758150365934798,
        "recall": 0.8296739853626082
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8038879912133405,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8038879912133405,
        "precision": 0.7898211513480974,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.6014637391882901,
        "f1": 0.5336623530236304,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.5336623530236304,
        "precision": 0.5074620600069703,
        "recall": 0.6014637391882901
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0009327688805558208,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009327688805558208,
        "precision": 0.0005944353282826217,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.5874916833000665,
        "f1": 0.5193897918448817,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5193897918448817,
        "precision": 0.49239457592751007,
        "recall": 0.5874916833000665
      },
      {
        "accuracy": 0.7531603459747173,
        "f1": 0.7087116771747509,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7087116771747509,
        "precision": 0.6899383772138262,
        "recall": 0.7531603459747173
      },
      {
        "accuracy": 0.8163672654690619,
        "f1": 0.7786384902153366,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7786384902153366,
        "precision": 0.7626691062319804,
        "recall": 0.8163672654690619
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.8308863753973533,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8308863753973533,
        "precision": 0.8181913949878021,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.8882235528942116,
        "f1": 0.8642936349523176,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.8642936349523176,
        "precision": 0.8532379685074295,
        "recall": 0.8882235528942116
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9174983366600133,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9174983366600133,
        "precision": 0.9110889332446219,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.1490352628077179,
        "f1": 0.1048228770064829,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.1048228770064829,
        "precision": 0.09466202050501017,
        "recall": 0.1490352628077179
      },
      {
        "accuracy": 0.6380572188955422,
        "f1": 0.5715230101457647,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5715230101457647,
        "precision": 0.5459105598327155,
        "recall": 0.6380572188955422
      },
      {
        "accuracy": 0.9447771124417831,
        "f1": 0.930616544688401,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.930616544688401,
        "precision": 0.9242467446060262,
        "recall": 0.9447771124417831
      },
      {
        "accuracy": 0.6413838988689288,
        "f1": 0.5823725564743528,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.5823725564743528,
        "precision": 0.5594563459675341,
        "recall": 0.6413838988689288
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9131514748281215,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9131514748281215,
        "precision": 0.9060989132845421,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9069527611443778,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.9069527611443778,
        "precision": 0.899318822672116,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.8542914171656687,
        "f1": 0.8225506658640391,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.8225506658640391,
        "precision": 0.8089654025282768,
        "recall": 0.8542914171656687
      },
      {
        "accuracy": 0.3320026613439787,
        "f1": 0.26389480950417293,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.26389480950417293,
        "precision": 0.24456885179883323,
        "recall": 0.3320026613439787
      },
      {
        "accuracy": 0.7451763140385895,
        "f1": 0.701993367761831,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.701993367761831,
        "precision": 0.6849531096537085,
        "recall": 0.7451763140385895
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9106010201818584,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9106010201818584,
        "precision": 0.9027944111776448,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00278810994140672,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.00278810994140672,
        "precision": 0.0025225629096979492,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9177771441244496,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.9177771441244496,
        "precision": 0.9108449767132402,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.887536039033045,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.887536039033045,
        "precision": 0.878420935905966,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8836992681304058,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.8836992681304058,
        "precision": 0.8743512974051897,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.4766292478867329,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.4766292478867329,
        "precision": 0.4505948014431049,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0012199410702404714,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0012199410702404714,
        "precision": 0.0007250593375092345,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.48502994011976047,
        "f1": 0.41781993049458116,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.41781993049458116,
        "precision": 0.3957587593286783,
        "recall": 0.48502994011976047
      },
      {
        "accuracy": 0.8715901530272788,
        "f1": 0.845388587903558,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.845388587903558,
        "precision": 0.8337436238633844,
        "recall": 0.8715901530272788
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8894560086176851,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.8894560086176851,
        "precision": 0.8805167442891992,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9044244843646041,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.9044244843646041,
        "precision": 0.8963026328295791,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.884323416658746,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.884323416658746,
        "precision": 0.8753271235307164,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9371701042359725,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9371701042359725,
        "precision": 0.9311931692171214,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.12574850299401197,
        "f1": 0.08695410815239785,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.08695410815239785,
        "precision": 0.07920725722275329,
        "recall": 0.12574850299401197
      },
      {
        "accuracy": 0.654690618762475,
        "f1": 0.5898774840890609,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5898774840890609,
        "precision": 0.5667524978902224,
        "recall": 0.654690618762475
      },
      {
        "accuracy": 0.9627411842980705,
        "f1": 0.9526946107784432,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9526946107784432,
        "precision": 0.9480483477489466,
        "recall": 0.9627411842980705
      },
      {
        "accuracy": 0.6826347305389222,
        "f1": 0.626305652652958,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.626305652652958,
        "precision": 0.6063740244378967,
        "recall": 0.6826347305389222
      },
      {
        "accuracy": 0.9540918163672655,
        "f1": 0.9434242625859393,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9434242625859393,
        "precision": 0.9386781991572412,
        "recall": 0.9540918163672655
      },
      {
        "accuracy": 0.948769128409847,
        "f1": 0.9365491239742736,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9365491239742736,
        "precision": 0.9310268352184521,
        "recall": 0.948769128409847
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8223183263103422,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8223183263103422,
        "precision": 0.8084608560656464,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.3253493013972056,
        "f1": 0.25848751079402443,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.25848751079402443,
        "precision": 0.2406979139061414,
        "recall": 0.3253493013972056
      },
      {
        "accuracy": 0.7937458416500333,
        "f1": 0.7527754015777968,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7527754015777968,
        "precision": 0.7364002154421316,
        "recall": 0.7937458416500333
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8859740835788741,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8859740835788741,
        "precision": 0.8753825681969395,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00031595647858497275,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00031595647858497275,
        "precision": 0.00016718400180613919,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.936295662642968,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.936295662642968,
        "precision": 0.9311599024173874,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9149478820137502,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9149478820137502,
        "precision": 0.906187624750499,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9193612774451098,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9193612774451098,
        "precision": 0.9126192060323798,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.552228875582169,
        "f1": 0.48144314772899705,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.48144314772899705,
        "precision": 0.457543386236001,
        "recall": 0.552228875582169
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0026815902368596523,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0026815902368596523,
        "precision": 0.0023867693846060093,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.5123087159015303,
        "f1": 0.44532988485004915,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.44532988485004915,
        "precision": 0.42517860641613126,
        "recall": 0.5123087159015303
      },
      {
        "accuracy": 0.8629407850964738,
        "f1": 0.8341349047935874,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8341349047935874,
        "precision": 0.8211355067642493,
        "recall": 0.8629407850964738
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.904280328232424,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.904280328232424,
        "precision": 0.8961188733643825,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.9423819028609448,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9423819028609448,
        "precision": 0.937624750499002,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.003133282832207497,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.003133282832207497,
        "precision": 0.00292539513671553,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003291863264594495,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.003291863264594495,
        "precision": 0.0029023266781395387,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0031528271897212166,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0031528271897212166,
        "precision": 0.0028140176972946216,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017629458432063747,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0017629458432063747,
        "precision": 0.0014452782826649621,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0037871787289618297,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0037871787289618297,
        "precision": 0.003262969980119072,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0017852329476814865,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0017852329476814865,
        "precision": 0.0016008129867355041,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004426606405526008,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.004426606405526008,
        "precision": 0.003861162923202332,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003260146373918829,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.003260146373918829,
        "precision": 0.0026160785106308696,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004545898088249354,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.004545898088249354,
        "precision": 0.003808967309708486,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0022461250338828517,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0022461250338828517,
        "precision": 0.002010379451319408,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002490888246174792,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.002490888246174792,
        "precision": 0.00214964786494162,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.002305776454146381,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.002305776454146381,
        "precision": 0.001974891823917178,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.003192530210562104,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.003192530210562104,
        "precision": 0.0026958896787465303,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0029846658131307473,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0029846658131307473,
        "precision": 0.0024739541901168615,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0030362955346321945,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0030362955346321945,
        "precision": 0.002677747820441157,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0037008673972035383,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0037008673972035383,
        "precision": 0.0033074168236081774,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0024901468000746827,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0024901468000746827,
        "precision": 0.0023027565077483,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.029667615595759308,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.029667615595759308,
        "precision": 0.0270683740743621,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0017690391696048588,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0017690391696048588,
        "precision": 0.0014012782436747676,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0015219151308295317,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0015219151308295317,
        "precision": 0.001236145533001978,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0016462458063466572,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0016462458063466572,
        "precision": 0.0012701037981931482,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0030294124901968037,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0030294124901968037,
        "precision": 0.0026098954694948997,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9039033045021069,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9039033045021069,
        "precision": 0.895043246839654,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.9560878243512974,
        "f1": 0.9451541361721002,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9451541361721002,
        "precision": 0.9401973830117544,
        "recall": 0.9560878243512974
      },
      {
        "accuracy": 0.13572854291417166,
        "f1": 0.09036090602821407,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.09036090602821407,
        "precision": 0.07995167608720112,
        "recall": 0.13572854291417166
      },
      {
        "accuracy": 0.6793080505655356,
        "f1": 0.6153480584618309,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6153480584618309,
        "precision": 0.5922166489531759,
        "recall": 0.6793080505655356
      },
      {
        "accuracy": 0.9727212242182302,
        "f1": 0.9650476824129519,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9650476824129519,
        "precision": 0.9617653581725438,
        "recall": 0.9727212242182302
      },
      {
        "accuracy": 0.6620093147039254,
        "f1": 0.6003262156896065,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6003262156896065,
        "precision": 0.5780750209114071,
        "recall": 0.6620093147039254
      },
      {
        "accuracy": 0.9580838323353293,
        "f1": 0.9489465513417608,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9489465513417608,
        "precision": 0.945131958305611,
        "recall": 0.9580838323353293
      },
      {
        "accuracy": 0.9580838323353293,
        "f1": 0.9482590374805944,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9482590374805944,
        "precision": 0.9439676203149256,
        "recall": 0.9580838323353293
      },
      {
        "accuracy": 0.8522954091816367,
        "f1": 0.8192208176240111,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8192208176240111,
        "precision": 0.8048010040525011,
        "recall": 0.8522954091816367
      },
      {
        "accuracy": 0.34331337325349304,
        "f1": 0.27772744972706365,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.27772744972706365,
        "precision": 0.26005823959503804,
        "recall": 0.34331337325349304
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7876696822804606,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7876696822804606,
        "precision": 0.7741184298070526,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8890124512879004,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8890124512879004,
        "precision": 0.8794632956309604,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9410512308715903,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9410512308715903,
        "precision": 0.9362053670436903,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0008179997626538926,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0008179997626538926,
        "precision": 0.0005019356608746305,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.9421157684630739,
        "f1": 0.9277001552450653,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9277001552450653,
        "precision": 0.9211798624972277,
        "recall": 0.9421157684630739
      },
      {
        "accuracy": 0.9474384564204924,
        "f1": 0.9353293413173651,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9353293413173651,
        "precision": 0.9298514082945221,
        "recall": 0.9474384564204924
      },
      {
        "accuracy": 0.5681969394544245,
        "f1": 0.5043211716430497,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.5043211716430497,
        "precision": 0.48364761452008015,
        "recall": 0.5681969394544245
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0018182754763451743,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0018182754763451743,
        "precision": 0.001384607680608679,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.5109780439121756,
        "f1": 0.4439140187511866,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4439140187511866,
        "precision": 0.4230566109293241,
        "recall": 0.5109780439121756
      },
      {
        "accuracy": 0.8662674650698603,
        "f1": 0.8394132370180275,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8394132370180275,
        "precision": 0.8276114437791086,
        "recall": 0.8662674650698603
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9152932230776543,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9152932230776543,
        "precision": 0.9083721445996895,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.9620758483033932,
        "f1": 0.9536482590374805,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9536482590374805,
        "precision": 0.9500110889332446,
        "recall": 0.9620758483033932
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9113328897760036,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.9113328897760036,
        "precision": 0.9032490574406742,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9540918163672655,
        "f1": 0.9426702151253049,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9426702151253049,
        "precision": 0.9372366378354403,
        "recall": 0.9540918163672655
      },
      {
        "accuracy": 0.15236194278110446,
        "f1": 0.10337277831632118,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.10337277831632118,
        "precision": 0.09310430519603198,
        "recall": 0.15236194278110446
      },
      {
        "accuracy": 0.6939454424484365,
        "f1": 0.6327963121376295,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6327963121376295,
        "precision": 0.6093778052360888,
        "recall": 0.6939454424484365
      },
      {
        "accuracy": 0.9647371922821024,
        "f1": 0.9550232867598137,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9550232867598137,
        "precision": 0.9504879130627633,
        "recall": 0.9647371922821024
      },
      {
        "accuracy": 0.669328010645376,
        "f1": 0.6081730386121603,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.6081730386121603,
        "precision": 0.5847918542000965,
        "recall": 0.669328010645376
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9387669106231981,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9387669106231981,
        "precision": 0.9337990685296075,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9323575072078067,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.9323575072078067,
        "precision": 0.9259259259259258,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.8649367930805056,
        "f1": 0.831739695212749,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.831739695212749,
        "precision": 0.8171434907961853,
        "recall": 0.8649367930805056
      },
      {
        "accuracy": 0.35994677312042583,
        "f1": 0.28913107320958287,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.28913107320958287,
        "precision": 0.2688946953721326,
        "recall": 0.35994677312042583
      },
      {
        "accuracy": 0.8043912175648703,
        "f1": 0.7637814318453041,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.7637814318453041,
        "precision": 0.7466622310933687,
        "recall": 0.8043912175648703
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8849855843867819,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.8849855843867819,
        "precision": 0.8744954535373698,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9447771124417831,
        "f1": 0.9315591040141937,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9315591040141937,
        "precision": 0.9254823685961411,
        "recall": 0.9447771124417831
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0014200264887764455,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0014200264887764455,
        "precision": 0.0011070805767596397,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9398758039476601,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9398758039476601,
        "precision": 0.9343535151918385,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9203371035706365,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.9203371035706365,
        "precision": 0.9130627633621646,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.5688622754491018,
        "f1": 0.49964990653613406,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.49964990653613406,
        "precision": 0.4747296867526995,
        "recall": 0.5688622754491018
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.00048439517950012596,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00048439517950012596,
        "precision": 0.00025685031243089467,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.5242847638057219,
        "f1": 0.4561982698893089,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.4561982698893089,
        "precision": 0.43362054889001,
        "recall": 0.5242847638057219
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.8388809682222856,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.8388809682222856,
        "precision": 0.8269017520514526,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9010201818585052,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.9010201818585052,
        "precision": 0.8921601241960523,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9547571523619428,
        "f1": 0.9442670215125305,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9442670215125305,
        "precision": 0.9392880904856953,
        "recall": 0.9547571523619428
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8758609764597788,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8758609764597788,
        "precision": 0.8646263029496563,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9347083610556663,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9347083610556663,
        "precision": 0.9287757817697938,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.1490352628077179,
        "f1": 0.10302789434359247,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.10302789434359247,
        "precision": 0.0926969879486415,
        "recall": 0.1490352628077179
      },
      {
        "accuracy": 0.6939454424484365,
        "f1": 0.6339454328476284,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.6339454328476284,
        "precision": 0.6118057775742406,
        "recall": 0.6939454424484365
      },
      {
        "accuracy": 0.9647371922821024,
        "f1": 0.9561321800842758,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9561321800842758,
        "precision": 0.9521512530494566,
        "recall": 0.9647371922821024
      },
      {
        "accuracy": 0.6420492348636061,
        "f1": 0.5822394892754175,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.5822394892754175,
        "precision": 0.5605424546375977,
        "recall": 0.6420492348636061
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9371479263694832,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9371479263694832,
        "precision": 0.9316367265469062,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.948769128409847,
        "f1": 0.936039033045021,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.936039033045021,
        "precision": 0.9304169438899978,
        "recall": 0.948769128409847
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.7971316626007245,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.7971316626007245,
        "precision": 0.78145375914837,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.2891907816354809,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.2891907816354809,
        "precision": 0.27206349179787215,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.7957418496340652,
        "f1": 0.7541858082776246,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.7541858082776246,
        "precision": 0.7374877229667648,
        "recall": 0.7957418496340652
      },
      {
        "accuracy": 0.8982035928143712,
        "f1": 0.873985362608117,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.873985362608117,
        "precision": 0.8631847416278555,
        "recall": 0.8982035928143712
      },
      {
        "accuracy": 0.9454424484364604,
        "f1": 0.9338212463960966,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9338212463960966,
        "precision": 0.9285540031049014,
        "recall": 0.9454424484364604
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0013045976481096853,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.0013045976481096853,
        "precision": 0.0010510066839296425,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.9527611443779108,
        "f1": 0.9414060767354181,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9414060767354181,
        "precision": 0.9367043690396984,
        "recall": 0.9527611443779108
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9013750277223331,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.9013750277223331,
        "precision": 0.8923264581947217,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.5608782435129741,
        "f1": 0.49323234058763,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.49323234058763,
        "precision": 0.47080681830182824,
        "recall": 0.5608782435129741
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0026189583163065988,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0026189583163065988,
        "precision": 0.002088298588129808,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.5276114437791084,
        "f1": 0.4605061682847288,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.4605061682847288,
        "precision": 0.4387524881786359,
        "recall": 0.5276114437791084
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8176424927921933,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.8176424927921933,
        "precision": 0.8032332161074676,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8977505306846624,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.8977505306846624,
        "precision": 0.889498780217343,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.9560878243512974,
        "f1": 0.946396096695498,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.946396096695498,
        "precision": 0.9423375471279662,
        "recall": 0.9560878243512974
      },
      {
        "accuracy": 0.6467065868263473,
        "f1": 0.5883001193380435,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5883001193380435,
        "precision": 0.564930192525003,
        "recall": 0.6467065868263473
      },
      {
        "accuracy": 0.6799733865602129,
        "f1": 0.6266276969869784,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6266276969869784,
        "precision": 0.6063985378855639,
        "recall": 0.6799733865602129
      },
      {
        "accuracy": 0.16633399866932802,
        "f1": 0.12285529197958209,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12285529197958209,
        "precision": 0.10948277807060242,
        "recall": 0.16633399866932802
      },
      {
        "accuracy": 0.5103127079174984,
        "f1": 0.44811786984284097,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.44811786984284097,
        "precision": 0.4247296412466074,
        "recall": 0.5103127079174984
      },
      {
        "accuracy": 0.7351962741184298,
        "f1": 0.6896601802355513,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6896601802355513,
        "precision": 0.6721172853907385,
        "recall": 0.7351962741184298
      },
      {
        "accuracy": 0.5209580838323353,
        "f1": 0.4621171317778104,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4621171317778104,
        "precision": 0.4394887713749989,
        "recall": 0.5209580838323353
      },
      {
        "accuracy": 0.675981370592149,
        "f1": 0.6225801551150852,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6225801551150852,
        "precision": 0.6031051727159512,
        "recall": 0.675981370592149
      },
      {
        "accuracy": 0.6793080505655356,
        "f1": 0.6292840589811864,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6292840589811864,
        "precision": 0.6101578708864138,
        "recall": 0.6793080505655356
      },
      {
        "accuracy": 0.6320691949434465,
        "f1": 0.5772216657446199,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5772216657446199,
        "precision": 0.5559001045527991,
        "recall": 0.6320691949434465
      },
      {
        "accuracy": 0.32801064537591484,
        "f1": 0.2679362097467064,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2679362097467064,
        "precision": 0.24694247406323255,
        "recall": 0.32801064537591484
      },
      {
        "accuracy": 0.6287425149700598,
        "f1": 0.5744019896714507,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5744019896714507,
        "precision": 0.552833486466221,
        "recall": 0.6287425149700598
      },
      {
        "accuracy": 0.6440452428476381,
        "f1": 0.5864503796639524,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5864503796639524,
        "precision": 0.5643794661758734,
        "recall": 0.6440452428476381
      },
      {
        "accuracy": 0.7079174983366601,
        "f1": 0.6574010708741248,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6574010708741248,
        "precision": 0.637178288924796,
        "recall": 0.7079174983366601
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002257526608824014,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002257526608824014,
        "precision": 0.0017333833282202201,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.709913506320692,
        "f1": 0.6555000296517262,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6555000296517262,
        "precision": 0.6343992390399575,
        "recall": 0.709913506320692
      },
      {
        "accuracy": 0.6520292747837658,
        "f1": 0.5974420714939677,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5974420714939677,
        "precision": 0.5767000390752886,
        "recall": 0.6520292747837658
      },
      {
        "accuracy": 0.6679973386560213,
        "f1": 0.6148458549656154,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6148458549656154,
        "precision": 0.5948507746411938,
        "recall": 0.6679973386560213
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0015449412805577669,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0015449412805577669,
        "precision": 0.0009365653567556308,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.44045242847638055,
        "f1": 0.3849150904540126,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3849150904540126,
        "precision": 0.36373628404566527,
        "recall": 0.44045242847638055
      },
      {
        "accuracy": 0.5921490352628077,
        "f1": 0.5373819460645808,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5373819460645808,
        "precision": 0.5158724878285756,
        "recall": 0.5921490352628077
      },
      {
        "accuracy": 0.6660013306719893,
        "f1": 0.6083956425772793,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6083956425772793,
        "precision": 0.5854539838072772,
        "recall": 0.6660013306719893
      },
      {
        "accuracy": 0.6906187624750499,
        "f1": 0.6415351836010519,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6415351836010519,
        "precision": 0.6225121186199031,
        "recall": 0.6906187624750499
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0037736832848798197,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0037736832848798197,
        "precision": 0.0032459576042126346,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0031089488887529673,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0031089488887529673,
        "precision": 0.002733379906535218,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0028658980602590174,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0028658980602590174,
        "precision": 0.0023901535954611677,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000942192792742794,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.000942192792742794,
        "precision": 0.0006232182647100295,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0021544150377222657,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0021544150377222657,
        "precision": 0.0018848726155514793,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002503906140563329,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.002503906140563329,
        "precision": 0.0021117118809047602,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028795107465448442,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0028795107465448442,
        "precision": 0.0024481940944616628,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0033511681390487364,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0033511681390487364,
        "precision": 0.0029188153090348693,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0018110693550295249,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0018110693550295249,
        "precision": 0.0013775058422829342,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0032218289709797857,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0032218289709797857,
        "precision": 0.0030558506021373393,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001387690416354842,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.001387690416354842,
        "precision": 0.0011506787597704926,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008813339317798026,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0008813339317798026,
        "precision": 0.0005823730142814891,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003251556453426095,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.003251556453426095,
        "precision": 0.002673183778421313,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.030523934789088693,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.030523934789088693,
        "precision": 0.025648123992923755,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0029704078156087177,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0029704078156087177,
        "precision": 0.0024382138560024844,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0023853877078742806,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0023853877078742806,
        "precision": 0.0020381830089621477,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.004420613428775522,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.004420613428775522,
        "precision": 0.003741078363518363,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002238090075462593,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.002238090075462593,
        "precision": 0.0019289428370544716,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0016493985119707597,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0016493985119707597,
        "precision": 0.0013240541382078996,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0015904151778493591,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0015904151778493591,
        "precision": 0.001091027723530129,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0026482228744371126,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0026482228744371126,
        "precision": 0.0022367986002814317,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0028019226689194134,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0028019226689194134,
        "precision": 0.0023387306386183186,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.5874916833000665,
        "f1": 0.5262326865121275,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5262326865121275,
        "precision": 0.503226927578225,
        "recall": 0.5874916833000665
      },
      {
        "accuracy": 0.6187624750499002,
        "f1": 0.5586784103750171,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5586784103750171,
        "precision": 0.5355896506096106,
        "recall": 0.6187624750499002
      },
      {
        "accuracy": 0.20159680638722555,
        "f1": 0.15334353254476496,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.15334353254476496,
        "precision": 0.13914591452016603,
        "recall": 0.20159680638722555
      },
      {
        "accuracy": 0.5961410512308716,
        "f1": 0.5428181155726066,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5428181155726066,
        "precision": 0.521863968071553,
        "recall": 0.5961410512308716
      },
      {
        "accuracy": 0.6640053226879574,
        "f1": 0.6105149157045365,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6105149157045365,
        "precision": 0.5903777341901094,
        "recall": 0.6640053226879574
      },
      {
        "accuracy": 0.4930139720558882,
        "f1": 0.4368964959783323,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4368964959783323,
        "precision": 0.41482332564873364,
        "recall": 0.4930139720558882
      },
      {
        "accuracy": 0.6327345309381237,
        "f1": 0.578109661093693,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.578109661093693,
        "precision": 0.5572584460708213,
        "recall": 0.6327345309381237
      },
      {
        "accuracy": 0.6340652029274784,
        "f1": 0.5762317116608534,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5762317116608534,
        "precision": 0.5543008813467895,
        "recall": 0.6340652029274784
      },
      {
        "accuracy": 0.573519627411843,
        "f1": 0.5182107646179502,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5182107646179502,
        "precision": 0.49732228664364386,
        "recall": 0.573519627411843
      },
      {
        "accuracy": 0.36793080505655357,
        "f1": 0.3074813816330782,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3074813816330782,
        "precision": 0.28593397620343725,
        "recall": 0.36793080505655357
      },
      {
        "accuracy": 0.5768463073852296,
        "f1": 0.5209300614739736,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5209300614739736,
        "precision": 0.4999068768079134,
        "recall": 0.5768463073852296
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.5114057599087539,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5114057599087539,
        "precision": 0.4902818349737206,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.6440452428476381,
        "f1": 0.58850768880709,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.58850768880709,
        "precision": 0.5677449814176362,
        "recall": 0.6440452428476381
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0016770214997345013,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0016770214997345013,
        "precision": 0.0011326480033808253,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.6380572188955422,
        "f1": 0.5835838134182622,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5835838134182622,
        "precision": 0.562612737487987,
        "recall": 0.6380572188955422
      },
      {
        "accuracy": 0.5948103792415169,
        "f1": 0.5385677566316289,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5385677566316289,
        "precision": 0.5171838695790791,
        "recall": 0.5948103792415169
      },
      {
        "accuracy": 0.6167664670658682,
        "f1": 0.5600741493140905,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5600741493140905,
        "precision": 0.5386590116600685,
        "recall": 0.6167664670658682
      },
      {
        "accuracy": 0.44644045242847635,
        "f1": 0.3833722461466972,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.3833722461466972,
        "precision": 0.3599053696359085,
        "recall": 0.44644045242847635
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.00173683164543549,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00173683164543549,
        "precision": 0.0011856584472222762,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.5429141716566867,
        "f1": 0.4866830847868772,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4866830847868772,
        "precision": 0.46582208358655464,
        "recall": 0.5429141716566867
      },
      {
        "accuracy": 0.6027944111776448,
        "f1": 0.5473183743143822,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5473183743143822,
        "precision": 0.5266875487933372,
        "recall": 0.6027944111776448
      },
      {
        "accuracy": 0.6500332667997338,
        "f1": 0.5962683247114385,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5962683247114385,
        "precision": 0.5760928740939308,
        "recall": 0.6500332667997338
      },
      {
        "accuracy": 0.8143712574850299,
        "f1": 0.7755261962846792,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7755261962846792,
        "precision": 0.7592481703260145,
        "recall": 0.8143712574850299
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8544910179640718,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8544910179640718,
        "precision": 0.8425223626820433,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.1377245508982036,
        "f1": 0.09379447767542497,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.09379447767542497,
        "precision": 0.0836139364222506,
        "recall": 0.1377245508982036
      },
      {
        "accuracy": 0.5741849634065203,
        "f1": 0.5088201183011561,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.5088201183011561,
        "precision": 0.4864432750660296,
        "recall": 0.5741849634065203
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8680987231885435,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8680987231885435,
        "precision": 0.8584682486878096,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.48531640043679897,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.48531640043679897,
        "precision": 0.46136979161850467,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.8729208250166334,
        "f1": 0.8478598358837881,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.8478598358837881,
        "precision": 0.8368226509943077,
        "recall": 0.8729208250166334
      },
      {
        "accuracy": 0.8795741849634066,
        "f1": 0.8533625057577152,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.8533625057577152,
        "precision": 0.8418559705984855,
        "recall": 0.8795741849634066
      },
      {
        "accuracy": 0.8070525615435795,
        "f1": 0.7669454741311029,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.7669454741311029,
        "precision": 0.7497079914245584,
        "recall": 0.8070525615435795
      },
      {
        "accuracy": 0.29141716566866266,
        "f1": 0.22624348605870553,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.22624348605870553,
        "precision": 0.20771319306748448,
        "recall": 0.29141716566866266
      },
      {
        "accuracy": 0.688622754491018,
        "f1": 0.6382301774517343,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.6382301774517343,
        "precision": 0.6180094836781463,
        "recall": 0.688622754491018
      },
      {
        "accuracy": 0.8456420492348636,
        "f1": 0.8145613534835091,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8145613534835091,
        "precision": 0.8006320691949433,
        "recall": 0.8456420492348636
      },
      {
        "accuracy": 0.8695941450432468,
        "f1": 0.843366177697515,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.843366177697515,
        "precision": 0.831775338212464,
        "recall": 0.8695941450432468
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0010318257162803364,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0010318257162803364,
        "precision": 0.0008830651504694365,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.8662674650698603,
        "f1": 0.8380128631625637,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8380128631625637,
        "precision": 0.8253603903304502,
        "recall": 0.8662674650698603
      },
      {
        "accuracy": 0.8516300731869594,
        "f1": 0.8233152742134777,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.8233152742134777,
        "precision": 0.8108370154278338,
        "recall": 0.8516300731869594
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8151142160124197,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.8151142160124197,
        "precision": 0.8005718721287582,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.47904191616766467,
        "f1": 0.4084838487699432,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.4084838487699432,
        "precision": 0.38533822199617546,
        "recall": 0.47904191616766467
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008996061361917885,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0008996061361917885,
        "precision": 0.0005873116593865765,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.4431137724550898,
        "f1": 0.37227590298291,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.37227590298291,
        "precision": 0.3497052277568644,
        "recall": 0.4431137724550898
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.8489148686753476,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8489148686753476,
        "precision": 0.8373253493013972,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8485932896112537,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.8485932896112537,
        "precision": 0.8371283887251952,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.863606121091151,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.863606121091151,
        "precision": 0.8514637391882901,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9187751481164653,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9187751481164653,
        "precision": 0.9121756487025948,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.1437125748502994,
        "f1": 0.09781041349462184,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.09781041349462184,
        "precision": 0.08803628194650649,
        "recall": 0.1437125748502994
      },
      {
        "accuracy": 0.64604125083167,
        "f1": 0.581566760658577,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.581566760658577,
        "precision": 0.5573480024078826,
        "recall": 0.64604125083167
      },
      {
        "accuracy": 0.9447771124417831,
        "f1": 0.9301618984253714,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9301618984253714,
        "precision": 0.9239188290086494,
        "recall": 0.9447771124417831
      },
      {
        "accuracy": 0.648037258815702,
        "f1": 0.5915230865829668,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.5915230865829668,
        "precision": 0.570599099737881,
        "recall": 0.648037258815702
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9064981148813485,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.9064981148813485,
        "precision": 0.8991350632069196,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9111998225770681,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9111998225770681,
        "precision": 0.9046019072965181,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.8702594810379242,
        "f1": 0.8394544244843645,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.8394544244843645,
        "precision": 0.8265469061876247,
        "recall": 0.8702594810379242
      },
      {
        "accuracy": 0.3439787092481703,
        "f1": 0.27454309299705193,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.27454309299705193,
        "precision": 0.2550992899586713,
        "recall": 0.3439787092481703
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.720252136419801,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.720252136419801,
        "precision": 0.7029016041990095,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.895542248835662,
        "f1": 0.8738427906092576,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8738427906092576,
        "precision": 0.8641605677533821,
        "recall": 0.895542248835662
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9063872255489023,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.9063872255489023,
        "precision": 0.8992237746728764,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0004012957459238147,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0004012957459238147,
        "precision": 0.00023662025968621873,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9177201153249058,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9177201153249058,
        "precision": 0.9103681525837214,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8957862053670438,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.8957862053670438,
        "precision": 0.8867487247726769,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8881031587618413,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8881031587618413,
        "precision": 0.8797848746950543,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.5402528276779773,
        "f1": 0.47517918051914,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.47517918051914,
        "precision": 0.4541060689513783,
        "recall": 0.5402528276779773
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010324755760713115,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0010324755760713115,
        "precision": 0.0006921618802508187,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.49700598802395207,
        "f1": 0.42968700545768024,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.42968700545768024,
        "precision": 0.40804460841885987,
        "recall": 0.49700598802395207
      },
      {
        "accuracy": 0.8789088489687292,
        "f1": 0.8548141811614866,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.8548141811614866,
        "precision": 0.8435573297848746,
        "recall": 0.8789088489687292
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9178088267908627,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9178088267908627,
        "precision": 0.9105344865823908,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.8996895098691506,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8996895098691506,
        "precision": 0.8916278554003105,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.957418496340652,
        "f1": 0.9461299622976269,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9461299622976269,
        "precision": 0.9409514304723886,
        "recall": 0.957418496340652
      },
      {
        "accuracy": 0.13572854291417166,
        "f1": 0.09437811128213135,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.09437811128213135,
        "precision": 0.08488135133265727,
        "recall": 0.13572854291417166
      },
      {
        "accuracy": 0.6793080505655356,
        "f1": 0.6162948901471855,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6162948901471855,
        "precision": 0.593663490719379,
        "recall": 0.6793080505655356
      },
      {
        "accuracy": 0.9753825681969395,
        "f1": 0.9688179197161234,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9688179197161234,
        "precision": 0.9659569749390108,
        "recall": 0.9753825681969395
      },
      {
        "accuracy": 0.64604125083167,
        "f1": 0.5834030487390435,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5834030487390435,
        "precision": 0.5614466343760951,
        "recall": 0.64604125083167
      },
      {
        "accuracy": 0.957418496340652,
        "f1": 0.9465735196274119,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9465735196274119,
        "precision": 0.9416389443335551,
        "recall": 0.957418496340652
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9489687292082502,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9489687292082502,
        "precision": 0.9445775116433799,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.850964737192282,
        "f1": 0.8179202921717891,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.8179202921717891,
        "precision": 0.8043297243896045,
        "recall": 0.850964737192282
      },
      {
        "accuracy": 0.3685961410512309,
        "f1": 0.3008615809699546,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.3008615809699546,
        "precision": 0.28215510211739475,
        "recall": 0.3685961410512309
      },
      {
        "accuracy": 0.8043912175648703,
        "f1": 0.7623615203455522,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7623615203455522,
        "precision": 0.7457774926337801,
        "recall": 0.8043912175648703
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8876912840984698,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8876912840984698,
        "precision": 0.8777888667110224,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.959414504324684,
        "f1": 0.9500332667997339,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9500332667997339,
        "precision": 0.9458305611000222,
        "recall": 0.959414504324684
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0012623902627858351,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0012623902627858351,
        "precision": 0.0010775843264541724,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.9580838323353293,
        "f1": 0.9489687292082502,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9489687292082502,
        "precision": 0.9450210689731647,
        "recall": 0.9580838323353293
      },
      {
        "accuracy": 0.9414504324683965,
        "f1": 0.9260811709913507,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9260811709913507,
        "precision": 0.9190396983810157,
        "recall": 0.9414504324683965
      },
      {
        "accuracy": 0.9507651363938789,
        "f1": 0.9395874916832999,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9395874916832999,
        "precision": 0.934519849190508,
        "recall": 0.9507651363938789
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.4656639586559932,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.4656639586559932,
        "precision": 0.44309815914107337,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0016857743763521252,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0016857743763521252,
        "precision": 0.001309118608611911,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.5043246839654025,
        "f1": 0.43722260430251336,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.43722260430251336,
        "precision": 0.4164180143554727,
        "recall": 0.5043246839654025
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8507572157272756,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8507572157272756,
        "precision": 0.840026296613123,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9173763583943224,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9173763583943224,
        "precision": 0.9101305325856224,
        "recall": 0.9341317365269461
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}