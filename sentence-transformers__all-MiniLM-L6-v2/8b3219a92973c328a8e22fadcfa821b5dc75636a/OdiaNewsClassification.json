{
  "dataset_revision": "ffb8a34c9637fb20256e8c7be02504d16af4bd6b",
  "evaluation_time": 9.211507081985474,
  "kg_co2_emissions": 0.0013479314899229838,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.543115234375,
        "f1": 0.5363623537701006,
        "f1_weighted": 0.5387102977840875,
        "hf_subset": "default",
        "languages": [
          "ory-Orya"
        ],
        "main_score": 0.5363623537701006,
        "scores_per_experiment": [
          {
            "accuracy": 0.58056640625,
            "f1": 0.5917855453864568,
            "f1_weighted": 0.5873943208099361
          },
          {
            "accuracy": 0.51318359375,
            "f1": 0.5080605158730158,
            "f1_weighted": 0.5188315255301339
          },
          {
            "accuracy": 0.5205078125,
            "f1": 0.5329380182195199,
            "f1_weighted": 0.5222997067689257
          },
          {
            "accuracy": 0.4951171875,
            "f1": 0.4762411458386547,
            "f1_weighted": 0.4882101332143867
          },
          {
            "accuracy": 0.6162109375,
            "f1": 0.5700145010704012,
            "f1_weighted": 0.58436933504068
          },
          {
            "accuracy": 0.591796875,
            "f1": 0.611897406525801,
            "f1_weighted": 0.5990566050009001
          },
          {
            "accuracy": 0.53271484375,
            "f1": 0.5063806993161531,
            "f1_weighted": 0.5127740853088285
          },
          {
            "accuracy": 0.50244140625,
            "f1": 0.49714230236092033,
            "f1_weighted": 0.4966970149783748
          },
          {
            "accuracy": 0.552734375,
            "f1": 0.5444119195010989,
            "f1_weighted": 0.5422641712562274
          },
          {
            "accuracy": 0.52587890625,
            "f1": 0.5247514836089853,
            "f1_weighted": 0.5352060799324823
          }
        ]
      }
    ]
  },
  "task_name": "OdiaNewsClassification"
}