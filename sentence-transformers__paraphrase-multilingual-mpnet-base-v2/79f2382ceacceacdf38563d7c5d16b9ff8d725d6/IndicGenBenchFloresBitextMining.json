{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 141.8774058818817,
  "kg_co2_emissions": 0.023978724725165622,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9337944664031621,
        "f1": 0.9160737812911726,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9160737812911726,
        "precision": 0.9080204216073782,
        "recall": 0.9337944664031621
      },
      {
        "accuracy": 0.9258893280632411,
        "f1": 0.9036561264822134,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9036561264822134,
        "precision": 0.8932806324110671,
        "recall": 0.9258893280632411
      },
      {
        "accuracy": 0.9614624505928854,
        "f1": 0.9516798418972332,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9516798418972332,
        "precision": 0.9478590250329381,
        "recall": 0.9614624505928854
      },
      {
        "accuracy": 0.9258893280632411,
        "f1": 0.9036749482401656,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9036749482401656,
        "precision": 0.8931982872200265,
        "recall": 0.9258893280632411
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.9973649538866931,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973649538866931,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733859,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9947299077733859,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.8389328063241107,
        "f1": 0.8056754839363535,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8056754839363535,
        "precision": 0.7914426877470355,
        "recall": 0.8389328063241107
      },
      {
        "accuracy": 0.8310276679841897,
        "f1": 0.7859542631281762,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.7859542631281762,
        "precision": 0.7662055335968381,
        "recall": 0.8310276679841897
      },
      {
        "accuracy": 0.9071146245059288,
        "f1": 0.8810606060606061,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.8810606060606061,
        "precision": 0.8698451910408432,
        "recall": 0.9071146245059288
      },
      {
        "accuracy": 0.9090909090909091,
        "f1": 0.8829710144927537,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8829710144927537,
        "precision": 0.8711627140974967,
        "recall": 0.9090909090909091
      },
      {
        "accuracy": 0.9436758893280632,
        "f1": 0.9313302639389595,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9313302639389595,
        "precision": 0.9262187088274044,
        "recall": 0.9436758893280632
      },
      {
        "accuracy": 0.9150197628458498,
        "f1": 0.8883399209486166,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.8883399209486166,
        "precision": 0.8754940711462451,
        "recall": 0.9150197628458498
      },
      {
        "accuracy": 0.9120553359683794,
        "f1": 0.8897233201581027,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8897233201581027,
        "precision": 0.8801406926406926,
        "recall": 0.9120553359683794
      },
      {
        "accuracy": 0.9110671936758893,
        "f1": 0.883893280632411,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.883893280632411,
        "precision": 0.8710474308300395,
        "recall": 0.9110671936758893
      },
      {
        "accuracy": 0.8705533596837944,
        "f1": 0.8381807202459376,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8381807202459376,
        "precision": 0.8249353002070392,
        "recall": 0.8705533596837944
      },
      {
        "accuracy": 0.8754940711462451,
        "f1": 0.8395750988142291,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8395750988142291,
        "precision": 0.823346038019951,
        "recall": 0.8754940711462451
      },
      {
        "accuracy": 0.9782608695652174,
        "f1": 0.9713438735177866,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9713438735177866,
        "precision": 0.9680500658761529,
        "recall": 0.9782608695652174
      },
      {
        "accuracy": 0.9812252964426877,
        "f1": 0.975691699604743,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.975691699604743,
        "precision": 0.973237812911726,
        "recall": 0.9812252964426877
      },
      {
        "accuracy": 0.5335968379446641,
        "f1": 0.47452290433663524,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.47452290433663524,
        "precision": 0.454112340228941,
        "recall": 0.5335968379446641
      },
      {
        "accuracy": 0.5662055335968379,
        "f1": 0.48503520524271515,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.48503520524271515,
        "precision": 0.4542517923446777,
        "recall": 0.5662055335968379
      },
      {
        "accuracy": 0.9426877470355731,
        "f1": 0.9245718050065875,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9245718050065875,
        "precision": 0.9158432147562583,
        "recall": 0.9426877470355731
      },
      {
        "accuracy": 0.9140316205533597,
        "f1": 0.8882411067193675,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.8882411067193675,
        "precision": 0.8762351778656127,
        "recall": 0.9140316205533597
      },
      {
        "accuracy": 0.9851778656126482,
        "f1": 0.9805665349143611,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9805665349143611,
        "precision": 0.9782608695652174,
        "recall": 0.9851778656126482
      },
      {
        "accuracy": 0.9762845849802372,
        "f1": 0.9691040843214757,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9691040843214757,
        "precision": 0.9656620553359684,
        "recall": 0.9762845849802372
      },
      {
        "accuracy": 0.8428853754940712,
        "f1": 0.8011693017127799,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.8011693017127799,
        "precision": 0.7828322040278561,
        "recall": 0.8428853754940712
      },
      {
        "accuracy": 0.8626482213438735,
        "f1": 0.8245247506117072,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.8245247506117072,
        "precision": 0.8073122529644269,
        "recall": 0.8626482213438735
      },
      {
        "accuracy": 0.8675889328063241,
        "f1": 0.830961791831357,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.830961791831357,
        "precision": 0.8149209486166007,
        "recall": 0.8675889328063241
      },
      {
        "accuracy": 0.8853754940711462,
        "f1": 0.8525691699604743,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8525691699604743,
        "precision": 0.8380434782608694,
        "recall": 0.8853754940711462
      },
      {
        "accuracy": 0.8715415019762845,
        "f1": 0.8363965744400528,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8363965744400528,
        "precision": 0.8208168642951252,
        "recall": 0.8715415019762845
      },
      {
        "accuracy": 0.8547430830039525,
        "f1": 0.8145915678524375,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.8145915678524375,
        "precision": 0.7963603425559946,
        "recall": 0.8547430830039525
      },
      {
        "accuracy": 0.7450592885375494,
        "f1": 0.6929819082981138,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6929819082981138,
        "precision": 0.6727047870500354,
        "recall": 0.7450592885375494
      },
      {
        "accuracy": 0.7579051383399209,
        "f1": 0.696395633352155,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.696395633352155,
        "precision": 0.6696805006587616,
        "recall": 0.7579051383399209
      },
      {
        "accuracy": 0.9772727272727273,
        "f1": 0.9705204216073781,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9705204216073781,
        "precision": 0.9672266139657443,
        "recall": 0.9772727272727273
      },
      {
        "accuracy": 0.9693675889328063,
        "f1": 0.9606389986824769,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9606389986824769,
        "precision": 0.9563570487483531,
        "recall": 0.9693675889328063
      },
      {
        "accuracy": 0.9713438735177866,
        "f1": 0.9624505928853755,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9624505928853755,
        "precision": 0.9582015810276681,
        "recall": 0.9713438735177866
      },
      {
        "accuracy": 0.9555335968379447,
        "f1": 0.9420948616600792,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9420948616600792,
        "precision": 0.9358530961791832,
        "recall": 0.9555335968379447
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.022170848217116526,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.022170848217116526,
        "precision": 0.02143896260744087,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.0533596837944664,
        "f1": 0.01718501699373453,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.01718501699373453,
        "precision": 0.013078507742015414,
        "recall": 0.0533596837944664
      },
      {
        "accuracy": 0.09288537549407115,
        "f1": 0.07394048483541192,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07394048483541192,
        "precision": 0.06997086821633301,
        "recall": 0.09288537549407115
      },
      {
        "accuracy": 0.12648221343873517,
        "f1": 0.07270867253080691,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.07270867253080691,
        "precision": 0.06126861575278525,
        "recall": 0.12648221343873517
      },
      {
        "accuracy": 0.9624505928853755,
        "f1": 0.9504281949934124,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9504281949934124,
        "precision": 0.9446640316205533,
        "recall": 0.9624505928853755
      },
      {
        "accuracy": 0.950592885375494,
        "f1": 0.9346179183135704,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9346179183135704,
        "precision": 0.9268774703557312,
        "recall": 0.950592885375494
      },
      {
        "accuracy": 0.7233201581027668,
        "f1": 0.671282103091566,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.671282103091566,
        "precision": 0.651143557529427,
        "recall": 0.7233201581027668
      },
      {
        "accuracy": 0.7282608695652174,
        "f1": 0.6634387351778656,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6634387351778656,
        "precision": 0.6356358617228183,
        "recall": 0.7282608695652174
      },
      {
        "accuracy": 0.9525691699604744,
        "f1": 0.9379117259552042,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9379117259552042,
        "precision": 0.9308300395256917,
        "recall": 0.9525691699604744
      },
      {
        "accuracy": 0.9337944664031621,
        "f1": 0.9132740447957839,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9132740447957839,
        "precision": 0.9035737812911726,
        "recall": 0.9337944664031621
      },
      {
        "accuracy": 0.9604743083003953,
        "f1": 0.948517786561265,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.948517786561265,
        "precision": 0.942770092226614,
        "recall": 0.9604743083003953
      },
      {
        "accuracy": 0.9426877470355731,
        "f1": 0.924407114624506,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.924407114624506,
        "precision": 0.9155138339920948,
        "recall": 0.9426877470355731
      },
      {
        "accuracy": 0.958498023715415,
        "f1": 0.9455533596837945,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9455533596837945,
        "precision": 0.9394762845849802,
        "recall": 0.958498023715415
      },
      {
        "accuracy": 0.9525691699604744,
        "f1": 0.9388010540184453,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9388010540184453,
        "precision": 0.9325592885375494,
        "recall": 0.9525691699604744
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.030875062468765615,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.030875062468765615,
        "precision": 0.030184825192997027,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.06719367588932806,
        "f1": 0.03510133006457913,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.03510133006457913,
        "precision": 0.029987168236487467,
        "recall": 0.06719367588932806
      },
      {
        "accuracy": 0.9654150197628458,
        "f1": 0.9547101449275361,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9547101449275361,
        "precision": 0.9497694334650856,
        "recall": 0.9654150197628458
      },
      {
        "accuracy": 0.9515810276679841,
        "f1": 0.936429512516469,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.936429512516469,
        "precision": 0.9290184453227932,
        "recall": 0.9515810276679841
      },
      {
        "accuracy": 0.9752964426877471,
        "f1": 0.967391304347826,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.967391304347826,
        "precision": 0.9636034255599474,
        "recall": 0.9752964426877471
      },
      {
        "accuracy": 0.9496047430830039,
        "f1": 0.9340250329380765,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9340250329380765,
        "precision": 0.9264657444005271,
        "recall": 0.9496047430830039
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.007675699282196392,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.007675699282196392,
        "precision": 0.0074631917920200425,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.004866061846505284,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.004866061846505284,
        "precision": 0.003474880481376388,
        "recall": 0.021739130434782608
      }
    ],
    "validation": [
      {
        "accuracy": 0.9227683049147443,
        "f1": 0.8995987963891675,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.8995987963891675,
        "precision": 0.8885824139083918,
        "recall": 0.9227683049147443
      },
      {
        "accuracy": 0.9207622868605817,
        "f1": 0.8966900702106319,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.8966900702106319,
        "precision": 0.8854898027415581,
        "recall": 0.9207622868605817
      },
      {
        "accuracy": 0.9538615847542627,
        "f1": 0.9434661126235852,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9434661126235852,
        "precision": 0.9393219340561366,
        "recall": 0.9538615847542627
      },
      {
        "accuracy": 0.9488465396188566,
        "f1": 0.9327983951855566,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9327983951855566,
        "precision": 0.9249414911400871,
        "recall": 0.9488465396188566
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9908057505850887,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9908057505850887,
        "precision": 0.9898027415580074,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.839518555667001,
        "f1": 0.8064455270573626,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8064455270573626,
        "precision": 0.7930159850376381,
        "recall": 0.839518555667001
      },
      {
        "accuracy": 0.8555667001003009,
        "f1": 0.8126713473754598,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.8126713473754598,
        "precision": 0.7932129722500836,
        "recall": 0.8555667001003009
      },
      {
        "accuracy": 0.9077231695085256,
        "f1": 0.8801404212637913,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.8801404212637913,
        "precision": 0.8673019057171515,
        "recall": 0.9077231695085256
      },
      {
        "accuracy": 0.9187562688064193,
        "f1": 0.8947509194249416,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8947509194249416,
        "precision": 0.8834002006018055,
        "recall": 0.9187562688064193
      },
      {
        "accuracy": 0.9368104312938816,
        "f1": 0.9254198492914641,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9254198492914641,
        "precision": 0.9205850885991307,
        "recall": 0.9368104312938816
      },
      {
        "accuracy": 0.917753259779338,
        "f1": 0.892744901370779,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.892744901370779,
        "precision": 0.8810598462052824,
        "recall": 0.917753259779338
      },
      {
        "accuracy": 0.9187562688064193,
        "f1": 0.8973253092611168,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8973253092611168,
        "precision": 0.8876964226011367,
        "recall": 0.9187562688064193
      },
      {
        "accuracy": 0.9277833500501504,
        "f1": 0.9054496823804747,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9054496823804747,
        "precision": 0.8946004680708793,
        "recall": 0.9277833500501504
      },
      {
        "accuracy": 0.9017051153460381,
        "f1": 0.8737211634904714,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8737211634904714,
        "precision": 0.8614510197258441,
        "recall": 0.9017051153460381
      },
      {
        "accuracy": 0.9087261785356068,
        "f1": 0.8813774657305249,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8813774657305249,
        "precision": 0.868689401537947,
        "recall": 0.9087261785356068
      },
      {
        "accuracy": 0.9819458375125376,
        "f1": 0.9760949515212303,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9760949515212303,
        "precision": 0.9732530926111668,
        "recall": 0.9819458375125376
      },
      {
        "accuracy": 0.9759277833500501,
        "f1": 0.9686392510865931,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9686392510865931,
        "precision": 0.9653126044801069,
        "recall": 0.9759277833500501
      },
      {
        "accuracy": 0.5366098294884654,
        "f1": 0.47666240157397843,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.47666240157397843,
        "precision": 0.45636388296869734,
        "recall": 0.5366098294884654
      },
      {
        "accuracy": 0.571715145436309,
        "f1": 0.4887543583130344,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.4887543583130344,
        "precision": 0.45613550608535564,
        "recall": 0.571715145436309
      },
      {
        "accuracy": 0.9388164493480441,
        "f1": 0.920093614175861,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.920093614175861,
        "precision": 0.9110665329321297,
        "recall": 0.9388164493480441
      },
      {
        "accuracy": 0.9017051153460381,
        "f1": 0.8732865262454028,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.8732865262454028,
        "precision": 0.8599465061852224,
        "recall": 0.9017051153460381
      },
      {
        "accuracy": 0.9829488465396189,
        "f1": 0.9779338014042126,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9779338014042126,
        "precision": 0.9754262788365096,
        "recall": 0.9829488465396189
      },
      {
        "accuracy": 0.9829488465396189,
        "f1": 0.9777666332330324,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9777666332330324,
        "precision": 0.9752591106653293,
        "recall": 0.9829488465396189
      },
      {
        "accuracy": 0.8555667001003009,
        "f1": 0.8160003820986769,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.8160003820986769,
        "precision": 0.798462052825142,
        "recall": 0.8555667001003009
      },
      {
        "accuracy": 0.8565697091273822,
        "f1": 0.8159478435305918,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.8159478435305918,
        "precision": 0.797509194249415,
        "recall": 0.8565697091273822
      },
      {
        "accuracy": 0.8816449348044132,
        "f1": 0.847509194249415,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.847509194249415,
        "precision": 0.8318288197927114,
        "recall": 0.8816449348044132
      },
      {
        "accuracy": 0.9027081243731193,
        "f1": 0.8738548980274156,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8738548980274156,
        "precision": 0.8603309929789368,
        "recall": 0.9027081243731193
      },
      {
        "accuracy": 0.8525576730190572,
        "f1": 0.8148779672350385,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8148779672350385,
        "precision": 0.7985122032764962,
        "recall": 0.8525576730190572
      },
      {
        "accuracy": 0.8495486459378134,
        "f1": 0.805616850551655,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.805616850551655,
        "precision": 0.7856068204613842,
        "recall": 0.8495486459378134
      },
      {
        "accuracy": 0.7121364092276831,
        "f1": 0.6694490397599725,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6694490397599725,
        "precision": 0.6540670351603151,
        "recall": 0.7121364092276831
      },
      {
        "accuracy": 0.7412236710130391,
        "f1": 0.6792958239798761,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.6792958239798761,
        "precision": 0.6537959115441562,
        "recall": 0.7412236710130391
      },
      {
        "accuracy": 0.9809428284854563,
        "f1": 0.9754262788365096,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9754262788365096,
        "precision": 0.9727515880976263,
        "recall": 0.9809428284854563
      },
      {
        "accuracy": 0.9699097291875627,
        "f1": 0.9612169842861918,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9612169842861918,
        "precision": 0.9570377800066868,
        "recall": 0.9699097291875627
      },
      {
        "accuracy": 0.9749247743229689,
        "f1": 0.9667335339351388,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9667335339351388,
        "precision": 0.9627214978268137,
        "recall": 0.9749247743229689
      },
      {
        "accuracy": 0.9648946840521565,
        "f1": 0.9536944165830826,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9536944165830826,
        "precision": 0.948345035105316,
        "recall": 0.9648946840521565
      },
      {
        "accuracy": 0.025075225677031094,
        "f1": 0.020581712133098968,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.020581712133098968,
        "precision": 0.01956431408879663,
        "recall": 0.025075225677031094
      },
      {
        "accuracy": 0.05416248746238716,
        "f1": 0.014660303006891955,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.014660303006891955,
        "precision": 0.010403283356359434,
        "recall": 0.05416248746238716
      },
      {
        "accuracy": 0.11434302908726178,
        "f1": 0.09146141119492437,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09146141119492437,
        "precision": 0.08675887363988019,
        "recall": 0.11434302908726178
      },
      {
        "accuracy": 0.14543630892678033,
        "f1": 0.08881073869781411,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.08881073869781411,
        "precision": 0.07434966961045196,
        "recall": 0.14543630892678033
      },
      {
        "accuracy": 0.9478435305917753,
        "f1": 0.9311267134737545,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9311267134737545,
        "precision": 0.9231026412571046,
        "recall": 0.9478435305917753
      },
      {
        "accuracy": 0.9358074222668004,
        "f1": 0.9164159144098964,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9164159144098964,
        "precision": 0.9072216649949849,
        "recall": 0.9358074222668004
      },
      {
        "accuracy": 0.7251755265797393,
        "f1": 0.6797453042889351,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6797453042889351,
        "precision": 0.6614271385585326,
        "recall": 0.7251755265797393
      },
      {
        "accuracy": 0.728184553660983,
        "f1": 0.6640110808616325,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6640110808616325,
        "precision": 0.6364784830682523,
        "recall": 0.728184553660983
      },
      {
        "accuracy": 0.9388164493480441,
        "f1": 0.9200458518412379,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9200458518412379,
        "precision": 0.9110665329321298,
        "recall": 0.9388164493480441
      },
      {
        "accuracy": 0.9307923771313942,
        "f1": 0.9102306920762286,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9102306920762286,
        "precision": 0.9003677699765965,
        "recall": 0.9307923771313942
      },
      {
        "accuracy": 0.9498495486459378,
        "f1": 0.9348044132397192,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9348044132397192,
        "precision": 0.9276161818789703,
        "recall": 0.9498495486459378
      },
      {
        "accuracy": 0.9207622868605817,
        "f1": 0.8974256101638248,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.8974256101638248,
        "precision": 0.8864092276830492,
        "recall": 0.9207622868605817
      },
      {
        "accuracy": 0.9658976930792377,
        "f1": 0.9551989301237044,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9551989301237044,
        "precision": 0.950016716817118,
        "recall": 0.9658976930792377
      },
      {
        "accuracy": 0.954864593781344,
        "f1": 0.9401537947174857,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9401537947174857,
        "precision": 0.932965563356737,
        "recall": 0.954864593781344
      },
      {
        "accuracy": 0.03911735205616851,
        "f1": 0.031571549332968234,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.031571549332968234,
        "precision": 0.030516551753250343,
        "recall": 0.03911735205616851
      },
      {
        "accuracy": 0.06920762286860582,
        "f1": 0.035016096987981436,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.035016096987981436,
        "precision": 0.02944401803479035,
        "recall": 0.06920762286860582
      },
      {
        "accuracy": 0.9689067201604814,
        "f1": 0.9596121698428619,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9596121698428619,
        "precision": 0.9552825142092947,
        "recall": 0.9689067201604814
      },
      {
        "accuracy": 0.9458375125376128,
        "f1": 0.9288532263457037,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9288532263457037,
        "precision": 0.9206787027749918,
        "recall": 0.9458375125376128
      },
      {
        "accuracy": 0.9598796389167502,
        "f1": 0.9471748579070546,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9471748579070546,
        "precision": 0.941156803744567,
        "recall": 0.9598796389167502
      },
      {
        "accuracy": 0.9428284854563691,
        "f1": 0.9254429956536275,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9254429956536275,
        "precision": 0.9172517552657974,
        "recall": 0.9428284854563691
      },
      {
        "accuracy": 0.006018054162487462,
        "f1": 0.00434840695175452,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.00434840695175452,
        "precision": 0.0040130543916012,
        "recall": 0.006018054162487462
      },
      {
        "accuracy": 0.013039117352056168,
        "f1": 0.001127285209658913,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.001127285209658913,
        "precision": 0.0006195491055663584,
        "recall": 0.013039117352056168
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}