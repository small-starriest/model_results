{
  "dataset_revision": "5b740b7c42c73d586420812a35745fc37118862f",
  "evaluation_time": 9.732762575149536,
  "kg_co2_emissions": 0.0014292994850135532,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.4669921875,
        "f1": 0.45288274837442877,
        "f1_weighted": 0.47485129717856944,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ],
        "main_score": 0.4669921875,
        "scores_per_experiment": [
          {
            "accuracy": 0.44677734375,
            "f1": 0.44485073103812284,
            "f1_weighted": 0.4551516387471919
          },
          {
            "accuracy": 0.4404296875,
            "f1": 0.41010881159367735,
            "f1_weighted": 0.44344109824856315
          },
          {
            "accuracy": 0.486328125,
            "f1": 0.4810447530864197,
            "f1_weighted": 0.5011720190594092
          },
          {
            "accuracy": 0.48779296875,
            "f1": 0.4697463896209842,
            "f1_weighted": 0.49572573061219954
          },
          {
            "accuracy": 0.44482421875,
            "f1": 0.44108956336810284,
            "f1_weighted": 0.45260717495206837
          },
          {
            "accuracy": 0.47802734375,
            "f1": 0.45487304754185454,
            "f1_weighted": 0.4851720579100239
          },
          {
            "accuracy": 0.494140625,
            "f1": 0.4812890332092494,
            "f1_weighted": 0.5112274970678862
          },
          {
            "accuracy": 0.46240234375,
            "f1": 0.4438475879447103,
            "f1_weighted": 0.4729291983342838
          },
          {
            "accuracy": 0.44921875,
            "f1": 0.4407239763665068,
            "f1_weighted": 0.45657389857137576
          },
          {
            "accuracy": 0.47998046875,
            "f1": 0.4612535899746593,
            "f1_weighted": 0.474512658282692
          }
        ]
      }
    ]
  },
  "task_name": "NoRecClassification"
}