{
    "mteb_version": "0.0.2",
    "test": {
        "de": {
            "accuracy": 0.6126796280642435,
            "accuracy_stderr": 0.014136407614470803,
            "f1": 0.4454895811169869,
            "f1_stderr": 0.008525289336150727,
            "main_score": 0.6126796280642435
        },
        "en": {
            "accuracy": 0.6869129046967625,
            "accuracy_stderr": 0.006786383997161402,
            "f1": 0.5215845117562401,
            "f1_stderr": 0.009121528047047888,
            "main_score": 0.6869129046967625
        },
        "es": {
            "accuracy": 0.6659106070713809,
            "accuracy_stderr": 0.01147955106551365,
            "f1": 0.4556629396458189,
            "f1_stderr": 0.008120826136162898,
            "main_score": 0.6659106070713809
        },
        "evaluation_time": 129.54,
        "fr": {
            "accuracy": 0.5975884747886001,
            "accuracy_stderr": 0.019614215014588928,
            "f1": 0.4543239345676994,
            "f1_stderr": 0.015662580513560783,
            "main_score": 0.5975884747886001
        },
        "hi": {
            "accuracy": 0.6237361061312298,
            "accuracy_stderr": 0.02083193193796549,
            "f1": 0.4435346627839107,
            "f1_stderr": 0.012166138389245448,
            "main_score": 0.6237361061312298
        },
        "th": {
            "accuracy": 0.6480289330922242,
            "accuracy_stderr": 0.013641768890697905,
            "f1": 0.48201423606418,
            "f1_stderr": 0.012811669091272992,
            "main_score": 0.6480289330922242
        }
    },
    "mteb_dataset_name": "MTOPIntentClassification",
    "dataset_revision": "6299947a7777084cc2d4b64235bf7190381ce755"
}