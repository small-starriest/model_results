{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 25.935852527618408,
  "kg_co2_emissions": 0.004382264269376984,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.111328125,
        "f1": 0.0752542867288961,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.0752542867288961,
        "precision": 0.06601462316922843,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003800284025961131,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.003800284025961131,
        "precision": 0.002829475275380835,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003350770248668956,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.003350770248668956,
        "precision": 0.002775016387314933,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.785737376309299e-06,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 8.785737376309299e-06,
        "precision": 4.402901170021765e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007974960274908575,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.007974960274908575,
        "precision": 0.007198715957633597,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004941819805474264,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.004941819805474264,
        "precision": 0.004587538410764999,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006160338081861958,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.006160338081861958,
        "precision": 0.005737556796572469,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019766850120627263,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.00019766850120627263,
        "precision": 0.00010968636775362319,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00019078985054071101,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.00019078985054071101,
        "precision": 0.00010430007611621964,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.0045386036622673135,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0045386036622673135,
        "precision": 0.003296607943361715,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029516989087301584,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0029516989087301584,
        "precision": 0.0022928749894354293,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005535587576956176,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.005535587576956176,
        "precision": 0.004982679269803397,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029658292867585628,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0029658292867585628,
        "precision": 0.0025513610143776473,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004090547133824272,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.004090547133824272,
        "precision": 0.0032103181027713277,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0034036808790545202,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0034036808790545202,
        "precision": 0.002892636877011877,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026119480411686585,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0026119480411686585,
        "precision": 0.0024453125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.00796622810782967,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.00796622810782967,
        "precision": 0.006458760657979408,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9073486328125e-06,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9073486328125e-06,
        "precision": 9.546065493646139e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005883284420265971,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.005883284420265971,
        "precision": 0.0052645136624047,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0020486058266819982,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0020486058266819982,
        "precision": 0.0020015486123006357,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0050571298693293885,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0050571298693293885,
        "precision": 0.004725864955357143,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.765625e-05,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 9.765625e-05,
        "precision": 5.139802631578947e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.04903289921622753,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.04903289921622753,
        "precision": 0.04531273895525656,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00374824698817332,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.00374824698817332,
        "precision": 0.003384875099029511,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005174997070750691,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.005174997070750691,
        "precision": 0.004475265716519647,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.7924757281553396e-06,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 3.7924757281553396e-06,
        "precision": 1.8999270428015564e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.00823181957791478,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.00823181957791478,
        "precision": 0.0070523078492584065,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.358846618357488e-06,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 2.358846618357488e-06,
        "precision": 1.1808494558645707e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005046415509241445,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.005046415509241445,
        "precision": 0.004057870727720104,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1920594837261506e-06,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 2.1920594837261506e-06,
        "precision": 1.0972612359550563e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010275937265871277,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0010275937265871277,
        "precision": 0.0010024996758522704,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008134254789630951,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.008134254789630951,
        "precision": 0.007121810296505318,
        "recall": 0.015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000494328076625387,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.000494328076625387,
        "precision": 0.0003285536361283644,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0075016279324705065,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0075016279324705065,
        "precision": 0.00660073532462796,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015745192198222163,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0015745192198222163,
        "precision": 0.001122263967189154,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.005741787921751407,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.005741787921751407,
        "precision": 0.004249791186810781,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009892451298701298,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0009892451298701298,
        "precision": 0.0009829452614379085,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008451491425486566,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.008451491425486566,
        "precision": 0.007992739853934724,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9054878048780488e-06,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9054878048780488e-06,
        "precision": 9.5367431640625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006042744371386375,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.006042744371386375,
        "precision": 0.00539206941526829,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002452695989884393,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.002452695989884393,
        "precision": 0.002284323522286822,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009797486745513867,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0009797486745513867,
        "precision": 0.0009781581903594771,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001974134306198192,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.001974134306198192,
        "precision": 0.001963669988252441,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016778555508060577,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0016778555508060577,
        "precision": 0.0014163202567959,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023731376148368333,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0023731376148368333,
        "precision": 0.0021763341043097716,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2880859375,
        "f1": 0.2642371389843816,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2642371389843816,
        "precision": 0.25591459728422616,
        "recall": 0.2880859375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0056988777640981075,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0056988777640981075,
        "precision": 0.00469120280444804,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.23242070646367521,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.23242070646367521,
        "precision": 0.22272463672969187,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.012491945729947962,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.012491945729947962,
        "precision": 0.010263499879776884,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.287109375,
        "f1": 0.2560532902695913,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2560532902695913,
        "precision": 0.246450871609563,
        "recall": 0.287109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 4.970373483649789e-05,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 4.970373483649789e-05,
        "precision": 2.5172394320765e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.12128331942606428,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12128331942606428,
        "precision": 0.11172858407093897,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04802788494232536,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.04802788494232536,
        "precision": 0.04259410573533391,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.07828367093597471,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07828367093597471,
        "precision": 0.07006418661017122,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04636932971032236,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04636932971032236,
        "precision": 0.040761337713170205,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004082940435419017,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004082940435419017,
        "precision": 0.003588336489425997,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03995756305326617,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.03995756305326617,
        "precision": 0.03563139063627345,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002650383949390279,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002650383949390279,
        "precision": 0.0023336909773327263,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.11690873838667025,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.11690873838667025,
        "precision": 0.11096360114000403,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.02934121302902142,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.02934121302902142,
        "precision": 0.026505458772554145,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008830442266949153,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008830442266949153,
        "precision": 0.0005717348394373672,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.25497440193844145,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.25497440193844145,
        "precision": 0.2439652104080815,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.07112339413978787,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07112339413978787,
        "precision": 0.06628267505819371,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.10871211293960059,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.10871211293960059,
        "precision": 0.10120543617311588,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.12808009378449076,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.12808009378449076,
        "precision": 0.12095744931511132,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004103492133805842,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.004103492133805842,
        "precision": 0.0033653226934173336,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0058858996272152415,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0058858996272152415,
        "precision": 0.005245916499525534,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.2978515625,
        "f1": 0.2670563128277972,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2670563128277972,
        "precision": 0.25754595249224155,
        "recall": 0.2978515625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003941478738401855,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003941478738401855,
        "precision": 0.003255468465538883,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.3095703125,
        "f1": 0.27322886522362266,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.27322886522362266,
        "precision": 0.2614887752107633,
        "recall": 0.3095703125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.01617843371878602,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01617843371878602,
        "precision": 0.013603492504383318,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.4423828125,
        "f1": 0.3866182033401524,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3866182033401524,
        "precision": 0.3680183531746032,
        "recall": 0.4423828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015104558394370038,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0015104558394370038,
        "precision": 0.001285129123263889,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.12637487377539017,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12637487377539017,
        "precision": 0.11590241709679945,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.1961210176542208,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1961210176542208,
        "precision": 0.17874379485276773,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08142783494602984,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08142783494602984,
        "precision": 0.07346208840349465,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07340544465300325,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07340544465300325,
        "precision": 0.06557552017245188,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002727456462808025,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002727456462808025,
        "precision": 0.0019422202836059744,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.14221430967036436,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.14221430967036436,
        "precision": 0.13070620467338367,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0014632610244332844,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0014632610244332844,
        "precision": 0.00124204272759773,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.1323708500392764,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1323708500392764,
        "precision": 0.12452352449523915,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.02206326524046475,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.02206326524046475,
        "precision": 0.019513098812320245,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016465037719633308,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0016465037719633308,
        "precision": 0.001401795504385965,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.359375,
        "f1": 0.3205779372308978,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3205779372308978,
        "precision": 0.3077234604779412,
        "recall": 0.359375
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.09170155530397595,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.09170155530397595,
        "precision": 0.08547884435293515,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.10920491871568472,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.10920491871568472,
        "precision": 0.10055061312385531,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.1406645215263352,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.1406645215263352,
        "precision": 0.13209361015423518,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004650297619047619,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0004650297619047619,
        "precision": 0.0002616992065353346,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001542202594408665,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.001542202594408665,
        "precision": 0.001294223135228871,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.033892685244170294,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.033892685244170294,
        "precision": 0.028879190311121315,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.03026628226881707,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.03026628226881707,
        "precision": 0.025440696200600982,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.034485860445657754,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.034485860445657754,
        "precision": 0.030472665525794453,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004322535065872959,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.004322535065872959,
        "precision": 0.0028295425338961126,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.03482840178612237,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.03482840178612237,
        "precision": 0.028710142786234086,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012917258522727273,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0012917258522727273,
        "precision": 0.000841703869047619,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.020895935151991254,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.020895935151991254,
        "precision": 0.015841470297739135,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004395207798315814,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.004395207798315814,
        "precision": 0.003052781118338184,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02259399590210137,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.02259399590210137,
        "precision": 0.018377316654083573,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030924479166666665,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0030924479166666665,
        "precision": 0.0020899564844877347,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013191656766033026,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0013191656766033026,
        "precision": 0.001158117435023863,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003255208333333333,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0022135416666666666,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007495623950702075,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0007495623950702075,
        "precision": 0.0004209743107769424,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.0320146612931306,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.0320146612931306,
        "precision": 0.026961608599284995,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007246508629493464,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.007246508629493464,
        "precision": 0.006335152876254668,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0014288933722527474,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0014288933722527474,
        "precision": 0.0008647433474467942,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.03574016991656124,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.03574016991656124,
        "precision": 0.03066428552792893,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.015260839402975453,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.015260839402975453,
        "precision": 0.012818332718486584,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.02466269974804282,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.02466269974804282,
        "precision": 0.02024217996568093,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02822403663658774,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.02822403663658774,
        "precision": 0.023468964032928877,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004229736328125,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.004229736328125,
        "precision": 0.00372719951361955,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.008176977638058129,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.008176977638058129,
        "precision": 0.0070769542639778915,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.2783203125,
        "f1": 0.24057834924430252,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.24057834924430252,
        "precision": 0.22920791197705226,
        "recall": 0.2783203125
      },
      {
        "accuracy": 0.337890625,
        "f1": 0.2999867049183455,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2999867049183455,
        "precision": 0.2869990216138539,
        "recall": 0.337890625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0075216870171081664,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0075216870171081664,
        "precision": 0.006695182497204683,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01854496615399031,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01854496615399031,
        "precision": 0.015680019700790703,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.3388671875,
        "f1": 0.2960581681773088,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2960581681773088,
        "precision": 0.2828921601784653,
        "recall": 0.3388671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016247051639949458,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0016247051639949458,
        "precision": 0.0011615150999091735,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.1130743146676147,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1130743146676147,
        "precision": 0.10247180094169793,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.12496160523504274,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.12496160523504274,
        "precision": 0.11121060344118708,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.07635385968623559,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07635385968623559,
        "precision": 0.06880383613782051,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.333984375,
        "f1": 0.2661745101686508,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2661745101686508,
        "precision": 0.24074009486607145,
        "recall": 0.333984375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0023432486143848356,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0023432486143848356,
        "precision": 0.0018030635495242574,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.11127208295177043,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.11127208295177043,
        "precision": 0.09962387505901982,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0023551638473325144,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0023551638473325144,
        "precision": 0.002175319195269757,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.1191652041538166,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1191652041538166,
        "precision": 0.11255915821135744,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.055300316429652,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.055300316429652,
        "precision": 0.04914612066280839,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011727595644120147,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011727595644120147,
        "precision": 0.0010836050417795844,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.333984375,
        "f1": 0.29370088633040936,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.29370088633040936,
        "precision": 0.28096479258588636,
        "recall": 0.333984375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08314773876297313,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.08314773876297313,
        "precision": 0.07701452288037025,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.09959443183102999,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09959443183102999,
        "precision": 0.09134622671406525,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.11007556301905709,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.11007556301905709,
        "precision": 0.10180327375598391,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016299744639967637,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.0016299744639967637,
        "precision": 0.0014660303386998786,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012390377964426877,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0012390377964426877,
        "precision": 0.0011186079545454546,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.014605479156260405,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.014605479156260405,
        "precision": 0.013949625739210906,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.01573082154654463,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.01573082154654463,
        "precision": 0.01540133071407017,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016317333949964763,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.0016317333949964763,
        "precision": 0.0014669127383474577,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01648515441984835,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.01648515441984835,
        "precision": 0.015168626252216075,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018827223322574336,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.018827223322574336,
        "precision": 0.0181321670559138,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.1292699306285014,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.1292699306285014,
        "precision": 0.11928578826772185,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.010428649028629857,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.010428649028629857,
        "precision": 0.009966965663580246,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010298328226198865,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.0010298328226198865,
        "precision": 0.0006946484161786132,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07127595711580087,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.07127595711580087,
        "precision": 0.06476744284361471,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011198021796706792,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0011198021796706792,
        "precision": 0.0010523187582447027,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08226752089056777,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.08226752089056777,
        "precision": 0.07333186737052774,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9808569979716024e-06,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 1.9808569979716024e-06,
        "precision": 9.914340101522843e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.07909388246302308,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.07909388246302308,
        "precision": 0.0699051518143315,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.052004325070254945,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.052004325070254945,
        "precision": 0.046362288126611036,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004217606803263085,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0004217606803263085,
        "precision": 0.0002452403217761751,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07019220480110727,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.07019220480110727,
        "precision": 0.06277524463128784,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.017538580327967332,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.017538580327967332,
        "precision": 0.016633844757607295,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010321310066506864,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.010321310066506864,
        "precision": 0.00981393112269638,
        "recall": 0.015625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.09295386904761904,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.09295386904761904,
        "precision": 0.08438361672794117,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.014335663026988181,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.014335663026988181,
        "precision": 0.013678269047102381,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012095668859649124,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0012095668859649124,
        "precision": 0.0011005704365079365,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009720570264824509,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.009720570264824509,
        "precision": 0.00934752255145613,
        "recall": 0.015625
      },
      {
        "accuracy": 0.3134765625,
        "f1": 0.2774735011603867,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2774735011603867,
        "precision": 0.26665509805990306,
        "recall": 0.3134765625
      },
      {
        "accuracy": 0.443359375,
        "f1": 0.392294795590694,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.392294795590694,
        "precision": 0.3746186755952381,
        "recall": 0.443359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004757256039990117,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.004757256039990117,
        "precision": 0.0038261122375954195,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.3212890625,
        "f1": 0.286795784429109,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.286795784429109,
        "precision": 0.2759435863510649,
        "recall": 0.3212890625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01568610827304863,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01568610827304863,
        "precision": 0.012995376661892478,
        "recall": 0.03125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00013045216916354556,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00013045216916354556,
        "precision": 6.854215407754011e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.12609263751137584,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12609263751137584,
        "precision": 0.11636111429788666,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.34375,
        "f1": 0.2869800121753247,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2869800121753247,
        "precision": 0.2692059662694016,
        "recall": 0.34375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.0730430565156728,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0730430565156728,
        "precision": 0.06492905830064033,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.11647193331626013,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.11647193331626013,
        "precision": 0.10635040992963998,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003434952445652174,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003434952445652174,
        "precision": 0.0026452850877192982,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.244140625,
        "f1": 0.19125054632867133,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.19125054632867133,
        "precision": 0.1752124504907708,
        "recall": 0.244140625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007894731669690318,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0007894731669690318,
        "precision": 0.00044318067999708625,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10697936945243885,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10697936945243885,
        "precision": 0.1007801956919478,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03145777565074501,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.03145777565074501,
        "precision": 0.027505444777973065,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001956102324695122,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001956102324695122,
        "precision": 0.001954615935114504,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.35073442995806275,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.35073442995806275,
        "precision": 0.337813250814306,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07004982836529172,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07004982836529172,
        "precision": 0.06497198310710055,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.0971905548121214,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0971905548121214,
        "precision": 0.09094715410202542,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.14428677229827536,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.14428677229827536,
        "precision": 0.13537294742477232,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009925932708723202,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0009925932708723202,
        "precision": 0.0009846279880127773,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002895357299987726,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0002895357299987726,
        "precision": 0.00015515218377794093,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006051886469980554,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0006051886469980554,
        "precision": 0.00038756587841477075,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011669780242829077,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0011669780242829077,
        "precision": 0.001079238307958399,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001540700414781297,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0001540700414781297,
        "precision": 8.329879870661428e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002923112376161068,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.002923112376161068,
        "precision": 0.0026154555308061014,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.12495543464781744,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.12495543464781744,
        "precision": 0.11109254515016234,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009856308941424072,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0009856308941424072,
        "precision": 0.0009811073148800749,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009822401889534884,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0009822401889534884,
        "precision": 0.0009794096209912537,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0013492068230912268,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.0013492068230912268,
        "precision": 0.0008933904460005688,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06647983093295592,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.06647983093295592,
        "precision": 0.05763835859179198,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0024643849031754862,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0024643849031754862,
        "precision": 0.001977946581462177,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0684298322006484,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0684298322006484,
        "precision": 0.06021048256633345,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001466804718875502,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.001466804718875502,
        "precision": 0.0013030648031825795,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09877679557855337,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.09877679557855337,
        "precision": 0.0883735161323052,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.031625997559999425,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.031625997559999425,
        "precision": 0.026312925897886835,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0025323762758693324,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0025323762758693324,
        "precision": 0.0020152613303350527,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04928257097331389,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.04928257097331389,
        "precision": 0.04311039024366532,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017555015462381533,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0017555015462381533,
        "precision": 0.0014550367852715286,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009842218137254902,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0009842218137254902,
        "precision": 0.0009804072342519685,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.125,
        "f1": 0.09232641624358075,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.09232641624358075,
        "precision": 0.08101035113974567,
        "recall": 0.125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001956924854085603,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.001956924854085603,
        "precision": 0.0019550286306042886,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004731528779380342,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0004731528779380342,
        "precision": 0.0002860960218562735,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.12351701304338022,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.12351701304338022,
        "precision": 0.11641438802083334,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.141552734375,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.141552734375,
        "precision": 0.1334619915674603,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01686636911878315,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.01686636911878315,
        "precision": 0.015690543253419918,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11395447655044907,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.11395447655044907,
        "precision": 0.1072698846254079,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.014022033341297323,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.014022033341297323,
        "precision": 0.011350802138677028,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.13626006968292126,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.13626006968292126,
        "precision": 0.1288254368083158,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005076671060794044,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0005076671060794044,
        "precision": 0.00033527027668461747,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0032086182925962488,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0032086182925962488,
        "precision": 0.002719831579458638,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.07083624828389853,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07083624828389853,
        "precision": 0.06495817861353821,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0030290570175438595,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0030290570175438595,
        "precision": 0.0027029854910714285,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008755117814171123,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0008755117814171123,
        "precision": 0.000538917824074074,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030654579540149393,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0030654579540149393,
        "precision": 0.0026531327242231635,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001072095788043478,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.001072095788043478,
        "precision": 0.0006674704553354188,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11269737335947592,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.11269737335947592,
        "precision": 0.10667947237413145,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004382406661383027,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0004382406661383027,
        "precision": 0.0002527462008743058,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.505373023715415e-05,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 1.505373023715415e-05,
        "precision": 7.560923049155433e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.1370845329753278,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.1370845329753278,
        "precision": 0.1300368369979262,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.050712987522956915,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.050712987522956915,
        "precision": 0.047425147318386776,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.08424676500612654,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.08424676500612654,
        "precision": 0.07789222310835181,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.3359375,
        "f1": 0.3033633186804892,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.3033633186804892,
        "precision": 0.29256690389512696,
        "recall": 0.3359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002259583074855252,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.002259583074855252,
        "precision": 0.0018650600493018614,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01389649179104686,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.01389649179104686,
        "precision": 0.012463257841569661,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.04608474959679759,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.04608474959679759,
        "precision": 0.039461682349140936,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.2216796875,
        "f1": 0.1699400244235952,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.1699400244235952,
        "precision": 0.15547303660455658,
        "recall": 0.2216796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011955063543039087,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0011955063543039087,
        "precision": 0.0010995987496909,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08629677072059885,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08629677072059885,
        "precision": 0.07662889315290511,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003171502976190476,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.003171502976190476,
        "precision": 0.002749980777324527,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.22779684744505752,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.22779684744505752,
        "precision": 0.2086800971004011,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009796626984126984,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0009796626984126984,
        "precision": 0.0009781150635930047,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004479876135149573,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.004479876135149573,
        "precision": 0.003159771068128387,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0022263299851190475,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0022263299851190475,
        "precision": 0.0017992424242424241,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.17652452256944443,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.17652452256944443,
        "precision": 0.1640493349966006,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005915418993319638,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005915418993319638,
        "precision": 0.0055693102481862,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.330078125,
        "f1": 0.26819435989357865,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.26819435989357865,
        "precision": 0.2475051857864358,
        "recall": 0.330078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030957415507307474,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0030957415507307474,
        "precision": 0.002722073705960425,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010066526610644257,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0010066526610644257,
        "precision": 0.000991715848663711,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.054578923717864984,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.054578923717864984,
        "precision": 0.05050945390534385,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019096222158218124,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0019096222158218124,
        "precision": 0.0016291065705128205,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.07820214570471559,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.07820214570471559,
        "precision": 0.07110375897973555,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0035699048526266386,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0035699048526266386,
        "precision": 0.0031051199993239707,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022002313106716516,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0022002313106716516,
        "precision": 0.002090358962829736,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007183290562766943,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.007183290562766943,
        "precision": 0.006739174175506738,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.122961956521739e-06,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 2.122961956521739e-06,
        "precision": 1.0626360174102285e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010528382149790922,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0010528382149790922,
        "precision": 0.0010160954496891998,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.04875397858796296,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.04875397858796296,
        "precision": 0.045538397149725275,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.05053251957227179,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.05053251957227179,
        "precision": 0.047639965043835025,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.019865130953361253,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.019865130953361253,
        "precision": 0.018367882064571357,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.05913447627314815,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.05913447627314815,
        "precision": 0.05418730370455016,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.07280197016525142,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.07280197016525142,
        "precision": 0.06402990564123376,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.06721678535855553,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.06721678535855553,
        "precision": 0.0634621628942147,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.0774697660195707,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.0774697660195707,
        "precision": 0.06892554873511905,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.050993616609497604,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.050993616609497604,
        "precision": 0.04728662826500242,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0011945202924537584,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.0011945202924537584,
        "precision": 0.0008111785680661083,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 8.160545653848565e-05,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 8.160545653848565e-05,
        "precision": 4.1825041453128114e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.034184229399073146,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.034184229399073146,
        "precision": 0.0292149002933915,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004902641180203046,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0004902641180203046,
        "precision": 0.000326513274898374,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.030485989200125782,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.030485989200125782,
        "precision": 0.025901358298819236,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.13737589259188523,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.13737589259188523,
        "precision": 0.13022955912360207,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00029694509144237403,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.00029694509144237403,
        "precision": 0.00017178754664179104,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.01917025469486941,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.01917025469486941,
        "precision": 0.01647914804234038,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.05383582432050771,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.05383582432050771,
        "precision": 0.04987421717512443,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.03328817098348348,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.03328817098348348,
        "precision": 0.03127429612016908,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.17861145690247252,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.17861145690247252,
        "precision": 0.1674211178361569,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.05067977845079295,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.05067977845079295,
        "precision": 0.047211919560563545,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003758777537035516,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.003758777537035516,
        "precision": 0.0034186194663085125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.013048848684631334,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.013048848684631334,
        "precision": 0.01134768615095245,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.03974873031471768,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03974873031471768,
        "precision": 0.033111314366657915,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.06816580406402926,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.06816580406402926,
        "precision": 0.0610376683863012,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007615174871191757,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0007615174871191757,
        "precision": 0.0005467115343236184,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.2139332076343795,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2139332076343795,
        "precision": 0.19206003956980522,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0045830722639933165,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0045830722639933165,
        "precision": 0.003909441380718954,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09459852838228347,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.09459852838228347,
        "precision": 0.08515246641251926,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000564327293417367,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.000564327293417367,
        "precision": 0.00036450366040209793,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.00427828636612968,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.00427828636612968,
        "precision": 0.0037323762687754163,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.18169347673347583,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.18169347673347583,
        "precision": 0.16714954018420816,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00040364583333333333,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.00040364583333333333,
        "precision": 0.00023600260416666667,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0040338900317071266,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0040338900317071266,
        "precision": 0.003575852181854847,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.16163051067231538,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.16163051067231538,
        "precision": 0.14717507833962912,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025062805830754096,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0025062805830754096,
        "precision": 0.002311614519416199,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0025778743346788397,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0025778743346788397,
        "precision": 0.002120589249087789,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.0793532673886383,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.0793532673886383,
        "precision": 0.07282073666351009,
        "recall": 0.109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002932768138801262,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002932768138801262,
        "precision": 0.002931230252764613,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.07087510570373473,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.07087510570373473,
        "precision": 0.06293248309849872,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002616992487519201,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.002616992487519201,
        "precision": 0.0019677043114543114,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0032302102545830537,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0032302102545830537,
        "precision": 0.002723912905819127,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.003590950688588022,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.003590950688588022,
        "precision": 0.00292944408110096,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009875214073999349,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0009875214073999349,
        "precision": 0.0009820602560097393,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008611691449571039,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0008611691449571039,
        "precision": 0.0006042350765550157,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005832640855342443,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0005832640855342443,
        "precision": 0.0003743831098458355,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0009126674448898677,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0009126674448898677,
        "precision": 0.000628578704591132,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.3042510636330003e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 1.3042510636330003e-05,
        "precision": 6.546848667119806e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00010995682386546138,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.00010995682386546138,
        "precision": 5.6318614592441465e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07843706043048809,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.07843706043048809,
        "precision": 0.06997317988589893,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001302349882336373,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.001302349882336373,
        "precision": 0.0011511612647777526,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.07498398230820105,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.07498398230820105,
        "precision": 0.0669911215278288,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003659893670204584,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0003659893670204584,
        "precision": 0.00020253755030011044,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0010261421882515633,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0010261421882515633,
        "precision": 0.0005817540965092028,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026574631487769527,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.026574631487769527,
        "precision": 0.02303526907256155,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0020782609476647598,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0020782609476647598,
        "precision": 0.0020171336756061,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017365929216456323,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0017365929216456323,
        "precision": 0.001521533632112972,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06535934375546834,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.06535934375546834,
        "precision": 0.059062690239448046,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04064772926215941,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.04064772926215941,
        "precision": 0.0348428846079276,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00043084912180026505,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.00043084912180026505,
        "precision": 0.00022960900119617226,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.0744677734375,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.0744677734375,
        "precision": 0.06647448959460678,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0005513600077701353,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0005513600077701353,
        "precision": 0.00030295597563520353,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00016180527571181102,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.00016180527571181102,
        "precision": 8.717996288157089e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03521051607098605,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.03521051607098605,
        "precision": 0.029692733014389405,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.54288483211196e-05,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 7.54288483211196e-05,
        "precision": 3.863637521584147e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002247689440359477,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.002247689440359477,
        "precision": 0.001740998550772921,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.016410771219599125,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.016410771219599125,
        "precision": 0.014787937160736907,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.03749659749717194,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03749659749717194,
        "precision": 0.032636397583392596,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.11222780959338863,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.11222780959338863,
        "precision": 0.10223033440806878,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.95508008008008e-06,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 1.95508008008008e-06,
        "precision": 9.785195390781562e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.07818581700417637,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.07818581700417637,
        "precision": 0.0715376331453634,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0037167029220764474,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0037167029220764474,
        "precision": 0.0031197684151785714,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.1567651523069322,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1567651523069322,
        "precision": 0.13968980607838422,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021805565596684018,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00021805565596684018,
        "precision": 0.00011589897086656753,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004617504965615176,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.004617504965615176,
        "precision": 0.0039348177448659495,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.2728424028228716,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2728424028228716,
        "precision": 0.24998178633432538,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0006510416666666666,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.00048828125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.14994564163624363,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.14994564163624363,
        "precision": 0.137650881291018,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00416203112363133,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00416203112363133,
        "precision": 0.0036918177980782077,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005696614583333334,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.005696614583333334,
        "precision": 0.005048142817982456,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030427196118358395,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0030427196118358395,
        "precision": 0.0029873886289129127,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05284301315242861,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.05284301315242861,
        "precision": 0.04815616741943718,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018582509793447293,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0018582509793447293,
        "precision": 0.001547617057477413,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.06144131755716871,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.06144131755716871,
        "precision": 0.0558246583868509,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004839008337449191,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.004839008337449191,
        "precision": 0.0042014573315969275,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0033599525369623654,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0033599525369623654,
        "precision": 0.0028030875943273483,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004187358228152879,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.004187358228152879,
        "precision": 0.003339701738718555,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.1965797326512592e-05,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 1.1965797326512592e-05,
        "precision": 6.007774203431373e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000873674197892948,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.000873674197892948,
        "precision": 0.0005381053150288216,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0011903115781710914,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0011903115781710914,
        "precision": 0.0007218775955149502,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0002981569242398713,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0002981569242398713,
        "precision": 0.00015961952302679858,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003292840799614643,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0003292840799614643,
        "precision": 0.0001971977557915058,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007316091854280588,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0007316091854280588,
        "precision": 0.00045650773282883937,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08748185679338022,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.08748185679338022,
        "precision": 0.07766184824290293,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.2545046190493277e-05,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 5.2545046190493277e-05,
        "precision": 2.650111941351158e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.140625,
        "f1": 0.11156362084096459,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.11156362084096459,
        "precision": 0.10211835148358585,
        "recall": 0.140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00028845324361628707,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.00028845324361628707,
        "precision": 0.00016750101132686083,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019634866931991864,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0019634866931991864,
        "precision": 0.0013161264623714837,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.024177617981585908,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.024177617981585908,
        "precision": 0.020914573288265063,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0040794906113787366,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0040794906113787366,
        "precision": 0.0036974765041847026,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.0755711700529071,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0755711700529071,
        "precision": 0.06710397796392742,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002783698333180133,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.002783698333180133,
        "precision": 0.002051769673582996,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.028147509106788763,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.028147509106788763,
        "precision": 0.023218601213569792,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015684682248752369,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0015684682248752369,
        "precision": 0.001299013970498536,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.047221271024981956,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.047221271024981956,
        "precision": 0.0421118146857382,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012335158111376734,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0012335158111376734,
        "precision": 0.0011142329180071197,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00020924671351952998,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.00020924671351952998,
        "precision": 0.00011360510242097004,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.05087861301599238,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.05087861301599238,
        "precision": 0.04478932981839043,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.438920454545454e-06,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 4.438920454545454e-06,
        "precision": 2.224515945330296e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009803403046421664,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.0009803403046421664,
        "precision": 0.0009784550629844961,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002034505208333333,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.002034505208333333,
        "precision": 0.0016369047619047617,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.0999377882030541,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.0999377882030541,
        "precision": 0.09187274168181495,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11232408509267941,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.11232408509267941,
        "precision": 0.10178616698841503,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.031845003231721986,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.031845003231721986,
        "precision": 0.02878599631728993,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.1110826384352013,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.1110826384352013,
        "precision": 0.10352075924007462,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.07192038556017824,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.07192038556017824,
        "precision": 0.06425512360004912,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.10404100239359612,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.10404100239359612,
        "precision": 0.09512506100902446,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04384649367559523,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.04384649367559523,
        "precision": 0.03861646979322761,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.094619873941163,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.094619873941163,
        "precision": 0.08595362970362971,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0017427367898539337,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.0017427367898539337,
        "precision": 0.001420488416651859,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.14852609949059212,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.14852609949059212,
        "precision": 0.1382760712594697,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012530760882856443,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0012530760882856443,
        "precision": 0.0011269221230158731,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.048160737341809826,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.048160737341809826,
        "precision": 0.04206740254103535,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00288819530796354,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.00288819530796354,
        "precision": 0.0026012288119305,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.051097470238095244,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.051097470238095244,
        "precision": 0.046380166057900435,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004964263907115777,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0004964263907115777,
        "precision": 0.00027114154137033596,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.032896526844409246,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.032896526844409246,
        "precision": 0.028026748192244367,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.11110879736184906,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.11110879736184906,
        "precision": 0.10144170960507311,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.0569780121506586,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.0569780121506586,
        "precision": 0.053260746462974067,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.25,
        "f1": 0.21516763618326118,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.21516763618326118,
        "precision": 0.20341237208308846,
        "recall": 0.25
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.09017388378462932,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.09017388378462932,
        "precision": 0.08101115128997671,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007397061396425495,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.007397061396425495,
        "precision": 0.006032854321300045,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.00889434989082248,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00889434989082248,
        "precision": 0.00809742290513954,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.0254044851305128,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.0254044851305128,
        "precision": 0.021251393633624126,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.02299649677579365,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.02299649677579365,
        "precision": 0.020117158251082012,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006807110059879927,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0006807110059879927,
        "precision": 0.000503313607419712,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.06173821742238562,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.06173821742238562,
        "precision": 0.05539164430765993,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0031664299242424245,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0031664299242424245,
        "precision": 0.0030617227359693877,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.021977212051353404,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.021977212051353404,
        "precision": 0.018207234691753303,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011519574454518051,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0011519574454518051,
        "precision": 0.0010698963579822956,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00100115009362046,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.00100115009362046,
        "precision": 0.0006753727148952635,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06614164414949626,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.06614164414949626,
        "precision": 0.05976754500924422,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0015728369032585949,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0015728369032585949,
        "precision": 0.001307412128323581,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.125,
        "f1": 0.09442281351461039,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09442281351461039,
        "precision": 0.08576615441849816,
        "recall": 0.125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004041873885972658,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004041873885972658,
        "precision": 0.0036745581279754146,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.05490347232025221,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.05490347232025221,
        "precision": 0.04952726395725984,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0031940978557358896,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0031940978557358896,
        "precision": 0.002511011011361217,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011644485979693513,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0011644485979693513,
        "precision": 0.0008264612268518518,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0024649531045323227,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0024649531045323227,
        "precision": 0.002260278033715534,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02871242592119025,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02871242592119025,
        "precision": 0.025271581997235282,
        "recall": 0.046875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0010685197570510546,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0010685197570510546,
        "precision": 0.0007218273158293318,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0027746775793650795,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0027746775793650795,
        "precision": 0.002417470894607843,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0039324775136185125,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0039324775136185125,
        "precision": 0.003919458087228214,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.0661302982731556e-06,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 3.0661302982731556e-06,
        "precision": 1.5354756289308177e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014686339065619887,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0014686339065619887,
        "precision": 0.0012614586371640308,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010202505835965809,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0010202505835965809,
        "precision": 0.0009988594009859824,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0019789143803638906,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0019789143803638906,
        "precision": 0.0019660832712385073,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008335845994143625,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0008335845994143625,
        "precision": 0.0005224155100643422,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06055462549603174,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.06055462549603174,
        "precision": 0.05322354622075123,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013293023747298774,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0013293023747298774,
        "precision": 0.001185566949587237,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.046188186813186816,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.046188186813186816,
        "precision": 0.041055092910561655,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007595091441427317,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0007595091441427317,
        "precision": 0.0004725949199879227,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001648488127235479,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.001648488127235479,
        "precision": 0.0014753269912297974,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01820865766178266,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.01820865766178266,
        "precision": 0.015131901929787167,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020667448718798657,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0020667448718798657,
        "precision": 0.0020117799488852824,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.05671510022095959,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.05671510022095959,
        "precision": 0.047443202541433235,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00011747662641215427,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.00011747662641215427,
        "precision": 6.233033197944297e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.04123412060136555,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.04123412060136555,
        "precision": 0.03700651887175324,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.023017568443248617,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.023017568443248617,
        "precision": 0.019075052257592852,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017393486567936454,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0017393486567936454,
        "precision": 0.0014396490533911926,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0015866693508188921,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0015866693508188921,
        "precision": 0.0013167510941522892,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00025749122428809926,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.00025749122428809926,
        "precision": 0.00014620945149716968,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.03763536699682113,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.03763536699682113,
        "precision": 0.032436208643531285,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012787705459842264,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0012787705459842264,
        "precision": 0.0011510185070816865,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0032076370455276703,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0032076370455276703,
        "precision": 0.002451982728823588,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005771347130097513,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.005771347130097513,
        "precision": 0.004908416069488683,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.3193359375,
        "f1": 0.28274861638410875,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.28274861638410875,
        "precision": 0.27107647199534096,
        "recall": 0.3193359375
      },
      {
        "accuracy": 0.3720703125,
        "f1": 0.3410594658492926,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3410594658492926,
        "precision": 0.33017311146450923,
        "recall": 0.3720703125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008991762357292108,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.008991762357292108,
        "precision": 0.007927557363671275,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.33203125,
        "f1": 0.2983699514461233,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2983699514461233,
        "precision": 0.28642694382440476,
        "recall": 0.33203125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.01690522339193365,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01690522339193365,
        "precision": 0.014279240375970535,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.388671875,
        "f1": 0.35145679642646066,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.35145679642646066,
        "precision": 0.3387633377909588,
        "recall": 0.388671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0025678661616161617,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0025678661616161617,
        "precision": 0.0023229000342153286,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.11824291442139295,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.11824291442139295,
        "precision": 0.10821174367343678,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.11285530987511051,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.11285530987511051,
        "precision": 0.10311152295500553,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08439190465814643,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08439190465814643,
        "precision": 0.0757310867186998,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.09128117341395511,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09128117341395511,
        "precision": 0.08420584542410714,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0037496200817860297,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0037496200817860297,
        "precision": 0.0031789553521641666,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08785339049800792,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08785339049800792,
        "precision": 0.08141281145048124,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0031124292979307516,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0031124292979307516,
        "precision": 0.002371966877436507,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.12791145548666621,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12791145548666621,
        "precision": 0.12048411451593773,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.033556893632886754,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.033556893632886754,
        "precision": 0.02935379024130566,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002154198930678466,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002154198930678466,
        "precision": 0.002064521182610125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0845827726481709,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0845827726481709,
        "precision": 0.07922139257588476,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.1082544070379083,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1082544070379083,
        "precision": 0.09978368738983548,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.12318906174377091,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.12318906174377091,
        "precision": 0.11408717781544685,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006330409116972927,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0006330409116972927,
        "precision": 0.00034399434547129055,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025113227521650536,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0025113227521650536,
        "precision": 0.0022726683490044246,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.060962078693752426,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.060962078693752426,
        "precision": 0.055921763535643085,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07900345124788008,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.07900345124788008,
        "precision": 0.07418459858563434,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006675482855902777,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.006675482855902777,
        "precision": 0.006022395816618363,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.07306560413691177,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.07306560413691177,
        "precision": 0.06923090217200141,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.021541539566901493,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.021541539566901493,
        "precision": 0.018109985383201622,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.05883386918033657,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.05883386918033657,
        "precision": 0.05422713146901589,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003996419109124027,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.003996419109124027,
        "precision": 0.003674749812168018,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.038220806624854164,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.038220806624854164,
        "precision": 0.03490837850827696,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0021977390715901745,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0021977390715901745,
        "precision": 0.00141990089052508,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.09834402265783626,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.09834402265783626,
        "precision": 0.09147919088233131,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006917317708333333,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0006917317708333333,
        "precision": 0.0003999255952380952,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0025791028530662862,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0025791028530662862,
        "precision": 0.001683474936370023,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00050220040892563,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.00050220040892563,
        "precision": 0.0002891859178146769,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.008274728748011384,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.008274728748011384,
        "precision": 0.007065922634632085,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.09876774780088772,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.09876774780088772,
        "precision": 0.09254319477841613,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00035916317783094096,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.00035916317783094096,
        "precision": 0.00019380429536679537,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0049517511225981616,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0049517511225981616,
        "precision": 0.004263583096590909,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07178520153480161,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.07178520153480161,
        "precision": 0.06702502691406612,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.11945333822527085,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.11945333822527085,
        "precision": 0.11226921728033726,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.02898372387879614,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.02898372387879614,
        "precision": 0.026517534495372197,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004030404421029421,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.0004030404421029421,
        "precision": 0.00023557618388683887,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016018791454587848,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.0016018791454587848,
        "precision": 0.0013731054298984084,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06855488685906484,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.06855488685906484,
        "precision": 0.06417819933980354,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07840572433070483,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.07840572433070483,
        "precision": 0.07210836878295139,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.021828615273406522,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.021828615273406522,
        "precision": 0.01954143766146587,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07832506915090937,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.07832506915090937,
        "precision": 0.07232305249493441,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.08770146411747974,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.08770146411747974,
        "precision": 0.07692761882215007,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.07916704901385013,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.07916704901385013,
        "precision": 0.07302422126337421,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09701244212962963,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.09701244212962963,
        "precision": 0.08782742864774115,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.06306076251280042,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.06306076251280042,
        "precision": 0.058622704883448076,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0015242638860593035,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.0015242638860593035,
        "precision": 0.0012825031455070228,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.18105553300865798,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.18105553300865798,
        "precision": 0.16922433035714285,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.820593758093758e-05,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 7.820593758093758e-05,
        "precision": 4.008704605985842e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.04536530906159812,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.04536530906159812,
        "precision": 0.041177628332808046,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019550938760080645,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.0019550938760080645,
        "precision": 0.001954110431382442,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.051009114583333334,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.051009114583333334,
        "precision": 0.04501550758823032,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.20265098977204107,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.20265098977204107,
        "precision": 0.19379707404020183,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006814264167205343,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0006814264167205343,
        "precision": 0.00041281513206078914,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.03488891694817132,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.03488891694817132,
        "precision": 0.030371585152907273,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.07021157675038811,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.07021157675038811,
        "precision": 0.06492540306209646,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.05118262315893851,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.05118262315893851,
        "precision": 0.04903373485054646,
        "recall": 0.0625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.06208124964228479,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.06208124964228479,
        "precision": 0.056768908279435495,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005254710932892408,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0005254710932892408,
        "precision": 0.0003443073328180465,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013427881217671117,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0013427881217671117,
        "precision": 0.0011924787232817395,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.12098482301018837,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.12098482301018837,
        "precision": 0.11318811487268518,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.1457215049641965,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1457215049641965,
        "precision": 0.135600227309791,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.010990469323241412,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.010990469323241412,
        "precision": 0.009047334315610226,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.107093130664908,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.107093130664908,
        "precision": 0.09840587070299772,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.013746171845897092,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.013746171845897092,
        "precision": 0.011571789925796216,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.15067933003517098,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.15067933003517098,
        "precision": 0.14302505855183295,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.3427734375,
        "f1": 0.29012212639280655,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.29012212639280655,
        "precision": 0.2728103263381584,
        "recall": 0.3427734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004219747256630962,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.004219747256630962,
        "precision": 0.0037754232620492534,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07144879317730879,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07144879317730879,
        "precision": 0.06473999315053153,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00101046792072092,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.00101046792072092,
        "precision": 0.0009937038502109705,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000581281025787983,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.000581281025787983,
        "precision": 0.00033450209770851617,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016520182291666664,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0016520182291666664,
        "precision": 0.0014772053006329115,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00022197105893965029,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.00022197105893965029,
        "precision": 0.00012455520435750636,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.10835897309645012,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.10835897309645012,
        "precision": 0.10029653099721458,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019615075107296135,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.0019615075107296135,
        "precision": 0.0019573343211206897,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.563311129756616e-05,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 1.563311129756616e-05,
        "precision": 7.85576016185956e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.13375139854234347,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.13375139854234347,
        "precision": 0.12573212553250468,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04050545802674695,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.04050545802674695,
        "precision": 0.03624380489043377,
        "recall": 0.0625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08732577105762448,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.08732577105762448,
        "precision": 0.08040831781066156,
        "recall": 0.11328125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}