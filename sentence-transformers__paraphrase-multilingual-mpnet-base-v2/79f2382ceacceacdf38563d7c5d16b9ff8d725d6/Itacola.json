{
  "dataset_revision": "f8f98e5c4d3059cf1a00c8eb3d70aa271423f636",
  "evaluation_time": 9.386911392211914,
  "kg_co2_emissions": 0.001394185121728668,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.44728205128205134,
        "ap": 0.8415201562196902,
        "ap_weighted": 0.8415201562196902,
        "f1": 0.4005169636332882,
        "f1_weighted": 0.5070134979731153,
        "hf_subset": "default",
        "languages": [
          "ita-Latn"
        ],
        "main_score": 0.44728205128205134,
        "scores_per_experiment": [
          {
            "accuracy": 0.4748717948717949,
            "ap": 0.8451230247954498,
            "ap_weighted": 0.8451230247954498,
            "f1": 0.42429051186478206,
            "f1_weighted": 0.5410300127840815
          },
          {
            "accuracy": 0.5056410256410256,
            "ap": 0.8436499000816025,
            "ap_weighted": 0.8436499000816025,
            "f1": 0.4385680289012921,
            "f1_weighted": 0.5713208147333463
          },
          {
            "accuracy": 0.37538461538461537,
            "ap": 0.839926341203265,
            "ap_weighted": 0.839926341203265,
            "f1": 0.35765122822732187,
            "f1_weighted": 0.43066461856012916
          },
          {
            "accuracy": 0.4728205128205128,
            "ap": 0.8337254379947635,
            "ap_weighted": 0.8337254379947635,
            "f1": 0.4096227428657594,
            "f1_weighted": 0.5417635345893347
          },
          {
            "accuracy": 0.5938461538461538,
            "ap": 0.8463846327696132,
            "ap_weighted": 0.8463846327696132,
            "f1": 0.4807692307692308,
            "f1_weighted": 0.6465325443786983
          },
          {
            "accuracy": 0.41333333333333333,
            "ap": 0.8423956437022544,
            "ap_weighted": 0.8423956437022544,
            "f1": 0.38507779973184675,
            "f1_weighted": 0.4752521581633853
          },
          {
            "accuracy": 0.4512820512820513,
            "ap": 0.8463353886093186,
            "ap_weighted": 0.8463353886093186,
            "f1": 0.4120024213156943,
            "f1_weighted": 0.5159687434885519
          },
          {
            "accuracy": 0.318974358974359,
            "ap": 0.8472767259555918,
            "ap_weighted": 0.8472767259555918,
            "f1": 0.3162981675016686,
            "f1_weighted": 0.3455607857358405
          },
          {
            "accuracy": 0.4317948717948718,
            "ap": 0.8322603114305416,
            "ap_weighted": 0.8322603114305416,
            "f1": 0.38647205815538394,
            "f1_weighted": 0.5005487249385477
          },
          {
            "accuracy": 0.4348717948717949,
            "ap": 0.8381241556545014,
            "ap_weighted": 0.8381241556545014,
            "f1": 0.3944174469999019,
            "f1_weighted": 0.5014930423592376
          }
        ]
      }
    ]
  },
  "task_name": "Itacola"
}