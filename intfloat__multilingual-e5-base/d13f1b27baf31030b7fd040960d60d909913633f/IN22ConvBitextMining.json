{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 27.220678567886353,
  "kg_co2_emissions": 0.004298802317856124,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9035262807717898,
        "f1": 0.8809618857523048,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.8809618857523048,
        "precision": 0.8710800620980261,
        "recall": 0.9035262807717898
      },
      {
        "accuracy": 0.1490352628077179,
        "f1": 0.11620395578447215,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.11620395578447215,
        "precision": 0.10694928492608995,
        "recall": 0.1490352628077179
      },
      {
        "accuracy": 0.6154357950765137,
        "f1": 0.5625071461398807,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.5625071461398807,
        "precision": 0.542648613307296,
        "recall": 0.6154357950765137
      },
      {
        "accuracy": 0.8223552894211577,
        "f1": 0.7939765302821798,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.7939765302821798,
        "precision": 0.7836279821309761,
        "recall": 0.8223552894211577
      },
      {
        "accuracy": 0.5389221556886228,
        "f1": 0.48638060880418266,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.48638060880418266,
        "precision": 0.46753954812837045,
        "recall": 0.5389221556886228
      },
      {
        "accuracy": 0.8709248170326015,
        "f1": 0.8457693079449566,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8457693079449566,
        "precision": 0.835551912048918,
        "recall": 0.8709248170326015
      },
      {
        "accuracy": 0.8489687292082502,
        "f1": 0.8165805954229108,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.8165805954229108,
        "precision": 0.8035558512604422,
        "recall": 0.8489687292082502
      },
      {
        "accuracy": 0.7531603459747173,
        "f1": 0.7144795065952751,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.7144795065952751,
        "precision": 0.6995646273590385,
        "recall": 0.7531603459747173
      },
      {
        "accuracy": 0.5402528276779773,
        "f1": 0.4869656698000011,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.4869656698000011,
        "precision": 0.4669636916642904,
        "recall": 0.5402528276779773
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.8348192503881127,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8348192503881127,
        "precision": 0.823486360612109,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.8429807052561543,
        "f1": 0.8125083166999334,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8125083166999334,
        "precision": 0.7989243734752717,
        "recall": 0.8429807052561543
      },
      {
        "accuracy": 0.884896872920825,
        "f1": 0.8624813864334823,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.8624813864334823,
        "precision": 0.8527568794035859,
        "recall": 0.884896872920825
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.007685855214342823,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.007685855214342823,
        "precision": 0.00635219974568172,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.8882235528942116,
        "f1": 0.8667807242657543,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8667807242657543,
        "precision": 0.8574961188733643,
        "recall": 0.8882235528942116
      },
      {
        "accuracy": 0.8888888888888888,
        "f1": 0.863838988689288,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.863838988689288,
        "precision": 0.8528561923771505,
        "recall": 0.8888888888888888
      },
      {
        "accuracy": 0.8522954091816367,
        "f1": 0.8216234198270127,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8216234198270127,
        "precision": 0.8085289737984349,
        "recall": 0.8522954091816367
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7164511432974507,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.7164511432974507,
        "precision": 0.6983485410132118,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.0040223040937815355,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0040223040937815355,
        "precision": 0.0027553707357879467,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.4697272122421823,
        "f1": 0.4174745894306773,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.4174745894306773,
        "precision": 0.3989140086772408,
        "recall": 0.4697272122421823
      },
      {
        "accuracy": 0.7691284098469727,
        "f1": 0.7293798646094054,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.7293798646094054,
        "precision": 0.7125978202325507,
        "recall": 0.7691284098469727
      },
      {
        "accuracy": 0.8436460412508316,
        "f1": 0.8101606311187148,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8101606311187148,
        "precision": 0.7964404524284765,
        "recall": 0.8436460412508316
      },
      {
        "accuracy": 0.9028609447771124,
        "f1": 0.8828121534708362,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.8828121534708362,
        "precision": 0.8738633843424262,
        "recall": 0.9028609447771124
      },
      {
        "accuracy": 0.8855622089155023,
        "f1": 0.8631583394058444,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.8631583394058444,
        "precision": 0.854609035896461,
        "recall": 0.8855622089155023
      },
      {
        "accuracy": 0.16101131071190952,
        "f1": 0.1194194459793696,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.1194194459793696,
        "precision": 0.10776362218663375,
        "recall": 0.16101131071190952
      },
      {
        "accuracy": 0.6606786427145709,
        "f1": 0.6001780469844342,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6001780469844342,
        "precision": 0.5769775504306442,
        "recall": 0.6606786427145709
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9042861847253064,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9042861847253064,
        "precision": 0.8980982479485474,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.6101131071190952,
        "f1": 0.5545189899927994,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.5545189899927994,
        "precision": 0.5341110467856974,
        "recall": 0.6101131071190952
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8999419151115757,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8999419151115757,
        "precision": 0.8936404967842093,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9227323131514747,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9227323131514747,
        "precision": 0.9155577733422045,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.8276779773785762,
        "f1": 0.7918105587766266,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.7918105587766266,
        "precision": 0.7774968821376008,
        "recall": 0.8276779773785762
      },
      {
        "accuracy": 0.5828343313373253,
        "f1": 0.5184219343899983,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.5184219343899983,
        "precision": 0.49420154400194316,
        "recall": 0.5828343313373253
      },
      {
        "accuracy": 0.8915502328675982,
        "f1": 0.8702705699711686,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8702705699711686,
        "precision": 0.8610398251116814,
        "recall": 0.8915502328675982
      },
      {
        "accuracy": 0.9121756487025948,
        "f1": 0.8930044672559643,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8930044672559643,
        "precision": 0.8844644045242849,
        "recall": 0.9121756487025948
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9157019294743847,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9157019294743847,
        "precision": 0.9086493679308051,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.003974479116275901,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.003974479116275901,
        "precision": 0.0028330090052234,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.9103570636504769,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9103570636504769,
        "precision": 0.9029718341095586,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9198048347748947,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9198048347748947,
        "precision": 0.912641383898869,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.8995342648037259,
        "f1": 0.8759370148591705,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8759370148591705,
        "precision": 0.865480150809492,
        "recall": 0.8995342648037259
      },
      {
        "accuracy": 0.7811044577511643,
        "f1": 0.7376897479691891,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7376897479691891,
        "precision": 0.7196240035561392,
        "recall": 0.7811044577511643
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0031523298525420428,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0031523298525420428,
        "precision": 0.0022399124046216857,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.520292747837658,
        "f1": 0.4668081279513588,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.4668081279513588,
        "precision": 0.44759649184221095,
        "recall": 0.520292747837658
      },
      {
        "accuracy": 0.8449767132401863,
        "f1": 0.8131958305610999,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8131958305610999,
        "precision": 0.7995194795593996,
        "recall": 0.8449767132401863
      },
      {
        "accuracy": 0.9035262807717898,
        "f1": 0.8809492126857396,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8809492126857396,
        "precision": 0.8707584830339321,
        "recall": 0.9035262807717898
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9234752716788643,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9234752716788643,
        "precision": 0.9165399360010139,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.10978043912175649,
        "f1": 0.09183292886955728,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.09183292886955728,
        "precision": 0.08789833060207757,
        "recall": 0.10978043912175649
      },
      {
        "accuracy": 0.11976047904191617,
        "f1": 0.08974964896369424,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.08974964896369424,
        "precision": 0.08336648899475535,
        "recall": 0.11976047904191617
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.11147759644361507,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.11147759644361507,
        "precision": 0.10652660597974244,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.06320691949434465,
        "f1": 0.05309530056004848,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05309530056004848,
        "precision": 0.05077736634622861,
        "recall": 0.06320691949434465
      },
      {
        "accuracy": 0.10844976713240187,
        "f1": 0.0920835678430413,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.0920835678430413,
        "precision": 0.08845676808798884,
        "recall": 0.10844976713240187
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.09343046020584377,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.09343046020584377,
        "precision": 0.08889748519860766,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.14637391882900866,
        "f1": 0.11686238693759185,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.11686238693759185,
        "precision": 0.10992093463418776,
        "recall": 0.14637391882900866
      },
      {
        "accuracy": 0.07784431137724551,
        "f1": 0.06693915854761465,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.06693915854761465,
        "precision": 0.06419432009133005,
        "recall": 0.07784431137724551
      },
      {
        "accuracy": 0.09115103127079174,
        "f1": 0.07383029149843175,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.07383029149843175,
        "precision": 0.070703503381834,
        "recall": 0.09115103127079174
      },
      {
        "accuracy": 0.12508316699933467,
        "f1": 0.10091226388786066,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10091226388786066,
        "precision": 0.09474868621803836,
        "recall": 0.12508316699933467
      },
      {
        "accuracy": 0.11842980705256155,
        "f1": 0.08651575757714629,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08651575757714629,
        "precision": 0.07968486580094476,
        "recall": 0.11842980705256155
      },
      {
        "accuracy": 0.11909514304723885,
        "f1": 0.09277524106312274,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09277524106312274,
        "precision": 0.08728351648262475,
        "recall": 0.11909514304723885
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.009110659616524155,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009110659616524155,
        "precision": 0.007531755562503834,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.1088160977061644,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1088160977061644,
        "precision": 0.10350210216548968,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.12574850299401197,
        "f1": 0.09858272118750358,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.09858272118750358,
        "precision": 0.09256971898100597,
        "recall": 0.12574850299401197
      },
      {
        "accuracy": 0.11842980705256155,
        "f1": 0.0959671818810078,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0959671818810078,
        "precision": 0.09099793934432686,
        "recall": 0.11842980705256155
      },
      {
        "accuracy": 0.10445775116433799,
        "f1": 0.07906013239543362,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.07906013239543362,
        "precision": 0.07353239986362152,
        "recall": 0.10445775116433799
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.008472854312826175,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008472854312826175,
        "precision": 0.0063336537004461645,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.1217564870259481,
        "f1": 0.10360698241547554,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.10360698241547554,
        "precision": 0.0989086832888513,
        "recall": 0.1217564870259481
      },
      {
        "accuracy": 0.10246174318030606,
        "f1": 0.08051705134867773,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.08051705134867773,
        "precision": 0.07600702316955014,
        "recall": 0.10246174318030606
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.08908205899180888,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.08908205899180888,
        "precision": 0.08550876489312093,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.09402783341238852,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.09402783341238852,
        "precision": 0.0893847451972878,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.562874251497006,
        "f1": 0.5117572980506687,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5117572980506687,
        "precision": 0.4937962364999594,
        "recall": 0.562874251497006
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5748646708335902,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5748646708335902,
        "precision": 0.5556033419254346,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.16633399866932802,
        "f1": 0.13248832427206284,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.13248832427206284,
        "precision": 0.12323634952230703,
        "recall": 0.16633399866932802
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.5118944429735891,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5118944429735891,
        "precision": 0.4997816073299709,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.3852295409181637,
        "f1": 0.3461556514917089,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3461556514917089,
        "precision": 0.33384425173042337,
        "recall": 0.3852295409181637
      },
      {
        "accuracy": 0.6493679308050565,
        "f1": 0.6063859338220255,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6063859338220255,
        "precision": 0.5912086655273165,
        "recall": 0.6493679308050565
      },
      {
        "accuracy": 0.6573519627411843,
        "f1": 0.6084519816717188,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6084519816717188,
        "precision": 0.5920875421173213,
        "recall": 0.6573519627411843
      },
      {
        "accuracy": 0.5349301397205589,
        "f1": 0.4938121620007847,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4938121620007847,
        "precision": 0.480185003343216,
        "recall": 0.5349301397205589
      },
      {
        "accuracy": 0.36793080505655357,
        "f1": 0.31501152234748975,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.31501152234748975,
        "precision": 0.2992351278998573,
        "recall": 0.36793080505655357
      },
      {
        "accuracy": 0.699268130405855,
        "f1": 0.6519029665536652,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6519029665536652,
        "precision": 0.6339538941617394,
        "recall": 0.699268130405855
      },
      {
        "accuracy": 0.6027944111776448,
        "f1": 0.542086511380555,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.542086511380555,
        "precision": 0.5204911191907787,
        "recall": 0.6027944111776448
      },
      {
        "accuracy": 0.648037258815702,
        "f1": 0.6053944236472693,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6053944236472693,
        "precision": 0.590012658218352,
        "recall": 0.648037258815702
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.005506136074984145,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005506136074984145,
        "precision": 0.004252524877763762,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.635395874916833,
        "f1": 0.58667988911712,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.58667988911712,
        "precision": 0.5694158244357844,
        "recall": 0.635395874916833
      },
      {
        "accuracy": 0.6586826347305389,
        "f1": 0.6049919375951521,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6049919375951521,
        "precision": 0.5860598908004098,
        "recall": 0.6586826347305389
      },
      {
        "accuracy": 0.6753160345974717,
        "f1": 0.6288348735121856,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6288348735121856,
        "precision": 0.6128557736342167,
        "recall": 0.6753160345974717
      },
      {
        "accuracy": 0.520292747837658,
        "f1": 0.4639111910011287,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4639111910011287,
        "precision": 0.44416073595215305,
        "recall": 0.520292747837658
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.003470275027918312,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003470275027918312,
        "precision": 0.0024443806422908025,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.4530938123752495,
        "f1": 0.40707800368479014,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.40707800368479014,
        "precision": 0.39220699670573916,
        "recall": 0.4530938123752495
      },
      {
        "accuracy": 0.5249500998003992,
        "f1": 0.47115630602078756,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.47115630602078756,
        "precision": 0.4524991489865663,
        "recall": 0.5249500998003992
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.5062241438537234,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5062241438537234,
        "precision": 0.4898322530965442,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.6846307385229541,
        "f1": 0.6342726671568987,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6342726671568987,
        "precision": 0.6159456459855661,
        "recall": 0.6846307385229541
      },
      {
        "accuracy": 0.8629407850964738,
        "f1": 0.8349887526534233,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8349887526534233,
        "precision": 0.8236942953292862,
        "recall": 0.8629407850964738
      },
      {
        "accuracy": 0.9441117764471058,
        "f1": 0.9322244400088711,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9322244400088711,
        "precision": 0.9274340208471945,
        "recall": 0.9441117764471058
      },
      {
        "accuracy": 0.15169660678642716,
        "f1": 0.10327240847751548,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.10327240847751548,
        "precision": 0.09152803074773695,
        "recall": 0.15169660678642716
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6275259485838328,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.6275259485838328,
        "precision": 0.601933698740086,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.5395874916833001,
        "f1": 0.46457665717146757,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.46457665717146757,
        "precision": 0.43872913882893927,
        "recall": 0.5395874916833001
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9179915301671788,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9179915301671788,
        "precision": 0.9115232497967029,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.9336913474638024,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9336913474638024,
        "precision": 0.9281880683078287,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.8363273453093812,
        "f1": 0.7987792092582512,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.7987792092582512,
        "precision": 0.7832066026676805,
        "recall": 0.8363273453093812
      },
      {
        "accuracy": 0.5209580838323353,
        "f1": 0.445268817823708,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.445268817823708,
        "precision": 0.4178510918501525,
        "recall": 0.5209580838323353
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8919151595798303,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8919151595798303,
        "precision": 0.8837895637296835,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8957535908575005,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8957535908575005,
        "precision": 0.8878770237303171,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9055571396888763,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9055571396888763,
        "precision": 0.897989206771642,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002053072205921707,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.002053072205921707,
        "precision": 0.0015866290587309585,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9107800272470932,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9107800272470932,
        "precision": 0.9030336153090643,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9170473867080653,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9170473867080653,
        "precision": 0.9098192503881126,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8899344168805245,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8899344168805245,
        "precision": 0.8800251349153546,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.7771124417831005,
        "f1": 0.729791211228337,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.729791211228337,
        "precision": 0.7112230805344578,
        "recall": 0.7771124417831005
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0016562932571639569,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0016562932571639569,
        "precision": 0.0012386079111276651,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.5029940119760479,
        "f1": 0.42328500766624516,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.42328500766624516,
        "precision": 0.3959424307540768,
        "recall": 0.5029940119760479
      },
      {
        "accuracy": 0.8516300731869594,
        "f1": 0.8211576846307383,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.8211576846307383,
        "precision": 0.8078369955615464,
        "recall": 0.8516300731869594
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.87053728041752,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.87053728041752,
        "precision": 0.8608513132465226,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.9454424484364604,
        "f1": 0.9319583056110002,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9319583056110002,
        "precision": 0.9260257263251275,
        "recall": 0.9454424484364604
      },
      {
        "accuracy": 0.5455755156353959,
        "f1": 0.4986004212159744,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4986004212159744,
        "precision": 0.48258674707981974,
        "recall": 0.5455755156353959
      },
      {
        "accuracy": 0.5815036593479708,
        "f1": 0.5284763141050566,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5284763141050566,
        "precision": 0.5099917500821575,
        "recall": 0.5815036593479708
      },
      {
        "accuracy": 0.16833000665335995,
        "f1": 0.1345197347193355,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1345197347193355,
        "precision": 0.12338203121636256,
        "recall": 0.16833000665335995
      },
      {
        "accuracy": 0.479707252162342,
        "f1": 0.4297595285619238,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4297595285619238,
        "precision": 0.4110027081055613,
        "recall": 0.479707252162342
      },
      {
        "accuracy": 0.4457751164337991,
        "f1": 0.4092304038353117,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.4092304038353117,
        "precision": 0.3977703289093232,
        "recall": 0.4457751164337991
      },
      {
        "accuracy": 0.5981370592149036,
        "f1": 0.5538536277059231,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5538536277059231,
        "precision": 0.5374051979583022,
        "recall": 0.5981370592149036
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5597905975151485,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5597905975151485,
        "precision": 0.5412771526543982,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.48902195608782434,
        "f1": 0.4468337702001768,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4468337702001768,
        "precision": 0.4326380043167057,
        "recall": 0.48902195608782434
      },
      {
        "accuracy": 0.3712574850299401,
        "f1": 0.32451687072445556,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.32451687072445556,
        "precision": 0.30727276539358256,
        "recall": 0.3712574850299401
      },
      {
        "accuracy": 0.5974717232202262,
        "f1": 0.5439749316994826,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5439749316994826,
        "precision": 0.52500735200336,
        "recall": 0.5974717232202262
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.5109110194406269,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5109110194406269,
        "precision": 0.4910910853026622,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.6017503860817234,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6017503860817234,
        "precision": 0.5840604317433268,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.008220432169556764,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008220432169556764,
        "precision": 0.0063269495259743996,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.6067864271457086,
        "f1": 0.5504261318632576,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5504261318632576,
        "precision": 0.5303893947888567,
        "recall": 0.6067864271457086
      },
      {
        "accuracy": 0.6087824351297405,
        "f1": 0.5553094468430463,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5553094468430463,
        "precision": 0.5363722327794184,
        "recall": 0.6087824351297405
      },
      {
        "accuracy": 0.5834996673320026,
        "f1": 0.5319460140502267,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5319460140502267,
        "precision": 0.5132010998590534,
        "recall": 0.5834996673320026
      },
      {
        "accuracy": 0.5049900199600799,
        "f1": 0.44508657048577205,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.44508657048577205,
        "precision": 0.4237950025874178,
        "recall": 0.5049900199600799
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.006980076269655721,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006980076269655721,
        "precision": 0.0055693978237253364,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.4218230206254158,
        "f1": 0.37849434885363026,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.37849434885363026,
        "precision": 0.3630869477975266,
        "recall": 0.4218230206254158
      },
      {
        "accuracy": 0.490352628077179,
        "f1": 0.43518922241183605,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.43518922241183605,
        "precision": 0.41510975037343356,
        "recall": 0.490352628077179
      },
      {
        "accuracy": 0.5216234198270127,
        "f1": 0.4738423501816221,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.4738423501816221,
        "precision": 0.4582911063952982,
        "recall": 0.5216234198270127
      },
      {
        "accuracy": 0.6061210911510313,
        "f1": 0.5542502573939699,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5542502573939699,
        "precision": 0.5356650929426431,
        "recall": 0.6061210911510313
      },
      {
        "accuracy": 0.8789088489687292,
        "f1": 0.8546958992068772,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8546958992068772,
        "precision": 0.8443058327788867,
        "recall": 0.8789088489687292
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9092259924595254,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.9092259924595254,
        "precision": 0.9008094921268575,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.18097139055222888,
        "f1": 0.1372026005093204,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.1372026005093204,
        "precision": 0.1244742817106414,
        "recall": 0.18097139055222888
      },
      {
        "accuracy": 0.6859614105123087,
        "f1": 0.6311075447801994,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.6311075447801994,
        "precision": 0.6109946773120426,
        "recall": 0.6859614105123087
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.910902005512784,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.910902005512784,
        "precision": 0.903716376770269,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.6393878908848969,
        "f1": 0.5817701537761418,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.5817701537761418,
        "precision": 0.5603800957065016,
        "recall": 0.6393878908848969
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9069432563444538,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9069432563444538,
        "precision": 0.8996736685359439,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.8183632734530938,
        "f1": 0.7803134471797146,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.7803134471797146,
        "precision": 0.7641716566866267,
        "recall": 0.8183632734530938
      },
      {
        "accuracy": 0.571523619427811,
        "f1": 0.5031972758519665,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.5031972758519665,
        "precision": 0.47828654859592984,
        "recall": 0.571523619427811
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8728918305764612,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.8728918305764612,
        "precision": 0.8646972436892597,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8698381015746285,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.8698381015746285,
        "precision": 0.8591594588600576,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9161454868041694,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9161454868041694,
        "precision": 0.9092259924595254,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0034776524152383952,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0034776524152383952,
        "precision": 0.0026628510291116098,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9012694188342889,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9012694188342889,
        "precision": 0.8927422931913951,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.89371415898362,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.89371415898362,
        "precision": 0.8853626081170992,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8920825016633401,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.8920825016633401,
        "precision": 0.8825903748059436,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.7890884896872921,
        "f1": 0.746924237143798,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.746924237143798,
        "precision": 0.7297700894507282,
        "recall": 0.7890884896872921
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0026217361120782446,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.0026217361120782446,
        "precision": 0.0018580432017132667,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.5748502994011976,
        "f1": 0.5188490865820418,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.5188490865820418,
        "precision": 0.49855637450447826,
        "recall": 0.5748502994011976
      },
      {
        "accuracy": 0.8276779773785762,
        "f1": 0.7933899877013648,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.7933899877013648,
        "precision": 0.7781056933751546,
        "recall": 0.8276779773785762
      },
      {
        "accuracy": 0.8842315369261478,
        "f1": 0.8566771219465831,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.8566771219465831,
        "precision": 0.8447623271974569,
        "recall": 0.8842315369261478
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9121645597693502,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.9121645597693502,
        "precision": 0.9050296232930962,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8513766118556538,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8513766118556538,
        "precision": 0.8400896619459494,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.9414504324683965,
        "f1": 0.9274245160472706,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9274245160472706,
        "precision": 0.921290751829674,
        "recall": 0.9414504324683965
      },
      {
        "accuracy": 0.2102461743180306,
        "f1": 0.16702565008776113,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.16702565008776113,
        "precision": 0.1533629881719417,
        "recall": 0.2102461743180306
      },
      {
        "accuracy": 0.7351962741184298,
        "f1": 0.6886707252974718,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6886707252974718,
        "precision": 0.670600069701866,
        "recall": 0.7351962741184298
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9166159744004055,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9166159744004055,
        "precision": 0.9109289357792352,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.64604125083167,
        "f1": 0.5965914731383792,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5965914731383792,
        "precision": 0.5783342393464256,
        "recall": 0.64604125083167
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.9000892875144372,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9000892875144372,
        "precision": 0.8925593257928587,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8061390446619987,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8061390446619987,
        "precision": 0.7929197161233088,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.6107784431137725,
        "f1": 0.5529409435098058,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5529409435098058,
        "precision": 0.531339132886039,
        "recall": 0.6107784431137725
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8716255800088135,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8716255800088135,
        "precision": 0.8640919219761534,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8905870798086368,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8905870798086368,
        "precision": 0.8822703798751704,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9163910274688717,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9163910274688717,
        "precision": 0.9103855780502488,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.006581692936798708,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006581692936798708,
        "precision": 0.004917484594507618,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8977505306846624,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8977505306846624,
        "precision": 0.8895431359503216,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.906000697018661,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.906000697018661,
        "precision": 0.8980927034819249,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9188290086493679,
        "f1": 0.8990257580077937,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8990257580077937,
        "precision": 0.89025916421126,
        "recall": 0.9188290086493679
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7570185026771854,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.7570185026771854,
        "precision": 0.740249659411336,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.003105482043469535,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003105482043469535,
        "precision": 0.002219883226452139,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.6187624750499002,
        "f1": 0.5676089287366732,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5676089287366732,
        "precision": 0.5486812090105504,
        "recall": 0.6187624750499002
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8266815575198808,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8266815575198808,
        "precision": 0.8147176546378143,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8877483128980135,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8877483128980135,
        "precision": 0.8795630960301618,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9372366378354401,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9372366378354401,
        "precision": 0.9320691949434465,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.7917498336660014,
        "f1": 0.7565757374140608,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7565757374140608,
        "precision": 0.7415724107340873,
        "recall": 0.7917498336660014
      },
      {
        "accuracy": 0.8582834331337326,
        "f1": 0.8287662769698697,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.8287662769698697,
        "precision": 0.8158191553401134,
        "recall": 0.8582834331337326
      },
      {
        "accuracy": 0.1596806387225549,
        "f1": 0.11495474659147314,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.11495474659147314,
        "precision": 0.10203647289182101,
        "recall": 0.1596806387225549
      },
      {
        "accuracy": 0.5848303393213573,
        "f1": 0.5272873205008933,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.5272873205008933,
        "precision": 0.5043928016981908,
        "recall": 0.5848303393213573
      },
      {
        "accuracy": 0.8090485695276114,
        "f1": 0.7795502198695811,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.7795502198695811,
        "precision": 0.7684857658673185,
        "recall": 0.8090485695276114
      },
      {
        "accuracy": 0.5508982035928144,
        "f1": 0.4948214681747616,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.4948214681747616,
        "precision": 0.4727611536963422,
        "recall": 0.5508982035928144
      },
      {
        "accuracy": 0.8203592814371258,
        "f1": 0.7925028250377552,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.7925028250377552,
        "precision": 0.7813069221751857,
        "recall": 0.8203592814371258
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8140956182872351,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.8140956182872351,
        "precision": 0.8002196664871315,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.4963406520292748,
        "f1": 0.4348805515472182,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.4348805515472182,
        "precision": 0.410712701580965,
        "recall": 0.4963406520292748
      },
      {
        "accuracy": 0.7990685296074518,
        "f1": 0.759297278458955,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.759297278458955,
        "precision": 0.7427272439248487,
        "recall": 0.7990685296074518
      },
      {
        "accuracy": 0.8343313373253493,
        "f1": 0.803371035706365,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.803371035706365,
        "precision": 0.7894876912840986,
        "recall": 0.8343313373253493
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8289452840351044,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8289452840351044,
        "precision": 0.8164448880017743,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0031002243221700683,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0031002243221700683,
        "precision": 0.0020322686997070547,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8187529702499763,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.8187529702499763,
        "precision": 0.8061654468840098,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8172876469283655,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.8172876469283655,
        "precision": 0.8025900579792796,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.8143712574850299,
        "f1": 0.7800684345594525,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7800684345594525,
        "precision": 0.7655688622754492,
        "recall": 0.8143712574850299
      },
      {
        "accuracy": 0.6959414504324684,
        "f1": 0.6429194521010889,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.6429194521010889,
        "precision": 0.6214182745619872,
        "recall": 0.6959414504324684
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.003838547020430613,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.003838547020430613,
        "precision": 0.0029395986185297143,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.4763805721889554,
        "f1": 0.4241553116802617,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.4241553116802617,
        "precision": 0.40378900688281927,
        "recall": 0.4763805721889554
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7611348731109212,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.7611348731109212,
        "precision": 0.744954535373697,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.8279330228432024,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8279330228432024,
        "precision": 0.8144773944175141,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.8456420492348636,
        "f1": 0.8116766467065869,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8116766467065869,
        "precision": 0.7965798561606944,
        "recall": 0.8456420492348636
      },
      {
        "accuracy": 0.458416500332668,
        "f1": 0.41410978184924574,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.41410978184924574,
        "precision": 0.39973755800337935,
        "recall": 0.458416500332668
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.4873064596370224,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.4873064596370224,
        "precision": 0.47408502532268715,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.10379241516966067,
        "f1": 0.07963186735641825,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.07963186735641825,
        "precision": 0.07390033657637057,
        "recall": 0.10379241516966067
      },
      {
        "accuracy": 0.35994677312042583,
        "f1": 0.31163306219158005,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.31163306219158005,
        "precision": 0.2957562741830736,
        "recall": 0.35994677312042583
      },
      {
        "accuracy": 0.38389886892880903,
        "f1": 0.35260859613980394,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.35260859613980394,
        "precision": 0.34374137120902315,
        "recall": 0.38389886892880903
      },
      {
        "accuracy": 0.26081170991350633,
        "f1": 0.22608186198756255,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.22608186198756255,
        "precision": 0.21688018483429541,
        "recall": 0.26081170991350633
      },
      {
        "accuracy": 0.5089820359281437,
        "f1": 0.4668230511703386,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.4668230511703386,
        "precision": 0.453021890821701,
        "recall": 0.5089820359281437
      },
      {
        "accuracy": 0.4204923486360612,
        "f1": 0.380010857687027,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.380010857687027,
        "precision": 0.3684769974469168,
        "recall": 0.4204923486360612
      },
      {
        "accuracy": 0.3865602129075183,
        "f1": 0.35375334799070735,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.35375334799070735,
        "precision": 0.3442167147809784,
        "recall": 0.3865602129075183
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.5050138146375779,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.5050138146375779,
        "precision": 0.4892364626804072,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.5149700598802395,
        "f1": 0.46190012921575113,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.46190012921575113,
        "precision": 0.4439501788146603,
        "recall": 0.5149700598802395
      },
      {
        "accuracy": 0.52228875582169,
        "f1": 0.4803403829867296,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.4803403829867296,
        "precision": 0.46724409520875415,
        "recall": 0.52228875582169
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008784483116192012,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.008784483116192012,
        "precision": 0.007002821262731182,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.4580919927122112,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.4580919927122112,
        "precision": 0.44378344945835624,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.5256154357950765,
        "f1": 0.4786383584471619,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.4786383584471619,
        "precision": 0.4627360903309007,
        "recall": 0.5256154357950765
      },
      {
        "accuracy": 0.5229540918163673,
        "f1": 0.46988577936094666,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.46988577936094666,
        "precision": 0.45295652444900464,
        "recall": 0.5229540918163673
      },
      {
        "accuracy": 0.426480372588157,
        "f1": 0.3754737401128829,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.3754737401128829,
        "precision": 0.35881469384463394,
        "recall": 0.426480372588157
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.007235054994536033,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007235054994536033,
        "precision": 0.005064456596570756,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.2326262526741778,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.2326262526741778,
        "precision": 0.22174475290252282,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.4417831004657352,
        "f1": 0.39208258167007337,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.39208258167007337,
        "precision": 0.3742000871408722,
        "recall": 0.4417831004657352
      },
      {
        "accuracy": 0.4930139720558882,
        "f1": 0.44348761609678106,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.44348761609678106,
        "precision": 0.428243865988377,
        "recall": 0.4930139720558882
      },
      {
        "accuracy": 0.614105123087159,
        "f1": 0.5673570824278712,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.5673570824278712,
        "precision": 0.5508491815847691,
        "recall": 0.614105123087159
      },
      {
        "accuracy": 0.844311377245509,
        "f1": 0.8135427557583246,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8135427557583246,
        "precision": 0.8009895552809725,
        "recall": 0.844311377245509
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8650476824129519,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8650476824129519,
        "precision": 0.8540363717010424,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.15635395874916833,
        "f1": 0.1228024360103103,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1228024360103103,
        "precision": 0.11365602384682243,
        "recall": 0.15635395874916833
      },
      {
        "accuracy": 0.6640053226879574,
        "f1": 0.6107240545364298,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6107240545364298,
        "precision": 0.5908289241622575,
        "recall": 0.6640053226879574
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8256307490838427,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8256307490838427,
        "precision": 0.8179567247402166,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.4865676762133277,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4865676762133277,
        "precision": 0.47055749805608144,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.8822355289421158,
        "f1": 0.8599102568164444,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8599102568164444,
        "precision": 0.850832462060007,
        "recall": 0.8822355289421158
      },
      {
        "accuracy": 0.8436460412508316,
        "f1": 0.8132212246982705,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8132212246982705,
        "precision": 0.8019706618509014,
        "recall": 0.8436460412508316
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.7226774445337318,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7226774445337318,
        "precision": 0.7065947470139087,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.5801729873586161,
        "f1": 0.5227623784510012,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5227623784510012,
        "precision": 0.5007886583734886,
        "recall": 0.5801729873586161
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8167886449323575,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8167886449323575,
        "precision": 0.8041139942337546,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8744400088711466,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8744400088711466,
        "precision": 0.8648544181478313,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007182689381199111,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007182689381199111,
        "precision": 0.0061676453002657925,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8751866637096178,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8751866637096178,
        "precision": 0.866113012071096,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.8855622089155023,
        "f1": 0.8581408611348731,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8581408611348731,
        "precision": 0.846074517631404,
        "recall": 0.8855622089155023
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.828289452840351,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.828289452840351,
        "precision": 0.8151142160124195,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.7697937458416501,
        "f1": 0.7232243693321537,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7232243693321537,
        "precision": 0.7039254823685961,
        "recall": 0.7697937458416501
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005451444379535224,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005451444379535224,
        "precision": 0.004618348514125856,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.5029940119760479,
        "f1": 0.44955132826483146,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.44955132826483146,
        "precision": 0.432157813121206,
        "recall": 0.5029940119760479
      },
      {
        "accuracy": 0.7737857618097139,
        "f1": 0.7358368880324968,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7358368880324968,
        "precision": 0.7202769065044514,
        "recall": 0.7737857618097139
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7899777645286626,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7899777645286626,
        "precision": 0.7754443493964452,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8849190507873143,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8849190507873143,
        "precision": 0.8747726768684853,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.846307385229541,
        "f1": 0.816873660087233,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.816873660087233,
        "precision": 0.8046430947628552,
        "recall": 0.846307385229541
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9119760479041915,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9119760479041915,
        "precision": 0.905045464626303,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.14570858283433133,
        "f1": 0.10737512237730193,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.10737512237730193,
        "precision": 0.09667971564179148,
        "recall": 0.14570858283433133
      },
      {
        "accuracy": 0.612109115103127,
        "f1": 0.5499559766026832,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5499559766026832,
        "precision": 0.5261696664391274,
        "recall": 0.612109115103127
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8933292145866996,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.8933292145866996,
        "precision": 0.8854576561163388,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.564870259481038,
        "f1": 0.5067520710235282,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.5067520710235282,
        "precision": 0.4861613512935583,
        "recall": 0.564870259481038
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8715806482273548,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.8715806482273548,
        "precision": 0.8627818437199674,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.888301175426924,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.888301175426924,
        "precision": 0.8794585432309984,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.8063872255489022,
        "f1": 0.7689578514927817,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.7689578514927817,
        "precision": 0.7542589424325952,
        "recall": 0.8063872255489022
      },
      {
        "accuracy": 0.5375914836992681,
        "f1": 0.47276422660654194,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.47276422660654194,
        "precision": 0.4482838555692847,
        "recall": 0.5375914836992681
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.8313816810822798,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.8313816810822798,
        "precision": 0.8199001707983743,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8946551341760923,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.8946551341760923,
        "precision": 0.8863051674428919,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004032278451124284,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.004032278451124284,
        "precision": 0.003065089068318312,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8935589139181953,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.8935589139181953,
        "precision": 0.8849190507873143,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8872699046351741,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.8872699046351741,
        "precision": 0.8778221335107563,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.867598137059215,
        "f1": 0.8386696692085914,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.8386696692085914,
        "precision": 0.8264471057884232,
        "recall": 0.867598137059215
      },
      {
        "accuracy": 0.7551563539587491,
        "f1": 0.7081603175415552,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.7081603175415552,
        "precision": 0.6883246974065338,
        "recall": 0.7551563539587491
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004328324084463979,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004328324084463979,
        "precision": 0.0036003713582019557,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.48303393213572854,
        "f1": 0.42688056389048235,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.42688056389048235,
        "precision": 0.40650869977217285,
        "recall": 0.48303393213572854
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8288597408357888,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.8288597408357888,
        "precision": 0.8174983366600134,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.8962075848303394,
        "f1": 0.8734879447454297,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.8734879447454297,
        "precision": 0.8634841428254602,
        "recall": 0.8962075848303394
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.8989259576085923,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.8989259576085923,
        "precision": 0.8909588230945514,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.8842315369261478,
        "f1": 0.8596046003231632,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8596046003231632,
        "precision": 0.8491017964071855,
        "recall": 0.8842315369261478
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.9134841428254602,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9134841428254602,
        "precision": 0.906187624750499,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.16234198270126413,
        "f1": 0.12072471457208422,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12072471457208422,
        "precision": 0.10994506432826708,
        "recall": 0.16234198270126413
      },
      {
        "accuracy": 0.6852960745176314,
        "f1": 0.6288471637773034,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6288471637773034,
        "precision": 0.6067246699482228,
        "recall": 0.6852960745176314
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.8967129233596298,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8967129233596298,
        "precision": 0.8898778755066181,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.6613439787092482,
        "f1": 0.6083554643998973,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6083554643998973,
        "precision": 0.5886789432198614,
        "recall": 0.6613439787092482
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9029718341095586,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9029718341095586,
        "precision": 0.8955311599024174,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9173209137280993,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9173209137280993,
        "precision": 0.9108338877799955,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7881126635617653,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7881126635617653,
        "precision": 0.7736780407439091,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.5801729873586161,
        "f1": 0.5166735792484296,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5166735792484296,
        "precision": 0.4926572780365196,
        "recall": 0.5801729873586161
      },
      {
        "accuracy": 0.8942115768463074,
        "f1": 0.8726990463517409,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8726990463517409,
        "precision": 0.8638168108227988,
        "recall": 0.8942115768463074
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8841776763932454,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8841776763932454,
        "precision": 0.8744954535373697,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005799466266713372,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005799466266713372,
        "precision": 0.004710289812493585,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9038145930361499,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9038145930361499,
        "precision": 0.8963406520292747,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.8991794189398981,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8991794189398981,
        "precision": 0.89090707473941,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.871202040363717,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.871202040363717,
        "precision": 0.8604299337832273,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.7930805056553559,
        "f1": 0.7514494819884042,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.7514494819884042,
        "precision": 0.7341348641747844,
        "recall": 0.7930805056553559
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0031667570318984397,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0031667570318984397,
        "precision": 0.0024322932949498543,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.5335994677312043,
        "f1": 0.4781125782622788,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4781125782622788,
        "precision": 0.4580948806497709,
        "recall": 0.5335994677312043
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7942559325792858,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7942559325792858,
        "precision": 0.7807939676203149,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.8882235528942116,
        "f1": 0.8651490669454741,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8651490669454741,
        "precision": 0.8555222887558216,
        "recall": 0.8882235528942116
      },
      {
        "accuracy": 0.93812375249501,
        "f1": 0.9226436016855178,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9226436016855178,
        "precision": 0.9155799512086936,
        "recall": 0.93812375249501
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0021406117635794347,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0021406117635794347,
        "precision": 0.001616690467122595,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013737773628961908,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0013737773628961908,
        "precision": 0.0010910007742099743,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002620326584803645,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.002620326584803645,
        "precision": 0.0022537140634642156,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0015885869082684573,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0015885869082684573,
        "precision": 0.0014722331742462284,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0013770456888148334,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0013770456888148334,
        "precision": 0.00135446279158854,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015478930942122205,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0015478930942122205,
        "precision": 0.0014466341468050683,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017873297580901538,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0017873297580901538,
        "precision": 0.0015997548807695384,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0022111246087431063,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0022111246087431063,
        "precision": 0.00210989814369823,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001997789662317679,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.001997789662317679,
        "precision": 0.0017256697353571508,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.002828980016007452,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.002828980016007452,
        "precision": 0.0024734863481497946,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0017521093147345324,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0017521093147345324,
        "precision": 0.0013775316261974751,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011371748796898497,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0011371748796898497,
        "precision": 0.0009407484221706688,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001699530790985353,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.001699530790985353,
        "precision": 0.0015493501005983557,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001405864516297633,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.001405864516297633,
        "precision": 0.0011475771318155514,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00262476858456629,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.00262476858456629,
        "precision": 0.0022401740980196,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001633368651047169,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.001633368651047169,
        "precision": 0.0014960690046261875,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0013753278734620286,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0013753278734620286,
        "precision": 0.001067908205725286,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.026653869624450197,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.026653869624450197,
        "precision": 0.024143351289059874,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0017190821119660688,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0017190821119660688,
        "precision": 0.0013527712365105015,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010169900041674847,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0010169900041674847,
        "precision": 0.0008966695442613796,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0024272086115263124,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0024272086115263124,
        "precision": 0.0019876461636395013,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0022856676016973177,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0022856676016973177,
        "precision": 0.0021742129419069518,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8680654563888097,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8680654563888097,
        "precision": 0.8587444159300446,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9194278110445776,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9194278110445776,
        "precision": 0.9135839432246619,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.16633399866932802,
        "f1": 0.12628441572395768,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12628441572395768,
        "precision": 0.11447894069111868,
        "recall": 0.16633399866932802
      },
      {
        "accuracy": 0.6932801064537591,
        "f1": 0.642379790683184,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.642379790683184,
        "precision": 0.6233155622377179,
        "recall": 0.6932801064537591
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8912471353589119,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8912471353589119,
        "precision": 0.885125442894116,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.6180971390552229,
        "f1": 0.5685143421670369,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5685143421670369,
        "precision": 0.5502250961614843,
        "recall": 0.6180971390552229
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8925498209929348,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8925498209929348,
        "precision": 0.8849475651870862,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8861958622437665,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8861958622437665,
        "precision": 0.8775670880461299,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.8070525615435795,
        "f1": 0.7724360802205114,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7724360802205114,
        "precision": 0.7591792845285859,
        "recall": 0.8070525615435795
      },
      {
        "accuracy": 0.5868263473053892,
        "f1": 0.5259766181921871,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5259766181921871,
        "precision": 0.5031608980211775,
        "recall": 0.5868263473053892
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8911415264708676,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8911415264708676,
        "precision": 0.8832557108006209,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.8968729208250167,
        "f1": 0.8712923359629946,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8712923359629946,
        "precision": 0.8601685517853184,
        "recall": 0.8968729208250167
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9124196052339765,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9124196052339765,
        "precision": 0.9055999112885341,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.0054840193766626565,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0054840193766626565,
        "precision": 0.004597667720322378,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9044133954313595,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9044133954313595,
        "precision": 0.8951208693723665,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9001996007984032,
        "f1": 0.8785761809713906,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8785761809713906,
        "precision": 0.8692503881126635,
        "recall": 0.9001996007984032
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7781367667595211,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7781367667595211,
        "precision": 0.7614105123087159,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0028528783561449157,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0028528783561449157,
        "precision": 0.0022548172420403904,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.4802476244093011,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4802476244093011,
        "precision": 0.46098440444747824,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.8097139055222887,
        "f1": 0.773502729989756,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.773502729989756,
        "precision": 0.7581796724012293,
        "recall": 0.8097139055222887
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8700725533060862,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8700725533060862,
        "precision": 0.8598987210763659,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9329563096030162,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9329563096030162,
        "precision": 0.9268906631182081,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.8988689288090486,
        "f1": 0.8769476919177518,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8769476919177518,
        "precision": 0.8676424927921933,
        "recall": 0.8988689288090486
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9224661787536039,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9224661787536039,
        "precision": 0.9156132180084277,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.1550232867598137,
        "f1": 0.11601294288420037,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.11601294288420037,
        "precision": 0.10528857582531978,
        "recall": 0.1550232867598137
      },
      {
        "accuracy": 0.6420492348636061,
        "f1": 0.5816750792483537,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.5816750792483537,
        "precision": 0.5584465822489775,
        "recall": 0.6420492348636061
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8791232350114585,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.8791232350114585,
        "precision": 0.8710095681652568,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.5768463073852296,
        "f1": 0.5244569476760267,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.5244569476760267,
        "precision": 0.5055497710687331,
        "recall": 0.5768463073852296
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8963533250958401,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.8963533250958401,
        "precision": 0.8897477771729269,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8904524284763805,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.8904524284763805,
        "precision": 0.8812438614833823,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.8203592814371258,
        "f1": 0.7861330249553803,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.7861330249553803,
        "precision": 0.7722673700218611,
        "recall": 0.8203592814371258
      },
      {
        "accuracy": 0.571523619427811,
        "f1": 0.5094202210410969,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.5094202210410969,
        "precision": 0.4850686193750066,
        "recall": 0.571523619427811
      },
      {
        "accuracy": 0.8942115768463074,
        "f1": 0.8711370908975699,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.8711370908975699,
        "precision": 0.8612885340430251,
        "recall": 0.8942115768463074
      },
      {
        "accuracy": 0.9028609447771124,
        "f1": 0.8819250388112664,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.8819250388112664,
        "precision": 0.8722222222222222,
        "recall": 0.9028609447771124
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.904280328232424,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.904280328232424,
        "precision": 0.8968174761587934,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.005519675952907966,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.005519675952907966,
        "precision": 0.004389700106771458,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9080632386021606,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9080632386021606,
        "precision": 0.9005877134619649,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8566200931470392,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.8566200931470392,
        "precision": 0.8452095808383233,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.7777777777777778,
        "f1": 0.7336353747531392,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.7336353747531392,
        "precision": 0.7161521113616921,
        "recall": 0.7777777777777778
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0032187168494203157,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0032187168494203157,
        "precision": 0.0024639373960256084,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.49833666001330673,
        "f1": 0.444931186947155,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.444931186947155,
        "precision": 0.4257046753054736,
        "recall": 0.49833666001330673
      },
      {
        "accuracy": 0.8363273453093812,
        "f1": 0.8024078826474036,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.8024078826474036,
        "precision": 0.7873934670341856,
        "recall": 0.8363273453093812
      },
      {
        "accuracy": 0.8995342648037259,
        "f1": 0.874428919937902,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.874428919937902,
        "precision": 0.8631625637613662,
        "recall": 0.8995342648037259
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9219117320913729,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9219117320913729,
        "precision": 0.9148591705477933,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.8622754491017964,
        "f1": 0.8345013676351003,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8345013676351003,
        "precision": 0.8226565387743032,
        "recall": 0.8622754491017964
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8887241390235402,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.8887241390235402,
        "precision": 0.8797516078953205,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.1603459747172322,
        "f1": 0.1263279879987641,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.1263279879987641,
        "precision": 0.11653280512695828,
        "recall": 0.1603459747172322
      },
      {
        "accuracy": 0.6879574184963406,
        "f1": 0.6347696622147719,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.6347696622147719,
        "precision": 0.6131089672506839,
        "recall": 0.6879574184963406
      },
      {
        "accuracy": 0.8855622089155023,
        "f1": 0.862732783591067,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.862732783591067,
        "precision": 0.8538560445247072,
        "recall": 0.8855622089155023
      },
      {
        "accuracy": 0.5888223552894212,
        "f1": 0.5397779237100594,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.5397779237100594,
        "precision": 0.5214532756291345,
        "recall": 0.5888223552894212
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8856356070926927,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.8856356070926927,
        "precision": 0.8776344137122579,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8945099699590718,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.8945099699590718,
        "precision": 0.8861166555777333,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.7917498336660014,
        "f1": 0.7545718087634256,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.7545718087634256,
        "precision": 0.7398229995036382,
        "recall": 0.7917498336660014
      },
      {
        "accuracy": 0.5801729873586161,
        "f1": 0.5193608509476773,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.5193608509476773,
        "precision": 0.49805336417112867,
        "recall": 0.5801729873586161
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8546430947628553,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.8546430947628553,
        "precision": 0.8460163921241766,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.8649367930805056,
        "f1": 0.8351313246522828,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.8351313246522828,
        "precision": 0.822195291955771,
        "recall": 0.8649367930805056
      },
      {
        "accuracy": 0.9021956087824351,
        "f1": 0.8834150989839612,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.8834150989839612,
        "precision": 0.8753825681969395,
        "recall": 0.9021956087824351
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.004866044125692633,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.004866044125692633,
        "precision": 0.0035138439097897258,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8881823654278744,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.8881823654278744,
        "precision": 0.8802727877578178,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.8962075848303394,
        "f1": 0.8715014415613219,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.8715014415613219,
        "precision": 0.860734087380794,
        "recall": 0.8962075848303394
      },
      {
        "accuracy": 0.7651363938789089,
        "f1": 0.7190703249585485,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7190703249585485,
        "precision": 0.7001388996897978,
        "recall": 0.7651363938789089
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.002865634680240864,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.002865634680240864,
        "precision": 0.0017674063397782882,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.4951583689989232,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.4951583689989232,
        "precision": 0.47531591882302227,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.7870924817032602,
        "f1": 0.7525804719417494,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.7525804719417494,
        "precision": 0.7379703555851259,
        "recall": 0.7870924817032602
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8266926464531256,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.8266926464531256,
        "precision": 0.8134915354476233,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.912903293941218,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.912903293941218,
        "precision": 0.9067143490796186,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.7105788423153693,
        "f1": 0.667353700487433,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.667353700487433,
        "precision": 0.6516034069427283,
        "recall": 0.7105788423153693
      },
      {
        "accuracy": 0.7751164337990686,
        "f1": 0.7370919204252537,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7370919204252537,
        "precision": 0.7229356102609594,
        "recall": 0.7751164337990686
      },
      {
        "accuracy": 0.1277445109780439,
        "f1": 0.10327893309564376,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.10327893309564376,
        "precision": 0.09624324437824372,
        "recall": 0.1277445109780439
      },
      {
        "accuracy": 0.5369261477045908,
        "f1": 0.4816954822610178,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4816954822610178,
        "precision": 0.46215207318001733,
        "recall": 0.5369261477045908
      },
      {
        "accuracy": 0.6473719228210246,
        "f1": 0.6156423287660813,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6156423287660813,
        "precision": 0.6053560882706512,
        "recall": 0.6473719228210246
      },
      {
        "accuracy": 0.4364604125083167,
        "f1": 0.3902790345970549,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3902790345970549,
        "precision": 0.3760709602496617,
        "recall": 0.4364604125083167
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.6851789152928052,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6851789152928052,
        "precision": 0.6730228289859028,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.7132401862940785,
        "f1": 0.6763851644839098,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6763851644839098,
        "precision": 0.6646400843447925,
        "recall": 0.7132401862940785
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.5800495972093952,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5800495972093952,
        "precision": 0.5653549823929652,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.4491017964071856,
        "f1": 0.3966623553391194,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3966623553391194,
        "precision": 0.37768255714862503,
        "recall": 0.4491017964071856
      },
      {
        "accuracy": 0.7658017298735862,
        "f1": 0.7250393393107964,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7250393393107964,
        "precision": 0.7085170927985299,
        "recall": 0.7658017298735862
      },
      {
        "accuracy": 0.7451763140385895,
        "f1": 0.7037243454409123,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7037243454409123,
        "precision": 0.6874932674333871,
        "recall": 0.7451763140385895
      },
      {
        "accuracy": 0.7711244178310046,
        "f1": 0.7352755287885028,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7352755287885028,
        "precision": 0.7216913615449876,
        "recall": 0.7711244178310046
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.003991938091540744,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003991938091540744,
        "precision": 0.003270932985732686,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.7784431137724551,
        "f1": 0.7406639102746887,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7406639102746887,
        "precision": 0.7271435964050734,
        "recall": 0.7784431137724551
      },
      {
        "accuracy": 0.782435129740519,
        "f1": 0.7416871206233657,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7416871206233657,
        "precision": 0.7253998616523567,
        "recall": 0.782435129740519
      },
      {
        "accuracy": 0.7351962741184298,
        "f1": 0.6892220849306678,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6892220849306678,
        "precision": 0.6715386686943573,
        "recall": 0.7351962741184298
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.004765464983106606,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004765464983106606,
        "precision": 0.0035882923493918443,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.3745841650033267,
        "f1": 0.3273201612090398,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3273201612090398,
        "precision": 0.3115576588102125,
        "recall": 0.3745841650033267
      },
      {
        "accuracy": 0.6560212907518297,
        "f1": 0.6108991492724029,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6108991492724029,
        "precision": 0.5935675860326559,
        "recall": 0.6560212907518297
      },
      {
        "accuracy": 0.7105788423153693,
        "f1": 0.6660789789158438,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6660789789158438,
        "precision": 0.6505641920844125,
        "recall": 0.7105788423153693
      },
      {
        "accuracy": 0.7897538256819694,
        "f1": 0.7486846893034519,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7486846893034519,
        "precision": 0.732202526164602,
        "recall": 0.7897538256819694
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0009396720950251746,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0009396720950251746,
        "precision": 0.0008120908158957884,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0009647515477959851,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0009647515477959851,
        "precision": 0.0006554013689102268,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0016496227055870015,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0016496227055870015,
        "precision": 0.001281826349021755,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009625858451805731,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0009625858451805731,
        "precision": 0.0008473348511290018,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000716540199287796,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.000716540199287796,
        "precision": 0.0006916271765268132,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 8.790434328500533e-05,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 8.790434328500533e-05,
        "precision": 4.5255886331128486e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0016901146496641865,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0016901146496641865,
        "precision": 0.001530054378455936,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009248235033880805,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0009248235033880805,
        "precision": 0.0008063792607854332,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011781818506852934,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0011781818506852934,
        "precision": 0.001033562086993975,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0018559346620971497,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0018559346620971497,
        "precision": 0.0016131345757853458,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0008216777056353502,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0008216777056353502,
        "precision": 0.0007465206067337811,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007930151992038225,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0007930151992038225,
        "precision": 0.0007335885659494305,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00011262177963865648,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.00011262177963865648,
        "precision": 5.7325813352982314e-05,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.028778628778628777,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.028778628778628777,
        "precision": 0.02533711575627743,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008675917261970961,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0008675917261970961,
        "precision": 0.0007715643310533728,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0019562107215147554,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0019562107215147554,
        "precision": 0.0016909432325283996,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0004547342165488994,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0004547342165488994,
        "precision": 0.00028487388261301804,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0006579573378839297,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0006579573378839297,
        "precision": 0.00037455330698476814,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0005840955736038196,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0005840955736038196,
        "precision": 0.0004057496771409442,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007476869253316359,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0007476869253316359,
        "precision": 0.0007074461803750692,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0006944751263868646,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0006944751263868646,
        "precision": 0.0004658473034853009,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007504816797209637,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0007504816797209637,
        "precision": 0.0007093728549456055,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.4530938123752495,
        "f1": 0.40060218673958936,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.40060218673958936,
        "precision": 0.3828437789016631,
        "recall": 0.4530938123752495
      },
      {
        "accuracy": 0.5089820359281437,
        "f1": 0.4523215720102505,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.4523215720102505,
        "precision": 0.4337809832008842,
        "recall": 0.5089820359281437
      },
      {
        "accuracy": 0.18163672654690619,
        "f1": 0.1445951571682463,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1445951571682463,
        "precision": 0.13268938313848494,
        "recall": 0.18163672654690619
      },
      {
        "accuracy": 0.49700598802395207,
        "f1": 0.44247191890728343,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.44247191890728343,
        "precision": 0.4227614035997269,
        "recall": 0.49700598802395207
      },
      {
        "accuracy": 0.42381902860944776,
        "f1": 0.3884356638298128,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.3884356638298128,
        "precision": 0.37894046331347303,
        "recall": 0.42381902860944776
      },
      {
        "accuracy": 0.3992015968063872,
        "f1": 0.3510807277675048,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3510807277675048,
        "precision": 0.33656726488562816,
        "recall": 0.3992015968063872
      },
      {
        "accuracy": 0.5515635395874917,
        "f1": 0.5008395158147869,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5008395158147869,
        "precision": 0.4834896926463793,
        "recall": 0.5515635395874917
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.5081430682383948,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5081430682383948,
        "precision": 0.48796076954759593,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.4337990685296075,
        "f1": 0.39250873430514627,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.39250873430514627,
        "precision": 0.3789449900267844,
        "recall": 0.4337990685296075
      },
      {
        "accuracy": 0.35063206919494344,
        "f1": 0.30515640196278915,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.30515640196278915,
        "precision": 0.28975711819436134,
        "recall": 0.35063206919494344
      },
      {
        "accuracy": 0.5528942115768463,
        "f1": 0.49851754353131106,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.49851754353131106,
        "precision": 0.4798375065091633,
        "recall": 0.5528942115768463
      },
      {
        "accuracy": 0.48835662009314706,
        "f1": 0.4280624215093227,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4280624215093227,
        "precision": 0.40842085669929984,
        "recall": 0.48835662009314706
      },
      {
        "accuracy": 0.5316034597471723,
        "f1": 0.477533095610666,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.477533095610666,
        "precision": 0.459070343052379,
        "recall": 0.5316034597471723
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0026309708689751785,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0026309708689751785,
        "precision": 0.0018854601041376762,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.5276114437791084,
        "f1": 0.46869257008977566,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.46869257008977566,
        "precision": 0.4488306461320702,
        "recall": 0.5276114437791084
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.47542540670759936,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.47542540670759936,
        "precision": 0.45590751602004953,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.5011463992501916,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5011463992501916,
        "precision": 0.48281145488572735,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.4204923486360612,
        "f1": 0.36069819944875425,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.36069819944875425,
        "precision": 0.34044063886878256,
        "recall": 0.4204923486360612
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.00639389428065945,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00639389428065945,
        "precision": 0.004930715529326049,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.44510978043912175,
        "f1": 0.39044892340984366,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.39044892340984366,
        "precision": 0.3721436114688521,
        "recall": 0.44510978043912175
      },
      {
        "accuracy": 0.447771124417831,
        "f1": 0.3924015660542606,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3924015660542606,
        "precision": 0.3755014834593371,
        "recall": 0.447771124417831
      },
      {
        "accuracy": 0.5575515635395875,
        "f1": 0.5010328059095741,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5010328059095741,
        "precision": 0.48171565450713033,
        "recall": 0.5575515635395875
      },
      {
        "accuracy": 0.7624750499001997,
        "f1": 0.7176842563070107,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7176842563070107,
        "precision": 0.6992369351650789,
        "recall": 0.7624750499001997
      },
      {
        "accuracy": 0.8616101131071191,
        "f1": 0.8302506098913285,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8302506098913285,
        "precision": 0.8162748576920233,
        "recall": 0.8616101131071191
      },
      {
        "accuracy": 0.13506320691949433,
        "f1": 0.0995464528339954,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.0995464528339954,
        "precision": 0.08989501506673046,
        "recall": 0.13506320691949433
      },
      {
        "accuracy": 0.5449101796407185,
        "f1": 0.48198049824796335,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.48198049824796335,
        "precision": 0.4591692898050771,
        "recall": 0.5449101796407185
      },
      {
        "accuracy": 0.8023952095808383,
        "f1": 0.7711202414795228,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.7711202414795228,
        "precision": 0.7591105981325541,
        "recall": 0.8023952095808383
      },
      {
        "accuracy": 0.5109780439121756,
        "f1": 0.45707708227732124,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.45707708227732124,
        "precision": 0.4381097522036233,
        "recall": 0.5109780439121756
      },
      {
        "accuracy": 0.823020625415835,
        "f1": 0.7915518170009187,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7915518170009187,
        "precision": 0.7783274720400469,
        "recall": 0.823020625415835
      },
      {
        "accuracy": 0.8429807052561543,
        "f1": 0.8114913031080696,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.8114913031080696,
        "precision": 0.7980705256154358,
        "recall": 0.8429807052561543
      },
      {
        "accuracy": 0.7751164337990686,
        "f1": 0.7340446091943098,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.7340446091943098,
        "precision": 0.7171609162627126,
        "recall": 0.7751164337990686
      },
      {
        "accuracy": 0.4750499001996008,
        "f1": 0.41192165932684893,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.41192165932684893,
        "precision": 0.38908320924288986,
        "recall": 0.4750499001996008
      },
      {
        "accuracy": 0.780439121756487,
        "f1": 0.738486437787835,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.738486437787835,
        "precision": 0.7212434918522743,
        "recall": 0.780439121756487
      },
      {
        "accuracy": 0.8369926813040586,
        "f1": 0.8066327662136046,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8066327662136046,
        "precision": 0.7930092196559262,
        "recall": 0.8369926813040586
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.8033192873512235,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.8033192873512235,
        "precision": 0.7903544762327198,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004269745534032816,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.004269745534032816,
        "precision": 0.003265457620506936,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.8150365934797072,
        "f1": 0.7774862972467763,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.7774862972467763,
        "precision": 0.7610624904038078,
        "recall": 0.8150365934797072
      },
      {
        "accuracy": 0.83166999334664,
        "f1": 0.7948695202188216,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.7948695202188216,
        "precision": 0.7786223848599098,
        "recall": 0.83166999334664
      },
      {
        "accuracy": 0.7970725216234198,
        "f1": 0.758526861620674,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.758526861620674,
        "precision": 0.74157874726737,
        "recall": 0.7970725216234198
      },
      {
        "accuracy": 0.6799733865602129,
        "f1": 0.6215790640940342,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.6215790640940342,
        "precision": 0.5976911496871575,
        "recall": 0.6799733865602129
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.003252556644955618,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003252556644955618,
        "precision": 0.0023571568264790514,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.44644045242847635,
        "f1": 0.3888105087271971,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.3888105087271971,
        "precision": 0.36814367521081026,
        "recall": 0.44644045242847635
      },
      {
        "accuracy": 0.8469727212242182,
        "f1": 0.8142381902860945,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8142381902860945,
        "precision": 0.7995675316034597,
        "recall": 0.8469727212242182
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8176784478181683,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.8176784478181683,
        "precision": 0.8029552007096917,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.8416500332667998,
        "f1": 0.8069950046995954,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8069950046995954,
        "precision": 0.7919446820644425,
        "recall": 0.8416500332667998
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8896872920825017,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8896872920825017,
        "precision": 0.8810711909514305,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.1377245508982036,
        "f1": 0.10212807405517729,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.10212807405517729,
        "precision": 0.09300902289322363,
        "recall": 0.1377245508982036
      },
      {
        "accuracy": 0.5941450432468397,
        "f1": 0.5364700133163206,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.5364700133163206,
        "precision": 0.5149286083916822,
        "recall": 0.5941450432468397
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8625967641436701,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8625967641436701,
        "precision": 0.8552310722470402,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.5662009314703925,
        "f1": 0.5160876327043993,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.5160876327043993,
        "precision": 0.4983707142143466,
        "recall": 0.5662009314703925
      },
      {
        "accuracy": 0.8709248170326015,
        "f1": 0.8481565968591916,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8481565968591916,
        "precision": 0.8394391351976183,
        "recall": 0.8709248170326015
      },
      {
        "accuracy": 0.8988689288090486,
        "f1": 0.8783005417735956,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.8783005417735956,
        "precision": 0.8691727655799512,
        "recall": 0.8988689288090486
      },
      {
        "accuracy": 0.8163672654690619,
        "f1": 0.7814767290815195,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.7814767290815195,
        "precision": 0.7675601178595192,
        "recall": 0.8163672654690619
      },
      {
        "accuracy": 0.5369261477045908,
        "f1": 0.47432595127205907,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.47432595127205907,
        "precision": 0.4502019769983842,
        "recall": 0.5369261477045908
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8228226087507524,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8228226087507524,
        "precision": 0.8115129529301185,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8669882457307608,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8669882457307608,
        "precision": 0.8566486075468112,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.8711814466305483,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8711814466305483,
        "precision": 0.86187624750499,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0040743465402685855,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0040743465402685855,
        "precision": 0.003062780024195036,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8765136393878908,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8765136393878908,
        "precision": 0.867276557995121,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.864318981085448,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.864318981085448,
        "precision": 0.8533710357063651,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8144409593511389,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8144409593511389,
        "precision": 0.7996118873364382,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.7485029940119761,
        "f1": 0.7004022886258416,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7004022886258416,
        "precision": 0.6803369045385014,
        "recall": 0.7485029940119761
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0032713368541711853,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0032713368541711853,
        "precision": 0.002744668375905901,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.4657351962741184,
        "f1": 0.4157091885200885,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.4157091885200885,
        "precision": 0.39733248750214817,
        "recall": 0.4657351962741184
      },
      {
        "accuracy": 0.8536260811709914,
        "f1": 0.8246839654025283,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.8246839654025283,
        "precision": 0.8122532712353071,
        "recall": 0.8536260811709914
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8885118651585718,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.8885118651585718,
        "precision": 0.8792415169660679,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.8915502328675982,
        "f1": 0.8705235032580342,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8705235032580342,
        "precision": 0.8620980261698825,
        "recall": 0.8915502328675982
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9240334146521771,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9240334146521771,
        "precision": 0.9183799068529608,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.14238190286094476,
        "f1": 0.10891979908924251,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.10891979908924251,
        "precision": 0.10001910090412651,
        "recall": 0.14238190286094476
      },
      {
        "accuracy": 0.6773120425815037,
        "f1": 0.6221942838709306,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6221942838709306,
        "precision": 0.6014674976222469,
        "recall": 0.6773120425815037
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.8993584260051326,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8993584260051326,
        "precision": 0.8934310123713924,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.5568862275449101,
        "f1": 0.5061198818184846,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5061198818184846,
        "precision": 0.4882874661363511,
        "recall": 0.5568862275449101
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.9018835345182651,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9018835345182651,
        "precision": 0.8957703640338371,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9155466844089598,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9155466844089598,
        "precision": 0.90909292526059,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.8010645375914837,
        "f1": 0.7650767248571639,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.7650767248571639,
        "precision": 0.7513808602131956,
        "recall": 0.8010645375914837
      },
      {
        "accuracy": 0.6180971390552229,
        "f1": 0.5655929086068806,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.5655929086068806,
        "precision": 0.5468152827434264,
        "recall": 0.6180971390552229
      },
      {
        "accuracy": 0.9068529607451763,
        "f1": 0.8879162310300034,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8879162310300034,
        "precision": 0.8799955644267021,
        "recall": 0.9068529607451763
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8859297278458954,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8859297278458954,
        "precision": 0.8763583943224662,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9080727434020848,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9080727434020848,
        "precision": 0.9017409625194056,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.007178872079503093,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.007178872079503093,
        "precision": 0.006008291924425436,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9153486677438775,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9153486677438775,
        "precision": 0.909376485124988,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.8974606342869815,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.8974606342869815,
        "precision": 0.8885625574248328,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8774134271140259,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8774134271140259,
        "precision": 0.867476158793524,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.7791084497671324,
        "f1": 0.7382652351714227,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.7382652351714227,
        "precision": 0.7216939137597822,
        "recall": 0.7791084497671324
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.003441321043391839,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.003441321043391839,
        "precision": 0.0026402017625453108,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.5276114437791084,
        "f1": 0.4731540818167565,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.4731540818167565,
        "precision": 0.45406575017353457,
        "recall": 0.5276114437791084
      },
      {
        "accuracy": 0.8356620093147039,
        "f1": 0.8072595549641458,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8072595549641458,
        "precision": 0.7954165742588896,
        "recall": 0.8356620093147039
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8853900664279907,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8853900664279907,
        "precision": 0.8770181858505212,
        "recall": 0.9055222887558216
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}