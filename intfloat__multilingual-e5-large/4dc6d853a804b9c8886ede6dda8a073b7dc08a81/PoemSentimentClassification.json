{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 15.05955958366394,
  "kg_co2_emissions": 0.0022416744994737158,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.5,
        "f1": 0.3949554582869316,
        "f1_weighted": 0.5499898724506147,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5,
        "scores_per_experiment": [
          {
            "accuracy": 0.5480769230769231,
            "f1": 0.42431077694235586,
            "f1_weighted": 0.5909678041256989
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.4579852384155191,
            "f1_weighted": 0.6276210934628046
          },
          {
            "accuracy": 0.5576923076923077,
            "f1": 0.42143719056660695,
            "f1_weighted": 0.5956278008542306
          },
          {
            "accuracy": 0.5384615384615384,
            "f1": 0.4170233581998288,
            "f1_weighted": 0.6203485072263353
          },
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.4465465465465466,
            "f1_weighted": 0.6194617694617695
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.412828947368421,
            "f1_weighted": 0.5402960526315789
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.3898032918506624,
            "f1_weighted": 0.4968347589784764
          },
          {
            "accuracy": 0.41346153846153844,
            "f1": 0.31836121836121833,
            "f1_weighted": 0.4721050721050721
          },
          {
            "accuracy": 0.46153846153846156,
            "f1": 0.3604840208101078,
            "f1_weighted": 0.5002402952862819
          },
          {
            "accuracy": 0.33653846153846156,
            "f1": 0.30077399380804953,
            "f1_weighted": 0.43639557037389853
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.49142857142857144,
        "f1": 0.38898462307289006,
        "f1_weighted": 0.5446818069664626,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.49142857142857144,
        "scores_per_experiment": [
          {
            "accuracy": 0.5333333333333333,
            "f1": 0.4290819243649432,
            "f1_weighted": 0.5890145194727404
          },
          {
            "accuracy": 0.6095238095238096,
            "f1": 0.4713319057444558,
            "f1_weighted": 0.6514748586653984
          },
          {
            "accuracy": 0.45714285714285713,
            "f1": 0.3456876942998899,
            "f1_weighted": 0.5099399095005068
          },
          {
            "accuracy": 0.49523809523809526,
            "f1": 0.3757344653092548,
            "f1_weighted": 0.5585830658138019
          },
          {
            "accuracy": 0.6,
            "f1": 0.4493269908087143,
            "f1_weighted": 0.6377463871170854
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.39241277741099995,
            "f1_weighted": 0.5202957116013842
          },
          {
            "accuracy": 0.47619047619047616,
            "f1": 0.384976134976135,
            "f1_weighted": 0.5185132327989471
          },
          {
            "accuracy": 0.42857142857142855,
            "f1": 0.3469928130122305,
            "f1_weighted": 0.4834002797941771
          },
          {
            "accuracy": 0.4,
            "f1": 0.301358941070219,
            "f1_weighted": 0.45233176359277055
          },
          {
            "accuracy": 0.42857142857142855,
            "f1": 0.39294258373205737,
            "f1_weighted": 0.5255183413078149
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}