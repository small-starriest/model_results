{
  "dataset_revision": "f8f98e5c4d3059cf1a00c8eb3d70aa271423f636",
  "evaluation_time": 27.478600025177002,
  "kg_co2_emissions": 0.004992373119685213,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.4555897435897435,
        "ap": 0.8371825516381322,
        "ap_weighted": 0.8371825516381322,
        "f1": 0.39721923774498996,
        "f1_weighted": 0.512130520568286,
        "hf_subset": "default",
        "languages": [
          "ita-Latn"
        ],
        "main_score": 0.4555897435897435,
        "scores_per_experiment": [
          {
            "accuracy": 0.6553846153846153,
            "ap": 0.842738971331246,
            "ap_weighted": 0.842738971331246,
            "f1": 0.4919480906180988,
            "f1_weighted": 0.6890767741972427
          },
          {
            "accuracy": 0.38461538461538464,
            "ap": 0.8338849924571985,
            "ap_weighted": 0.8338849924571985,
            "f1": 0.35951897137651967,
            "f1_weighted": 0.4462511352642033
          },
          {
            "accuracy": 0.37435897435897436,
            "ap": 0.8343536395355892,
            "ap_weighted": 0.8343536395355892,
            "f1": 0.35303754177109437,
            "f1_weighted": 0.4333844092067776
          },
          {
            "accuracy": 0.39794871794871794,
            "ap": 0.8372365670523576,
            "ap_weighted": 0.8372365670523576,
            "f1": 0.3709476919086282,
            "f1_weighted": 0.4601045452192217
          },
          {
            "accuracy": 0.6594871794871795,
            "ap": 0.8448017599875393,
            "ap_weighted": 0.8448017599875393,
            "f1": 0.49799632763455,
            "f1_weighted": 0.692778241171085
          },
          {
            "accuracy": 0.3425641025641026,
            "ap": 0.8349443750167705,
            "ap_weighted": 0.8349443750167705,
            "f1": 0.33066481030281936,
            "f1_weighted": 0.3917173329049417
          },
          {
            "accuracy": 0.41333333333333333,
            "ap": 0.8315161132571207,
            "ap_weighted": 0.8315161132571207,
            "f1": 0.37515685501218987,
            "f1_weighted": 0.48081540704622594
          },
          {
            "accuracy": 0.5025641025641026,
            "ap": 0.8474365404364688,
            "ap_weighted": 0.8474365404364688,
            "f1": 0.4416671291152512,
            "f1_weighted": 0.567810859830729
          },
          {
            "accuracy": 0.4164102564102564,
            "ap": 0.829345528678554,
            "ap_weighted": 0.829345528678554,
            "f1": 0.3746343508946356,
            "f1_weighted": 0.48520787858875897
          },
          {
            "accuracy": 0.40923076923076923,
            "ap": 0.835567028628476,
            "ap_weighted": 0.835567028628476,
            "f1": 0.376620608816112,
            "f1_weighted": 0.47415862225367433
          }
        ]
      }
    ]
  },
  "task_name": "Itacola"
}