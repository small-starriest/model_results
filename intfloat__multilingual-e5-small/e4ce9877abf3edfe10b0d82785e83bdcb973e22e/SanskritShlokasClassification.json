{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "evaluation_time": 14.290714979171753,
  "kg_co2_emissions": 0.0021072483303901024,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.8039164490861618,
        "f1": 0.8037447508265825,
        "f1_weighted": 0.80356805513972,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ],
        "main_score": 0.8039164490861618,
        "scores_per_experiment": [
          {
            "accuracy": 0.8015665796344648,
            "f1": 0.8023212745580478,
            "f1_weighted": 0.8014675239829688
          },
          {
            "accuracy": 0.8224543080939948,
            "f1": 0.8170385982697649,
            "f1_weighted": 0.8192523457460644
          },
          {
            "accuracy": 0.7519582245430809,
            "f1": 0.7504862287470982,
            "f1_weighted": 0.7478105577776369
          },
          {
            "accuracy": 0.793733681462141,
            "f1": 0.7940162452575561,
            "f1_weighted": 0.794045657102432
          },
          {
            "accuracy": 0.8668407310704961,
            "f1": 0.8677535580755756,
            "f1_weighted": 0.8679192368152315
          },
          {
            "accuracy": 0.8198433420365535,
            "f1": 0.8205350158969469,
            "f1_weighted": 0.8204777619068748
          },
          {
            "accuracy": 0.8328981723237598,
            "f1": 0.8330374320631456,
            "f1_weighted": 0.8334470791993708
          },
          {
            "accuracy": 0.7702349869451697,
            "f1": 0.7711853408059621,
            "f1_weighted": 0.770317928476361
          },
          {
            "accuracy": 0.7911227154046997,
            "f1": 0.7919160171648386,
            "f1_weighted": 0.7917548065097053
          },
          {
            "accuracy": 0.7885117493472585,
            "f1": 0.7891577974268884,
            "f1_weighted": 0.7891876538805529
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.784375,
        "f1": 0.7913092818752071,
        "f1_weighted": 0.7835577227708412,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ],
        "main_score": 0.784375,
        "scores_per_experiment": [
          {
            "accuracy": 0.7395833333333334,
            "f1": 0.7503539757060884,
            "f1_weighted": 0.7360901520232507
          },
          {
            "accuracy": 0.7708333333333334,
            "f1": 0.7660317460317461,
            "f1_weighted": 0.7652678571428572
          },
          {
            "accuracy": 0.7395833333333334,
            "f1": 0.7503539757060884,
            "f1_weighted": 0.7360901520232507
          },
          {
            "accuracy": 0.75,
            "f1": 0.7611408199643493,
            "f1_weighted": 0.7505570409982175
          },
          {
            "accuracy": 0.8645833333333334,
            "f1": 0.8696010180402723,
            "f1_weighted": 0.8654956396436858
          },
          {
            "accuracy": 0.8333333333333334,
            "f1": 0.837870538415003,
            "f1_weighted": 0.8340139140955838
          },
          {
            "accuracy": 0.8541666666666666,
            "f1": 0.8591591591591592,
            "f1_weighted": 0.8550863363363365
          },
          {
            "accuracy": 0.7291666666666666,
            "f1": 0.7412358882947118,
            "f1_weighted": 0.728442513368984
          },
          {
            "accuracy": 0.8229166666666666,
            "f1": 0.8269917217285639,
            "f1_weighted": 0.8233201374648743
          },
          {
            "accuracy": 0.7395833333333334,
            "f1": 0.7503539757060884,
            "f1_weighted": 0.7412134846113719
          }
        ]
      }
    ]
  },
  "task_name": "SanskritShlokasClassification"
}