{
  "dataset_revision": "d51bf2435d030e0041344f576c5e8d7154828977",
  "evaluation_time": 13.650861501693726,
  "kg_co2_emissions": 0.0022379622537650533,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.715380859375,
        "ap": 0.8287978527952766,
        "ap_weighted": 0.8287978527952766,
        "f1": 0.6924033811162668,
        "f1_weighted": 0.7245403492252207,
        "hf_subset": "default",
        "languages": [
          "ara-Arab"
        ],
        "main_score": 0.715380859375,
        "scores_per_experiment": [
          {
            "accuracy": 0.638671875,
            "ap": 0.7744203379881365,
            "ap_weighted": 0.7744203379881365,
            "f1": 0.6090199493938406,
            "f1_weighted": 0.6544441758543401
          },
          {
            "accuracy": 0.78759765625,
            "ap": 0.8479383277184015,
            "ap_weighted": 0.8479383277184015,
            "f1": 0.7543954930602557,
            "f1_weighted": 0.7924919990309583
          },
          {
            "accuracy": 0.7431640625,
            "ap": 0.8328578831720815,
            "ap_weighted": 0.8328578831720815,
            "f1": 0.7143944913362412,
            "f1_weighted": 0.7526358905446837
          },
          {
            "accuracy": 0.46630859375,
            "ap": 0.7386835062340225,
            "ap_weighted": 0.7386835062340225,
            "f1": 0.46621581824576885,
            "f1_weighted": 0.4691846343811664
          },
          {
            "accuracy": 0.69482421875,
            "ap": 0.8176650841957741,
            "ap_weighted": 0.8176650841957741,
            "f1": 0.672830321881287,
            "f1_weighted": 0.7086170015320743
          },
          {
            "accuracy": 0.80615234375,
            "ap": 0.8618007159835982,
            "ap_weighted": 0.8618007159835982,
            "f1": 0.7758505994136127,
            "f1_weighted": 0.8106191347477941
          },
          {
            "accuracy": 0.70654296875,
            "ap": 0.8402271556568431,
            "ap_weighted": 0.8402271556568431,
            "f1": 0.6914468068571944,
            "f1_weighted": 0.7202394864938038
          },
          {
            "accuracy": 0.798828125,
            "ap": 0.874125799080727,
            "ap_weighted": 0.874125799080727,
            "f1": 0.7758280623002108,
            "f1_weighted": 0.8061208278072503
          },
          {
            "accuracy": 0.76171875,
            "ap": 0.8420613698456512,
            "ap_weighted": 0.8420613698456512,
            "f1": 0.7325832787488815,
            "f1_weighted": 0.769821514194098
          },
          {
            "accuracy": 0.75,
            "ap": 0.8581983480775309,
            "ap_weighted": 0.8581983480775309,
            "f1": 0.731468989925375,
            "f1_weighted": 0.7612288276660367
          }
        ]
      }
    ]
  },
  "task_name": "RestaurantReviewSentimentClassification"
}