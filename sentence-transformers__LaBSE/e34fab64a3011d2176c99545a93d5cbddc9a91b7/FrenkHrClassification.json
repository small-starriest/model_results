{
  "dataset_revision": "e7fc9f3d8d6c5640a26679d8a50b1666b02cc41f",
  "evaluation_time": 10.14712405204773,
  "kg_co2_emissions": 0.0015545043543348346,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.6136385087305333,
        "ap": 0.6346872266175376,
        "ap_weighted": 0.6346872266175376,
        "f1": 0.6097809075353666,
        "f1_weighted": 0.6120047379553332,
        "hf_subset": "default",
        "languages": [
          "hrv-Latn"
        ],
        "main_score": 0.6136385087305333,
        "scores_per_experiment": [
          {
            "accuracy": 0.5927324209532798,
            "ap": 0.6304907004573864,
            "ap_weighted": 0.6304907004573864,
            "f1": 0.5909468632683907,
            "f1_weighted": 0.5875925656174917
          },
          {
            "accuracy": 0.6191599811231713,
            "ap": 0.6251294257228731,
            "ap_weighted": 0.6251294257228731,
            "f1": 0.6104979039041707,
            "f1_weighted": 0.6177071643744148
          },
          {
            "accuracy": 0.6498348277489382,
            "ap": 0.6583994711629237,
            "ap_weighted": 0.6583994711629237,
            "f1": 0.6489058299168431,
            "f1_weighted": 0.6511473567961185
          },
          {
            "accuracy": 0.6639924492685229,
            "ap": 0.6723070455614639,
            "ap_weighted": 0.6723070455614639,
            "f1": 0.6636147973744293,
            "f1_weighted": 0.6650137050948043
          },
          {
            "accuracy": 0.5724398301085417,
            "ap": 0.6132221980481516,
            "ap_weighted": 0.6132221980481516,
            "f1": 0.5715787246805275,
            "f1_weighted": 0.5691948222850772
          },
          {
            "accuracy": 0.6328456819254366,
            "ap": 0.6414923304567606,
            "ap_weighted": 0.6414923304567606,
            "f1": 0.6302069033583664,
            "f1_weighted": 0.634083991420598
          },
          {
            "accuracy": 0.5356300141576216,
            "ap": 0.5713282457235526,
            "ap_weighted": 0.5713282457235526,
            "f1": 0.5155896292166156,
            "f1_weighted": 0.5278184487977863
          },
          {
            "accuracy": 0.659273242095328,
            "ap": 0.6763894830321276,
            "ap_weighted": 0.6763894830321276,
            "f1": 0.6592003029493005,
            "f1_weighted": 0.6585814966459065
          },
          {
            "accuracy": 0.6370929683813119,
            "ap": 0.6447419265875725,
            "ap_weighted": 0.6447419265875725,
            "f1": 0.6345720125987148,
            "f1_weighted": 0.6383391226602094
          },
          {
            "accuracy": 0.5733836715431807,
            "ap": 0.6133714394225638,
            "ap_weighted": 0.6133714394225638,
            "f1": 0.5726961080863078,
            "f1_weighted": 0.5705687058609241
          }
        ]
      }
    ]
  },
  "task_name": "FrenkHrClassification"
}