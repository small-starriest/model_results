{
  "dataset_revision": "673a610d6d3dd91a547a0d57ae1b56f37ebbf6a1",
  "evaluation_time": 13.214990377426147,
  "kg_co2_emissions": 0.0019739532520284668,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.53193359375,
        "f1": 0.529038201409928,
        "f1_weighted": 0.5291579330233603,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.53193359375,
        "scores_per_experiment": [
          {
            "accuracy": 0.54931640625,
            "f1": 0.5457219170201418,
            "f1_weighted": 0.5458089699470166
          },
          {
            "accuracy": 0.54150390625,
            "f1": 0.5413860959312798,
            "f1_weighted": 0.5415055036543456
          },
          {
            "accuracy": 0.49853515625,
            "f1": 0.49509664689953514,
            "f1_weighted": 0.4952169161006035
          },
          {
            "accuracy": 0.56591796875,
            "f1": 0.5616241311852406,
            "f1_weighted": 0.5617572843861289
          },
          {
            "accuracy": 0.53564453125,
            "f1": 0.5370138411519967,
            "f1_weighted": 0.5370376973629517
          },
          {
            "accuracy": 0.52197265625,
            "f1": 0.516652507049508,
            "f1_weighted": 0.5167721213073401
          },
          {
            "accuracy": 0.51416015625,
            "f1": 0.5105101783568153,
            "f1_weighted": 0.5106471763362896
          },
          {
            "accuracy": 0.52783203125,
            "f1": 0.5218310772423697,
            "f1_weighted": 0.5219861898698236
          },
          {
            "accuracy": 0.525390625,
            "f1": 0.5234302601616807,
            "f1_weighted": 0.5236330494541068
          },
          {
            "accuracy": 0.5390625,
            "f1": 0.5371153591007112,
            "f1_weighted": 0.5372144218149966
          }
        ]
      }
    ]
  },
  "task_name": "RuSciBenchGRNTIClassification"
}