{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 7.2044055461883545,
  "kg_co2_emissions": 0.0011072595704798337,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8013282481361705,
        "cosine_spearman": 0.7884117363892273,
        "euclidean_pearson": 0.7856340001524875,
        "euclidean_spearman": 0.7884117363892273,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7884117363892273,
        "manhattan_pearson": 0.7800290044648371,
        "manhattan_spearman": 0.7840446964380581,
        "pearson": 0.8013282481361705,
        "spearman": 0.7884117363892273
      },
      {
        "cosine_pearson": 0.7794925744392724,
        "cosine_spearman": 0.7634117143292312,
        "euclidean_pearson": 0.7767776530395644,
        "euclidean_spearman": 0.7634117143292312,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7634117143292312,
        "manhattan_pearson": 0.7779166018943872,
        "manhattan_spearman": 0.7676502030361565,
        "pearson": 0.7794925744392724,
        "spearman": 0.7634117143292312
      },
      {
        "cosine_pearson": 0.4884776397895282,
        "cosine_spearman": 0.5076148701802652,
        "euclidean_pearson": 0.5056324216359095,
        "euclidean_spearman": 0.5076148701802652,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.5076148701802652,
        "manhattan_pearson": 0.5006309529517136,
        "manhattan_spearman": 0.5051426030415299,
        "pearson": 0.4884776397895282,
        "spearman": 0.5076148701802652
      },
      {
        "cosine_pearson": 0.4653510104747446,
        "cosine_spearman": 0.4553979942400511,
        "euclidean_pearson": 0.4788689827089901,
        "euclidean_spearman": 0.45540682612863975,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.4553979942400511,
        "manhattan_pearson": 0.4849349573971775,
        "manhattan_spearman": 0.4583833583756795,
        "pearson": 0.4653510104747446,
        "spearman": 0.4553979942400511
      },
      {
        "cosine_pearson": 0.45287665545811423,
        "cosine_spearman": 0.45405360263386674,
        "euclidean_pearson": 0.4581169597448908,
        "euclidean_spearman": 0.45405360263386674,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.45405360263386674,
        "manhattan_pearson": 0.4574671449788499,
        "manhattan_spearman": 0.45362110459378463,
        "pearson": 0.45287665545811423,
        "spearman": 0.45405360263386674
      },
      {
        "cosine_pearson": 0.8071625959270988,
        "cosine_spearman": 0.7969894041494415,
        "euclidean_pearson": 0.8086775040596763,
        "euclidean_spearman": 0.7969897211642916,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7969894041494415,
        "manhattan_pearson": 0.8058579426043355,
        "manhattan_spearman": 0.7932849082668055,
        "pearson": 0.8071625959270988,
        "spearman": 0.7969894041494415
      },
      {
        "cosine_pearson": 0.39455412764279196,
        "cosine_spearman": 0.3535995681296493,
        "euclidean_pearson": 0.40404798962771277,
        "euclidean_spearman": 0.3535995681296493,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.3535995681296493,
        "manhattan_pearson": 0.3972165619941319,
        "manhattan_spearman": 0.3471575137243313,
        "pearson": 0.39455412764279196,
        "spearman": 0.3535995681296493
      },
      {
        "cosine_pearson": 0.7309354617398625,
        "cosine_spearman": 0.7251194626450058,
        "euclidean_pearson": 0.7112973980540181,
        "euclidean_spearman": 0.7251194626450058,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7251194626450058,
        "manhattan_pearson": 0.7053298236892616,
        "manhattan_spearman": 0.7126407252168284,
        "pearson": 0.7309354617398625,
        "spearman": 0.7251194626450058
      },
      {
        "cosine_pearson": 0.4215106468546786,
        "cosine_spearman": 0.44441415403303786,
        "euclidean_pearson": 0.45867512781624414,
        "euclidean_spearman": 0.44441415403303786,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.44441415403303786,
        "manhattan_pearson": 0.45903218736325524,
        "manhattan_spearman": 0.44431512939112966,
        "pearson": 0.4215106468546786,
        "spearman": 0.44441415403303786
      },
      {
        "cosine_pearson": 0.4262349088242822,
        "cosine_spearman": 0.4204836066537142,
        "euclidean_pearson": 0.4323750772261392,
        "euclidean_spearman": 0.4204836066537142,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.4204836066537142,
        "manhattan_pearson": 0.43594863978818904,
        "manhattan_spearman": 0.4269292570164815,
        "pearson": 0.4262349088242822,
        "spearman": 0.4204836066537142
      },
      {
        "cosine_pearson": 0.7981715626697378,
        "cosine_spearman": 0.7754204835005339,
        "euclidean_pearson": 0.7924297343403665,
        "euclidean_spearman": 0.7754204835005339,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7754204835005339,
        "manhattan_pearson": 0.7894169154199804,
        "manhattan_spearman": 0.7705547131622464,
        "pearson": 0.7981715626697378,
        "spearman": 0.7754204835005339
      },
      {
        "cosine_pearson": 0.7940537510238568,
        "cosine_spearman": 0.7584170419193923,
        "euclidean_pearson": 0.771730956504444,
        "euclidean_spearman": 0.7584170419193923,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7584170419193923,
        "manhattan_pearson": 0.7700171214664414,
        "manhattan_spearman": 0.7568732679605634,
        "pearson": 0.7940537510238568,
        "spearman": 0.7584170419193923
      }
    ]
  },
  "task_name": "SemRel24STS"
}