{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "evaluation_time": 14.98286247253418,
  "kg_co2_emissions": 0.0022291315262859676,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.7483028720626632,
        "f1": 0.744677685038172,
        "f1_weighted": 0.744743230766469,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ],
        "main_score": 0.7483028720626632,
        "scores_per_experiment": [
          {
            "accuracy": 0.7362924281984334,
            "f1": 0.7379286547202589,
            "f1_weighted": 0.7371520319661132
          },
          {
            "accuracy": 0.7989556135770235,
            "f1": 0.7914358242369565,
            "f1_weighted": 0.7941224279037243
          },
          {
            "accuracy": 0.7101827676240209,
            "f1": 0.7035469480946914,
            "f1_weighted": 0.6989411621609458
          },
          {
            "accuracy": 0.7284595300261096,
            "f1": 0.7243036139587864,
            "f1_weighted": 0.7207156918330052
          },
          {
            "accuracy": 0.7702349869451697,
            "f1": 0.7709020333086486,
            "f1_weighted": 0.7709549516738601
          },
          {
            "accuracy": 0.7754569190600522,
            "f1": 0.7756741311574094,
            "f1_weighted": 0.7740094811766692
          },
          {
            "accuracy": 0.7911227154046997,
            "f1": 0.7882029215806324,
            "f1_weighted": 0.7898402325384327
          },
          {
            "accuracy": 0.741514360313316,
            "f1": 0.742414982724045,
            "f1_weighted": 0.7424414839100258
          },
          {
            "accuracy": 0.7258485639686684,
            "f1": 0.7216527944529131,
            "f1_weighted": 0.7239224037047547
          },
          {
            "accuracy": 0.7049608355091384,
            "f1": 0.6907149461473789,
            "f1_weighted": 0.6953324407971577
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7541666666666667,
        "f1": 0.7603365438298864,
        "f1_weighted": 0.7528505335037341,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ],
        "main_score": 0.7541666666666667,
        "scores_per_experiment": [
          {
            "accuracy": 0.7291666666666666,
            "f1": 0.7407738095238096,
            "f1_weighted": 0.7266276041666666
          },
          {
            "accuracy": 0.7291666666666666,
            "f1": 0.7311728395061728,
            "f1_weighted": 0.7275366512345679
          },
          {
            "accuracy": 0.6666666666666666,
            "f1": 0.6809523809523809,
            "f1_weighted": 0.6635416666666667
          },
          {
            "accuracy": 0.7604166666666666,
            "f1": 0.7711442786069652,
            "f1_weighted": 0.7604166666666666
          },
          {
            "accuracy": 0.78125,
            "f1": 0.7893554906804402,
            "f1_weighted": 0.7827237255782619
          },
          {
            "accuracy": 0.7916666666666666,
            "f1": 0.8005952380952381,
            "f1_weighted": 0.7927827380952381
          },
          {
            "accuracy": 0.8541666666666666,
            "f1": 0.8552469135802468,
            "f1_weighted": 0.8532889660493828
          },
          {
            "accuracy": 0.71875,
            "f1": 0.7291713451605659,
            "f1_weighted": 0.7206447900291938
          },
          {
            "accuracy": 0.78125,
            "f1": 0.7862838915470495,
            "f1_weighted": 0.7817484051036683
          },
          {
            "accuracy": 0.7291666666666666,
            "f1": 0.7186692506459949,
            "f1_weighted": 0.7191941214470284
          }
        ]
      }
    ]
  },
  "task_name": "SanskritShlokasClassification"
}