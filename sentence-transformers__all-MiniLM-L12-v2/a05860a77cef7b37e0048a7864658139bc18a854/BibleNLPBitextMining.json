{
  "dataset_revision": "264a18480c529d9e922483839b4b9758e690b762",
  "evaluation_time": 418.79830622673035,
  "kg_co2_emissions": 0.06536300302958425,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.0859375,
        "f1": 0.053113914442039445,
        "hf_subset": "eng_Latn-aai_Latn",
        "languages": [
          "eng-Latn",
          "aai-Latn"
        ],
        "main_score": 0.053113914442039445,
        "precision": 0.046316414876242176,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04865211970732118,
        "hf_subset": "aai_Latn-eng_Latn",
        "languages": [
          "aai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04865211970732118,
        "precision": 0.044288334453405014,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004310005252100841,
        "hf_subset": "eng_Latn-aak_Arab",
        "languages": [
          "eng-Latn",
          "aak-Arab"
        ],
        "main_score": 0.004310005252100841,
        "precision": 0.002445281498015873,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.8125e-05,
        "hf_subset": "aak_Arab-eng_Latn",
        "languages": [
          "aak-Arab",
          "eng-Latn"
        ],
        "main_score": 7.8125e-05,
        "precision": 3.945707070707071e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006702986683455434,
        "hf_subset": "eng_Latn-aau_Latn",
        "languages": [
          "eng-Latn",
          "aau-Latn"
        ],
        "main_score": 0.006702986683455434,
        "precision": 0.005441337719298246,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004142992424242424,
        "hf_subset": "aau_Latn-eng_Latn",
        "languages": [
          "aau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004142992424242424,
        "precision": 0.0040283203125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0052468039772727276,
        "hf_subset": "eng_Latn-aaz_Latn",
        "languages": [
          "eng-Latn",
          "aaz-Latn"
        ],
        "main_score": 0.0052468039772727276,
        "precision": 0.0033275462962962963,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010894379058441556,
        "hf_subset": "aaz_Latn-eng_Latn",
        "languages": [
          "aaz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010894379058441556,
        "precision": 0.008808223967297763,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.006949296928916495,
        "hf_subset": "eng_Latn-abt_Latn",
        "languages": [
          "eng-Latn",
          "abt-Latn"
        ],
        "main_score": 0.006949296928916495,
        "precision": 0.004126165144087939,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013237847222222222,
        "hf_subset": "abt_Latn-eng_Latn",
        "languages": [
          "abt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013237847222222222,
        "precision": 0.011555989583333332,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014546130952380953,
        "hf_subset": "eng_Latn-abx_Latn",
        "languages": [
          "eng-Latn",
          "abx-Latn"
        ],
        "main_score": 0.014546130952380953,
        "precision": 0.010087554043356472,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007622713940648723,
        "hf_subset": "abx_Latn-eng_Latn",
        "languages": [
          "abx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007622713940648723,
        "precision": 0.006108940972222222,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004464285714285714,
        "hf_subset": "eng_Latn-aby_Latn",
        "languages": [
          "eng-Latn",
          "aby-Latn"
        ],
        "main_score": 0.004464285714285714,
        "precision": 0.004206730769230769,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010035021551724137,
        "hf_subset": "aby_Latn-eng_Latn",
        "languages": [
          "aby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010035021551724137,
        "precision": 0.009254092261904762,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0070873060762766645,
        "hf_subset": "eng_Latn-acf_Latn",
        "languages": [
          "eng-Latn",
          "acf-Latn"
        ],
        "main_score": 0.0070873060762766645,
        "precision": 0.004581079727564103,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002153445512820513,
        "hf_subset": "acf_Latn-eng_Latn",
        "languages": [
          "acf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002153445512820513,
        "precision": 0.0014048793859649123,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010315688775510205,
        "hf_subset": "eng_Latn-acr_Latn",
        "languages": [
          "eng-Latn",
          "acr-Latn"
        ],
        "main_score": 0.010315688775510205,
        "precision": 0.008055083109051037,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.016927083333333332,
        "hf_subset": "acr_Latn-eng_Latn",
        "languages": [
          "acr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016927083333333332,
        "precision": 0.015625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010561342592592591,
        "hf_subset": "eng_Latn-acu_Latn",
        "languages": [
          "eng-Latn",
          "acu-Latn"
        ],
        "main_score": 0.010561342592592591,
        "precision": 0.008537244496855346,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004826688218390804,
        "hf_subset": "acu_Latn-eng_Latn",
        "languages": [
          "acu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004826688218390804,
        "precision": 0.0033947172619047616,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03298506902761104,
        "hf_subset": "eng_Latn-adz_Latn",
        "languages": [
          "eng-Latn",
          "adz-Latn"
        ],
        "main_score": 0.03298506902761104,
        "precision": 0.028754340277777776,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03753255208333333,
        "hf_subset": "adz_Latn-eng_Latn",
        "languages": [
          "adz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03753255208333333,
        "precision": 0.03576373191681736,
        "recall": 0.046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022642278065072182,
        "hf_subset": "eng_Latn-aer_Latn",
        "languages": [
          "eng-Latn",
          "aer-Latn"
        ],
        "main_score": 0.022642278065072182,
        "precision": 0.018770292207792205,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.0321484375,
        "hf_subset": "aer_Latn-eng_Latn",
        "languages": [
          "aer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0321484375,
        "precision": 0.028224347267316013,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.027285258144633145,
        "hf_subset": "eng_Latn-aey_Latn",
        "languages": [
          "eng-Latn",
          "aey-Latn"
        ],
        "main_score": 0.027285258144633145,
        "precision": 0.024204101562499997,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014364650106837606,
        "hf_subset": "aey_Latn-eng_Latn",
        "languages": [
          "aey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014364650106837606,
        "precision": 0.013196773737904252,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001171875,
        "hf_subset": "eng_Latn-agd_Latn",
        "languages": [
          "eng-Latn",
          "agd-Latn"
        ],
        "main_score": 0.001171875,
        "precision": 0.0006341314935064935,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015024038461538462,
        "hf_subset": "agd_Latn-eng_Latn",
        "languages": [
          "agd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015024038461538462,
        "precision": 7.659313725490196e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013633268755615454,
        "hf_subset": "eng_Latn-agg_Latn",
        "languages": [
          "eng-Latn",
          "agg-Latn"
        ],
        "main_score": 0.013633268755615454,
        "precision": 0.012800025495337996,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026599702380952378,
        "hf_subset": "agg_Latn-eng_Latn",
        "languages": [
          "agg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026599702380952378,
        "precision": 0.0019812275179856113,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "eng_Latn-agm_Latn",
        "languages": [
          "eng-Latn",
          "agm-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004648386034255599,
        "hf_subset": "agm_Latn-eng_Latn",
        "languages": [
          "agm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004648386034255599,
        "precision": 0.0042908430570068505,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016764322916666664,
        "hf_subset": "eng_Latn-agn_Latn",
        "languages": [
          "eng-Latn",
          "agn-Latn"
        ],
        "main_score": 0.016764322916666664,
        "precision": 0.015234375,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001220703125,
        "hf_subset": "agn_Latn-eng_Latn",
        "languages": [
          "agn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001220703125,
        "precision": 6.200396825396825e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01349826388888889,
        "hf_subset": "eng_Latn-agr_Latn",
        "languages": [
          "eng-Latn",
          "agr-Latn"
        ],
        "main_score": 0.01349826388888889,
        "precision": 0.010188802083333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004423744658119658,
        "hf_subset": "agr_Latn-eng_Latn",
        "languages": [
          "agr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004423744658119658,
        "precision": 0.004174107142857143,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019915956439393936,
        "hf_subset": "eng_Latn-agt_Latn",
        "languages": [
          "eng-Latn",
          "agt-Latn"
        ],
        "main_score": 0.019915956439393936,
        "precision": 0.018526785714285714,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006944444444444444,
        "hf_subset": "agt_Latn-eng_Latn",
        "languages": [
          "agt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006944444444444444,
        "precision": 0.006089154411764706,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015360383064516129,
        "hf_subset": "eng_Latn-agu_Latn",
        "languages": [
          "eng-Latn",
          "agu-Latn"
        ],
        "main_score": 0.015360383064516129,
        "precision": 0.012889557718579234,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006525376436846791,
        "hf_subset": "agu_Latn-eng_Latn",
        "languages": [
          "agu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006525376436846791,
        "precision": 0.005392013810756075,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011024305555555555,
        "hf_subset": "eng_Latn-aia_Latn",
        "languages": [
          "eng-Latn",
          "aia-Latn"
        ],
        "main_score": 0.011024305555555555,
        "precision": 0.009711371527777778,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002445992626002291,
        "hf_subset": "aia_Latn-eng_Latn",
        "languages": [
          "aia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002445992626002291,
        "precision": 0.001366024925595238,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0030192353860927805,
        "hf_subset": "eng_Latn-aii_Syrc",
        "languages": [
          "eng-Latn",
          "aii-Syrc"
        ],
        "main_score": 0.0030192353860927805,
        "precision": 0.0018694196428571427,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.300403225806451e-05,
        "hf_subset": "aii_Syrc-eng_Latn",
        "languages": [
          "aii-Syrc",
          "eng-Latn"
        ],
        "main_score": 6.300403225806451e-05,
        "precision": 3.1758130081300816e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021947616185897436,
        "hf_subset": "eng_Latn-aka_Latn",
        "languages": [
          "eng-Latn",
          "aka-Latn"
        ],
        "main_score": 0.021947616185897436,
        "precision": 0.01939608134920635,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "aka_Latn-eng_Latn",
        "languages": [
          "aka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0040283203125,
        "hf_subset": "eng_Latn-ake_Latn",
        "languages": [
          "eng-Latn",
          "ake-Latn"
        ],
        "main_score": 0.0040283203125,
        "precision": 0.003968253968253968,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005460349462365592,
        "hf_subset": "ake_Latn-eng_Latn",
        "languages": [
          "ake-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005460349462365592,
        "precision": 0.004036458333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004501488095238095,
        "hf_subset": "eng_Latn-alp_Latn",
        "languages": [
          "eng-Latn",
          "alp-Latn"
        ],
        "main_score": 0.004501488095238095,
        "precision": 0.003038194444444444,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003946520618556701,
        "hf_subset": "alp_Latn-eng_Latn",
        "languages": [
          "alp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003946520618556701,
        "precision": 0.0039264896373056996,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021571180555555555,
        "hf_subset": "eng_Latn-alq_Latn",
        "languages": [
          "eng-Latn",
          "alq-Latn"
        ],
        "main_score": 0.021571180555555555,
        "precision": 0.015462239583333332,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020405028998778996,
        "hf_subset": "alq_Latn-eng_Latn",
        "languages": [
          "alq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020405028998778996,
        "precision": 0.019995935673015438,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013106496710526314,
        "hf_subset": "eng_Latn-als_Latn",
        "languages": [
          "eng-Latn",
          "als-Latn"
        ],
        "main_score": 0.013106496710526314,
        "precision": 0.011321924603174603,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004734519675925926,
        "hf_subset": "als_Latn-eng_Latn",
        "languages": [
          "als-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004734519675925926,
        "precision": 0.004340529753265602,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023209672421687505,
        "hf_subset": "eng_Latn-aly_Latn",
        "languages": [
          "eng-Latn",
          "aly-Latn"
        ],
        "main_score": 0.023209672421687505,
        "precision": 0.01852314162141465,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019834125905797098,
        "hf_subset": "aly_Latn-eng_Latn",
        "languages": [
          "aly-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019834125905797098,
        "precision": 0.018576033128415298,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005030555282313593,
        "hf_subset": "eng_Latn-ame_Latn",
        "languages": [
          "eng-Latn",
          "ame-Latn"
        ],
        "main_score": 0.005030555282313593,
        "precision": 0.004499497441520468,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012109375,
        "hf_subset": "ame_Latn-eng_Latn",
        "languages": [
          "ame-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012109375,
        "precision": 0.010622258771929825,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006762432795698924,
        "hf_subset": "eng_Latn-amf_Latn",
        "languages": [
          "eng-Latn",
          "amf-Latn"
        ],
        "main_score": 0.006762432795698924,
        "precision": 0.005989583333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002864583333333333,
        "hf_subset": "amf_Latn-eng_Latn",
        "languages": [
          "amf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002864583333333333,
        "precision": 0.002087823275862069,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01766378837719298,
        "hf_subset": "eng_Latn-amk_Latn",
        "languages": [
          "eng-Latn",
          "amk-Latn"
        ],
        "main_score": 0.01766378837719298,
        "precision": 0.01562907920843776,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0029270833333333336,
        "hf_subset": "amk_Latn-eng_Latn",
        "languages": [
          "amk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029270833333333336,
        "precision": 0.0017893145161290323,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-amm_Latn",
        "languages": [
          "eng-Latn",
          "amm-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006097992081447964,
        "hf_subset": "amm_Latn-eng_Latn",
        "languages": [
          "amm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006097992081447964,
        "precision": 0.00032073376225490196,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005191735347985348,
        "hf_subset": "eng_Latn-amn_Latn",
        "languages": [
          "eng-Latn",
          "amn-Latn"
        ],
        "main_score": 0.005191735347985348,
        "precision": 0.00458984375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020638020833333333,
        "hf_subset": "amn_Latn-eng_Latn",
        "languages": [
          "amn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020638020833333333,
        "precision": 0.019021540908029877,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016567460317460314,
        "hf_subset": "eng_Latn-amo_Latn",
        "languages": [
          "eng-Latn",
          "amo-Latn"
        ],
        "main_score": 0.016567460317460314,
        "precision": 0.013588169642857143,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010594223484848484,
        "hf_subset": "amo_Latn-eng_Latn",
        "languages": [
          "amo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010594223484848484,
        "precision": 0.009856468023255814,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00984468005952381,
        "hf_subset": "eng_Latn-amp_Latn",
        "languages": [
          "eng-Latn",
          "amp-Latn"
        ],
        "main_score": 0.00984468005952381,
        "precision": 0.0074805402930402925,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012970753205128204,
        "hf_subset": "amp_Latn-eng_Latn",
        "languages": [
          "amp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012970753205128204,
        "precision": 0.011393229166666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015234375,
        "hf_subset": "eng_Latn-amr_Latn",
        "languages": [
          "eng-Latn",
          "amr-Latn"
        ],
        "main_score": 0.015234375,
        "precision": 0.012825520833333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007850060096153846,
        "hf_subset": "amr_Latn-eng_Latn",
        "languages": [
          "amr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007850060096153846,
        "precision": 0.00783137077294686,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011694444444444445,
        "hf_subset": "eng_Latn-amu_Latn",
        "languages": [
          "eng-Latn",
          "amu-Latn"
        ],
        "main_score": 0.011694444444444445,
        "precision": 0.009050343927893738,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0064570729663712785,
        "hf_subset": "amu_Latn-eng_Latn",
        "languages": [
          "amu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0064570729663712785,
        "precision": 0.004406123872269706,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07176992841055341,
        "hf_subset": "eng_Latn-amx_Latn",
        "languages": [
          "eng-Latn",
          "amx-Latn"
        ],
        "main_score": 0.07176992841055341,
        "precision": 0.06378229677287582,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07910426782080593,
        "hf_subset": "amx_Latn-eng_Latn",
        "languages": [
          "amx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07910426782080593,
        "precision": 0.07122747189153439,
        "recall": 0.109375
      },
      {
        "accuracy": 0.06306306306306306,
        "f1": 0.03930485509432878,
        "hf_subset": "eng_Latn-anh_Latn",
        "languages": [
          "eng-Latn",
          "anh-Latn"
        ],
        "main_score": 0.03930485509432878,
        "precision": 0.03546403546403546,
        "recall": 0.06306306306306306
      },
      {
        "accuracy": 0.04504504504504504,
        "f1": 0.023400323400323397,
        "hf_subset": "anh_Latn-eng_Latn",
        "languages": [
          "anh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023400323400323397,
        "precision": 0.021230036855036855,
        "recall": 0.04504504504504504
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013533319978632479,
        "hf_subset": "eng_Latn-anv_Latn",
        "languages": [
          "eng-Latn",
          "anv-Latn"
        ],
        "main_score": 0.013533319978632479,
        "precision": 0.010485998376623376,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "anv_Latn-eng_Latn",
        "languages": [
          "anv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0014796401515151515,
        "hf_subset": "eng_Latn-aoi_Latn",
        "languages": [
          "eng-Latn",
          "aoi-Latn"
        ],
        "main_score": 0.0014796401515151515,
        "precision": 0.0008720930232558139,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000390625,
        "hf_subset": "aoi_Latn-eng_Latn",
        "languages": [
          "aoi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000390625,
        "precision": 0.00020559210526315788,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018297371031746033,
        "hf_subset": "eng_Latn-aoj_Latn",
        "languages": [
          "eng-Latn",
          "aoj-Latn"
        ],
        "main_score": 0.018297371031746033,
        "precision": 0.013592581463675212,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021158854166666664,
        "hf_subset": "aoj_Latn-eng_Latn",
        "languages": [
          "aoj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021158854166666664,
        "precision": 0.018266369047619045,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.05364489927068388,
        "hf_subset": "eng_Latn-aom_Latn",
        "languages": [
          "eng-Latn",
          "aom-Latn"
        ],
        "main_score": 0.05364489927068388,
        "precision": 0.04559947231359649,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03466949701682316,
        "hf_subset": "aom_Latn-eng_Latn",
        "languages": [
          "aom-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03466949701682316,
        "precision": 0.03218470982142857,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016079460903679656,
        "hf_subset": "eng_Latn-aon_Latn",
        "languages": [
          "eng-Latn",
          "aon-Latn"
        ],
        "main_score": 0.016079460903679656,
        "precision": 0.014623397435897436,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "aon_Latn-eng_Latn",
        "languages": [
          "aon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001714297497845292,
        "hf_subset": "eng_Latn-apb_Latn",
        "languages": [
          "eng-Latn",
          "apb-Latn"
        ],
        "main_score": 0.001714297497845292,
        "precision": 0.0009142097712070538,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000390625,
        "hf_subset": "apb_Latn-eng_Latn",
        "languages": [
          "apb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000390625,
        "precision": 0.00020559210526315788,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03788197479603729,
        "hf_subset": "eng_Latn-ape_Latn",
        "languages": [
          "eng-Latn",
          "ape-Latn"
        ],
        "main_score": 0.03788197479603729,
        "precision": 0.034372837070874865,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021048226033834584,
        "hf_subset": "ape_Latn-eng_Latn",
        "languages": [
          "ape-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021048226033834584,
        "precision": 0.017853536280846065,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-apn_Latn",
        "languages": [
          "eng-Latn",
          "apn-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "apn_Latn-eng_Latn",
        "languages": [
          "apn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.010317460317460317,
        "hf_subset": "eng_Latn-apr_Latn",
        "languages": [
          "eng-Latn",
          "apr-Latn"
        ],
        "main_score": 0.010317460317460317,
        "precision": 0.006580535860177404,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008909254807692307,
        "hf_subset": "apr_Latn-eng_Latn",
        "languages": [
          "apr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008909254807692307,
        "precision": 0.008431570870535714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-apu_Latn",
        "languages": [
          "eng-Latn",
          "apu-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "apu_Latn-eng_Latn",
        "languages": [
          "apu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.04320989340520591,
        "hf_subset": "eng_Latn-apw_Latn",
        "languages": [
          "eng-Latn",
          "apw-Latn"
        ],
        "main_score": 0.04320989340520591,
        "precision": 0.03746014339259297,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04440226715686274,
        "hf_subset": "apw_Latn-eng_Latn",
        "languages": [
          "apw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04440226715686274,
        "precision": 0.0402540909169911,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008933911483253587,
        "hf_subset": "eng_Latn-apz_Latn",
        "languages": [
          "eng-Latn",
          "apz-Latn"
        ],
        "main_score": 0.008933911483253587,
        "precision": 0.008420138888888888,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "apz_Latn-eng_Latn",
        "languages": [
          "apz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00038008989952406137,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00038008989952406137,
        "precision": 0.0001953125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.05709316002284752,
        "hf_subset": "eng_Latn-are_Latn",
        "languages": [
          "eng-Latn",
          "are-Latn"
        ],
        "main_score": 0.05709316002284752,
        "precision": 0.04613307390435388,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.0648014506826742,
        "hf_subset": "are_Latn-eng_Latn",
        "languages": [
          "are-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0648014506826742,
        "precision": 0.05847987732753357,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01735085227272727,
        "hf_subset": "eng_Latn-arl_Latn",
        "languages": [
          "eng-Latn",
          "arl-Latn"
        ],
        "main_score": 0.01735085227272727,
        "precision": 0.015552068771357563,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00216456754562326,
        "hf_subset": "arl_Latn-eng_Latn",
        "languages": [
          "arl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00216456754562326,
        "precision": 0.0014094865834922653,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015234374999999998,
        "hf_subset": "eng_Latn-arn_Latn",
        "languages": [
          "eng-Latn",
          "arn-Latn"
        ],
        "main_score": 0.015234374999999998,
        "precision": 0.012790586890243903,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015590577107279693,
        "hf_subset": "arn_Latn-eng_Latn",
        "languages": [
          "arn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015590577107279693,
        "precision": 0.014082651289682538,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.13978494623655913,
        "f1": 0.08461611016789285,
        "hf_subset": "eng_Latn-arp_Latn",
        "languages": [
          "eng-Latn",
          "arp-Latn"
        ],
        "main_score": 0.08461611016789285,
        "precision": 0.07118155021380827,
        "recall": 0.13978494623655913
      },
      {
        "accuracy": 0.15053763440860216,
        "f1": 0.11788701143539854,
        "hf_subset": "arp_Latn-eng_Latn",
        "languages": [
          "arp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11788701143539854,
        "precision": 0.11361719663427443,
        "recall": 0.15053763440860216
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003199404761904762,
        "hf_subset": "eng_Latn-aso_Latn",
        "languages": [
          "eng-Latn",
          "aso-Latn"
        ],
        "main_score": 0.003199404761904762,
        "precision": 0.0019066220238095235,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "aso_Latn-eng_Latn",
        "languages": [
          "aso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0012692577030812323,
        "hf_subset": "eng_Latn-ata_Latn",
        "languages": [
          "eng-Latn",
          "ata-Latn"
        ],
        "main_score": 0.0012692577030812323,
        "precision": 0.0007291666666666666,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005208333333333333,
        "hf_subset": "ata_Latn-eng_Latn",
        "languages": [
          "ata-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.004634122670807453,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005028011204481792,
        "hf_subset": "eng_Latn-atb_Latn",
        "languages": [
          "eng-Latn",
          "atb-Latn"
        ],
        "main_score": 0.005028011204481792,
        "precision": 0.0033317835563929313,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "atb_Latn-eng_Latn",
        "languages": [
          "atb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011979166666666666,
        "hf_subset": "eng_Latn-atd_Latn",
        "languages": [
          "eng-Latn",
          "atd-Latn"
        ],
        "main_score": 0.011979166666666666,
        "precision": 0.0107421875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007763231981981982,
        "hf_subset": "atd_Latn-eng_Latn",
        "languages": [
          "atd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007763231981981982,
        "precision": 0.006359610404896422,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00701264880952381,
        "hf_subset": "eng_Latn-atg_Latn",
        "languages": [
          "eng-Latn",
          "atg-Latn"
        ],
        "main_score": 0.00701264880952381,
        "precision": 0.005837673611111111,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006302083333333333,
        "hf_subset": "atg_Latn-eng_Latn",
        "languages": [
          "atg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006302083333333333,
        "precision": 0.005437301377118644,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012188632246376811,
        "hf_subset": "eng_Latn-att_Latn",
        "languages": [
          "eng-Latn",
          "att-Latn"
        ],
        "main_score": 0.012188632246376811,
        "precision": 0.00932246817946546,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026950096899224806,
        "hf_subset": "att_Latn-eng_Latn",
        "languages": [
          "att-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026950096899224806,
        "precision": 0.001999080882352941,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "eng_Latn-auc_Latn",
        "languages": [
          "eng-Latn",
          "auc-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0046875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "auc_Latn-eng_Latn",
        "languages": [
          "auc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.002734375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01859550677910053,
        "hf_subset": "eng_Latn-aui_Latn",
        "languages": [
          "eng-Latn",
          "aui-Latn"
        ],
        "main_score": 0.01859550677910053,
        "precision": 0.01512027734941945,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026183420566502462,
        "hf_subset": "aui_Latn-eng_Latn",
        "languages": [
          "aui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026183420566502462,
        "precision": 0.025099071557971014,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0041015625,
        "hf_subset": "eng_Latn-auy_Latn",
        "languages": [
          "eng-Latn",
          "auy-Latn"
        ],
        "main_score": 0.0041015625,
        "precision": 0.002790178571428571,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0059928749392318915,
        "hf_subset": "auy_Latn-eng_Latn",
        "languages": [
          "auy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0059928749392318915,
        "precision": 0.005159505208333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019870923913043476,
        "hf_subset": "eng_Latn-avt_Latn",
        "languages": [
          "eng-Latn",
          "avt-Latn"
        ],
        "main_score": 0.019870923913043476,
        "precision": 0.016583806818181817,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010105298913043478,
        "hf_subset": "avt_Latn-eng_Latn",
        "languages": [
          "avt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010105298913043478,
        "precision": 0.009292140151515152,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008463541666666666,
        "hf_subset": "eng_Latn-awb_Latn",
        "languages": [
          "eng-Latn",
          "awb-Latn"
        ],
        "main_score": 0.008463541666666666,
        "precision": 0.005989583333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006283788238396624,
        "hf_subset": "awb_Latn-eng_Latn",
        "languages": [
          "awb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006283788238396624,
        "precision": 0.0054282504180602,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04040404040404041,
        "f1": 0.025974025974025972,
        "hf_subset": "eng_Latn-awk_Latn",
        "languages": [
          "eng-Latn",
          "awk-Latn"
        ],
        "main_score": 0.025974025974025972,
        "precision": 0.02356902356902357,
        "recall": 0.04040404040404041
      },
      {
        "accuracy": 0.020202020202020204,
        "f1": 0.004921004921004921,
        "hf_subset": "awk_Latn-eng_Latn",
        "languages": [
          "awk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004921004921004921,
        "precision": 0.002861952861952862,
        "recall": 0.020202020202020204
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.09165474354169069,
        "hf_subset": "eng_Latn-awx_Latn",
        "languages": [
          "eng-Latn",
          "awx-Latn"
        ],
        "main_score": 0.09165474354169069,
        "precision": 0.07640382620851371,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.125,
        "f1": 0.09976557730463981,
        "hf_subset": "awx_Latn-eng_Latn",
        "languages": [
          "awx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09976557730463981,
        "precision": 0.09454730238851439,
        "recall": 0.125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00556798384542287,
        "hf_subset": "eng_Latn-azb_Arab",
        "languages": [
          "eng-Latn",
          "azb-Arab"
        ],
        "main_score": 0.00556798384542287,
        "precision": 0.0033731567911255414,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003976632882882883,
        "hf_subset": "azb_Arab-eng_Latn",
        "languages": [
          "azb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.003976632882882883,
        "precision": 0.003941761363636363,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024218749999999997,
        "hf_subset": "eng_Latn-azg_Latn",
        "languages": [
          "eng-Latn",
          "azg-Latn"
        ],
        "main_score": 0.024218749999999997,
        "precision": 0.021568080357142857,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014117132867132866,
        "hf_subset": "azg_Latn-eng_Latn",
        "languages": [
          "azg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014117132867132866,
        "precision": 0.013253934241413391,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009765625,
        "hf_subset": "eng_Latn-azz_Latn",
        "languages": [
          "eng-Latn",
          "azz-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.007942708333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007071314102564103,
        "hf_subset": "azz_Latn-eng_Latn",
        "languages": [
          "azz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007071314102564103,
        "precision": 0.006150323275862069,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019846754807692307,
        "hf_subset": "eng_Latn-bao_Latn",
        "languages": [
          "eng-Latn",
          "bao-Latn"
        ],
        "main_score": 0.019846754807692307,
        "precision": 0.01818577408690998,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01153013653013653,
        "hf_subset": "bao_Latn-eng_Latn",
        "languages": [
          "bao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01153013653013653,
        "precision": 0.009964288726624254,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008752893518518517,
        "hf_subset": "eng_Latn-bba_Latn",
        "languages": [
          "eng-Latn",
          "bba-Latn"
        ],
        "main_score": 0.008752893518518517,
        "precision": 0.007311698717948718,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001201923076923077,
        "hf_subset": "bba_Latn-eng_Latn",
        "languages": [
          "bba-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001201923076923077,
        "precision": 6.103515625e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005208333333333333,
        "hf_subset": "eng_Latn-bbb_Latn",
        "languages": [
          "eng-Latn",
          "bbb-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0033854166666666668,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "bbb_Latn-eng_Latn",
        "languages": [
          "bbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009664481026785715,
        "hf_subset": "eng_Latn-bbr_Latn",
        "languages": [
          "eng-Latn",
          "bbr-Latn"
        ],
        "main_score": 0.009664481026785715,
        "precision": 0.00752394307081807,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012305234593837536,
        "hf_subset": "bbr_Latn-eng_Latn",
        "languages": [
          "bbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012305234593837536,
        "precision": 0.009798728813559322,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011659071180555557,
        "hf_subset": "eng_Latn-bch_Latn",
        "languages": [
          "eng-Latn",
          "bch-Latn"
        ],
        "main_score": 0.011659071180555557,
        "precision": 0.01016290042562724,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011979166666666666,
        "hf_subset": "bch_Latn-eng_Latn",
        "languages": [
          "bch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011979166666666666,
        "precision": 0.0107421875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02160994010518467,
        "hf_subset": "eng_Latn-bco_Latn",
        "languages": [
          "eng-Latn",
          "bco-Latn"
        ],
        "main_score": 0.02160994010518467,
        "precision": 0.01918153461122211,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011093239379084968,
        "hf_subset": "bco_Latn-eng_Latn",
        "languages": [
          "bco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011093239379084968,
        "precision": 0.009847005208333332,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010360667977855478,
        "hf_subset": "eng_Latn-bdd_Latn",
        "languages": [
          "eng-Latn",
          "bdd-Latn"
        ],
        "main_score": 0.010360667977855478,
        "precision": 0.009221379823481117,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006572916666666666,
        "hf_subset": "bdd_Latn-eng_Latn",
        "languages": [
          "bdd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006572916666666666,
        "precision": 0.005890877016129032,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.12666666666666668,
        "f1": 0.06300672167338833,
        "hf_subset": "eng_Latn-bea_Latn",
        "languages": [
          "eng-Latn",
          "bea-Latn"
        ],
        "main_score": 0.06300672167338833,
        "precision": 0.04753418803418803,
        "recall": 0.12666666666666668
      },
      {
        "accuracy": 0.08666666666666667,
        "f1": 0.06059416362279565,
        "hf_subset": "bea_Latn-eng_Latn",
        "languages": [
          "bea-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06059416362279565,
        "precision": 0.058184899099931776,
        "recall": 0.08666666666666667
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-bef_Latn",
        "languages": [
          "eng-Latn",
          "bef-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "bef_Latn-eng_Latn",
        "languages": [
          "bef-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0025306619623655913,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ],
        "main_score": 0.0025306619623655913,
        "precision": 0.0014694940476190476,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002733027087646653,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.002733027087646653,
        "precision": 0.0015619777740641713,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006009615384615385,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0006009615384615385,
        "precision": 0.0003255208333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008336715367965368,
        "hf_subset": "eng_Latn-beo_Latn",
        "languages": [
          "eng-Latn",
          "beo-Latn"
        ],
        "main_score": 0.008336715367965368,
        "precision": 0.005598958333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004117398648648648,
        "hf_subset": "beo_Latn-eng_Latn",
        "languages": [
          "beo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004117398648648648,
        "precision": 0.004014756944444444,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015028211805555556,
        "hf_subset": "eng_Latn-beu_Latn",
        "languages": [
          "eng-Latn",
          "beu-Latn"
        ],
        "main_score": 0.015028211805555556,
        "precision": 0.012428021480331264,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.013585715868794326,
        "hf_subset": "beu_Latn-eng_Latn",
        "languages": [
          "beu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013585715868794326,
        "precision": 0.009096796480689048,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008339056776556776,
        "hf_subset": "eng_Latn-bgs_Latn",
        "languages": [
          "eng-Latn",
          "bgs-Latn"
        ],
        "main_score": 0.008339056776556776,
        "precision": 0.005316840277777778,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000678228021978022,
        "hf_subset": "bgs_Latn-eng_Latn",
        "languages": [
          "bgs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000678228021978022,
        "precision": 0.00036151592548076925,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02091346153846154,
        "hf_subset": "eng_Latn-bgt_Latn",
        "languages": [
          "eng-Latn",
          "bgt-Latn"
        ],
        "main_score": 0.02091346153846154,
        "precision": 0.017686631944444444,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009285910087719298,
        "hf_subset": "bgt_Latn-eng_Latn",
        "languages": [
          "bgt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009285910087719298,
        "precision": 0.007595486111111111,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.03868117559523809,
        "hf_subset": "eng_Latn-bhg_Latn",
        "languages": [
          "eng-Latn",
          "bhg-Latn"
        ],
        "main_score": 0.03868117559523809,
        "precision": 0.030439901893400633,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05125437729507226,
        "hf_subset": "bhg_Latn-eng_Latn",
        "languages": [
          "bhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05125437729507226,
        "precision": 0.04732946090367965,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006510416666666667,
        "hf_subset": "eng_Latn-bhl_Latn",
        "languages": [
          "eng-Latn",
          "bhl-Latn"
        ],
        "main_score": 0.006510416666666667,
        "precision": 0.005563446969696969,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006969975490196078,
        "hf_subset": "bhl_Latn-eng_Latn",
        "languages": [
          "bhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006969975490196078,
        "precision": 0.006103515625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "eng_Latn-big_Latn",
        "languages": [
          "eng-Latn",
          "big-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "big_Latn-eng_Latn",
        "languages": [
          "big-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023230277687998277,
        "hf_subset": "eng_Latn-bjk_Latn",
        "languages": [
          "eng-Latn",
          "bjk-Latn"
        ],
        "main_score": 0.023230277687998277,
        "precision": 0.019689825148809525,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019856770833333332,
        "hf_subset": "bjk_Latn-eng_Latn",
        "languages": [
          "bjk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019856770833333332,
        "precision": 0.017485119047619048,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009529532967032966,
        "hf_subset": "eng_Latn-bjp_Latn",
        "languages": [
          "eng-Latn",
          "bjp-Latn"
        ],
        "main_score": 0.009529532967032966,
        "precision": 0.0087890625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004712803643724696,
        "hf_subset": "bjp_Latn-eng_Latn",
        "languages": [
          "bjp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004712803643724696,
        "precision": 0.004337345157657657,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-bjr_Latn",
        "languages": [
          "eng-Latn",
          "bjr-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00030048076923076925,
        "hf_subset": "bjr_Latn-eng_Latn",
        "languages": [
          "bjr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00030048076923076925,
        "precision": 0.00015625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010424417162698412,
        "hf_subset": "eng_Latn-bjv_Latn",
        "languages": [
          "eng-Latn",
          "bjv-Latn"
        ],
        "main_score": 0.010424417162698412,
        "precision": 0.008092034556878305,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003957648026315789,
        "hf_subset": "bjv_Latn-eng_Latn",
        "languages": [
          "bjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003957648026315789,
        "precision": 0.003932119205298013,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016540537541771094,
        "hf_subset": "eng_Latn-bjz_Latn",
        "languages": [
          "eng-Latn",
          "bjz-Latn"
        ],
        "main_score": 0.016540537541771094,
        "precision": 0.013496642891174141,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009765625,
        "hf_subset": "bjz_Latn-eng_Latn",
        "languages": [
          "bjz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.009114583333333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01773838141025641,
        "hf_subset": "eng_Latn-bkd_Latn",
        "languages": [
          "eng-Latn",
          "bkd-Latn"
        ],
        "main_score": 0.01773838141025641,
        "precision": 0.014648437500000002,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008854166666666666,
        "hf_subset": "bkd_Latn-eng_Latn",
        "languages": [
          "bkd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008854166666666666,
        "precision": 0.00697642543859649,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "eng_Latn-bki_Latn",
        "languages": [
          "eng-Latn",
          "bki-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005191312636165578,
        "hf_subset": "bki_Latn-eng_Latn",
        "languages": [
          "bki-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005191312636165578,
        "precision": 0.00026861159673659675,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0127847413003663,
        "hf_subset": "eng_Latn-bkq_Latn",
        "languages": [
          "eng-Latn",
          "bkq-Latn"
        ],
        "main_score": 0.0127847413003663,
        "precision": 0.010091145833333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00938813025210084,
        "hf_subset": "bkq_Latn-eng_Latn",
        "languages": [
          "bkq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00938813025210084,
        "precision": 0.008707682291666668,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005755427170868348,
        "hf_subset": "eng_Latn-bkx_Latn",
        "languages": [
          "eng-Latn",
          "bkx-Latn"
        ],
        "main_score": 0.005755427170868348,
        "precision": 0.0033528645833333336,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.006558451361440492,
        "hf_subset": "bkx_Latn-eng_Latn",
        "languages": [
          "bkx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006558451361440492,
        "precision": 0.00405603511072261,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008147321428571427,
        "hf_subset": "eng_Latn-blw_Latn",
        "languages": [
          "eng-Latn",
          "blw-Latn"
        ],
        "main_score": 0.008147321428571427,
        "precision": 0.005208333333333332,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00028935185185185184,
        "hf_subset": "blw_Latn-eng_Latn",
        "languages": [
          "blw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00028935185185185184,
        "precision": 0.00015024038461538462,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018520585317460314,
        "hf_subset": "eng_Latn-blz_Latn",
        "languages": [
          "eng-Latn",
          "blz-Latn"
        ],
        "main_score": 0.018520585317460314,
        "precision": 0.013964843749999999,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0166015625,
        "hf_subset": "blz_Latn-eng_Latn",
        "languages": [
          "blz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0166015625,
        "precision": 0.016183035714285712,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017708333333333333,
        "hf_subset": "eng_Latn-bmh_Latn",
        "languages": [
          "eng-Latn",
          "bmh-Latn"
        ],
        "main_score": 0.017708333333333333,
        "precision": 0.016059027777777776,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008590777729002049,
        "hf_subset": "bmh_Latn-eng_Latn",
        "languages": [
          "bmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008590777729002049,
        "precision": 0.00710944842575188,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.07086614173228346,
        "f1": 0.032648563160374185,
        "hf_subset": "eng_Latn-bmk_Latn",
        "languages": [
          "eng-Latn",
          "bmk-Latn"
        ],
        "main_score": 0.032648563160374185,
        "precision": 0.02643044619422572,
        "recall": 0.07086614173228346
      },
      {
        "accuracy": 0.047244094488188976,
        "f1": 0.023002547475683182,
        "hf_subset": "bmk_Latn-eng_Latn",
        "languages": [
          "bmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023002547475683182,
        "precision": 0.020740076112186853,
        "recall": 0.047244094488188976
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008004473824786324,
        "hf_subset": "eng_Latn-bmr_Latn",
        "languages": [
          "eng-Latn",
          "bmr-Latn"
        ],
        "main_score": 0.008004473824786324,
        "precision": 0.006410900297619047,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006439294467787114,
        "hf_subset": "bmr_Latn-eng_Latn",
        "languages": [
          "bmr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006439294467787114,
        "precision": 0.005396843905472637,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006270534647550776,
        "hf_subset": "eng_Latn-bmu_Latn",
        "languages": [
          "eng-Latn",
          "bmu-Latn"
        ],
        "main_score": 0.006270534647550776,
        "precision": 0.005237345269672856,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008002101608187134,
        "hf_subset": "bmu_Latn-eng_Latn",
        "languages": [
          "bmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008002101608187134,
        "precision": 0.007908473782771536,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019715711805555553,
        "hf_subset": "eng_Latn-bnp_Latn",
        "languages": [
          "eng-Latn",
          "bnp-Latn"
        ],
        "main_score": 0.019715711805555553,
        "precision": 0.015806361607142858,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017125777867965368,
        "hf_subset": "bnp_Latn-eng_Latn",
        "languages": [
          "bnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017125777867965368,
        "precision": 0.01527157738095238,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01911582341269841,
        "hf_subset": "eng_Latn-boa_Latn",
        "languages": [
          "eng-Latn",
          "boa-Latn"
        ],
        "main_score": 0.01911582341269841,
        "precision": 0.01777245767140468,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006640625,
        "hf_subset": "boa_Latn-eng_Latn",
        "languages": [
          "boa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006640625,
        "precision": 0.005642361111111111,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02079855308600713,
        "hf_subset": "eng_Latn-boj_Latn",
        "languages": [
          "eng-Latn",
          "boj-Latn"
        ],
        "main_score": 0.02079855308600713,
        "precision": 0.017531572866329406,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011994190705128204,
        "hf_subset": "boj_Latn-eng_Latn",
        "languages": [
          "boj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011994190705128204,
        "precision": 0.010649181547619048,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007762419871794872,
        "hf_subset": "eng_Latn-bon_Latn",
        "languages": [
          "eng-Latn",
          "bon-Latn"
        ],
        "main_score": 0.007762419871794872,
        "precision": 0.00654000946969697,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004007711038961039,
        "hf_subset": "bon_Latn-eng_Latn",
        "languages": [
          "bon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004007711038961039,
        "precision": 0.003957648026315789,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008380681818181818,
        "hf_subset": "eng_Latn-box_Latn",
        "languages": [
          "eng-Latn",
          "box-Latn"
        ],
        "main_score": 0.008380681818181818,
        "precision": 0.008108935128518971,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002675840978593272,
        "hf_subset": "box_Latn-eng_Latn",
        "languages": [
          "box-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002675840978593272,
        "precision": 0.0019892939814814816,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006336805555555556,
        "hf_subset": "eng_Latn-bpr_Latn",
        "languages": [
          "eng-Latn",
          "bpr-Latn"
        ],
        "main_score": 0.006336805555555556,
        "precision": 0.005342371323529412,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004802389705882353,
        "hf_subset": "bpr_Latn-eng_Latn",
        "languages": [
          "bpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004802389705882353,
        "precision": 0.004398580016583747,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013430312028657616,
        "hf_subset": "eng_Latn-bps_Latn",
        "languages": [
          "eng-Latn",
          "bps-Latn"
        ],
        "main_score": 0.013430312028657616,
        "precision": 0.01034556606359649,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00862552332535885,
        "hf_subset": "bps_Latn-eng_Latn",
        "languages": [
          "bps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00862552332535885,
        "precision": 0.008255208333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009384105477855478,
        "hf_subset": "eng_Latn-bqc_Latn",
        "languages": [
          "eng-Latn",
          "bqc-Latn"
        ],
        "main_score": 0.009384105477855478,
        "precision": 0.0062499999999999995,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002672101449275362,
        "hf_subset": "bqc_Latn-eng_Latn",
        "languages": [
          "bqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002672101449275362,
        "precision": 0.001987390350877193,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.002197222935609372,
        "hf_subset": "eng_Latn-bqp_Latn",
        "languages": [
          "eng-Latn",
          "bqp-Latn"
        ],
        "main_score": 0.002197222935609372,
        "precision": 0.0011713980463980464,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004094283773291925,
        "hf_subset": "bqp_Latn-eng_Latn",
        "languages": [
          "bqp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004094283773291925,
        "precision": 0.00021274825962325962,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.018329001347093452,
        "hf_subset": "eng_Latn-bre_Latn",
        "languages": [
          "eng-Latn",
          "bre-Latn"
        ],
        "main_score": 0.018329001347093452,
        "precision": 0.014724273122710622,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.029887462797619044,
        "hf_subset": "bre_Latn-eng_Latn",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029887462797619044,
        "precision": 0.02532998582497515,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010548464845339845,
        "hf_subset": "eng_Latn-bsj_Latn",
        "languages": [
          "eng-Latn",
          "bsj-Latn"
        ],
        "main_score": 0.010548464845339845,
        "precision": 0.00827487889909104,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.016741071428571428,
        "hf_subset": "bsj_Latn-eng_Latn",
        "languages": [
          "bsj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016741071428571428,
        "precision": 0.016276041666666664,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0029082531138452192,
        "hf_subset": "eng_Latn-bsn_Latn",
        "languages": [
          "eng-Latn",
          "bsn-Latn"
        ],
        "main_score": 0.0029082531138452192,
        "precision": 0.0016259759111978123,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012176724137931035,
        "hf_subset": "bsn_Latn-eng_Latn",
        "languages": [
          "bsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012176724137931035,
        "precision": 0.010656226163234172,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.019168526785714284,
        "hf_subset": "eng_Latn-bsp_Latn",
        "languages": [
          "eng-Latn",
          "bsp-Latn"
        ],
        "main_score": 0.019168526785714284,
        "precision": 0.013903715924775706,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02225525379614475,
        "hf_subset": "bsp_Latn-eng_Latn",
        "languages": [
          "bsp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02225525379614475,
        "precision": 0.020015030961981567,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0061392471677893445,
        "hf_subset": "eng_Latn-bss_Latn",
        "languages": [
          "eng-Latn",
          "bss-Latn"
        ],
        "main_score": 0.0061392471677893445,
        "precision": 0.00535094246031746,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007776331018518518,
        "hf_subset": "bss_Latn-eng_Latn",
        "languages": [
          "bss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007776331018518518,
        "precision": 0.0004106570512820513,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012403786945812807,
        "hf_subset": "eng_Latn-buk_Latn",
        "languages": [
          "eng-Latn",
          "buk-Latn"
        ],
        "main_score": 0.012403786945812807,
        "precision": 0.010896115956072351,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0039449257425742575,
        "hf_subset": "buk_Latn-eng_Latn",
        "languages": [
          "buk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0039449257425742575,
        "precision": 0.00392568407960199,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005324074074074075,
        "hf_subset": "eng_Latn-bus_Latn",
        "languages": [
          "eng-Latn",
          "bus-Latn"
        ],
        "main_score": 0.005324074074074075,
        "precision": 0.0035682091346153845,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00045166015625,
        "hf_subset": "bus_Latn-eng_Latn",
        "languages": [
          "bus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00045166015625,
        "precision": 0.00023634997927890591,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007710193452380952,
        "hf_subset": "eng_Latn-bvd_Latn",
        "languages": [
          "eng-Latn",
          "bvd-Latn"
        ],
        "main_score": 0.007710193452380952,
        "precision": 0.006141675420168067,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "bvd_Latn-eng_Latn",
        "languages": [
          "bvd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029975818452380946,
        "hf_subset": "eng_Latn-bvr_Latn",
        "languages": [
          "eng-Latn",
          "bvr-Latn"
        ],
        "main_score": 0.029975818452380946,
        "precision": 0.02567020313396443,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0130835196419078,
        "hf_subset": "bvr_Latn-eng_Latn",
        "languages": [
          "bvr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0130835196419078,
        "precision": 0.010960279576286118,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014428605248917746,
        "hf_subset": "eng_Latn-bxh_Latn",
        "languages": [
          "eng-Latn",
          "bxh-Latn"
        ],
        "main_score": 0.014428605248917746,
        "precision": 0.01217859642621871,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011026372354497355,
        "hf_subset": "bxh_Latn-eng_Latn",
        "languages": [
          "bxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011026372354497355,
        "precision": 0.009656879578754577,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002232142857142857,
        "hf_subset": "eng_Latn-byr_Latn",
        "languages": [
          "eng-Latn",
          "byr-Latn"
        ],
        "main_score": 0.0002232142857142857,
        "precision": 0.00011488970588235294,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004230604091995221,
        "hf_subset": "byr_Latn-eng_Latn",
        "languages": [
          "byr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004230604091995221,
        "precision": 0.004072965342679128,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013242020566239316,
        "hf_subset": "eng_Latn-byx_Latn",
        "languages": [
          "eng-Latn",
          "byx-Latn"
        ],
        "main_score": 0.013242020566239316,
        "precision": 0.010190716911764704,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006850090579710145,
        "hf_subset": "byx_Latn-eng_Latn",
        "languages": [
          "byx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006850090579710145,
        "precision": 0.005741003787878787,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016424851190476188,
        "hf_subset": "eng_Latn-bzd_Latn",
        "languages": [
          "eng-Latn",
          "bzd-Latn"
        ],
        "main_score": 0.016424851190476188,
        "precision": 0.012514467592592591,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012068365989356556,
        "hf_subset": "bzd_Latn-eng_Latn",
        "languages": [
          "bzd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012068365989356556,
        "precision": 0.011899723101265823,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015268841911764705,
        "hf_subset": "eng_Latn-bzh_Latn",
        "languages": [
          "eng-Latn",
          "bzh-Latn"
        ],
        "main_score": 0.015268841911764705,
        "precision": 0.012766506779754062,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004014756944444444,
        "hf_subset": "bzh_Latn-eng_Latn",
        "languages": [
          "bzh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004014756944444444,
        "precision": 0.003961267605633803,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06083829365079365,
        "hf_subset": "eng_Latn-bzj_Latn",
        "languages": [
          "eng-Latn",
          "bzj-Latn"
        ],
        "main_score": 0.06083829365079365,
        "precision": 0.053371888528138525,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04568033854166667,
        "hf_subset": "bzj_Latn-eng_Latn",
        "languages": [
          "bzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04568033854166667,
        "precision": 0.044495161976080756,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009006212192323736,
        "hf_subset": "eng_Latn-caa_Latn",
        "languages": [
          "eng-Latn",
          "caa-Latn"
        ],
        "main_score": 0.009006212192323736,
        "precision": 0.006145518313172043,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.002917792353683898,
        "hf_subset": "caa_Latn-eng_Latn",
        "languages": [
          "caa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002917792353683898,
        "precision": 0.0016111167478354978,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023075810185185185,
        "hf_subset": "eng_Latn-cab_Latn",
        "languages": [
          "eng-Latn",
          "cab-Latn"
        ],
        "main_score": 0.023075810185185185,
        "precision": 0.02098357371794872,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013676041755085872,
        "hf_subset": "cab_Latn-eng_Latn",
        "languages": [
          "cab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013676041755085872,
        "precision": 0.011637244591346154,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01050430689102564,
        "hf_subset": "eng_Latn-cac_Latn",
        "languages": [
          "eng-Latn",
          "cac-Latn"
        ],
        "main_score": 0.01050430689102564,
        "precision": 0.0085546875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008020213293650793,
        "hf_subset": "cac_Latn-eng_Latn",
        "languages": [
          "cac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008020213293650793,
        "precision": 0.005474430083805083,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.05026041666666666,
        "hf_subset": "eng_Latn-caf_Latn",
        "languages": [
          "eng-Latn",
          "caf-Latn"
        ],
        "main_score": 0.05026041666666666,
        "precision": 0.04584122474747475,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02915274064171123,
        "hf_subset": "caf_Latn-eng_Latn",
        "languages": [
          "caf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02915274064171123,
        "precision": 0.02569009728461945,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006610076121794871,
        "hf_subset": "eng_Latn-cak_Latn",
        "languages": [
          "eng-Latn",
          "cak-Latn"
        ],
        "main_score": 0.006610076121794871,
        "precision": 0.004654947916666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007230392156862745,
        "hf_subset": "cak_Latn-eng_Latn",
        "languages": [
          "cak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007230392156862745,
        "precision": 0.005837180397727272,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011288024607487922,
        "hf_subset": "eng_Latn-cao_Latn",
        "languages": [
          "eng-Latn",
          "cao-Latn"
        ],
        "main_score": 0.011288024607487922,
        "precision": 0.008805773729946523,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013826245704467353,
        "hf_subset": "cao_Latn-eng_Latn",
        "languages": [
          "cao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013826245704467353,
        "precision": 0.0008219401041666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011126893939393938,
        "hf_subset": "eng_Latn-cap_Latn",
        "languages": [
          "eng-Latn",
          "cap-Latn"
        ],
        "main_score": 0.011126893939393938,
        "precision": 0.009765625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009985002552756977,
        "hf_subset": "cap_Latn-eng_Latn",
        "languages": [
          "cap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009985002552756977,
        "precision": 0.008054178702731092,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020249698367963455,
        "hf_subset": "eng_Latn-car_Latn",
        "languages": [
          "eng-Latn",
          "car-Latn"
        ],
        "main_score": 0.020249698367963455,
        "precision": 0.01683562748015873,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019718424479166666,
        "hf_subset": "car_Latn-eng_Latn",
        "languages": [
          "car-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019718424479166666,
        "precision": 0.017364516363372197,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-cav_Latn",
        "languages": [
          "eng-Latn",
          "cav-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004357332598235766,
        "hf_subset": "cav_Latn-eng_Latn",
        "languages": [
          "cav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004357332598235766,
        "precision": 0.004138764880952381,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005679086538461538,
        "hf_subset": "eng_Latn-cax_Latn",
        "languages": [
          "eng-Latn",
          "cax-Latn"
        ],
        "main_score": 0.005679086538461538,
        "precision": 0.0038597470238095235,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004296875,
        "hf_subset": "cax_Latn-eng_Latn",
        "languages": [
          "cax-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004296875,
        "precision": 0.002712673611111111,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011793154761904762,
        "hf_subset": "eng_Latn-cbc_Latn",
        "languages": [
          "eng-Latn",
          "cbc-Latn"
        ],
        "main_score": 0.011793154761904762,
        "precision": 0.010221354166666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008611992138854297,
        "hf_subset": "cbc_Latn-eng_Latn",
        "languages": [
          "cbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008611992138854297,
        "precision": 0.007112421541132478,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018548768939393938,
        "hf_subset": "eng_Latn-cbi_Latn",
        "languages": [
          "eng-Latn",
          "cbi-Latn"
        ],
        "main_score": 0.018548768939393938,
        "precision": 0.016341145833333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009027777777777777,
        "hf_subset": "cbi_Latn-eng_Latn",
        "languages": [
          "cbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009027777777777777,
        "precision": 0.008476307189542483,
        "recall": 0.015625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.062171183850871344,
        "hf_subset": "eng_Latn-cbk_Latn",
        "languages": [
          "eng-Latn",
          "cbk-Latn"
        ],
        "main_score": 0.062171183850871344,
        "precision": 0.05319666929271708,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.040523538961038955,
        "hf_subset": "cbk_Latn-eng_Latn",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.040523538961038955,
        "precision": 0.03522205295915325,
        "recall": 0.0625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004052294481981982,
        "hf_subset": "eng_Latn-cbr_Latn",
        "languages": [
          "eng-Latn",
          "cbr-Latn"
        ],
        "main_score": 0.004052294481981982,
        "precision": 0.002556989734299517,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006544237012987012,
        "hf_subset": "cbr_Latn-eng_Latn",
        "languages": [
          "cbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006544237012987012,
        "precision": 0.005876358695652174,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0123046875,
        "hf_subset": "eng_Latn-cbs_Latn",
        "languages": [
          "eng-Latn",
          "cbs-Latn"
        ],
        "main_score": 0.0123046875,
        "precision": 0.010649181547619048,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004606737869198312,
        "hf_subset": "cbs_Latn-eng_Latn",
        "languages": [
          "cbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004606737869198312,
        "precision": 0.0032800889065817407,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007378472222222222,
        "hf_subset": "eng_Latn-cbt_Latn",
        "languages": [
          "eng-Latn",
          "cbt-Latn"
        ],
        "main_score": 0.007378472222222222,
        "precision": 0.00634765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "cbt_Latn-eng_Latn",
        "languages": [
          "cbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "eng_Latn-cbu_Latn",
        "languages": [
          "eng-Latn",
          "cbu-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013020833333333333,
        "hf_subset": "cbu_Latn-eng_Latn",
        "languages": [
          "cbu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00013020833333333333,
        "precision": 6.620762711864407e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01775018601190476,
        "hf_subset": "eng_Latn-cbv_Latn",
        "languages": [
          "eng-Latn",
          "cbv-Latn"
        ],
        "main_score": 0.01775018601190476,
        "precision": 0.014192708333333331,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012041513739883304,
        "hf_subset": "cbv_Latn-eng_Latn",
        "languages": [
          "cbv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012041513739883304,
        "precision": 0.010259402056277057,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006265024038461539,
        "hf_subset": "eng_Latn-cco_Latn",
        "languages": [
          "eng-Latn",
          "cco-Latn"
        ],
        "main_score": 0.006265024038461539,
        "precision": 0.005223834325396826,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01658187984496124,
        "hf_subset": "cco_Latn-eng_Latn",
        "languages": [
          "cco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01658187984496124,
        "precision": 0.014020239400584795,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.025478094143175662,
        "hf_subset": "eng_Latn-ceb_Latn",
        "languages": [
          "eng-Latn",
          "ceb-Latn"
        ],
        "main_score": 0.025478094143175662,
        "precision": 0.02004442401960784,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01171875,
        "hf_subset": "ceb_Latn-eng_Latn",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.010416666666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.028431919642857142,
        "hf_subset": "eng_Latn-cek_Latn",
        "languages": [
          "eng-Latn",
          "cek-Latn"
        ],
        "main_score": 0.028431919642857142,
        "precision": 0.023956927575348626,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01667773909580312,
        "hf_subset": "cek_Latn-eng_Latn",
        "languages": [
          "cek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01667773909580312,
        "precision": 0.015060192799707602,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.01908031421703297,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ],
        "main_score": 0.01908031421703297,
        "precision": 0.013002896471088436,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.02822707926034539,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02822707926034539,
        "precision": 0.02367564418859649,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023697916666666666,
        "hf_subset": "eng_Latn-cgc_Latn",
        "languages": [
          "eng-Latn",
          "cgc-Latn"
        ],
        "main_score": 0.023697916666666666,
        "precision": 0.0212890625,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004946822478991596,
        "hf_subset": "cgc_Latn-eng_Latn",
        "languages": [
          "cgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004946822478991596,
        "precision": 0.004458825850684403,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.04532857146597956,
        "hf_subset": "eng_Latn-cha_Latn",
        "languages": [
          "eng-Latn",
          "cha-Latn"
        ],
        "main_score": 0.04532857146597956,
        "precision": 0.0383499257251179,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.0341796875,
        "hf_subset": "cha_Latn-eng_Latn",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0341796875,
        "precision": 0.028778310104529616,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014664273648648647,
        "hf_subset": "eng_Latn-chd_Latn",
        "languages": [
          "eng-Latn",
          "chd-Latn"
        ],
        "main_score": 0.014664273648648647,
        "precision": 0.011610243055555556,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01180937296914143,
        "hf_subset": "chd_Latn-eng_Latn",
        "languages": [
          "chd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01180937296914143,
        "precision": 0.010510571451527525,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008581349206349205,
        "hf_subset": "eng_Latn-chf_Latn",
        "languages": [
          "eng-Latn",
          "chf-Latn"
        ],
        "main_score": 0.008581349206349205,
        "precision": 0.007019213935574229,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009421307858807858,
        "hf_subset": "chf_Latn-eng_Latn",
        "languages": [
          "chf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009421307858807858,
        "precision": 0.007211802041160594,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018238467261904763,
        "hf_subset": "eng_Latn-chk_Latn",
        "languages": [
          "eng-Latn",
          "chk-Latn"
        ],
        "main_score": 0.018238467261904763,
        "precision": 0.01357717803030303,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01904296875,
        "hf_subset": "chk_Latn-eng_Latn",
        "languages": [
          "chk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01904296875,
        "precision": 0.015792410714285714,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012760416666666666,
        "hf_subset": "eng_Latn-chq_Latn",
        "languages": [
          "eng-Latn",
          "chq-Latn"
        ],
        "main_score": 0.012760416666666666,
        "precision": 0.011074240523968784,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00840435606060606,
        "hf_subset": "chq_Latn-eng_Latn",
        "languages": [
          "chq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00840435606060606,
        "precision": 0.006632486979166666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015136613403451994,
        "hf_subset": "eng_Latn-chz_Latn",
        "languages": [
          "eng-Latn",
          "chz-Latn"
        ],
        "main_score": 0.015136613403451994,
        "precision": 0.011572725681181563,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028930196360153253,
        "hf_subset": "chz_Latn-eng_Latn",
        "languages": [
          "chz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028930196360153253,
        "precision": 0.02526183197463768,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-cjo_Latn",
        "languages": [
          "eng-Latn",
          "cjo-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001220703125,
        "hf_subset": "cjo_Latn-eng_Latn",
        "languages": [
          "cjo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001220703125,
        "precision": 6.200396825396825e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008741749127116548,
        "hf_subset": "eng_Latn-cjv_Latn",
        "languages": [
          "eng-Latn",
          "cjv-Latn"
        ],
        "main_score": 0.008741749127116548,
        "precision": 0.006808502969070403,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004696800595238095,
        "hf_subset": "cjv_Latn-eng_Latn",
        "languages": [
          "cjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004696800595238095,
        "precision": 0.0031622023809523806,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020389766483516485,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ],
        "main_score": 0.0020389766483516485,
        "precision": 0.001345486111111111,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006716008771929825,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.006716008771929825,
        "precision": 0.005964949324324324,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014846850198412698,
        "hf_subset": "eng_Latn-cle_Latn",
        "languages": [
          "eng-Latn",
          "cle-Latn"
        ],
        "main_score": 0.014846850198412698,
        "precision": 0.012351828142419176,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00982436560150376,
        "hf_subset": "cle_Latn-eng_Latn",
        "languages": [
          "cle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00982436560150376,
        "precision": 0.009144176136363636,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01964905753968254,
        "hf_subset": "eng_Latn-clu_Latn",
        "languages": [
          "eng-Latn",
          "clu-Latn"
        ],
        "main_score": 0.01964905753968254,
        "precision": 0.016147806186868688,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01608455882352941,
        "hf_subset": "clu_Latn-eng_Latn",
        "languages": [
          "clu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01608455882352941,
        "precision": 0.014567057291666664,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009114583333333332,
        "hf_subset": "eng_Latn-cme_Latn",
        "languages": [
          "eng-Latn",
          "cme-Latn"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.007291666666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004312162618083671,
        "hf_subset": "cme_Latn-eng_Latn",
        "languages": [
          "cme-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004312162618083671,
        "precision": 0.004114620376955903,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.07021120474705034,
        "hf_subset": "eng_Latn-cmn_Hans",
        "languages": [
          "eng-Latn",
          "cmn-Hans"
        ],
        "main_score": 0.07021120474705034,
        "precision": 0.05662401292284104,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07007688492063494,
        "hf_subset": "cmn_Hans-eng_Latn",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.07007688492063494,
        "precision": 0.06347926386652142,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-cni_Latn",
        "languages": [
          "eng-Latn",
          "cni-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.7560096153846156e-05,
        "hf_subset": "cni_Latn-eng_Latn",
        "languages": [
          "cni-Latn",
          "eng-Latn"
        ],
        "main_score": 3.7560096153846156e-05,
        "precision": 1.8870772946859902e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013382538222146145,
        "hf_subset": "eng_Latn-cnl_Latn",
        "languages": [
          "eng-Latn",
          "cnl-Latn"
        ],
        "main_score": 0.013382538222146145,
        "precision": 0.01064116182383041,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012444196428571428,
        "hf_subset": "cnl_Latn-eng_Latn",
        "languages": [
          "cnl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012444196428571428,
        "precision": 0.0107421875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026520961145194274,
        "hf_subset": "eng_Latn-cnt_Latn",
        "languages": [
          "eng-Latn",
          "cnt-Latn"
        ],
        "main_score": 0.0026520961145194274,
        "precision": 0.0019772376543209878,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002864583333333333,
        "hf_subset": "cnt_Latn-eng_Latn",
        "languages": [
          "cnt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002864583333333333,
        "precision": 0.002087823275862069,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-cof_Latn",
        "languages": [
          "eng-Latn",
          "cof-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003956980519480519,
        "hf_subset": "cof_Latn-eng_Latn",
        "languages": [
          "cof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003956980519480519,
        "precision": 0.003931781045751634,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02046130952380952,
        "hf_subset": "eng_Latn-con_Latn",
        "languages": [
          "eng-Latn",
          "con-Latn"
        ],
        "main_score": 0.02046130952380952,
        "precision": 0.017578125,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01611328125,
        "hf_subset": "con_Latn-eng_Latn",
        "languages": [
          "con-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01611328125,
        "precision": 0.015885416666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005208333333333333,
        "hf_subset": "eng_Latn-cop_Copt",
        "languages": [
          "eng-Latn",
          "cop-Copt"
        ],
        "main_score": 0.0005208333333333333,
        "precision": 0.00027901785714285713,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "cop_Copt-eng_Latn",
        "languages": [
          "cop-Copt",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "eng_Latn-cot_Latn",
        "languages": [
          "eng-Latn",
          "cot-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "cot_Latn-eng_Latn",
        "languages": [
          "cot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01472567287784679,
        "hf_subset": "eng_Latn-cpa_Latn",
        "languages": [
          "eng-Latn",
          "cpa-Latn"
        ],
        "main_score": 0.01472567287784679,
        "precision": 0.01204231281328321,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01413690476190476,
        "hf_subset": "cpa_Latn-eng_Latn",
        "languages": [
          "cpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01413690476190476,
        "precision": 0.012369791666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00887841832963784,
        "hf_subset": "eng_Latn-cpb_Latn",
        "languages": [
          "eng-Latn",
          "cpb-Latn"
        ],
        "main_score": 0.00887841832963784,
        "precision": 0.007274787808641975,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015943877551020407,
        "hf_subset": "cpb_Latn-eng_Latn",
        "languages": [
          "cpb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015943877551020407,
        "precision": 8.138020833333333e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008742559523809524,
        "hf_subset": "eng_Latn-cpc_Latn",
        "languages": [
          "eng-Latn",
          "cpc-Latn"
        ],
        "main_score": 0.008742559523809524,
        "precision": 0.006770833333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028366815476190475,
        "hf_subset": "cpc_Latn-eng_Latn",
        "languages": [
          "cpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028366815476190475,
        "precision": 0.002071146637891867,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01427784455128205,
        "hf_subset": "eng_Latn-cpu_Latn",
        "languages": [
          "eng-Latn",
          "cpu-Latn"
        ],
        "main_score": 0.01427784455128205,
        "precision": 0.01222102422699849,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00039355322338830584,
        "hf_subset": "cpu_Latn-eng_Latn",
        "languages": [
          "cpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00039355322338830584,
        "precision": 0.0002046835542929293,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009846166237113402,
        "hf_subset": "eng_Latn-cpy_Latn",
        "languages": [
          "eng-Latn",
          "cpy-Latn"
        ],
        "main_score": 0.009846166237113402,
        "precision": 0.009155273437499998,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027858527131782943,
        "hf_subset": "cpy_Latn-eng_Latn",
        "languages": [
          "cpy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027858527131782943,
        "precision": 0.0020461309523809525,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011744281045751634,
        "hf_subset": "eng_Latn-crn_Latn",
        "languages": [
          "eng-Latn",
          "crn-Latn"
        ],
        "main_score": 0.011744281045751634,
        "precision": 0.009195963541666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0034226190476190476,
        "hf_subset": "crn_Latn-eng_Latn",
        "languages": [
          "crn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0034226190476190476,
        "precision": 0.0020582932692307693,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03650517146610897,
        "hf_subset": "eng_Latn-crx_Latn",
        "languages": [
          "eng-Latn",
          "crx-Latn"
        ],
        "main_score": 0.03650517146610897,
        "precision": 0.03192981959541063,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028226207728674832,
        "hf_subset": "crx_Latn-eng_Latn",
        "languages": [
          "crx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028226207728674832,
        "precision": 0.025156249999999998,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010751488095238093,
        "hf_subset": "eng_Latn-cso_Latn",
        "languages": [
          "eng-Latn",
          "cso-Latn"
        ],
        "main_score": 0.010751488095238093,
        "precision": 0.008463541666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011753015350877194,
        "hf_subset": "cso_Latn-eng_Latn",
        "languages": [
          "cso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011753015350877194,
        "precision": 0.010433874816446403,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03280239238298449,
        "hf_subset": "eng_Latn-csy_Latn",
        "languages": [
          "eng-Latn",
          "csy-Latn"
        ],
        "main_score": 0.03280239238298449,
        "precision": 0.025976562499999998,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.049479166666666664,
        "hf_subset": "csy_Latn-eng_Latn",
        "languages": [
          "csy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.049479166666666664,
        "precision": 0.045572916666666664,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015469990079365078,
        "hf_subset": "eng_Latn-cta_Latn",
        "languages": [
          "eng-Latn",
          "cta-Latn"
        ],
        "main_score": 0.015469990079365078,
        "precision": 0.010658482142857143,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005984841853408029,
        "hf_subset": "cta_Latn-eng_Latn",
        "languages": [
          "cta-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005984841853408029,
        "precision": 0.004066647289019964,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01414784266701236,
        "hf_subset": "eng_Latn-cth_Latn",
        "languages": [
          "eng-Latn",
          "cth-Latn"
        ],
        "main_score": 0.01414784266701236,
        "precision": 0.013147109707704219,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.020833333333333332,
        "hf_subset": "cth_Latn-eng_Latn",
        "languages": [
          "cth-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020833333333333332,
        "precision": 0.01953125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0212042297979798,
        "hf_subset": "eng_Latn-ctp_Latn",
        "languages": [
          "eng-Latn",
          "ctp-Latn"
        ],
        "main_score": 0.0212042297979798,
        "precision": 0.018100508432539682,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011361012871811606,
        "hf_subset": "ctp_Latn-eng_Latn",
        "languages": [
          "ctp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011361012871811606,
        "precision": 0.010275649533462035,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016603990627428126,
        "hf_subset": "eng_Latn-ctu_Latn",
        "languages": [
          "eng-Latn",
          "ctu-Latn"
        ],
        "main_score": 0.016603990627428126,
        "precision": 0.014573246772300468,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015026041666666667,
        "hf_subset": "ctu_Latn-eng_Latn",
        "languages": [
          "ctu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015026041666666667,
        "precision": 0.011154598694810091,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0061415270702716825,
        "hf_subset": "eng_Latn-cub_Latn",
        "languages": [
          "eng-Latn",
          "cub-Latn"
        ],
        "main_score": 0.0061415270702716825,
        "precision": 0.004398100083056479,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008374601548269581,
        "hf_subset": "cub_Latn-eng_Latn",
        "languages": [
          "cub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008374601548269581,
        "precision": 0.008107383578431372,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010474111519607842,
        "hf_subset": "eng_Latn-cuc_Latn",
        "languages": [
          "eng-Latn",
          "cuc-Latn"
        ],
        "main_score": 0.010474111519607842,
        "precision": 0.008492476851851852,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0055208333333333325,
        "hf_subset": "cuc_Latn-eng_Latn",
        "languages": [
          "cuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0055208333333333325,
        "precision": 0.004069010416666666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003255208333333333,
        "hf_subset": "eng_Latn-cui_Latn",
        "languages": [
          "eng-Latn",
          "cui-Latn"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0020833333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0023615752064027923,
        "hf_subset": "cui_Latn-eng_Latn",
        "languages": [
          "cui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0023615752064027923,
        "precision": 0.0013063108766233765,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005408190784404377,
        "hf_subset": "eng_Latn-cuk_Latn",
        "languages": [
          "eng-Latn",
          "cuk-Latn"
        ],
        "main_score": 0.005408190784404377,
        "precision": 0.004788800600885515,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00819450655933214,
        "hf_subset": "cuk_Latn-eng_Latn",
        "languages": [
          "cuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00819450655933214,
        "precision": 0.00800830200501253,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008277529761904762,
        "hf_subset": "eng_Latn-cut_Latn",
        "languages": [
          "eng-Latn",
          "cut-Latn"
        ],
        "main_score": 0.008277529761904762,
        "precision": 0.005859374999999999,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "cut_Latn-eng_Latn",
        "languages": [
          "cut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.0026041666666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012491599462365591,
        "hf_subset": "eng_Latn-cux_Latn",
        "languages": [
          "eng-Latn",
          "cux-Latn"
        ],
        "main_score": 0.012491599462365591,
        "precision": 0.009053969109195401,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0046875,
        "hf_subset": "cux_Latn-eng_Latn",
        "languages": [
          "cux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0046875,
        "precision": 0.004340277777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008496543778801843,
        "hf_subset": "eng_Latn-cwe_Latn",
        "languages": [
          "eng-Latn",
          "cwe-Latn"
        ],
        "main_score": 0.008496543778801843,
        "precision": 0.00817701765447667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "cwe_Latn-eng_Latn",
        "languages": [
          "cwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018959122474747472,
        "hf_subset": "eng_Latn-cya_Latn",
        "languages": [
          "eng-Latn",
          "cya-Latn"
        ],
        "main_score": 0.018959122474747472,
        "precision": 0.015795068027210882,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0071180555555555546,
        "hf_subset": "cya_Latn-eng_Latn",
        "languages": [
          "cya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0071180555555555546,
        "precision": 0.005805121527777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005093149038461539,
        "hf_subset": "eng_Latn-daa_Latn",
        "languages": [
          "eng-Latn",
          "daa-Latn"
        ],
        "main_score": 0.005093149038461539,
        "precision": 0.0031622023809523806,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "daa_Latn-eng_Latn",
        "languages": [
          "daa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012426120036572622,
        "hf_subset": "eng_Latn-dad_Latn",
        "languages": [
          "eng-Latn",
          "dad-Latn"
        ],
        "main_score": 0.012426120036572622,
        "precision": 0.00967045611849391,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009975961538461538,
        "hf_subset": "dad_Latn-eng_Latn",
        "languages": [
          "dad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009975961538461538,
        "precision": 0.009114583333333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005091783216783216,
        "hf_subset": "eng_Latn-dah_Latn",
        "languages": [
          "eng-Latn",
          "dah-Latn"
        ],
        "main_score": 0.005091783216783216,
        "precision": 0.004543922061011905,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004036458333333334,
        "hf_subset": "dah_Latn-eng_Latn",
        "languages": [
          "dah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004036458333333334,
        "precision": 0.0023974323830409355,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05233624706972172,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ],
        "main_score": 0.05233624706972172,
        "precision": 0.04673440822700691,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.0627601431197479,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0627601431197479,
        "precision": 0.05693996144960241,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013237847222222224,
        "hf_subset": "eng_Latn-ded_Latn",
        "languages": [
          "eng-Latn",
          "ded-Latn"
        ],
        "main_score": 0.013237847222222224,
        "precision": 0.012543402777777778,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.456858407079646e-05,
        "hf_subset": "ded_Latn-eng_Latn",
        "languages": [
          "ded-Latn",
          "eng-Latn"
        ],
        "main_score": 3.456858407079646e-05,
        "precision": 1.736111111111111e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.05839176014957265,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.05839176014957265,
        "precision": 0.04955040578831214,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07497782165750916,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07497782165750916,
        "precision": 0.06479414682539683,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014309895833333332,
        "hf_subset": "eng_Latn-dgc_Latn",
        "languages": [
          "eng-Latn",
          "dgc-Latn"
        ],
        "main_score": 0.014309895833333332,
        "precision": 0.012181555706521739,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008034754224270352,
        "hf_subset": "dgc_Latn-eng_Latn",
        "languages": [
          "dgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008034754224270352,
        "precision": 0.006720344387755102,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021649512764042814,
        "hf_subset": "eng_Latn-dgr_Latn",
        "languages": [
          "eng-Latn",
          "dgr-Latn"
        ],
        "main_score": 0.021649512764042814,
        "precision": 0.01962174773755656,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008029513888888888,
        "hf_subset": "dgr_Latn-eng_Latn",
        "languages": [
          "dgr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008029513888888888,
        "precision": 0.007924107142857142,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006510416666666666,
        "hf_subset": "eng_Latn-dgz_Latn",
        "languages": [
          "eng-Latn",
          "dgz-Latn"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.0003551136363636364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0028393779735355336,
        "hf_subset": "dgz_Latn-eng_Latn",
        "languages": [
          "dgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028393779735355336,
        "precision": 0.0017766294409613374,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003255208333333333,
        "hf_subset": "eng_Latn-dhg_Latn",
        "languages": [
          "eng-Latn",
          "dhg-Latn"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0020833333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.633720930232558e-05,
        "hf_subset": "dhg_Latn-eng_Latn",
        "languages": [
          "dhg-Latn",
          "eng-Latn"
        ],
        "main_score": 3.633720930232558e-05,
        "precision": 1.8253504672897195e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017537471719457014,
        "hf_subset": "eng_Latn-dif_Latn",
        "languages": [
          "eng-Latn",
          "dif-Latn"
        ],
        "main_score": 0.017537471719457014,
        "precision": 0.013295454545454546,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022355033420789608,
        "hf_subset": "dif_Latn-eng_Latn",
        "languages": [
          "dif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022355033420789608,
        "precision": 0.02042395652593021,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005478050595238095,
        "hf_subset": "eng_Latn-dik_Latn",
        "languages": [
          "eng-Latn",
          "dik-Latn"
        ],
        "main_score": 0.005478050595238095,
        "precision": 0.0031424158204948647,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006448412698412698,
        "hf_subset": "dik_Latn-eng_Latn",
        "languages": [
          "dik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006448412698412698,
        "precision": 0.00034202188940092164,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.07368421052631578,
        "f1": 0.031979453766380755,
        "hf_subset": "eng_Latn-dji_Latn",
        "languages": [
          "eng-Latn",
          "dji-Latn"
        ],
        "main_score": 0.031979453766380755,
        "precision": 0.02317738791423002,
        "recall": 0.07368421052631578
      },
      {
        "accuracy": 0.02631578947368421,
        "f1": 0.009884566488685482,
        "hf_subset": "dji_Latn-eng_Latn",
        "languages": [
          "dji-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009884566488685482,
        "precision": 0.008472886762360446,
        "recall": 0.02631578947368421
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012558128720238095,
        "hf_subset": "eng_Latn-djk_Latn",
        "languages": [
          "eng-Latn",
          "djk-Latn"
        ],
        "main_score": 0.012558128720238095,
        "precision": 0.009488607270865335,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011413447851966874,
        "hf_subset": "djk_Latn-eng_Latn",
        "languages": [
          "djk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011413447851966874,
        "precision": 0.010030544669790992,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006898230150697255,
        "hf_subset": "eng_Latn-djr_Latn",
        "languages": [
          "eng-Latn",
          "djr-Latn"
        ],
        "main_score": 0.006898230150697255,
        "precision": 0.005664700776143791,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003205128205128205,
        "hf_subset": "djr_Latn-eng_Latn",
        "languages": [
          "djr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003205128205128205,
        "precision": 0.0022786458333333335,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0062499999999999995,
        "hf_subset": "eng_Latn-dob_Latn",
        "languages": [
          "eng-Latn",
          "dob-Latn"
        ],
        "main_score": 0.0062499999999999995,
        "precision": 0.004144965277777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009765625,
        "hf_subset": "dob_Latn-eng_Latn",
        "languages": [
          "dob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.009114583333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002663352272727273,
        "hf_subset": "eng_Latn-dop_Latn",
        "languages": [
          "eng-Latn",
          "dop-Latn"
        ],
        "main_score": 0.002663352272727273,
        "precision": 0.0016927083333333334,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00026041666666666666,
        "hf_subset": "dop_Latn-eng_Latn",
        "languages": [
          "dop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00026041666666666666,
        "precision": 0.00013469827586206896,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013228748813837128,
        "hf_subset": "eng_Latn-dov_Latn",
        "languages": [
          "eng-Latn",
          "dov-Latn"
        ],
        "main_score": 0.013228748813837128,
        "precision": 0.01017104640151515,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00818452380952381,
        "hf_subset": "dov_Latn-eng_Latn",
        "languages": [
          "dov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00818452380952381,
        "precision": 0.0080078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00914248511904762,
        "hf_subset": "eng_Latn-dwr_Latn",
        "languages": [
          "eng-Latn",
          "dwr-Latn"
        ],
        "main_score": 0.00914248511904762,
        "precision": 0.00595999053030303,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003965435606060606,
        "hf_subset": "dwr_Latn-eng_Latn",
        "languages": [
          "dwr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003965435606060606,
        "precision": 0.0024739583333333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008754185267857144,
        "hf_subset": "eng_Latn-dww_Latn",
        "languages": [
          "eng-Latn",
          "dww-Latn"
        ],
        "main_score": 0.008754185267857144,
        "precision": 0.007078405191845321,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00661638331475288,
        "hf_subset": "dww_Latn-eng_Latn",
        "languages": [
          "dww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00661638331475288,
        "precision": 0.005600293347003873,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.07518796992481203,
        "f1": 0.034204559016589094,
        "hf_subset": "eng_Latn-dwy_Latn",
        "languages": [
          "eng-Latn",
          "dwy-Latn"
        ],
        "main_score": 0.034204559016589094,
        "precision": 0.027545296121147516,
        "recall": 0.07518796992481203
      },
      {
        "accuracy": 0.03007518796992481,
        "f1": 0.020188084891126896,
        "hf_subset": "dwy_Latn-eng_Latn",
        "languages": [
          "dwy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020188084891126896,
        "precision": 0.018866610971874132,
        "recall": 0.03007518796992481
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021330492424242425,
        "hf_subset": "eng_Latn-ebk_Latn",
        "languages": [
          "eng-Latn",
          "ebk-Latn"
        ],
        "main_score": 0.021330492424242425,
        "precision": 0.018155924479166665,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00234375,
        "hf_subset": "ebk_Latn-eng_Latn",
        "languages": [
          "ebk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00234375,
        "precision": 0.0015076754385964911,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0087859623015873,
        "hf_subset": "eng_Latn-eko_Latn",
        "languages": [
          "eng-Latn",
          "eko-Latn"
        ],
        "main_score": 0.0087859623015873,
        "precision": 0.006769788881461677,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003763163919413919,
        "hf_subset": "eko_Latn-eng_Latn",
        "languages": [
          "eko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003763163919413919,
        "precision": 0.002579126602564103,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019299635176651304,
        "hf_subset": "eng_Latn-emi_Latn",
        "languages": [
          "eng-Latn",
          "emi-Latn"
        ],
        "main_score": 0.019299635176651304,
        "precision": 0.0158603766025641,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016112637928194992,
        "hf_subset": "emi_Latn-eng_Latn",
        "languages": [
          "emi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016112637928194992,
        "precision": 0.014654178058783322,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0065800577090592335,
        "hf_subset": "eng_Latn-emp_Latn",
        "languages": [
          "eng-Latn",
          "emp-Latn"
        ],
        "main_score": 0.0065800577090592335,
        "precision": 0.004116492402882205,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002734375,
        "hf_subset": "emp_Latn-eng_Latn",
        "languages": [
          "emp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002734375,
        "precision": 0.001736111111111111,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002900965073529412,
        "hf_subset": "eng_Latn-enq_Latn",
        "languages": [
          "eng-Latn",
          "enq-Latn"
        ],
        "main_score": 0.002900965073529412,
        "precision": 0.0016206287202380951,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003720238095238095,
        "hf_subset": "enq_Latn-eng_Latn",
        "languages": [
          "enq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003720238095238095,
        "precision": 0.0026041666666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.058117287243500834,
        "hf_subset": "eng_Latn-epo_Latn",
        "languages": [
          "eng-Latn",
          "epo-Latn"
        ],
        "main_score": 0.058117287243500834,
        "precision": 0.050959055497198875,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07661178246442255,
        "hf_subset": "epo_Latn-eng_Latn",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07661178246442255,
        "precision": 0.06954520089285714,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010228447917025502,
        "hf_subset": "eng_Latn-eri_Latn",
        "languages": [
          "eng-Latn",
          "eri-Latn"
        ],
        "main_score": 0.010228447917025502,
        "precision": 0.006980613425925927,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015427714646464646,
        "hf_subset": "eri_Latn-eng_Latn",
        "languages": [
          "eri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015427714646464646,
        "precision": 0.0142822265625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0017127403846153846,
        "hf_subset": "eng_Latn-ese_Latn",
        "languages": [
          "eng-Latn",
          "ese-Latn"
        ],
        "main_score": 0.0017127403846153846,
        "precision": 0.001053155637254902,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0021721117424242423,
        "hf_subset": "ese_Latn-eng_Latn",
        "languages": [
          "ese-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0021721117424242423,
        "precision": 0.001260177203065134,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.0359414457070707,
        "hf_subset": "eng_Latn-esk_Latn",
        "languages": [
          "eng-Latn",
          "esk-Latn"
        ],
        "main_score": 0.0359414457070707,
        "precision": 0.028512788114698186,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03385416666666667,
        "hf_subset": "esk_Latn-eng_Latn",
        "languages": [
          "esk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03385416666666667,
        "precision": 0.0328125,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005823863636363637,
        "hf_subset": "eng_Latn-etr_Latn",
        "languages": [
          "eng-Latn",
          "etr-Latn"
        ],
        "main_score": 0.005823863636363637,
        "precision": 0.005068824404761905,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0019351893463570994,
        "hf_subset": "etr_Latn-eng_Latn",
        "languages": [
          "etr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019351893463570994,
        "precision": 0.0010805483217592594,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.024666078629032254,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ],
        "main_score": 0.024666078629032254,
        "precision": 0.021445900742775748,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011824324324324325,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011824324324324325,
        "precision": 0.010547007944780057,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "eng_Latn-faa_Latn",
        "languages": [
          "eng-Latn",
          "faa-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "faa_Latn-eng_Latn",
        "languages": [
          "faa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00546875,
        "hf_subset": "eng_Latn-fai_Latn",
        "languages": [
          "eng-Latn",
          "fai-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0037109375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0039590371621621625,
        "hf_subset": "fai_Latn-eng_Latn",
        "languages": [
          "fai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0039590371621621625,
        "precision": 0.003932823129251701,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02775015782828283,
        "hf_subset": "eng_Latn-far_Latn",
        "languages": [
          "eng-Latn",
          "far-Latn"
        ],
        "main_score": 0.02775015782828283,
        "precision": 0.02605251736111111,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0126953125,
        "hf_subset": "far_Latn-eng_Latn",
        "languages": [
          "far-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0126953125,
        "precision": 0.012276785714285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014987291930046354,
        "hf_subset": "eng_Latn-ffm_Latn",
        "languages": [
          "eng-Latn",
          "ffm-Latn"
        ],
        "main_score": 0.014987291930046354,
        "precision": 0.011536613343253968,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009241627546637212,
        "hf_subset": "ffm_Latn-eng_Latn",
        "languages": [
          "ffm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009241627546637212,
        "precision": 0.007409623254349816,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "eng_Latn-for_Latn",
        "languages": [
          "eng-Latn",
          "for-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "for_Latn-eng_Latn",
        "languages": [
          "for-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.28125,
        "f1": 0.20494119957010581,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ],
        "main_score": 0.20494119957010581,
        "precision": 0.1853733971553365,
        "recall": 0.28125
      },
      {
        "accuracy": 0.4296875,
        "f1": 0.35970390286796533,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.35970390286796533,
        "precision": 0.33397507440476193,
        "recall": 0.4296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03259186921296296,
        "hf_subset": "eng_Latn-fue_Latn",
        "languages": [
          "eng-Latn",
          "fue-Latn"
        ],
        "main_score": 0.03259186921296296,
        "precision": 0.027471244543854835,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018320980235042736,
        "hf_subset": "fue_Latn-eng_Latn",
        "languages": [
          "fue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018320980235042736,
        "precision": 0.016123071350250626,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007378472222222222,
        "hf_subset": "eng_Latn-fuf_Latn",
        "languages": [
          "eng-Latn",
          "fuf-Latn"
        ],
        "main_score": 0.007378472222222222,
        "precision": 0.00517578125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00033967391304347825,
        "hf_subset": "fuf_Latn-eng_Latn",
        "languages": [
          "fuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00033967391304347825,
        "precision": 0.0001775568181818182,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011863982371794871,
        "hf_subset": "eng_Latn-fuh_Latn",
        "languages": [
          "eng-Latn",
          "fuh-Latn"
        ],
        "main_score": 0.011863982371794871,
        "precision": 0.010321514423076921,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01578063622334456,
        "hf_subset": "fuh_Latn-eng_Latn",
        "languages": [
          "fuh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01578063622334456,
        "precision": 0.013460286458333331,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0033203125000000003,
        "hf_subset": "eng_Latn-gah_Latn",
        "languages": [
          "eng-Latn",
          "gah-Latn"
        ],
        "main_score": 0.0033203125000000003,
        "precision": 0.0020532852564102565,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005382719494047619,
        "hf_subset": "gah_Latn-eng_Latn",
        "languages": [
          "gah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005382719494047619,
        "precision": 0.004743086013645224,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004079861111111111,
        "hf_subset": "eng_Latn-gai_Latn",
        "languages": [
          "eng-Latn",
          "gai-Latn"
        ],
        "main_score": 0.004079861111111111,
        "precision": 0.0024216196895424837,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004924665178571428,
        "hf_subset": "gai_Latn-eng_Latn",
        "languages": [
          "gai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004924665178571428,
        "precision": 0.004447514315935369,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011500186011904761,
        "hf_subset": "eng_Latn-gam_Latn",
        "languages": [
          "eng-Latn",
          "gam-Latn"
        ],
        "main_score": 0.011500186011904761,
        "precision": 0.009157986111111112,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016821569683908046,
        "hf_subset": "gam_Latn-eng_Latn",
        "languages": [
          "gam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016821569683908046,
        "precision": 0.016294664853032263,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008385416666666666,
        "hf_subset": "eng_Latn-gaw_Latn",
        "languages": [
          "eng-Latn",
          "gaw-Latn"
        ],
        "main_score": 0.008385416666666666,
        "precision": 0.006998697916666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00803125,
        "hf_subset": "gaw_Latn-eng_Latn",
        "languages": [
          "gaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00803125,
        "precision": 0.007923721403884134,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008928571428571428,
        "hf_subset": "eng_Latn-gdn_Latn",
        "languages": [
          "eng-Latn",
          "gdn-Latn"
        ],
        "main_score": 0.008928571428571428,
        "precision": 0.007291666666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029166666666666664,
        "hf_subset": "gdn_Latn-eng_Latn",
        "languages": [
          "gdn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029166666666666664,
        "precision": 0.0021158854166666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010886548913043477,
        "hf_subset": "eng_Latn-gdr_Latn",
        "languages": [
          "eng-Latn",
          "gdr-Latn"
        ],
        "main_score": 0.010886548913043477,
        "precision": 0.008779198232323232,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00871975806451613,
        "hf_subset": "gdr_Latn-eng_Latn",
        "languages": [
          "gdr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00871975806451613,
        "precision": 0.006899974385245902,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015743371212121212,
        "hf_subset": "eng_Latn-geb_Latn",
        "languages": [
          "eng-Latn",
          "geb-Latn"
        ],
        "main_score": 0.015743371212121212,
        "precision": 0.012994123931623932,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "geb_Latn-eng_Latn",
        "languages": [
          "geb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0045138888888888885,
        "hf_subset": "eng_Latn-gfk_Latn",
        "languages": [
          "eng-Latn",
          "gfk-Latn"
        ],
        "main_score": 0.0045138888888888885,
        "precision": 0.0031075812381404174,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005570175438596491,
        "hf_subset": "gfk_Latn-eng_Latn",
        "languages": [
          "gfk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005570175438596491,
        "precision": 0.004872793712079426,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-ghs_Latn",
        "languages": [
          "eng-Latn",
          "ghs-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "ghs_Latn-eng_Latn",
        "languages": [
          "ghs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.021505376344086023,
        "f1": 0.0062561094819159335,
        "hf_subset": "eng_Latn-glk_Arab",
        "languages": [
          "eng-Latn",
          "glk-Arab"
        ],
        "main_score": 0.0062561094819159335,
        "precision": 0.0037634408602150535,
        "recall": 0.021505376344086023
      },
      {
        "accuracy": 0.010752688172043012,
        "f1": 0.0005812263876780006,
        "hf_subset": "glk_Arab-eng_Latn",
        "languages": [
          "glk-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0005812263876780006,
        "precision": 0.0002986857825567503,
        "recall": 0.010752688172043012
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010158456920903954,
        "hf_subset": "eng_Latn-gmv_Latn",
        "languages": [
          "eng-Latn",
          "gmv-Latn"
        ],
        "main_score": 0.010158456920903954,
        "precision": 0.008205369971264368,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002744607087827427,
        "hf_subset": "gmv_Latn-eng_Latn",
        "languages": [
          "gmv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002744607087827427,
        "precision": 0.00013968710089399744,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007170438218390804,
        "hf_subset": "eng_Latn-gng_Latn",
        "languages": [
          "eng-Latn",
          "gng-Latn"
        ],
        "main_score": 0.007170438218390804,
        "precision": 0.004902392700501253,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00048828125,
        "hf_subset": "gng_Latn-eng_Latn",
        "languages": [
          "gng-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00048828125,
        "precision": 0.00026041666666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0009563893779342722,
        "hf_subset": "eng_Latn-gnn_Latn",
        "languages": [
          "eng-Latn",
          "gnn-Latn"
        ],
        "main_score": 0.0009563893779342722,
        "precision": 0.0005110774642024642,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.852484472049689e-05,
        "hf_subset": "gnn_Latn-eng_Latn",
        "languages": [
          "gnn-Latn",
          "eng-Latn"
        ],
        "main_score": 4.852484472049689e-05,
        "precision": 2.44140625e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009552636745784337,
        "hf_subset": "eng_Latn-gnw_Latn",
        "languages": [
          "eng-Latn",
          "gnw-Latn"
        ],
        "main_score": 0.009552636745784337,
        "precision": 0.007274199695121952,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017838541666666666,
        "hf_subset": "gnw_Latn-eng_Latn",
        "languages": [
          "gnw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017838541666666666,
        "precision": 0.016114811912225704,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01013764880952381,
        "hf_subset": "eng_Latn-gof_Latn",
        "languages": [
          "eng-Latn",
          "gof-Latn"
        ],
        "main_score": 0.01013764880952381,
        "precision": 0.008138020833333332,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00011488970588235294,
        "hf_subset": "gof_Latn-eng_Latn",
        "languages": [
          "gof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00011488970588235294,
        "precision": 5.830223880597015e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019030448717948718,
        "hf_subset": "eng_Latn-grc_Grek",
        "languages": [
          "eng-Latn",
          "grc-Grek"
        ],
        "main_score": 0.0019030448717948718,
        "precision": 0.0011067708333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00016742310681767709,
        "hf_subset": "grc_Grek-eng_Latn",
        "languages": [
          "grc-Grek",
          "eng-Latn"
        ],
        "main_score": 0.00016742310681767709,
        "precision": 8.464871227592466e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009982638888888888,
        "hf_subset": "eng_Latn-gub_Latn",
        "languages": [
          "eng-Latn",
          "gub-Latn"
        ],
        "main_score": 0.009982638888888888,
        "precision": 0.008054315476190475,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006640625,
        "hf_subset": "gub_Latn-eng_Latn",
        "languages": [
          "gub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006640625,
        "precision": 0.005642361111111111,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013235047043010753,
        "hf_subset": "eng_Latn-guh_Latn",
        "languages": [
          "eng-Latn",
          "guh-Latn"
        ],
        "main_score": 0.013235047043010753,
        "precision": 0.011544195350241548,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004217728758169934,
        "hf_subset": "guh_Latn-eng_Latn",
        "languages": [
          "guh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004217728758169934,
        "precision": 0.0029553865131578946,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011867559523809523,
        "hf_subset": "eng_Latn-gui_Latn",
        "languages": [
          "eng-Latn",
          "gui-Latn"
        ],
        "main_score": 0.011867559523809523,
        "precision": 0.007812499999999999,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007817150297619048,
        "hf_subset": "gui_Latn-eng_Latn",
        "languages": [
          "gui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007817150297619048,
        "precision": 0.006147875816993465,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011272321428571428,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.011272321428571428,
        "precision": 0.009874131944444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00021701388888888888,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.00021701388888888888,
        "precision": 0.00011160714285714285,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.37109375,
        "f1": 0.29978894803113554,
        "hf_subset": "eng_Latn-gul_Latn",
        "languages": [
          "eng-Latn",
          "gul-Latn"
        ],
        "main_score": 0.29978894803113554,
        "precision": 0.2784688120039682,
        "recall": 0.37109375
      },
      {
        "accuracy": 0.35546875,
        "f1": 0.29635219381313127,
        "hf_subset": "gul_Latn-eng_Latn",
        "languages": [
          "gul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.29635219381313127,
        "precision": 0.2768676229369589,
        "recall": 0.35546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017737563775510203,
        "hf_subset": "eng_Latn-gum_Latn",
        "languages": [
          "eng-Latn",
          "gum-Latn"
        ],
        "main_score": 0.017737563775510203,
        "precision": 0.013753255208333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004740223795930317,
        "hf_subset": "gum_Latn-eng_Latn",
        "languages": [
          "gum-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004740223795930317,
        "precision": 0.004339515057857525,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006119791666666667,
        "hf_subset": "eng_Latn-gun_Latn",
        "languages": [
          "eng-Latn",
          "gun-Latn"
        ],
        "main_score": 0.006119791666666667,
        "precision": 0.004231770833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006102807971014492,
        "hf_subset": "gun_Latn-eng_Latn",
        "languages": [
          "gun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006102807971014492,
        "precision": 0.005219275210084033,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013226761664261665,
        "hf_subset": "eng_Latn-guo_Latn",
        "languages": [
          "eng-Latn",
          "guo-Latn"
        ],
        "main_score": 0.013226761664261665,
        "precision": 0.011169319509345795,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00929677960927961,
        "hf_subset": "guo_Latn-eng_Latn",
        "languages": [
          "guo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00929677960927961,
        "precision": 0.00790478515625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07002511160714285,
        "hf_subset": "eng_Latn-gup_Latn",
        "languages": [
          "eng-Latn",
          "gup-Latn"
        ],
        "main_score": 0.07002511160714285,
        "precision": 0.062174321910225434,
        "recall": 0.109375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.056125515109890105,
        "hf_subset": "gup_Latn-eng_Latn",
        "languages": [
          "gup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.056125515109890105,
        "precision": 0.05445725355691057,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007400730056980056,
        "hf_subset": "eng_Latn-gux_Latn",
        "languages": [
          "eng-Latn",
          "gux-Latn"
        ],
        "main_score": 0.007400730056980056,
        "precision": 0.006335136217948718,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011414930555555557,
        "hf_subset": "gux_Latn-eng_Latn",
        "languages": [
          "gux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011414930555555557,
        "precision": 0.010320113877118644,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006687973484848485,
        "hf_subset": "eng_Latn-gvc_Latn",
        "languages": [
          "eng-Latn",
          "gvc-Latn"
        ],
        "main_score": 0.006687973484848485,
        "precision": 0.005654289992952783,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001553683427834243,
        "hf_subset": "gvc_Latn-eng_Latn",
        "languages": [
          "gvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001553683427834243,
        "precision": 0.0008331526713879656,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010850694444444444,
        "hf_subset": "eng_Latn-gvf_Latn",
        "languages": [
          "eng-Latn",
          "gvf-Latn"
        ],
        "main_score": 0.010850694444444444,
        "precision": 0.0087890625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005669972625268881,
        "hf_subset": "gvf_Latn-eng_Latn",
        "languages": [
          "gvf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005669972625268881,
        "precision": 0.003513132974481659,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07506415025946275,
        "hf_subset": "eng_Latn-gvn_Latn",
        "languages": [
          "eng-Latn",
          "gvn-Latn"
        ],
        "main_score": 0.07506415025946275,
        "precision": 0.06764577932987711,
        "recall": 0.109375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0516506520068101,
        "hf_subset": "gvn_Latn-eng_Latn",
        "languages": [
          "gvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0516506520068101,
        "precision": 0.042896975440753146,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020104166666666666,
        "hf_subset": "eng_Latn-gvs_Latn",
        "languages": [
          "eng-Latn",
          "gvs-Latn"
        ],
        "main_score": 0.020104166666666666,
        "precision": 0.017415364583333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008329994658119658,
        "hf_subset": "gvs_Latn-eng_Latn",
        "languages": [
          "gvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008329994658119658,
        "precision": 0.008080357142857143,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.05123416080447331,
        "hf_subset": "eng_Latn-gwi_Latn",
        "languages": [
          "eng-Latn",
          "gwi-Latn"
        ],
        "main_score": 0.05123416080447331,
        "precision": 0.04335502975622933,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04546747104667363,
        "hf_subset": "gwi_Latn-eng_Latn",
        "languages": [
          "gwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04546747104667363,
        "precision": 0.0424544838808615,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021484627504848093,
        "hf_subset": "eng_Latn-gym_Latn",
        "languages": [
          "eng-Latn",
          "gym-Latn"
        ],
        "main_score": 0.021484627504848093,
        "precision": 0.01834309895833333,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0076491648274478324,
        "hf_subset": "gym_Latn-eng_Latn",
        "languages": [
          "gym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0076491648274478324,
        "precision": 0.006136279085497836,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01267361111111111,
        "hf_subset": "eng_Latn-gyr_Latn",
        "languages": [
          "eng-Latn",
          "gyr-Latn"
        ],
        "main_score": 0.01267361111111111,
        "precision": 0.010288431186868688,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005064498546511628,
        "hf_subset": "gyr_Latn-eng_Latn",
        "languages": [
          "gyr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005064498546511628,
        "precision": 0.003038194444444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022794646036833538,
        "hf_subset": "eng_Latn-hat_Latn",
        "languages": [
          "eng-Latn",
          "hat-Latn"
        ],
        "main_score": 0.022794646036833538,
        "precision": 0.018204776993839492,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03927951388888889,
        "hf_subset": "hat_Latn-eng_Latn",
        "languages": [
          "hat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03927951388888889,
        "precision": 0.0354788115530303,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01105800985166794,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ],
        "main_score": 0.01105800985166794,
        "precision": 0.008209765158512464,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019004216269841268,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019004216269841268,
        "precision": 0.0169900873655914,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01953125,
        "hf_subset": "eng_Latn-haw_Latn",
        "languages": [
          "eng-Latn",
          "haw-Latn"
        ],
        "main_score": 0.01953125,
        "precision": 0.016840277777777777,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "haw_Latn-eng_Latn",
        "languages": [
          "haw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004092261904761905,
        "hf_subset": "eng_Latn-hbo_Hebr",
        "languages": [
          "eng-Latn",
          "hbo-Hebr"
        ],
        "main_score": 0.004092261904761905,
        "precision": 0.0040015243902439025,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00042253521126760566,
        "hf_subset": "hbo_Hebr-eng_Latn",
        "languages": [
          "hbo-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.00042253521126760566,
        "precision": 0.00021856398809523808,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006921600877192982,
        "hf_subset": "eng_Latn-hch_Latn",
        "languages": [
          "eng-Latn",
          "hch-Latn"
        ],
        "main_score": 0.006921600877192982,
        "precision": 0.006076388888888889,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005601165254237288,
        "hf_subset": "hch_Latn-eng_Latn",
        "languages": [
          "hch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005601165254237288,
        "precision": 0.004950161637931034,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.300403225806451e-05,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ],
        "main_score": 6.300403225806451e-05,
        "precision": 3.1758130081300816e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00035350678733031673,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.00035350678733031673,
        "precision": 0.00018092105263157896,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016036184210526314,
        "hf_subset": "eng_Latn-heg_Latn",
        "languages": [
          "eng-Latn",
          "heg-Latn"
        ],
        "main_score": 0.016036184210526314,
        "precision": 0.01349826388888889,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008463541666666666,
        "hf_subset": "heg_Latn-eng_Latn",
        "languages": [
          "heg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008463541666666666,
        "precision": 0.007161458333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006119791666666667,
        "hf_subset": "eng_Latn-hix_Latn",
        "languages": [
          "eng-Latn",
          "hix-Latn"
        ],
        "main_score": 0.006119791666666667,
        "precision": 0.004123263888888889,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002269639328063241,
        "hf_subset": "hix_Latn-eng_Latn",
        "languages": [
          "hix-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002269639328063241,
        "precision": 0.00011526378713878714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010374758846226238,
        "hf_subset": "eng_Latn-hla_Latn",
        "languages": [
          "eng-Latn",
          "hla-Latn"
        ],
        "main_score": 0.010374758846226238,
        "precision": 0.009252206127206127,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004544890873015873,
        "hf_subset": "hla_Latn-eng_Latn",
        "languages": [
          "hla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004544890873015873,
        "precision": 0.002661520337301587,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028678255500200464,
        "hf_subset": "eng_Latn-hlt_Latn",
        "languages": [
          "eng-Latn",
          "hlt-Latn"
        ],
        "main_score": 0.028678255500200464,
        "precision": 0.02532425257034632,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01959128111471861,
        "hf_subset": "hlt_Latn-eng_Latn",
        "languages": [
          "hlt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01959128111471861,
        "precision": 0.017293989828169515,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03153239989177489,
        "hf_subset": "eng_Latn-hmo_Latn",
        "languages": [
          "eng-Latn",
          "hmo-Latn"
        ],
        "main_score": 0.03153239989177489,
        "precision": 0.026547181372549022,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023090277777777776,
        "hf_subset": "hmo_Latn-eng_Latn",
        "languages": [
          "hmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023090277777777776,
        "precision": 0.020872290187626777,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011480034722222221,
        "hf_subset": "eng_Latn-hns_Latn",
        "languages": [
          "eng-Latn",
          "hns-Latn"
        ],
        "main_score": 0.011480034722222221,
        "precision": 0.009182191506410257,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012178308823529412,
        "hf_subset": "hns_Latn-eng_Latn",
        "languages": [
          "hns-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012178308823529412,
        "precision": 0.011962890625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03553847446236559,
        "hf_subset": "eng_Latn-hop_Latn",
        "languages": [
          "eng-Latn",
          "hop-Latn"
        ],
        "main_score": 0.03553847446236559,
        "precision": 0.03036473299808429,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.0336921541999667,
        "hf_subset": "hop_Latn-eng_Latn",
        "languages": [
          "hop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0336921541999667,
        "precision": 0.03258704981361231,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00572089947089947,
        "hf_subset": "eng_Latn-hot_Latn",
        "languages": [
          "eng-Latn",
          "hot-Latn"
        ],
        "main_score": 0.00572089947089947,
        "precision": 0.004952630090497737,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0018934461805555556,
        "hf_subset": "hot_Latn-eng_Latn",
        "languages": [
          "hot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0018934461805555556,
        "precision": 0.0010708845743486073,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01949122925685426,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ],
        "main_score": 0.01949122925685426,
        "precision": 0.016503906250000002,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006971459853321173,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006971459853321173,
        "precision": 0.005820695465686274,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008053558538141284,
        "hf_subset": "eng_Latn-hto_Latn",
        "languages": [
          "eng-Latn",
          "hto-Latn"
        ],
        "main_score": 0.008053558538141284,
        "precision": 0.006715804811507936,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014417049963924962,
        "hf_subset": "hto_Latn-eng_Latn",
        "languages": [
          "hto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014417049963924962,
        "precision": 0.011094037224264705,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011720956920903955,
        "hf_subset": "eng_Latn-hub_Latn",
        "languages": [
          "eng-Latn",
          "hub-Latn"
        ],
        "main_score": 0.011720956920903955,
        "precision": 0.008010057471264367,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0021117424242424244,
        "hf_subset": "hub_Latn-eng_Latn",
        "languages": [
          "hub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0021117424242424244,
        "precision": 0.0012613932291666665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007576407967032967,
        "hf_subset": "eng_Latn-hui_Latn",
        "languages": [
          "eng-Latn",
          "hui-Latn"
        ],
        "main_score": 0.007576407967032967,
        "precision": 0.005013020833333334,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00594284188034188,
        "hf_subset": "hui_Latn-eng_Latn",
        "languages": [
          "hui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00594284188034188,
        "precision": 0.005127840909090909,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022743055555555558,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ],
        "main_score": 0.022743055555555558,
        "precision": 0.017433965773809526,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017838541666666666,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017838541666666666,
        "precision": 0.015784801136363637,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0023175445492662474,
        "hf_subset": "eng_Latn-hus_Latn",
        "languages": [
          "eng-Latn",
          "hus-Latn"
        ],
        "main_score": 0.0023175445492662474,
        "precision": 0.0014888106684981684,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006672942219817219,
        "hf_subset": "hus_Latn-eng_Latn",
        "languages": [
          "hus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006672942219817219,
        "precision": 0.004447115384615384,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01998096113445378,
        "hf_subset": "eng_Latn-huu_Latn",
        "languages": [
          "eng-Latn",
          "huu-Latn"
        ],
        "main_score": 0.01998096113445378,
        "precision": 0.016334343905472636,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029241971486175113,
        "hf_subset": "huu_Latn-eng_Latn",
        "languages": [
          "huu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029241971486175113,
        "precision": 0.024982377819548873,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01865079365079365,
        "hf_subset": "eng_Latn-huv_Latn",
        "languages": [
          "eng-Latn",
          "huv-Latn"
        ],
        "main_score": 0.01865079365079365,
        "precision": 0.016318873355263157,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01002288593256059,
        "hf_subset": "huv_Latn-eng_Latn",
        "languages": [
          "huv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01002288593256059,
        "precision": 0.009245429942810458,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.031746031746031744,
        "f1": 0.013125763125763124,
        "hf_subset": "eng_Latn-hvn_Latn",
        "languages": [
          "eng-Latn",
          "hvn-Latn"
        ],
        "main_score": 0.013125763125763124,
        "precision": 0.010906685906685906,
        "recall": 0.031746031746031744
      },
      {
        "accuracy": 0.023809523809523808,
        "f1": 0.002399848828420257,
        "hf_subset": "hvn_Latn-eng_Latn",
        "languages": [
          "hvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002399848828420257,
        "precision": 0.0012998070469334838,
        "recall": 0.023809523809523808
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0022135416666666666,
        "hf_subset": "eng_Latn-ian_Latn",
        "languages": [
          "eng-Latn",
          "ian-Latn"
        ],
        "main_score": 0.0022135416666666666,
        "precision": 0.0014367816091954023,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 9.412650602409639e-05,
        "hf_subset": "ian_Latn-eng_Latn",
        "languages": [
          "ian-Latn",
          "eng-Latn"
        ],
        "main_score": 9.412650602409639e-05,
        "precision": 4.763719512195122e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010881696428571428,
        "hf_subset": "eng_Latn-ign_Latn",
        "languages": [
          "eng-Latn",
          "ign-Latn"
        ],
        "main_score": 0.010881696428571428,
        "precision": 0.00859375,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001201923076923077,
        "hf_subset": "ign_Latn-eng_Latn",
        "languages": [
          "ign-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001201923076923077,
        "precision": 6.103515625e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005096726190476191,
        "hf_subset": "eng_Latn-ikk_Latn",
        "languages": [
          "eng-Latn",
          "ikk-Latn"
        ],
        "main_score": 0.005096726190476191,
        "precision": 0.0029992816091954024,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008118872549019607,
        "hf_subset": "ikk_Latn-eng_Latn",
        "languages": [
          "ikk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008118872549019607,
        "precision": 0.006796875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008696546052631579,
        "hf_subset": "eng_Latn-ikw_Latn",
        "languages": [
          "eng-Latn",
          "ikw-Latn"
        ],
        "main_score": 0.008696546052631579,
        "precision": 0.005716145833333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ikw_Latn-eng_Latn",
        "languages": [
          "ikw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.011924342105263159,
        "hf_subset": "eng_Latn-ilo_Latn",
        "languages": [
          "eng-Latn",
          "ilo-Latn"
        ],
        "main_score": 0.011924342105263159,
        "precision": 0.007962134719947219,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011825433298319327,
        "hf_subset": "ilo_Latn-eng_Latn",
        "languages": [
          "ilo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011825433298319327,
        "precision": 0.009099702380952382,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006119791666666667,
        "hf_subset": "eng_Latn-imo_Latn",
        "languages": [
          "eng-Latn",
          "imo-Latn"
        ],
        "main_score": 0.006119791666666667,
        "precision": 0.005224199054621848,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012433035714285714,
        "hf_subset": "imo_Latn-eng_Latn",
        "languages": [
          "imo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012433035714285714,
        "precision": 0.01209895015698587,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012313988095238095,
        "hf_subset": "eng_Latn-inb_Latn",
        "languages": [
          "eng-Latn",
          "inb-Latn"
        ],
        "main_score": 0.012313988095238095,
        "precision": 0.010850694444444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0033854166666666668,
        "hf_subset": "inb_Latn-eng_Latn",
        "languages": [
          "inb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0033854166666666668,
        "precision": 0.002387152777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01895594175170068,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ],
        "main_score": 0.01895594175170068,
        "precision": 0.014991925392316016,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028921274038461536,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028921274038461536,
        "precision": 0.025753348214285716,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00041118421052631577,
        "hf_subset": "eng_Latn-ino_Latn",
        "languages": [
          "eng-Latn",
          "ino-Latn"
        ],
        "main_score": 0.00041118421052631577,
        "precision": 0.00021701388888888888,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.201844262295082e-05,
        "hf_subset": "ino_Latn-eng_Latn",
        "languages": [
          "ino-Latn",
          "eng-Latn"
        ],
        "main_score": 3.201844262295082e-05,
        "precision": 1.6075102880658438e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006673177083333333,
        "hf_subset": "eng_Latn-iou_Latn",
        "languages": [
          "eng-Latn",
          "iou-Latn"
        ],
        "main_score": 0.006673177083333333,
        "precision": 0.0055059523809523805,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004022854477611941,
        "hf_subset": "iou_Latn-eng_Latn",
        "languages": [
          "iou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004022854477611941,
        "precision": 0.003965435606060606,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003444602272727273,
        "hf_subset": "eng_Latn-ipi_Latn",
        "languages": [
          "eng-Latn",
          "ipi-Latn"
        ],
        "main_score": 0.003444602272727273,
        "precision": 0.0021267361111111114,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.314625850340136e-05,
        "hf_subset": "ipi_Latn-eng_Latn",
        "languages": [
          "ipi-Latn",
          "eng-Latn"
        ],
        "main_score": 5.314625850340136e-05,
        "precision": 2.675513698630137e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007413474462365591,
        "hf_subset": "eng_Latn-isn_Latn",
        "languages": [
          "eng-Latn",
          "isn-Latn"
        ],
        "main_score": 0.007413474462365591,
        "precision": 0.006119791666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010286458333333333,
        "hf_subset": "isn_Latn-eng_Latn",
        "languages": [
          "isn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010286458333333333,
        "precision": 0.00939360119047619,
        "recall": 0.015625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06508802973646723,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ],
        "main_score": 0.06508802973646723,
        "precision": 0.05400117631819934,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08759920634920634,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08759920634920634,
        "precision": 0.07958531970480501,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009799770541958042,
        "hf_subset": "eng_Latn-iws_Latn",
        "languages": [
          "eng-Latn",
          "iws-Latn"
        ],
        "main_score": 0.009799770541958042,
        "precision": 0.007745535714285714,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "iws_Latn-eng_Latn",
        "languages": [
          "iws-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0046875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010837996981089084,
        "hf_subset": "eng_Latn-ixl_Latn",
        "languages": [
          "eng-Latn",
          "ixl-Latn"
        ],
        "main_score": 0.010837996981089084,
        "precision": 0.008719856580433071,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001494057158119658,
        "hf_subset": "ixl_Latn-eng_Latn",
        "languages": [
          "ixl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001494057158119658,
        "precision": 0.0008143682065217392,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015234375,
        "hf_subset": "eng_Latn-jac_Latn",
        "languages": [
          "eng-Latn",
          "jac-Latn"
        ],
        "main_score": 0.015234375,
        "precision": 0.013831676136363637,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014646464646464645,
        "hf_subset": "jac_Latn-eng_Latn",
        "languages": [
          "jac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014646464646464645,
        "precision": 0.0123291015625,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01636532738095238,
        "hf_subset": "eng_Latn-jae_Latn",
        "languages": [
          "eng-Latn",
          "jae-Latn"
        ],
        "main_score": 0.01636532738095238,
        "precision": 0.014415533894478843,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009895833333333333,
        "hf_subset": "jae_Latn-eng_Latn",
        "languages": [
          "jae-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009895833333333333,
        "precision": 0.009027777777777777,
        "recall": 0.015625
      },
      {
        "accuracy": 0.031496062992125984,
        "f1": 0.017497812773403325,
        "hf_subset": "eng_Latn-jao_Latn",
        "languages": [
          "eng-Latn",
          "jao-Latn"
        ],
        "main_score": 0.017497812773403325,
        "precision": 0.014107611548556429,
        "recall": 0.031496062992125984
      },
      {
        "accuracy": 0.007874015748031496,
        "f1": 0.00034234851078397807,
        "hf_subset": "jao_Latn-eng_Latn",
        "languages": [
          "jao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00034234851078397807,
        "precision": 0.00017497812773403326,
        "recall": 0.007874015748031496
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017139771363971944,
        "hf_subset": "eng_Latn-jic_Latn",
        "languages": [
          "eng-Latn",
          "jic-Latn"
        ],
        "main_score": 0.017139771363971944,
        "precision": 0.013081287202380953,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0042706695492662474,
        "hf_subset": "jic_Latn-eng_Latn",
        "languages": [
          "jic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0042706695492662474,
        "precision": 0.0040929773351648345,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.018312026515151514,
        "hf_subset": "eng_Latn-jid_Latn",
        "languages": [
          "eng-Latn",
          "jid-Latn"
        ],
        "main_score": 0.018312026515151514,
        "precision": 0.013556950861638361,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018424479166666667,
        "hf_subset": "jid_Latn-eng_Latn",
        "languages": [
          "jid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018424479166666667,
        "precision": 0.017678285256410256,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004600694444444444,
        "hf_subset": "eng_Latn-jiv_Latn",
        "languages": [
          "eng-Latn",
          "jiv-Latn"
        ],
        "main_score": 0.004600694444444444,
        "precision": 0.003159466911764706,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015943877551020409,
        "hf_subset": "jiv_Latn-eng_Latn",
        "languages": [
          "jiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015943877551020409,
        "precision": 0.0009925717213114754,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009018085062582344,
        "hf_subset": "eng_Latn-jni_Latn",
        "languages": [
          "eng-Latn",
          "jni-Latn"
        ],
        "main_score": 0.009018085062582344,
        "precision": 0.006243799603174603,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009765625,
        "hf_subset": "jni_Latn-eng_Latn",
        "languages": [
          "jni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.009114583333333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028171502976190477,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ],
        "main_score": 0.028171502976190477,
        "precision": 0.023449662316849813,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.027745503917378914,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.027745503917378914,
        "precision": 0.02218090769129979,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016248421717171717,
        "hf_subset": "eng_Latn-jvn_Latn",
        "languages": [
          "eng-Latn",
          "jvn-Latn"
        ],
        "main_score": 0.016248421717171717,
        "precision": 0.01229265143557423,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010633680555555556,
        "hf_subset": "jvn_Latn-eng_Latn",
        "languages": [
          "jvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010633680555555556,
        "precision": 0.009602864583333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002904647435897436,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.002904647435897436,
        "precision": 0.002109375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00041134822497008376,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.00041134822497008376,
        "precision": 0.00021372579966329967,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019700351731601732,
        "hf_subset": "eng_Latn-kaq_Latn",
        "languages": [
          "eng-Latn",
          "kaq-Latn"
        ],
        "main_score": 0.019700351731601732,
        "precision": 0.017175099206349208,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014569894195716564,
        "hf_subset": "kaq_Latn-eng_Latn",
        "languages": [
          "kaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014569894195716564,
        "precision": 0.012301199776785714,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006438948934837093,
        "hf_subset": "eng_Latn-kbc_Latn",
        "languages": [
          "eng-Latn",
          "kbc-Latn"
        ],
        "main_score": 0.006438948934837093,
        "precision": 0.00421486066017316,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0053741550744514106,
        "hf_subset": "kbc_Latn-eng_Latn",
        "languages": [
          "kbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0053741550744514106,
        "precision": 0.004686120379190034,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01489955357142857,
        "hf_subset": "eng_Latn-kbh_Latn",
        "languages": [
          "eng-Latn",
          "kbh-Latn"
        ],
        "main_score": 0.01489955357142857,
        "precision": 0.011626603304385317,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008388744784804567,
        "hf_subset": "kbh_Latn-eng_Latn",
        "languages": [
          "kbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008388744784804567,
        "precision": 0.006644907627029306,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021363027793084445,
        "hf_subset": "eng_Latn-kbm_Latn",
        "languages": [
          "eng-Latn",
          "kbm-Latn"
        ],
        "main_score": 0.021363027793084445,
        "precision": 0.019254557291666665,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.8125e-05,
        "hf_subset": "kbm_Latn-eng_Latn",
        "languages": [
          "kbm-Latn",
          "eng-Latn"
        ],
        "main_score": 7.8125e-05,
        "precision": 3.945707070707071e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016065777013556617,
        "hf_subset": "eng_Latn-kbq_Latn",
        "languages": [
          "eng-Latn",
          "kbq-Latn"
        ],
        "main_score": 0.016065777013556617,
        "precision": 0.014599851386536168,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018953222352024922,
        "hf_subset": "kbq_Latn-eng_Latn",
        "languages": [
          "kbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018953222352024922,
        "precision": 0.01774518474842767,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00302734375,
        "hf_subset": "eng_Latn-kdc_Latn",
        "languages": [
          "eng-Latn",
          "kdc-Latn"
        ],
        "main_score": 0.00302734375,
        "precision": 0.0017950148809523809,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000390625,
        "hf_subset": "kdc_Latn-eng_Latn",
        "languages": [
          "kdc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000390625,
        "precision": 0.00020559210526315788,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005673363095238095,
        "hf_subset": "eng_Latn-kde_Latn",
        "languages": [
          "eng-Latn",
          "kde-Latn"
        ],
        "main_score": 0.005673363095238095,
        "precision": 0.00390625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005558548850574712,
        "hf_subset": "kde_Latn-eng_Latn",
        "languages": [
          "kde-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005558548850574712,
        "precision": 0.004928234011627907,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "eng_Latn-kdl_Latn",
        "languages": [
          "eng-Latn",
          "kdl-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006655092592592592,
        "hf_subset": "kdl_Latn-eng_Latn",
        "languages": [
          "kdl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006655092592592592,
        "precision": 0.005933077830188679,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019534632034632033,
        "hf_subset": "eng_Latn-kek_Latn",
        "languages": [
          "eng-Latn",
          "kek-Latn"
        ],
        "main_score": 0.019534632034632033,
        "precision": 0.015969122023809523,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011540938620071686,
        "hf_subset": "kek_Latn-eng_Latn",
        "languages": [
          "kek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011540938620071686,
        "precision": 0.010100929246357013,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0030597976370035193,
        "hf_subset": "eng_Latn-ken_Latn",
        "languages": [
          "eng-Latn",
          "ken-Latn"
        ],
        "main_score": 0.0030597976370035193,
        "precision": 0.0017348391397527911,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.87784090909091e-05,
        "hf_subset": "ken_Latn-eng_Latn",
        "languages": [
          "ken-Latn",
          "eng-Latn"
        ],
        "main_score": 8.87784090909091e-05,
        "precision": 4.489942528735632e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021176495295698924,
        "hf_subset": "eng_Latn-kew_Latn",
        "languages": [
          "eng-Latn",
          "kew-Latn"
        ],
        "main_score": 0.021176495295698924,
        "precision": 0.019131828377902886,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015234375,
        "hf_subset": "kew_Latn-eng_Latn",
        "languages": [
          "kew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015234375,
        "precision": 0.012044270833333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0125,
        "hf_subset": "eng_Latn-kgf_Latn",
        "languages": [
          "eng-Latn",
          "kgf-Latn"
        ],
        "main_score": 0.0125,
        "precision": 0.010980902777777777,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0021630929834054835,
        "hf_subset": "kgf_Latn-eng_Latn",
        "languages": [
          "kgf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0021630929834054835,
        "precision": 0.0014084989652829254,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01210097446236559,
        "hf_subset": "eng_Latn-kgk_Latn",
        "languages": [
          "eng-Latn",
          "kgk-Latn"
        ],
        "main_score": 0.01210097446236559,
        "precision": 0.01044141214177979,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004107481060606061,
        "hf_subset": "kgk_Latn-eng_Latn",
        "languages": [
          "kgk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004107481060606061,
        "precision": 0.004008294783081946,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010440057237716849,
        "hf_subset": "eng_Latn-kgp_Latn",
        "languages": [
          "eng-Latn",
          "kgp-Latn"
        ],
        "main_score": 0.010440057237716849,
        "precision": 0.00785836884469697,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0040211397058823525,
        "hf_subset": "kgp_Latn-eng_Latn",
        "languages": [
          "kgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0040211397058823525,
        "precision": 0.00396455223880597,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004557291666666666,
        "hf_subset": "eng_Latn-khs_Latn",
        "languages": [
          "eng-Latn",
          "khs-Latn"
        ],
        "main_score": 0.004557291666666666,
        "precision": 0.003255208333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013020833333333333,
        "hf_subset": "khs_Latn-eng_Latn",
        "languages": [
          "khs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00013020833333333333,
        "precision": 6.620762711864407e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006845238095238095,
        "hf_subset": "eng_Latn-khz_Latn",
        "languages": [
          "eng-Latn",
          "khz-Latn"
        ],
        "main_score": 0.006845238095238095,
        "precision": 0.004265396062271063,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011524438222807788,
        "hf_subset": "khz_Latn-eng_Latn",
        "languages": [
          "khz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011524438222807788,
        "precision": 0.010052206652043363,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015104166666666665,
        "hf_subset": "eng_Latn-kik_Latn",
        "languages": [
          "eng-Latn",
          "kik-Latn"
        ],
        "main_score": 0.015104166666666665,
        "precision": 0.01151201571637427,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "kik_Latn-eng_Latn",
        "languages": [
          "kik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.07228915662650602,
        "f1": 0.04039013195639701,
        "hf_subset": "eng_Latn-kiw_Latn",
        "languages": [
          "eng-Latn",
          "kiw-Latn"
        ],
        "main_score": 0.04039013195639701,
        "precision": 0.02911646586345382,
        "recall": 0.07228915662650602
      },
      {
        "accuracy": 0.07228915662650602,
        "f1": 0.025254263808480677,
        "hf_subset": "kiw_Latn-eng_Latn",
        "languages": [
          "kiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025254263808480677,
        "precision": 0.017202141900937083,
        "recall": 0.07228915662650602
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02893288352272727,
        "hf_subset": "eng_Latn-kiz_Latn",
        "languages": [
          "eng-Latn",
          "kiz-Latn"
        ],
        "main_score": 0.02893288352272727,
        "precision": 0.023546006944444444,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0013511029411764706,
        "hf_subset": "kiz_Latn-eng_Latn",
        "languages": [
          "kiz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013511029411764706,
        "precision": 0.0007277003566066065,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010822017609126983,
        "hf_subset": "eng_Latn-kje_Latn",
        "languages": [
          "eng-Latn",
          "kje-Latn"
        ],
        "main_score": 0.010822017609126983,
        "precision": 0.00703790042562724,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01404389880952381,
        "hf_subset": "kje_Latn-eng_Latn",
        "languages": [
          "kje-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01404389880952381,
        "precision": 0.013216145833333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01127660352080715,
        "hf_subset": "eng_Latn-kjs_Latn",
        "languages": [
          "eng-Latn",
          "kjs-Latn"
        ],
        "main_score": 0.01127660352080715,
        "precision": 0.008673128342245989,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017466517857142858,
        "hf_subset": "kjs_Latn-eng_Latn",
        "languages": [
          "kjs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017466517857142858,
        "precision": 0.015299479166666664,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008408073251823252,
        "hf_subset": "eng_Latn-kkc_Latn",
        "languages": [
          "eng-Latn",
          "kkc-Latn"
        ],
        "main_score": 0.008408073251823252,
        "precision": 0.0070074484767025085,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018722098214285714,
        "hf_subset": "kkc_Latn-eng_Latn",
        "languages": [
          "kkc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018722098214285714,
        "precision": 0.017460078983516484,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029599552266081873,
        "hf_subset": "eng_Latn-kkl_Latn",
        "languages": [
          "eng-Latn",
          "kkl-Latn"
        ],
        "main_score": 0.029599552266081873,
        "precision": 0.025413876488095236,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.0259765625,
        "hf_subset": "kkl_Latn-eng_Latn",
        "languages": [
          "kkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0259765625,
        "precision": 0.02261453823953824,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021801549145299144,
        "hf_subset": "eng_Latn-klt_Latn",
        "languages": [
          "eng-Latn",
          "klt-Latn"
        ],
        "main_score": 0.021801549145299144,
        "precision": 0.019616447431245226,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012040682414698162,
        "hf_subset": "klt_Latn-eng_Latn",
        "languages": [
          "klt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012040682414698162,
        "precision": 0.010773189484126984,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005868354885057471,
        "hf_subset": "eng_Latn-klv_Latn",
        "languages": [
          "eng-Latn",
          "klv-Latn"
        ],
        "main_score": 0.005868354885057471,
        "precision": 0.004251351033834587,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "klv_Latn-eng_Latn",
        "languages": [
          "klv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014574196822373695,
        "hf_subset": "eng_Latn-kmg_Latn",
        "languages": [
          "eng-Latn",
          "kmg-Latn"
        ],
        "main_score": 0.014574196822373695,
        "precision": 0.011461759868421052,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01071309840425532,
        "hf_subset": "kmg_Latn-eng_Latn",
        "languages": [
          "kmg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01071309840425532,
        "precision": 0.009916751105379514,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007010206228956228,
        "hf_subset": "eng_Latn-kmh_Latn",
        "languages": [
          "eng-Latn",
          "kmh-Latn"
        ],
        "main_score": 0.007010206228956228,
        "precision": 0.006119089734950584,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005222641941391941,
        "hf_subset": "kmh_Latn-eng_Latn",
        "languages": [
          "kmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005222641941391941,
        "precision": 0.00027190563725490197,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01186474116161616,
        "hf_subset": "eng_Latn-kmk_Latn",
        "languages": [
          "eng-Latn",
          "kmk-Latn"
        ],
        "main_score": 0.01186474116161616,
        "precision": 0.00831938244047619,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003305993401759531,
        "hf_subset": "kmk_Latn-eng_Latn",
        "languages": [
          "kmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003305993401759531,
        "precision": 0.0019314236111111112,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024386935763888888,
        "hf_subset": "eng_Latn-kmo_Latn",
        "languages": [
          "eng-Latn",
          "kmo-Latn"
        ],
        "main_score": 0.024386935763888888,
        "precision": 0.021708039314516127,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0036151960784313727,
        "hf_subset": "kmo_Latn-eng_Latn",
        "languages": [
          "kmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0036151960784313727,
        "precision": 0.00250552398989899,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01665678756550467,
        "hf_subset": "eng_Latn-kms_Latn",
        "languages": [
          "eng-Latn",
          "kms-Latn"
        ],
        "main_score": 0.01665678756550467,
        "precision": 0.012065972222222221,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01651141826923077,
        "hf_subset": "kms_Latn-eng_Latn",
        "languages": [
          "kms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01651141826923077,
        "precision": 0.01497452445652174,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005568910256410256,
        "hf_subset": "eng_Latn-kmu_Latn",
        "languages": [
          "eng-Latn",
          "kmu-Latn"
        ],
        "main_score": 0.005568910256410256,
        "precision": 0.004933543019480519,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003939636752136752,
        "hf_subset": "kmu_Latn-eng_Latn",
        "languages": [
          "kmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003939636752136752,
        "precision": 0.003923015021459228,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.0287109375,
        "hf_subset": "eng_Latn-kne_Latn",
        "languages": [
          "eng-Latn",
          "kne-Latn"
        ],
        "main_score": 0.0287109375,
        "precision": 0.023680294486215538,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017254849137931034,
        "hf_subset": "kne_Latn-eng_Latn",
        "languages": [
          "kne-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017254849137931034,
        "precision": 0.016635529891304346,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004427083333333333,
        "hf_subset": "eng_Latn-knf_Latn",
        "languages": [
          "eng-Latn",
          "knf-Latn"
        ],
        "main_score": 0.004427083333333333,
        "precision": 0.002734375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0014169730392156862,
        "hf_subset": "knf_Latn-eng_Latn",
        "languages": [
          "knf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0014169730392156862,
        "precision": 0.0008395522388059701,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004282501352813853,
        "hf_subset": "eng_Latn-knj_Latn",
        "languages": [
          "eng-Latn",
          "knj-Latn"
        ],
        "main_score": 0.004282501352813853,
        "precision": 0.0026669000933706817,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011408253205128204,
        "hf_subset": "knj_Latn-eng_Latn",
        "languages": [
          "knj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011408253205128204,
        "precision": 0.01029673793859649,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005477855477855478,
        "hf_subset": "eng_Latn-knv_Latn",
        "languages": [
          "eng-Latn",
          "knv-Latn"
        ],
        "main_score": 0.005477855477855478,
        "precision": 0.0036458333333333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "knv_Latn-eng_Latn",
        "languages": [
          "knv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0679015246449457,
        "hf_subset": "eng_Latn-kos_Latn",
        "languages": [
          "eng-Latn",
          "kos-Latn"
        ],
        "main_score": 0.0679015246449457,
        "precision": 0.05772276182432432,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05749396160485577,
        "hf_subset": "kos_Latn-eng_Latn",
        "languages": [
          "kos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05749396160485577,
        "precision": 0.054789978780864196,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006882440476190476,
        "hf_subset": "eng_Latn-kpf_Latn",
        "languages": [
          "eng-Latn",
          "kpf-Latn"
        ],
        "main_score": 0.006882440476190476,
        "precision": 0.0060546875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009434637404580153,
        "hf_subset": "kpf_Latn-eng_Latn",
        "languages": [
          "kpf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009434637404580153,
        "precision": 0.008758496352785146,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06343454946633825,
        "hf_subset": "eng_Latn-kpg_Latn",
        "languages": [
          "eng-Latn",
          "kpg-Latn"
        ],
        "main_score": 0.06343454946633825,
        "precision": 0.05475603070175438,
        "recall": 0.09375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.0556843570761638,
        "hf_subset": "kpg_Latn-eng_Latn",
        "languages": [
          "kpg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0556843570761638,
        "precision": 0.053690003743971676,
        "recall": 0.078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0059225063131313135,
        "hf_subset": "eng_Latn-kpj_Latn",
        "languages": [
          "eng-Latn",
          "kpj-Latn"
        ],
        "main_score": 0.0059225063131313135,
        "precision": 0.003899436773255814,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008330799425033172,
        "hf_subset": "kpj_Latn-eng_Latn",
        "languages": [
          "kpj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008330799425033172,
        "precision": 0.008086233428030304,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019487510604538256,
        "hf_subset": "eng_Latn-kpr_Latn",
        "languages": [
          "eng-Latn",
          "kpr-Latn"
        ],
        "main_score": 0.019487510604538256,
        "precision": 0.015367753990800866,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02058531746031746,
        "hf_subset": "kpr_Latn-eng_Latn",
        "languages": [
          "kpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02058531746031746,
        "precision": 0.018920885180995474,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015438988095238094,
        "hf_subset": "eng_Latn-kpw_Latn",
        "languages": [
          "eng-Latn",
          "kpw-Latn"
        ],
        "main_score": 0.015438988095238094,
        "precision": 0.014322916666666668,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006865530303030302,
        "hf_subset": "kpw_Latn-eng_Latn",
        "languages": [
          "kpw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006865530303030302,
        "precision": 0.006045386904761905,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006009615384615385,
        "hf_subset": "eng_Latn-kpx_Latn",
        "languages": [
          "eng-Latn",
          "kpx-Latn"
        ],
        "main_score": 0.0006009615384615385,
        "precision": 0.0003255208333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005208333333333333,
        "hf_subset": "kpx_Latn-eng_Latn",
        "languages": [
          "kpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005208333333333333,
        "precision": 0.00027901785714285713,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.06349206349206349,
        "f1": 0.027513227513227514,
        "hf_subset": "eng_Latn-kqa_Latn",
        "languages": [
          "eng-Latn",
          "kqa-Latn"
        ],
        "main_score": 0.027513227513227514,
        "precision": 0.01825396825396825,
        "recall": 0.06349206349206349
      },
      {
        "accuracy": 0.031746031746031744,
        "f1": 0.02222222222222222,
        "hf_subset": "kqa_Latn-eng_Latn",
        "languages": [
          "kqa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02222222222222222,
        "precision": 0.01984126984126984,
        "recall": 0.031746031746031744
      },
      {
        "accuracy": 0.09375,
        "f1": 0.05119782880008064,
        "hf_subset": "eng_Latn-kqc_Latn",
        "languages": [
          "eng-Latn",
          "kqc-Latn"
        ],
        "main_score": 0.05119782880008064,
        "precision": 0.04370858633553946,
        "recall": 0.09375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.030753582980234867,
        "hf_subset": "kqc_Latn-eng_Latn",
        "languages": [
          "kqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030753582980234867,
        "precision": 0.027398641748366013,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026220703125,
        "hf_subset": "eng_Latn-kqf_Latn",
        "languages": [
          "eng-Latn",
          "kqf-Latn"
        ],
        "main_score": 0.026220703125,
        "precision": 0.02314498127880184,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017086226851851852,
        "hf_subset": "kqf_Latn-eng_Latn",
        "languages": [
          "kqf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017086226851851852,
        "precision": 0.014892662847021398,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03571428571428571,
        "f1": 0.018282312925170068,
        "hf_subset": "eng_Latn-kql_Latn",
        "languages": [
          "eng-Latn",
          "kql-Latn"
        ],
        "main_score": 0.018282312925170068,
        "precision": 0.01466509680795395,
        "recall": 0.03571428571428571
      },
      {
        "accuracy": 0.05714285714285714,
        "f1": 0.03371720116618076,
        "hf_subset": "kql_Latn-eng_Latn",
        "languages": [
          "kql-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03371720116618076,
        "precision": 0.0300880677169337,
        "recall": 0.05714285714285714
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016144691154970758,
        "hf_subset": "eng_Latn-kqw_Latn",
        "languages": [
          "eng-Latn",
          "kqw-Latn"
        ],
        "main_score": 0.016144691154970758,
        "precision": 0.014340390512265513,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016849578373015872,
        "hf_subset": "kqw_Latn-eng_Latn",
        "languages": [
          "kqw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016849578373015872,
        "precision": 0.01633105927230047,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015752093301435406,
        "hf_subset": "eng_Latn-ksd_Latn",
        "languages": [
          "eng-Latn",
          "ksd-Latn"
        ],
        "main_score": 0.015752093301435406,
        "precision": 0.013034396701388888,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007335112803862804,
        "hf_subset": "ksd_Latn-eng_Latn",
        "languages": [
          "ksd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007335112803862804,
        "precision": 0.0051041666666666674,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018815104166666666,
        "hf_subset": "eng_Latn-ksj_Latn",
        "languages": [
          "eng-Latn",
          "ksj-Latn"
        ],
        "main_score": 0.018815104166666666,
        "precision": 0.016508556547619048,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02806392883480826,
        "hf_subset": "ksj_Latn-eng_Latn",
        "languages": [
          "ksj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02806392883480826,
        "precision": 0.02672758556547619,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.013739257074050408,
        "hf_subset": "eng_Latn-ksr_Latn",
        "languages": [
          "eng-Latn",
          "ksr-Latn"
        ],
        "main_score": 0.013739257074050408,
        "precision": 0.010362342295936047,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01099624060150376,
        "hf_subset": "ksr_Latn-eng_Latn",
        "languages": [
          "ksr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01099624060150376,
        "precision": 0.01007423566017316,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.05900012849691158,
        "hf_subset": "eng_Latn-ktm_Latn",
        "languages": [
          "eng-Latn",
          "ktm-Latn"
        ],
        "main_score": 0.05900012849691158,
        "precision": 0.05255998883928571,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.045510912698412696,
        "hf_subset": "ktm_Latn-eng_Latn",
        "languages": [
          "ktm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.045510912698412696,
        "precision": 0.03997157647357723,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016415550595238096,
        "hf_subset": "eng_Latn-kto_Latn",
        "languages": [
          "eng-Latn",
          "kto-Latn"
        ],
        "main_score": 0.016415550595238096,
        "precision": 0.01488095238095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012753739316239314,
        "hf_subset": "kto_Latn-eng_Latn",
        "languages": [
          "kto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012753739316239314,
        "precision": 0.010320925245098039,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008203125,
        "hf_subset": "eng_Latn-kud_Latn",
        "languages": [
          "eng-Latn",
          "kud-Latn"
        ],
        "main_score": 0.008203125,
        "precision": 0.008018092105263157,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00824408567774936,
        "hf_subset": "kud_Latn-eng_Latn",
        "languages": [
          "kud-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00824408567774936,
        "precision": 0.008036559794372294,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.032924906741542775,
        "hf_subset": "eng_Latn-kue_Latn",
        "languages": [
          "eng-Latn",
          "kue-Latn"
        ],
        "main_score": 0.032924906741542775,
        "precision": 0.027328869047619046,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01912503888932099,
        "hf_subset": "kue_Latn-eng_Latn",
        "languages": [
          "kue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01912503888932099,
        "precision": 0.01805409663865546,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-kup_Latn",
        "languages": [
          "eng-Latn",
          "kup-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004982972756410256,
        "hf_subset": "kup_Latn-eng_Latn",
        "languages": [
          "kup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004982972756410256,
        "precision": 0.004515016233766233,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01182905835098267,
        "hf_subset": "eng_Latn-kvg_Latn",
        "languages": [
          "eng-Latn",
          "kvg-Latn"
        ],
        "main_score": 0.01182905835098267,
        "precision": 0.009305570731351982,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007908950617283951,
        "hf_subset": "kvg_Latn-eng_Latn",
        "languages": [
          "kvg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007908950617283951,
        "precision": 0.007861328125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013050426136363636,
        "hf_subset": "eng_Latn-kvn_Latn",
        "languages": [
          "eng-Latn",
          "kvn-Latn"
        ],
        "main_score": 0.013050426136363636,
        "precision": 0.01050967261904762,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00813592069892473,
        "hf_subset": "kvn_Latn-eng_Latn",
        "languages": [
          "kvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00813592069892473,
        "precision": 0.0068676956300813006,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00546875,
        "hf_subset": "eng_Latn-kwd_Latn",
        "languages": [
          "eng-Latn",
          "kwd-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0037109375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003159797054597701,
        "hf_subset": "kwd_Latn-eng_Latn",
        "languages": [
          "kwd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003159797054597701,
        "precision": 0.0022475090579710142,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.033011642156862746,
        "hf_subset": "eng_Latn-kwf_Latn",
        "languages": [
          "eng-Latn",
          "kwf-Latn"
        ],
        "main_score": 0.033011642156862746,
        "precision": 0.029245087594696968,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010788690476190476,
        "hf_subset": "kwf_Latn-eng_Latn",
        "languages": [
          "kwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010788690476190476,
        "precision": 0.0099609375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02020892518939394,
        "hf_subset": "eng_Latn-kwi_Latn",
        "languages": [
          "eng-Latn",
          "kwi-Latn"
        ],
        "main_score": 0.02020892518939394,
        "precision": 0.017188901764354066,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005939180107526882,
        "hf_subset": "kwi_Latn-eng_Latn",
        "languages": [
          "kwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005939180107526882,
        "precision": 0.004012746124376337,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01489132612179487,
        "hf_subset": "eng_Latn-kwj_Latn",
        "languages": [
          "eng-Latn",
          "kwj-Latn"
        ],
        "main_score": 0.01489132612179487,
        "precision": 0.012738715277777778,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0034608004385964907,
        "hf_subset": "kwj_Latn-eng_Latn",
        "languages": [
          "kwj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0034608004385964907,
        "precision": 0.002188907657657658,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008314732142857143,
        "hf_subset": "eng_Latn-kyc_Latn",
        "languages": [
          "eng-Latn",
          "kyc-Latn"
        ],
        "main_score": 0.008314732142857143,
        "precision": 0.00545343137254902,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003925830200501253,
        "hf_subset": "kyc_Latn-eng_Latn",
        "languages": [
          "kyc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003925830200501253,
        "precision": 0.002709740990990991,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011685363247863248,
        "hf_subset": "eng_Latn-kyf_Latn",
        "languages": [
          "eng-Latn",
          "kyf-Latn"
        ],
        "main_score": 0.0011685363247863248,
        "precision": 0.00064453125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kyf_Latn-eng_Latn",
        "languages": [
          "kyf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0056857638888888895,
        "hf_subset": "eng_Latn-kyg_Latn",
        "languages": [
          "eng-Latn",
          "kyg-Latn"
        ],
        "main_score": 0.0056857638888888895,
        "precision": 0.0035822598288923714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006062610229276896,
        "hf_subset": "kyg_Latn-eng_Latn",
        "languages": [
          "kyg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006062610229276896,
        "precision": 0.0003247431915910177,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013686183608058608,
        "hf_subset": "eng_Latn-kyq_Latn",
        "languages": [
          "eng-Latn",
          "kyq-Latn"
        ],
        "main_score": 0.013686183608058608,
        "precision": 0.011821546052631578,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "kyq_Latn-eng_Latn",
        "languages": [
          "kyq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004142992424242424,
        "hf_subset": "eng_Latn-kyz_Latn",
        "languages": [
          "eng-Latn",
          "kyz-Latn"
        ],
        "main_score": 0.004142992424242424,
        "precision": 0.0040283203125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005284926470588236,
        "hf_subset": "kyz_Latn-eng_Latn",
        "languages": [
          "kyz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005284926470588236,
        "precision": 0.004726175742574257,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004507688492063492,
        "hf_subset": "eng_Latn-kze_Latn",
        "languages": [
          "eng-Latn",
          "kze-Latn"
        ],
        "main_score": 0.004507688492063492,
        "precision": 0.0028089060143288084,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kze_Latn-eng_Latn",
        "languages": [
          "kze-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01213282867494824,
        "hf_subset": "eng_Latn-lac_Latn",
        "languages": [
          "eng-Latn",
          "lac-Latn"
        ],
        "main_score": 0.01213282867494824,
        "precision": 0.010398910984848485,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004085656368371212,
        "hf_subset": "lac_Latn-eng_Latn",
        "languages": [
          "lac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004085656368371212,
        "precision": 0.003997104027861902,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.1998978462305668,
        "hf_subset": "eng_Latn-lat_Latn",
        "languages": [
          "eng-Latn",
          "lat-Latn"
        ],
        "main_score": 0.1998978462305668,
        "precision": 0.1789560797275641,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.3046875,
        "f1": 0.2274436858076564,
        "hf_subset": "lat_Latn-eng_Latn",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2274436858076564,
        "precision": 0.20565553695436506,
        "recall": 0.3046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009415064102564102,
        "hf_subset": "eng_Latn-lbb_Latn",
        "languages": [
          "eng-Latn",
          "lbb-Latn"
        ],
        "main_score": 0.009415064102564102,
        "precision": 0.007096185064935065,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014609067723697149,
        "hf_subset": "lbb_Latn-eng_Latn",
        "languages": [
          "lbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014609067723697149,
        "precision": 0.013543991815476192,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016489955357142858,
        "hf_subset": "eng_Latn-lbk_Latn",
        "languages": [
          "eng-Latn",
          "lbk-Latn"
        ],
        "main_score": 0.016489955357142858,
        "precision": 0.013220263092885376,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01607828164160401,
        "hf_subset": "lbk_Latn-eng_Latn",
        "languages": [
          "lbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01607828164160401,
        "precision": 0.014401139965640727,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011300223214285714,
        "hf_subset": "eng_Latn-lcm_Latn",
        "languages": [
          "eng-Latn",
          "lcm-Latn"
        ],
        "main_score": 0.011300223214285714,
        "precision": 0.009973099816849816,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "lcm_Latn-eng_Latn",
        "languages": [
          "lcm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00611359126984127,
        "hf_subset": "eng_Latn-leu_Latn",
        "languages": [
          "eng-Latn",
          "leu-Latn"
        ],
        "main_score": 0.00611359126984127,
        "precision": 0.0052248343894009215,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003494480056980057,
        "hf_subset": "leu_Latn-eng_Latn",
        "languages": [
          "leu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003494480056980057,
        "precision": 0.002428886217948718,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012959624287749289,
        "hf_subset": "eng_Latn-lex_Latn",
        "languages": [
          "eng-Latn",
          "lex-Latn"
        ],
        "main_score": 0.012959624287749289,
        "precision": 0.01091255099067599,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010451700298953662,
        "hf_subset": "lex_Latn-eng_Latn",
        "languages": [
          "lex-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010451700298953662,
        "precision": 0.009783220720720721,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.025173611111111112,
        "hf_subset": "eng_Latn-lgl_Latn",
        "languages": [
          "eng-Latn",
          "lgl-Latn"
        ],
        "main_score": 0.025173611111111112,
        "precision": 0.023667279411764705,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005403645833333333,
        "hf_subset": "lgl_Latn-eng_Latn",
        "languages": [
          "lgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005403645833333333,
        "precision": 0.004743303571428571,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019808836996336992,
        "hf_subset": "eng_Latn-lid_Latn",
        "languages": [
          "eng-Latn",
          "lid-Latn"
        ],
        "main_score": 0.019808836996336992,
        "precision": 0.01594271134567187,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007291666666666666,
        "hf_subset": "lid_Latn-eng_Latn",
        "languages": [
          "lid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007291666666666666,
        "precision": 0.006293402777777778,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001680871212121212,
        "hf_subset": "eng_Latn-lif_Deva",
        "languages": [
          "eng-Latn",
          "lif-Deva"
        ],
        "main_score": 0.001680871212121212,
        "precision": 0.0010366586538461538,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "lif_Deva-eng_Latn",
        "languages": [
          "lif-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003515625,
        "hf_subset": "eng_Latn-lin_Latn",
        "languages": [
          "eng-Latn",
          "lin-Latn"
        ],
        "main_score": 0.003515625,
        "precision": 0.002278645833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003978587962962963,
        "hf_subset": "lin_Latn-eng_Latn",
        "languages": [
          "lin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003978587962962963,
        "precision": 0.00020634396586753352,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008284065315315314,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ],
        "main_score": 0.008284065315315314,
        "precision": 0.006944444444444444,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010415572478991596,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010415572478991596,
        "precision": 0.008289692078754579,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0009896927521008403,
        "hf_subset": "eng_Latn-llg_Latn",
        "languages": [
          "eng-Latn",
          "llg-Latn"
        ],
        "main_score": 0.0009896927521008403,
        "precision": 0.0005207554575358852,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0045865221088435375,
        "hf_subset": "llg_Latn-eng_Latn",
        "languages": [
          "llg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0045865221088435375,
        "precision": 0.00426664806547619,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009131521002710027,
        "hf_subset": "eng_Latn-lug_Latn",
        "languages": [
          "eng-Latn",
          "lug-Latn"
        ],
        "main_score": 0.009131521002710027,
        "precision": 0.007031249999999999,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "lug_Latn-eng_Latn",
        "languages": [
          "lug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012764246323529412,
        "hf_subset": "eng_Latn-luo_Latn",
        "languages": [
          "eng-Latn",
          "luo-Latn"
        ],
        "main_score": 0.012764246323529412,
        "precision": 0.010893322172619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011211444805194804,
        "hf_subset": "luo_Latn-eng_Latn",
        "languages": [
          "luo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011211444805194804,
        "precision": 0.010188176081730768,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00827205882352941,
        "hf_subset": "eng_Latn-lww_Latn",
        "languages": [
          "eng-Latn",
          "lww-Latn"
        ],
        "main_score": 0.00827205882352941,
        "precision": 0.006884765625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00048792802025560643,
        "hf_subset": "lww_Latn-eng_Latn",
        "languages": [
          "lww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00048792802025560643,
        "precision": 0.0002503356018981019,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015438988095238094,
        "hf_subset": "eng_Latn-maa_Latn",
        "languages": [
          "eng-Latn",
          "maa-Latn"
        ],
        "main_score": 0.015438988095238094,
        "precision": 0.014322916666666668,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004422319613821138,
        "hf_subset": "maa_Latn-eng_Latn",
        "languages": [
          "maa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004422319613821138,
        "precision": 0.0027390252976190474,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017252604166666664,
        "hf_subset": "eng_Latn-maj_Latn",
        "languages": [
          "eng-Latn",
          "maj-Latn"
        ],
        "main_score": 0.017252604166666664,
        "precision": 0.01260422137605042,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007192460317460318,
        "hf_subset": "maj_Latn-eng_Latn",
        "languages": [
          "maj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007192460317460318,
        "precision": 0.005826822916666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004431464415305954,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.004431464415305954,
        "precision": 0.0030646961405529955,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016483516483516484,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.0016483516483516484,
        "precision": 0.0010199652777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004153788919413919,
        "hf_subset": "eng_Latn-mam_Latn",
        "languages": [
          "eng-Latn",
          "mam-Latn"
        ],
        "main_score": 0.004153788919413919,
        "precision": 0.002475769844190897,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008764022435897436,
        "hf_subset": "mam_Latn-eng_Latn",
        "languages": [
          "mam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008764022435897436,
        "precision": 0.006927083333333334,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0172559862012987,
        "hf_subset": "eng_Latn-maq_Latn",
        "languages": [
          "eng-Latn",
          "maq-Latn"
        ],
        "main_score": 0.0172559862012987,
        "precision": 0.014934634763993317,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016477864583333335,
        "hf_subset": "maq_Latn-eng_Latn",
        "languages": [
          "maq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016477864583333335,
        "precision": 0.014571016328828828,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008057697510822512,
        "hf_subset": "eng_Latn-mau_Latn",
        "languages": [
          "eng-Latn",
          "mau-Latn"
        ],
        "main_score": 0.008057697510822512,
        "precision": 0.006475482723577236,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013745106713856713,
        "hf_subset": "mau_Latn-eng_Latn",
        "languages": [
          "mau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013745106713856713,
        "precision": 0.01157721920289855,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018489583333333334,
        "hf_subset": "eng_Latn-mav_Latn",
        "languages": [
          "eng-Latn",
          "mav-Latn"
        ],
        "main_score": 0.018489583333333334,
        "precision": 0.0166015625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mav_Latn-eng_Latn",
        "languages": [
          "mav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.039986526705276706,
        "hf_subset": "eng_Latn-maz_Latn",
        "languages": [
          "eng-Latn",
          "maz-Latn"
        ],
        "main_score": 0.039986526705276706,
        "precision": 0.03518472020987004,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020667251275510203,
        "hf_subset": "maz_Latn-eng_Latn",
        "languages": [
          "maz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020667251275510203,
        "precision": 0.018868582589285712,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.030508210106225588,
        "hf_subset": "eng_Latn-mbb_Latn",
        "languages": [
          "eng-Latn",
          "mbb-Latn"
        ],
        "main_score": 0.030508210106225588,
        "precision": 0.027743854452838827,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03930179462520084,
        "hf_subset": "mbb_Latn-eng_Latn",
        "languages": [
          "mbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03930179462520084,
        "precision": 0.03458617822128851,
        "recall": 0.0625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012970753205128204,
        "hf_subset": "eng_Latn-mbc_Latn",
        "languages": [
          "eng-Latn",
          "mbc-Latn"
        ],
        "main_score": 0.012970753205128204,
        "precision": 0.011393229166666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011970766129032258,
        "hf_subset": "mbc_Latn-eng_Latn",
        "languages": [
          "mbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011970766129032258,
        "precision": 0.011848958333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013680980477855476,
        "hf_subset": "eng_Latn-mbh_Latn",
        "languages": [
          "eng-Latn",
          "mbh-Latn"
        ],
        "main_score": 0.013680980477855476,
        "precision": 0.010611979166666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008723958333333334,
        "hf_subset": "mbh_Latn-eng_Latn",
        "languages": [
          "mbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008723958333333334,
        "precision": 0.006966145833333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0076171875,
        "hf_subset": "eng_Latn-mbj_Latn",
        "languages": [
          "eng-Latn",
          "mbj-Latn"
        ],
        "main_score": 0.0076171875,
        "precision": 0.006200396825396825,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mbj_Latn-eng_Latn",
        "languages": [
          "mbj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005338541666666667,
        "hf_subset": "eng_Latn-mbl_Latn",
        "languages": [
          "eng-Latn",
          "mbl-Latn"
        ],
        "main_score": 0.005338541666666667,
        "precision": 0.003689236111111111,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0017400568181818183,
        "hf_subset": "mbl_Latn-eng_Latn",
        "languages": [
          "mbl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0017400568181818183,
        "precision": 0.001067405523255814,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010026041666666666,
        "hf_subset": "eng_Latn-mbs_Latn",
        "languages": [
          "eng-Latn",
          "mbs-Latn"
        ],
        "main_score": 0.010026041666666666,
        "precision": 0.0068359375,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006789434523809524,
        "hf_subset": "mbs_Latn-eng_Latn",
        "languages": [
          "mbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006789434523809524,
        "precision": 0.006004050925925926,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0028645833333333336,
        "hf_subset": "eng_Latn-mbt_Latn",
        "languages": [
          "eng-Latn",
          "mbt-Latn"
        ],
        "main_score": 0.0028645833333333336,
        "precision": 0.0017578125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004413980607966457,
        "hf_subset": "mbt_Latn-eng_Latn",
        "languages": [
          "mbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004413980607966457,
        "precision": 0.004173231792717087,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.013970259683664289,
        "hf_subset": "eng_Latn-mca_Latn",
        "languages": [
          "eng-Latn",
          "mca-Latn"
        ],
        "main_score": 0.013970259683664289,
        "precision": 0.011491932905245486,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013083333333333332,
        "hf_subset": "mca_Latn-eng_Latn",
        "languages": [
          "mca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013083333333333332,
        "precision": 0.011750252016129031,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-mcb_Latn",
        "languages": [
          "eng-Latn",
          "mcb-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mcb_Latn-eng_Latn",
        "languages": [
          "mcb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023437500000000003,
        "hf_subset": "eng_Latn-mcd_Latn",
        "languages": [
          "eng-Latn",
          "mcd-Latn"
        ],
        "main_score": 0.0023437500000000003,
        "precision": 0.0014105902777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.456858407079646e-05,
        "hf_subset": "mcd_Latn-eng_Latn",
        "languages": [
          "mcd-Latn",
          "eng-Latn"
        ],
        "main_score": 3.456858407079646e-05,
        "precision": 1.736111111111111e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0068359375,
        "hf_subset": "eng_Latn-mcf_Latn",
        "languages": [
          "eng-Latn",
          "mcf-Latn"
        ],
        "main_score": 0.0068359375,
        "precision": 0.005766369047619047,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003442564391058147,
        "hf_subset": "mcf_Latn-eng_Latn",
        "languages": [
          "mcf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003442564391058147,
        "precision": 0.002391804391270515,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008056640625,
        "hf_subset": "eng_Latn-mco_Latn",
        "languages": [
          "eng-Latn",
          "mco-Latn"
        ],
        "main_score": 0.008056640625,
        "precision": 0.006766633064516129,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004829545454545454,
        "hf_subset": "mco_Latn-eng_Latn",
        "languages": [
          "mco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004829545454545454,
        "precision": 0.004412615740740741,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008037299960967994,
        "hf_subset": "eng_Latn-mcp_Latn",
        "languages": [
          "eng-Latn",
          "mcp-Latn"
        ],
        "main_score": 0.008037299960967994,
        "precision": 0.005515917304421769,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004087936046511628,
        "hf_subset": "mcp_Latn-eng_Latn",
        "languages": [
          "mcp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004087936046511628,
        "precision": 0.003999255952380952,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005316840277777778,
        "hf_subset": "eng_Latn-mcq_Latn",
        "languages": [
          "eng-Latn",
          "mcq-Latn"
        ],
        "main_score": 0.005316840277777778,
        "precision": 0.00469406512605042,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004985119047619047,
        "hf_subset": "mcq_Latn-eng_Latn",
        "languages": [
          "mcq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004985119047619047,
        "precision": 0.004484778654349248,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012456597222222221,
        "hf_subset": "eng_Latn-mcr_Latn",
        "languages": [
          "eng-Latn",
          "mcr-Latn"
        ],
        "main_score": 0.012456597222222221,
        "precision": 0.011111598782771534,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0035068215682622465,
        "hf_subset": "mcr_Latn-eng_Latn",
        "languages": [
          "mcr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035068215682622465,
        "precision": 0.0024320503715034966,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005403645833333333,
        "hf_subset": "eng_Latn-mdy_Latn",
        "languages": [
          "eng-Latn",
          "mdy-Latn"
        ],
        "main_score": 0.005403645833333333,
        "precision": 0.004743303571428571,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "mdy_Latn-eng_Latn",
        "languages": [
          "mdy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0056640625,
        "hf_subset": "eng_Latn-med_Latn",
        "languages": [
          "eng-Latn",
          "med-Latn"
        ],
        "main_score": 0.0056640625,
        "precision": 0.004898313492063492,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "med_Latn-eng_Latn",
        "languages": [
          "med-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004222579656862745,
        "hf_subset": "eng_Latn-mee_Latn",
        "languages": [
          "eng-Latn",
          "mee-Latn"
        ],
        "main_score": 0.004222579656862745,
        "precision": 0.002546037946428571,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008112980769230768,
        "hf_subset": "mee_Latn-eng_Latn",
        "languages": [
          "mee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008112980769230768,
        "precision": 0.00796875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019208829365079366,
        "hf_subset": "eng_Latn-mek_Latn",
        "languages": [
          "eng-Latn",
          "mek-Latn"
        ],
        "main_score": 0.019208829365079366,
        "precision": 0.014558015046296297,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02055931281094527,
        "hf_subset": "mek_Latn-eng_Latn",
        "languages": [
          "mek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02055931281094527,
        "precision": 0.01796283143939394,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.018323018127705627,
        "hf_subset": "eng_Latn-meq_Latn",
        "languages": [
          "eng-Latn",
          "meq-Latn"
        ],
        "main_score": 0.018323018127705627,
        "precision": 0.01350328036661421,
        "recall": 0.046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "meq_Latn-eng_Latn",
        "languages": [
          "meq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010686063218390805,
        "hf_subset": "eng_Latn-met_Latn",
        "languages": [
          "eng-Latn",
          "met-Latn"
        ],
        "main_score": 0.010686063218390805,
        "precision": 0.008603050595238096,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01879205486542443,
        "hf_subset": "met_Latn-eng_Latn",
        "languages": [
          "met-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01879205486542443,
        "precision": 0.015526821524064172,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013796240651709401,
        "hf_subset": "eng_Latn-meu_Latn",
        "languages": [
          "eng-Latn",
          "meu-Latn"
        ],
        "main_score": 0.013796240651709401,
        "precision": 0.01182154605263158,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010135825163398693,
        "hf_subset": "meu_Latn-eng_Latn",
        "languages": [
          "meu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010135825163398693,
        "precision": 0.008013870320855616,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01704089739709443,
        "hf_subset": "eng_Latn-mgc_Latn",
        "languages": [
          "eng-Latn",
          "mgc-Latn"
        ],
        "main_score": 0.01704089739709443,
        "precision": 0.013844392407161805,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016001452664399094,
        "hf_subset": "mgc_Latn-eng_Latn",
        "languages": [
          "mgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016001452664399094,
        "precision": 0.014371744791666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008624751984126983,
        "hf_subset": "eng_Latn-mgh_Latn",
        "languages": [
          "eng-Latn",
          "mgh-Latn"
        ],
        "main_score": 0.008624751984126983,
        "precision": 0.005609809027777778,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005440629890453833,
        "hf_subset": "mgh_Latn-eng_Latn",
        "languages": [
          "mgh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005440629890453833,
        "precision": 0.0002855829831932773,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0430622009569378,
        "f1": 0.024955276403274388,
        "hf_subset": "eng_Latn-mgw_Latn",
        "languages": [
          "eng-Latn",
          "mgw-Latn"
        ],
        "main_score": 0.024955276403274388,
        "precision": 0.021717171717171718,
        "recall": 0.0430622009569378
      },
      {
        "accuracy": 0.028708133971291867,
        "f1": 0.01308811438034752,
        "hf_subset": "mgw_Latn-eng_Latn",
        "languages": [
          "mgw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01308811438034752,
        "precision": 0.010655725288304023,
        "recall": 0.028708133971291867
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005985449735449735,
        "hf_subset": "eng_Latn-mhl_Latn",
        "languages": [
          "eng-Latn",
          "mhl-Latn"
        ],
        "main_score": 0.005985449735449735,
        "precision": 0.003954912766086114,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "mhl_Latn-eng_Latn",
        "languages": [
          "mhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009958566760037348,
        "hf_subset": "eng_Latn-mib_Latn",
        "languages": [
          "eng-Latn",
          "mib-Latn"
        ],
        "main_score": 0.009958566760037348,
        "precision": 0.009096207157258064,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005673363095238095,
        "hf_subset": "mib_Latn-eng_Latn",
        "languages": [
          "mib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005673363095238095,
        "precision": 0.00390625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004313812669376693,
        "hf_subset": "eng_Latn-mic_Latn",
        "languages": [
          "eng-Latn",
          "mic-Latn"
        ],
        "main_score": 0.004313812669376693,
        "precision": 0.0026692708333333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007894736842105263,
        "hf_subset": "mic_Latn-eng_Latn",
        "languages": [
          "mic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007894736842105263,
        "precision": 0.00785405585106383,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012900958994708995,
        "hf_subset": "eng_Latn-mie_Latn",
        "languages": [
          "eng-Latn",
          "mie-Latn"
        ],
        "main_score": 0.012900958994708995,
        "precision": 0.01086738782051282,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003908803104575163,
        "hf_subset": "mie_Latn-eng_Latn",
        "languages": [
          "mie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003908803104575163,
        "precision": 0.0026701122605886016,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011326455662393162,
        "hf_subset": "eng_Latn-mig_Latn",
        "languages": [
          "eng-Latn",
          "mig-Latn"
        ],
        "main_score": 0.011326455662393162,
        "precision": 0.008807116596638655,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004774305555555556,
        "hf_subset": "mig_Latn-eng_Latn",
        "languages": [
          "mig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004774305555555556,
        "precision": 0.0030924479166666665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0188394288003663,
        "hf_subset": "eng_Latn-mih_Latn",
        "languages": [
          "eng-Latn",
          "mih-Latn"
        ],
        "main_score": 0.0188394288003663,
        "precision": 0.015994877518315017,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005984176090718081,
        "hf_subset": "mih_Latn-eng_Latn",
        "languages": [
          "mih-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005984176090718081,
        "precision": 0.005058442344961241,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013041392543859649,
        "hf_subset": "eng_Latn-mil_Latn",
        "languages": [
          "eng-Latn",
          "mil-Latn"
        ],
        "main_score": 0.013041392543859649,
        "precision": 0.011089409722222221,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.004423155703575016,
        "hf_subset": "mil_Latn-eng_Latn",
        "languages": [
          "mil-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004423155703575016,
        "precision": 0.0024820188492063492,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.010259402056277057,
        "hf_subset": "eng_Latn-mio_Latn",
        "languages": [
          "eng-Latn",
          "mio-Latn"
        ],
        "main_score": 0.010259402056277057,
        "precision": 0.006359444213732005,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010633680555555556,
        "hf_subset": "mio_Latn-eng_Latn",
        "languages": [
          "mio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010633680555555556,
        "precision": 0.009602864583333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007235386141636141,
        "hf_subset": "eng_Latn-mir_Latn",
        "languages": [
          "eng-Latn",
          "mir-Latn"
        ],
        "main_score": 0.007235386141636141,
        "precision": 0.005020532852564102,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008101465017825311,
        "hf_subset": "mir_Latn-eng_Latn",
        "languages": [
          "mir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008101465017825311,
        "precision": 0.006723484848484848,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009092024717024718,
        "hf_subset": "eng_Latn-mit_Latn",
        "languages": [
          "eng-Latn",
          "mit-Latn"
        ],
        "main_score": 0.009092024717024718,
        "precision": 0.0074843684732665,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0021778998801463474,
        "hf_subset": "mit_Latn-eng_Latn",
        "languages": [
          "mit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0021778998801463474,
        "precision": 0.001228155525030525,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01141624579124579,
        "hf_subset": "eng_Latn-miz_Latn",
        "languages": [
          "eng-Latn",
          "miz-Latn"
        ],
        "main_score": 0.01141624579124579,
        "precision": 0.010306490384615384,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030691964285714285,
        "hf_subset": "miz_Latn-eng_Latn",
        "languages": [
          "miz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030691964285714285,
        "precision": 0.001953125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01804315476190476,
        "hf_subset": "eng_Latn-mjc_Latn",
        "languages": [
          "eng-Latn",
          "mjc-Latn"
        ],
        "main_score": 0.01804315476190476,
        "precision": 0.015885416666666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010858217442601351,
        "hf_subset": "mjc_Latn-eng_Latn",
        "languages": [
          "mjc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010858217442601351,
        "precision": 0.009704228063603063,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.054382327741702735,
        "hf_subset": "eng_Latn-mkj_Latn",
        "languages": [
          "eng-Latn",
          "mkj-Latn"
        ],
        "main_score": 0.054382327741702735,
        "precision": 0.04818356053358843,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07380503261299633,
        "hf_subset": "mkj_Latn-eng_Latn",
        "languages": [
          "mkj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07380503261299633,
        "precision": 0.06941825643300799,
        "recall": 0.09375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010825892857142857,
        "hf_subset": "eng_Latn-mkl_Latn",
        "languages": [
          "eng-Latn",
          "mkl-Latn"
        ],
        "main_score": 0.010825892857142857,
        "precision": 0.009548611111111112,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mkl_Latn-eng_Latn",
        "languages": [
          "mkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008364456798589342,
        "hf_subset": "eng_Latn-mkn_Latn",
        "languages": [
          "eng-Latn",
          "mkn-Latn"
        ],
        "main_score": 0.008364456798589342,
        "precision": 0.006578947368421052,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003965435606060606,
        "hf_subset": "mkn_Latn-eng_Latn",
        "languages": [
          "mkn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003965435606060606,
        "precision": 0.002683738425925926,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011653645833333334,
        "hf_subset": "eng_Latn-mks_Latn",
        "languages": [
          "eng-Latn",
          "mks-Latn"
        ],
        "main_score": 0.011653645833333334,
        "precision": 0.010128348214285715,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0066831931089743595,
        "hf_subset": "mks_Latn-eng_Latn",
        "languages": [
          "mks-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0066831931089743595,
        "precision": 0.005561884673694927,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-mle_Latn",
        "languages": [
          "eng-Latn",
          "mle-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.848522167487685e-05,
        "hf_subset": "mle_Latn-eng_Latn",
        "languages": [
          "mle-Latn",
          "eng-Latn"
        ],
        "main_score": 3.848522167487685e-05,
        "precision": 1.9337871287128713e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005985449735449735,
        "hf_subset": "eng_Latn-mlh_Latn",
        "languages": [
          "eng-Latn",
          "mlh-Latn"
        ],
        "main_score": 0.005985449735449735,
        "precision": 0.003954912766086114,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "mlh_Latn-eng_Latn",
        "languages": [
          "mlh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011604324494949494,
        "hf_subset": "eng_Latn-mlp_Latn",
        "languages": [
          "eng-Latn",
          "mlp-Latn"
        ],
        "main_score": 0.011604324494949494,
        "precision": 0.007549124053030302,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014462425595238094,
        "hf_subset": "mlp_Latn-eng_Latn",
        "languages": [
          "mlp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014462425595238094,
        "precision": 0.012539628623188404,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005397727272727273,
        "hf_subset": "eng_Latn-mmo_Latn",
        "languages": [
          "eng-Latn",
          "mmo-Latn"
        ],
        "main_score": 0.005397727272727273,
        "precision": 0.003303402326839827,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004338727678571429,
        "hf_subset": "mmo_Latn-eng_Latn",
        "languages": [
          "mmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004338727678571429,
        "precision": 0.0026475694444444446,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006569602272727273,
        "hf_subset": "eng_Latn-mmx_Latn",
        "languages": [
          "eng-Latn",
          "mmx-Latn"
        ],
        "main_score": 0.006569602272727273,
        "precision": 0.004427083333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010066105769230768,
        "hf_subset": "mmx_Latn-eng_Latn",
        "languages": [
          "mmx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010066105769230768,
        "precision": 0.007317708333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018281549329501913,
        "hf_subset": "eng_Latn-mna_Latn",
        "languages": [
          "eng-Latn",
          "mna-Latn"
        ],
        "main_score": 0.018281549329501913,
        "precision": 0.016124496673669466,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007872596153846154,
        "hf_subset": "mna_Latn-eng_Latn",
        "languages": [
          "mna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007872596153846154,
        "precision": 0.007842781007751938,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010627003205128204,
        "hf_subset": "eng_Latn-mop_Latn",
        "languages": [
          "eng-Latn",
          "mop-Latn"
        ],
        "main_score": 0.010627003205128204,
        "precision": 0.007291666666666667,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006613452672735762,
        "hf_subset": "mop_Latn-eng_Latn",
        "languages": [
          "mop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006613452672735762,
        "precision": 0.005402715199934869,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008680555555555556,
        "hf_subset": "eng_Latn-mox_Latn",
        "languages": [
          "eng-Latn",
          "mox-Latn"
        ],
        "main_score": 0.008680555555555556,
        "precision": 0.00830078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333333,
        "hf_subset": "mox_Latn-eng_Latn",
        "languages": [
          "mox-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007161458333333333,
        "precision": 0.005989583333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.08433734939759036,
        "f1": 0.063855421686747,
        "hf_subset": "eng_Latn-mph_Latn",
        "languages": [
          "eng-Latn",
          "mph-Latn"
        ],
        "main_score": 0.063855421686747,
        "precision": 0.058232931726907626,
        "recall": 0.08433734939759036
      },
      {
        "accuracy": 0.03614457831325301,
        "f1": 0.014478968505601352,
        "hf_subset": "mph_Latn-eng_Latn",
        "languages": [
          "mph-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014478968505601352,
        "precision": 0.010255306942053932,
        "recall": 0.03614457831325301
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "eng_Latn-mpj_Latn",
        "languages": [
          "eng-Latn",
          "mpj-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mpj_Latn-eng_Latn",
        "languages": [
          "mpj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027025767543859647,
        "hf_subset": "eng_Latn-mpm_Latn",
        "languages": [
          "eng-Latn",
          "mpm-Latn"
        ],
        "main_score": 0.027025767543859647,
        "precision": 0.023550939078282828,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015574919871794872,
        "hf_subset": "mpm_Latn-eng_Latn",
        "languages": [
          "mpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015574919871794872,
        "precision": 0.013346354166666664,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010529663553639847,
        "hf_subset": "eng_Latn-mpp_Latn",
        "languages": [
          "eng-Latn",
          "mpp-Latn"
        ],
        "main_score": 0.010529663553639847,
        "precision": 0.00801780416113814,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.1629554655870446e-05,
        "hf_subset": "mpp_Latn-eng_Latn",
        "languages": [
          "mpp-Latn",
          "eng-Latn"
        ],
        "main_score": 3.1629554655870446e-05,
        "precision": 1.5879065040650408e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014211309523809522,
        "hf_subset": "eng_Latn-mps_Latn",
        "languages": [
          "eng-Latn",
          "mps-Latn"
        ],
        "main_score": 0.014211309523809522,
        "precision": 0.012044270833333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0037536140259658408,
        "hf_subset": "mps_Latn-eng_Latn",
        "languages": [
          "mps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0037536140259658408,
        "precision": 0.002585018382352941,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003507224462365591,
        "hf_subset": "eng_Latn-mpt_Latn",
        "languages": [
          "eng-Latn",
          "mpt-Latn"
        ],
        "main_score": 0.003507224462365591,
        "precision": 0.0022135416666666666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008291544357469016,
        "hf_subset": "mpt_Latn-eng_Latn",
        "languages": [
          "mpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008291544357469016,
        "precision": 0.008062065972222221,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025124289772727272,
        "hf_subset": "eng_Latn-mpx_Latn",
        "languages": [
          "eng-Latn",
          "mpx-Latn"
        ],
        "main_score": 0.025124289772727272,
        "precision": 0.020612545289855073,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011941964285714285,
        "hf_subset": "mpx_Latn-eng_Latn",
        "languages": [
          "mpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011941964285714285,
        "precision": 0.010661764705882353,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.011722793615434744,
        "hf_subset": "eng_Latn-mqb_Latn",
        "languages": [
          "eng-Latn",
          "mqb-Latn"
        ],
        "main_score": 0.011722793615434744,
        "precision": 0.008551587301587303,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010827850877192981,
        "hf_subset": "mqb_Latn-eng_Latn",
        "languages": [
          "mqb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010827850877192981,
        "precision": 0.009982638888888888,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012904478334165834,
        "hf_subset": "eng_Latn-mqj_Latn",
        "languages": [
          "eng-Latn",
          "mqj-Latn"
        ],
        "main_score": 0.012904478334165834,
        "precision": 0.010774429563492064,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017838541666666666,
        "hf_subset": "mqj_Latn-eng_Latn",
        "languages": [
          "mqj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017838541666666666,
        "precision": 0.015950520833333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02025188577586207,
        "hf_subset": "eng_Latn-msb_Latn",
        "languages": [
          "eng-Latn",
          "msb-Latn"
        ],
        "main_score": 0.02025188577586207,
        "precision": 0.017358337249373433,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019864309210526315,
        "hf_subset": "msb_Latn-eng_Latn",
        "languages": [
          "msb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019864309210526315,
        "precision": 0.018283420138888888,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03295861807366624,
        "hf_subset": "eng_Latn-msc_Latn",
        "languages": [
          "eng-Latn",
          "msc-Latn"
        ],
        "main_score": 0.03295861807366624,
        "precision": 0.029821583581349204,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.031048768939393935,
        "hf_subset": "msc_Latn-eng_Latn",
        "languages": [
          "msc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031048768939393935,
        "precision": 0.02663788377192982,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0052827380952380956,
        "hf_subset": "eng_Latn-msk_Latn",
        "languages": [
          "eng-Latn",
          "msk-Latn"
        ],
        "main_score": 0.0052827380952380956,
        "precision": 0.0035807291666666665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009480574324324325,
        "hf_subset": "msk_Latn-eng_Latn",
        "languages": [
          "msk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009480574324324325,
        "precision": 0.007540489440639269,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007899305555555555,
        "hf_subset": "eng_Latn-msm_Latn",
        "languages": [
          "eng-Latn",
          "msm-Latn"
        ],
        "main_score": 0.007899305555555555,
        "precision": 0.00517578125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011005704365079364,
        "hf_subset": "msm_Latn-eng_Latn",
        "languages": [
          "msm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011005704365079364,
        "precision": 0.008900669642857142,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005592660675381263,
        "hf_subset": "eng_Latn-msy_Latn",
        "languages": [
          "eng-Latn",
          "msy-Latn"
        ],
        "main_score": 0.005592660675381263,
        "precision": 0.0036425031751482644,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018590856481481483,
        "hf_subset": "msy_Latn-eng_Latn",
        "languages": [
          "msy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018590856481481483,
        "precision": 0.016067055352118505,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023281816123188404,
        "hf_subset": "eng_Latn-mti_Latn",
        "languages": [
          "eng-Latn",
          "mti-Latn"
        ],
        "main_score": 0.023281816123188404,
        "precision": 0.022129216269841268,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008035714285714285,
        "hf_subset": "mti_Latn-eng_Latn",
        "languages": [
          "mti-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008035714285714285,
        "precision": 0.007927389705882353,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010170145750988142,
        "hf_subset": "eng_Latn-mto_Latn",
        "languages": [
          "eng-Latn",
          "mto-Latn"
        ],
        "main_score": 0.010170145750988142,
        "precision": 0.009222613324175824,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006588541666666666,
        "hf_subset": "mto_Latn-eng_Latn",
        "languages": [
          "mto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006588541666666666,
        "precision": 0.005898832070707071,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013620923913043478,
        "hf_subset": "eng_Latn-mux_Latn",
        "languages": [
          "eng-Latn",
          "mux-Latn"
        ],
        "main_score": 0.013620923913043478,
        "precision": 0.012872869318181818,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0054687500000000005,
        "hf_subset": "mux_Latn-eng_Latn",
        "languages": [
          "mux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0054687500000000005,
        "precision": 0.004819915254237288,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007921430048446176,
        "hf_subset": "eng_Latn-muy_Latn",
        "languages": [
          "eng-Latn",
          "muy-Latn"
        ],
        "main_score": 0.007921430048446176,
        "precision": 0.006615584935897436,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004317434210526315,
        "hf_subset": "muy_Latn-eng_Latn",
        "languages": [
          "muy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004317434210526315,
        "precision": 0.004123263888888889,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013085937499999999,
        "hf_subset": "eng_Latn-mva_Latn",
        "languages": [
          "eng-Latn",
          "mva-Latn"
        ],
        "main_score": 0.013085937499999999,
        "precision": 0.011366430841404358,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026523919753086416,
        "hf_subset": "mva_Latn-eng_Latn",
        "languages": [
          "mva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026523919753086416,
        "precision": 0.0019773874223602485,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006239557226399331,
        "hf_subset": "eng_Latn-mvn_Latn",
        "languages": [
          "eng-Latn",
          "mvn-Latn"
        ],
        "main_score": 0.006239557226399331,
        "precision": 0.0044483176908974974,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008673878205128204,
        "hf_subset": "mvn_Latn-eng_Latn",
        "languages": [
          "mvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008673878205128204,
        "precision": 0.007100844109195402,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.10489886776996152,
        "hf_subset": "eng_Latn-mwc_Latn",
        "languages": [
          "eng-Latn",
          "mwc-Latn"
        ],
        "main_score": 0.10489886776996152,
        "precision": 0.09277773008241758,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.12128220613516608,
        "hf_subset": "mwc_Latn-eng_Latn",
        "languages": [
          "mwc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12128220613516608,
        "precision": 0.11196741740532859,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0043294270833333336,
        "hf_subset": "eng_Latn-mwe_Latn",
        "languages": [
          "eng-Latn",
          "mwe-Latn"
        ],
        "main_score": 0.0043294270833333336,
        "precision": 0.0027088994565217387,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00395868288590604,
        "hf_subset": "mwe_Latn-eng_Latn",
        "languages": [
          "mwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00395868288590604,
        "precision": 0.003932643581081081,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.05788778279012654,
        "hf_subset": "eng_Latn-mwf_Latn",
        "languages": [
          "eng-Latn",
          "mwf-Latn"
        ],
        "main_score": 0.05788778279012654,
        "precision": 0.04887152777777778,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05160314961650083,
        "hf_subset": "mwf_Latn-eng_Latn",
        "languages": [
          "mwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05160314961650083,
        "precision": 0.045859966856060606,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.003964915293040293,
        "hf_subset": "eng_Latn-mwp_Latn",
        "languages": [
          "eng-Latn",
          "mwp-Latn"
        ],
        "main_score": 0.003964915293040293,
        "precision": 0.0022474747474747476,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009809027777777778,
        "hf_subset": "mwp_Latn-eng_Latn",
        "languages": [
          "mwp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009809027777777778,
        "precision": 0.009018841911764705,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.017390703914141416,
        "hf_subset": "eng_Latn-mxb_Latn",
        "languages": [
          "eng-Latn",
          "mxb-Latn"
        ],
        "main_score": 0.017390703914141416,
        "precision": 0.01265706566717596,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008590994268077601,
        "hf_subset": "mxb_Latn-eng_Latn",
        "languages": [
          "mxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008590994268077601,
        "precision": 0.007047526041666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008331446256038648,
        "hf_subset": "eng_Latn-mxp_Latn",
        "languages": [
          "eng-Latn",
          "mxp-Latn"
        ],
        "main_score": 0.008331446256038648,
        "precision": 0.006783121902607196,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010037580373058314,
        "hf_subset": "mxp_Latn-eng_Latn",
        "languages": [
          "mxp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010037580373058314,
        "precision": 0.008009914329432337,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007074175824175823,
        "hf_subset": "eng_Latn-mxq_Latn",
        "languages": [
          "eng-Latn",
          "mxq-Latn"
        ],
        "main_score": 0.007074175824175823,
        "precision": 0.0057572508169934635,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003513558201058201,
        "hf_subset": "mxq_Latn-eng_Latn",
        "languages": [
          "mxq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003513558201058201,
        "precision": 0.00018118293527172031,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013910276333634718,
        "hf_subset": "eng_Latn-mxt_Latn",
        "languages": [
          "eng-Latn",
          "mxt-Latn"
        ],
        "main_score": 0.013910276333634718,
        "precision": 0.009698851495726496,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009635416666666667,
        "hf_subset": "mxt_Latn-eng_Latn",
        "languages": [
          "mxt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009635416666666667,
        "precision": 0.0078125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-mya_Latn",
        "languages": [
          "eng-Latn",
          "mya-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.8125e-05,
        "hf_subset": "mya_Latn-eng_Latn",
        "languages": [
          "mya-Latn",
          "eng-Latn"
        ],
        "main_score": 7.8125e-05,
        "precision": 3.945707070707071e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003720238095238095,
        "hf_subset": "eng_Latn-myk_Latn",
        "languages": [
          "eng-Latn",
          "myk-Latn"
        ],
        "main_score": 0.003720238095238095,
        "precision": 0.0026041666666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.680555555555556e-05,
        "hf_subset": "myk_Latn-eng_Latn",
        "languages": [
          "myk-Latn",
          "eng-Latn"
        ],
        "main_score": 8.680555555555556e-05,
        "precision": 4.3890449438202246e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010850694444444444,
        "hf_subset": "eng_Latn-myu_Latn",
        "languages": [
          "eng-Latn",
          "myu-Latn"
        ],
        "main_score": 0.010850694444444444,
        "precision": 0.008693321078431373,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010488340978593271,
        "hf_subset": "myu_Latn-eng_Latn",
        "languages": [
          "myu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010488340978593271,
        "precision": 0.008629918981481481,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00783110119047619,
        "hf_subset": "eng_Latn-myw_Latn",
        "languages": [
          "eng-Latn",
          "myw-Latn"
        ],
        "main_score": 0.00783110119047619,
        "precision": 0.006562086640211641,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01015625,
        "hf_subset": "myw_Latn-eng_Latn",
        "languages": [
          "myw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01015625,
        "precision": 0.00932017543859649,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0104421977124183,
        "hf_subset": "eng_Latn-myy_Latn",
        "languages": [
          "eng-Latn",
          "myy-Latn"
        ],
        "main_score": 0.0104421977124183,
        "precision": 0.008544921875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.008941139894015558,
        "hf_subset": "myy_Latn-eng_Latn",
        "languages": [
          "myy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008941139894015558,
        "precision": 0.0069022547877846795,
        "recall": 0.03125
      },
      {
        "accuracy": 0.032,
        "f1": 0.026666666666666665,
        "hf_subset": "eng_Latn-mzz_Latn",
        "languages": [
          "eng-Latn",
          "mzz-Latn"
        ],
        "main_score": 0.026666666666666665,
        "precision": 0.024,
        "recall": 0.032
      },
      {
        "accuracy": 0.032,
        "f1": 0.01682962962962963,
        "hf_subset": "mzz_Latn-eng_Latn",
        "languages": [
          "mzz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01682962962962963,
        "precision": 0.016426805465191933,
        "recall": 0.032
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006928733031674208,
        "hf_subset": "eng_Latn-nab_Latn",
        "languages": [
          "eng-Latn",
          "nab-Latn"
        ],
        "main_score": 0.0006928733031674208,
        "precision": 0.0003720238095238095,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0001813042485153038,
        "hf_subset": "nab_Latn-eng_Latn",
        "languages": [
          "nab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001813042485153038,
        "precision": 9.206649831649832e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006939935064935065,
        "hf_subset": "eng_Latn-naf_Latn",
        "languages": [
          "eng-Latn",
          "naf-Latn"
        ],
        "main_score": 0.006939935064935065,
        "precision": 0.004417782738095238,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "naf_Latn-eng_Latn",
        "languages": [
          "naf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012514467592592593,
        "hf_subset": "eng_Latn-nak_Latn",
        "languages": [
          "eng-Latn",
          "nak-Latn"
        ],
        "main_score": 0.012514467592592593,
        "precision": 0.011141411163522014,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002864583333333333,
        "hf_subset": "nak_Latn-eng_Latn",
        "languages": [
          "nak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002864583333333333,
        "precision": 0.002087823275862069,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012404343263718262,
        "hf_subset": "eng_Latn-nas_Latn",
        "languages": [
          "eng-Latn",
          "nas-Latn"
        ],
        "main_score": 0.012404343263718262,
        "precision": 0.009558718607305935,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012008101851851851,
        "hf_subset": "nas_Latn-eng_Latn",
        "languages": [
          "nas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012008101851851851,
        "precision": 0.011868990384615384,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014929898227690967,
        "hf_subset": "eng_Latn-nbq_Latn",
        "languages": [
          "eng-Latn",
          "nbq-Latn"
        ],
        "main_score": 0.014929898227690967,
        "precision": 0.012453567482864358,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0109375,
        "hf_subset": "nbq_Latn-eng_Latn",
        "languages": [
          "nbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0109375,
        "precision": 0.010044642857142856,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008662683823529412,
        "hf_subset": "eng_Latn-nca_Latn",
        "languages": [
          "eng-Latn",
          "nca-Latn"
        ],
        "main_score": 0.008662683823529412,
        "precision": 0.007146285752118644,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006584821428571428,
        "hf_subset": "nca_Latn-eng_Latn",
        "languages": [
          "nca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006584821428571428,
        "precision": 0.005896935096153846,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004680205415499533,
        "hf_subset": "eng_Latn-nch_Latn",
        "languages": [
          "eng-Latn",
          "nch-Latn"
        ],
        "main_score": 0.004680205415499533,
        "precision": 0.0031389508928571425,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004856612278487278,
        "hf_subset": "nch_Latn-eng_Latn",
        "languages": [
          "nch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004856612278487278,
        "precision": 0.003240083122895623,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014583333333333332,
        "hf_subset": "eng_Latn-ncj_Latn",
        "languages": [
          "eng-Latn",
          "ncj-Latn"
        ],
        "main_score": 0.014583333333333332,
        "precision": 0.0126953125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007373583139267437,
        "hf_subset": "ncj_Latn-eng_Latn",
        "languages": [
          "ncj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007373583139267437,
        "precision": 0.004743276000494071,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017138543390841185,
        "hf_subset": "eng_Latn-ncl_Latn",
        "languages": [
          "eng-Latn",
          "ncl-Latn"
        ],
        "main_score": 0.017138543390841185,
        "precision": 0.014235888817755015,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01184141002415459,
        "hf_subset": "ncl_Latn-eng_Latn",
        "languages": [
          "ncl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01184141002415459,
        "precision": 0.010181873211534229,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00048828125,
        "hf_subset": "eng_Latn-ncu_Latn",
        "languages": [
          "eng-Latn",
          "ncu-Latn"
        ],
        "main_score": 0.00048828125,
        "precision": 0.00026041666666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0007896387721755369,
        "hf_subset": "ncu_Latn-eng_Latn",
        "languages": [
          "ncu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007896387721755369,
        "precision": 0.0004131310802648892,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016666666666666663,
        "hf_subset": "eng_Latn-ndg_Latn",
        "languages": [
          "eng-Latn",
          "ndg-Latn"
        ],
        "main_score": 0.016666666666666663,
        "precision": 0.015082465277777778,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005738146551724138,
        "hf_subset": "ndg_Latn-eng_Latn",
        "languages": [
          "ndg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005738146551724138,
        "precision": 0.005022321428571428,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0034271559233449477,
        "hf_subset": "eng_Latn-ndj_Latn",
        "languages": [
          "eng-Latn",
          "ndj-Latn"
        ],
        "main_score": 0.0034271559233449477,
        "precision": 0.002025741185897436,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "ndj_Latn-eng_Latn",
        "languages": [
          "ndj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008686755952380953,
        "hf_subset": "eng_Latn-nfa_Latn",
        "languages": [
          "eng-Latn",
          "nfa-Latn"
        ],
        "main_score": 0.008686755952380953,
        "precision": 0.0057370580808080805,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006634424603174603,
        "hf_subset": "nfa_Latn-eng_Latn",
        "languages": [
          "nfa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006634424603174603,
        "precision": 0.005476262019230769,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005814830043859649,
        "hf_subset": "eng_Latn-ngp_Latn",
        "languages": [
          "eng-Latn",
          "ngp-Latn"
        ],
        "main_score": 0.005814830043859649,
        "precision": 0.004223424145299145,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "ngp_Latn-eng_Latn",
        "languages": [
          "ngp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0114220906760922,
        "hf_subset": "eng_Latn-ngu_Latn",
        "languages": [
          "eng-Latn",
          "ngu-Latn"
        ],
        "main_score": 0.0114220906760922,
        "precision": 0.008468191964285714,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012296195652173913,
        "hf_subset": "ngu_Latn-eng_Latn",
        "languages": [
          "ngu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012296195652173913,
        "precision": 0.012026280630865485,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02531974749654025,
        "hf_subset": "eng_Latn-nhe_Latn",
        "languages": [
          "eng-Latn",
          "nhe-Latn"
        ],
        "main_score": 0.02531974749654025,
        "precision": 0.023336046006944444,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011946099537566306,
        "hf_subset": "nhe_Latn-eng_Latn",
        "languages": [
          "nhe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011946099537566306,
        "precision": 0.0103380616359447,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017708333333333333,
        "hf_subset": "eng_Latn-nhg_Latn",
        "languages": [
          "eng-Latn",
          "nhg-Latn"
        ],
        "main_score": 0.017708333333333333,
        "precision": 0.014105902777777778,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006830536701860231,
        "hf_subset": "nhg_Latn-eng_Latn",
        "languages": [
          "nhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006830536701860231,
        "precision": 0.004798177083333334,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013361791237113401,
        "hf_subset": "eng_Latn-nhi_Latn",
        "languages": [
          "eng-Latn",
          "nhi-Latn"
        ],
        "main_score": 0.013361791237113401,
        "precision": 0.010262044270833333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010061043906810035,
        "hf_subset": "nhi_Latn-eng_Latn",
        "languages": [
          "nhi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010061043906810035,
        "precision": 0.0083105045995671,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.048883928571428564,
        "hf_subset": "eng_Latn-nho_Latn",
        "languages": [
          "eng-Latn",
          "nho-Latn"
        ],
        "main_score": 0.048883928571428564,
        "precision": 0.04132326007326008,
        "recall": 0.078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04241798782814408,
        "hf_subset": "nho_Latn-eng_Latn",
        "languages": [
          "nho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04241798782814408,
        "precision": 0.04099220261121857,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009405461108908272,
        "hf_subset": "eng_Latn-nhr_Latn",
        "languages": [
          "eng-Latn",
          "nhr-Latn"
        ],
        "main_score": 0.009405461108908272,
        "precision": 0.007166637073863637,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011913895232657722,
        "hf_subset": "nhr_Latn-eng_Latn",
        "languages": [
          "nhr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011913895232657722,
        "precision": 0.011817664117388759,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006882102272727272,
        "hf_subset": "eng_Latn-nhu_Latn",
        "languages": [
          "eng-Latn",
          "nhu-Latn"
        ],
        "main_score": 0.006882102272727272,
        "precision": 0.004589843749999999,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013908617424242423,
        "hf_subset": "nhu_Latn-eng_Latn",
        "languages": [
          "nhu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013908617424242423,
        "precision": 0.0008261494252873563,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009038606639839034,
        "hf_subset": "eng_Latn-nhw_Latn",
        "languages": [
          "eng-Latn",
          "nhw-Latn"
        ],
        "main_score": 0.009038606639839034,
        "precision": 0.007347470238095238,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004097202139965298,
        "hf_subset": "nhw_Latn-eng_Latn",
        "languages": [
          "nhw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004097202139965298,
        "precision": 0.002470999053030303,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01672273612765535,
        "hf_subset": "eng_Latn-nhy_Latn",
        "languages": [
          "eng-Latn",
          "nhy-Latn"
        ],
        "main_score": 0.01672273612765535,
        "precision": 0.013252643623737374,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004417044860301807,
        "hf_subset": "nhy_Latn-eng_Latn",
        "languages": [
          "nhy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004417044860301807,
        "precision": 0.0041684439355842914,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015220377934557168,
        "hf_subset": "eng_Latn-nif_Latn",
        "languages": [
          "eng-Latn",
          "nif-Latn"
        ],
        "main_score": 0.015220377934557168,
        "precision": 0.013856044573737965,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02081592075647782,
        "hf_subset": "nif_Latn-eng_Latn",
        "languages": [
          "nif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02081592075647782,
        "precision": 0.017837160021292563,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007371794871794872,
        "hf_subset": "eng_Latn-nii_Latn",
        "languages": [
          "eng-Latn",
          "nii-Latn"
        ],
        "main_score": 0.007371794871794872,
        "precision": 0.005208333333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003957312091503268,
        "hf_subset": "nii_Latn-eng_Latn",
        "languages": [
          "nii-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003957312091503268,
        "precision": 0.003931949013157895,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01525297619047619,
        "hf_subset": "eng_Latn-nin_Latn",
        "languages": [
          "eng-Latn",
          "nin-Latn"
        ],
        "main_score": 0.01525297619047619,
        "precision": 0.013165509259259259,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "nin_Latn-eng_Latn",
        "languages": [
          "nin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007820396731805929,
        "hf_subset": "eng_Latn-nko_Latn",
        "languages": [
          "eng-Latn",
          "nko-Latn"
        ],
        "main_score": 0.007820396731805929,
        "precision": 0.006587805296837309,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004575083291160594,
        "hf_subset": "nko_Latn-eng_Latn",
        "languages": [
          "nko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004575083291160594,
        "precision": 0.0042511860264519835,
        "recall": 0.015625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.03979952658146592,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ],
        "main_score": 0.03979952658146592,
        "precision": 0.03201714483750497,
        "recall": 0.078125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.058750717940685045,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.058750717940685045,
        "precision": 0.051193576388888884,
        "recall": 0.09375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.06632450266290726,
        "hf_subset": "eng_Latn-nlg_Latn",
        "languages": [
          "eng-Latn",
          "nlg-Latn"
        ],
        "main_score": 0.06632450266290726,
        "precision": 0.05888545048701299,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04694505455214122,
        "hf_subset": "nlg_Latn-eng_Latn",
        "languages": [
          "nlg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04694505455214122,
        "precision": 0.044094081761492473,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.12121931510518466,
        "hf_subset": "eng_Latn-nna_Latn",
        "languages": [
          "eng-Latn",
          "nna-Latn"
        ],
        "main_score": 0.12121931510518466,
        "precision": 0.11148064175407925,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.09093199608824609,
        "hf_subset": "nna_Latn-eng_Latn",
        "languages": [
          "nna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09093199608824609,
        "precision": 0.08425397302350428,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003693409455128205,
        "hf_subset": "eng_Latn-nnq_Latn",
        "languages": [
          "eng-Latn",
          "nnq-Latn"
        ],
        "main_score": 0.003693409455128205,
        "precision": 0.0025390625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002129934210526316,
        "hf_subset": "nnq_Latn-eng_Latn",
        "languages": [
          "nnq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002129934210526316,
        "precision": 0.0012732957766439911,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0021372560877277857,
        "hf_subset": "eng_Latn-noa_Latn",
        "languages": [
          "eng-Latn",
          "noa-Latn"
        ],
        "main_score": 0.0021372560877277857,
        "precision": 0.0011679401327838828,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013467989935700307,
        "hf_subset": "noa_Latn-eng_Latn",
        "languages": [
          "noa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013467989935700307,
        "precision": 0.012789836590778923,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007692571271929825,
        "hf_subset": "eng_Latn-nop_Latn",
        "languages": [
          "eng-Latn",
          "nop-Latn"
        ],
        "main_score": 0.007692571271929825,
        "precision": 0.006522985038610038,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004340277777777778,
        "hf_subset": "nop_Latn-eng_Latn",
        "languages": [
          "nop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004340277777777778,
        "precision": 0.004136029411764706,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-not_Latn",
        "languages": [
          "eng-Latn",
          "not-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002170138888888889,
        "hf_subset": "not_Latn-eng_Latn",
        "languages": [
          "not-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002170138888888889,
        "precision": 0.0014136904761904762,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.035297287195394586,
        "hf_subset": "eng_Latn-nou_Latn",
        "languages": [
          "eng-Latn",
          "nou-Latn"
        ],
        "main_score": 0.035297287195394586,
        "precision": 0.031578284996253744,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03481024184149184,
        "hf_subset": "nou_Latn-eng_Latn",
        "languages": [
          "nou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03481024184149184,
        "precision": 0.032412574404761904,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01306733630952381,
        "hf_subset": "eng_Latn-npl_Latn",
        "languages": [
          "eng-Latn",
          "npl-Latn"
        ],
        "main_score": 0.01306733630952381,
        "precision": 0.011170014880952381,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0074745783730158725,
        "hf_subset": "npl_Latn-eng_Latn",
        "languages": [
          "npl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0074745783730158725,
        "precision": 0.00536813446969697,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023190384184587815,
        "hf_subset": "eng_Latn-nsn_Latn",
        "languages": [
          "eng-Latn",
          "nsn-Latn"
        ],
        "main_score": 0.023190384184587815,
        "precision": 0.01921037946428571,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009885817307692307,
        "hf_subset": "nsn_Latn-eng_Latn",
        "languages": [
          "nsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009885817307692307,
        "precision": 0.009175618489583334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014324048913043477,
        "hf_subset": "eng_Latn-nss_Latn",
        "languages": [
          "eng-Latn",
          "nss-Latn"
        ],
        "main_score": 0.014324048913043477,
        "precision": 0.01124230587121212,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014883814102564102,
        "hf_subset": "nss_Latn-eng_Latn",
        "languages": [
          "nss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014883814102564102,
        "precision": 0.011549479166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-ntj_Latn",
        "languages": [
          "eng-Latn",
          "ntj-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00028935185185185184,
        "hf_subset": "ntj_Latn-eng_Latn",
        "languages": [
          "ntj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00028935185185185184,
        "precision": 0.00015024038461538462,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01022518382352941,
        "hf_subset": "eng_Latn-ntp_Latn",
        "languages": [
          "eng-Latn",
          "ntp-Latn"
        ],
        "main_score": 0.01022518382352941,
        "precision": 0.008133471629140786,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007852157360406092,
        "hf_subset": "ntp_Latn-eng_Latn",
        "languages": [
          "ntp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007852157360406092,
        "precision": 0.007832429846938774,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008088699494949494,
        "hf_subset": "eng_Latn-ntu_Latn",
        "languages": [
          "eng-Latn",
          "ntu-Latn"
        ],
        "main_score": 0.008088699494949494,
        "precision": 0.00673828125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.228305785123967e-05,
        "hf_subset": "ntu_Latn-eng_Latn",
        "languages": [
          "ntu-Latn",
          "eng-Latn"
        ],
        "main_score": 3.228305785123967e-05,
        "precision": 1.620850622406639e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012453671956635317,
        "hf_subset": "eng_Latn-nuy_Latn",
        "languages": [
          "eng-Latn",
          "nuy-Latn"
        ],
        "main_score": 0.012453671956635317,
        "precision": 0.008481061392580288,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008964082792207792,
        "hf_subset": "nuy_Latn-eng_Latn",
        "languages": [
          "nuy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008964082792207792,
        "precision": 0.008481378424657534,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0029947916666666664,
        "hf_subset": "eng_Latn-nvm_Latn",
        "languages": [
          "eng-Latn",
          "nvm-Latn"
        ],
        "main_score": 0.0029947916666666664,
        "precision": 0.0018601190476190475,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00043402777777777775,
        "hf_subset": "nvm_Latn-eng_Latn",
        "languages": [
          "nvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00043402777777777775,
        "precision": 0.00022977941176470588,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012517197327044025,
        "hf_subset": "eng_Latn-nwi_Latn",
        "languages": [
          "eng-Latn",
          "nwi-Latn"
        ],
        "main_score": 0.012517197327044025,
        "precision": 0.010977108828671329,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008708639705882353,
        "hf_subset": "nwi_Latn-eng_Latn",
        "languages": [
          "nwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008708639705882353,
        "precision": 0.008304830016583747,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009926835317460317,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ],
        "main_score": 0.009926835317460317,
        "precision": 0.006763026725113122,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005237926136363636,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005237926136363636,
        "precision": 0.004650297619047619,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.13934426229508196,
        "f1": 0.09223039374500529,
        "hf_subset": "eng_Latn-nys_Latn",
        "languages": [
          "eng-Latn",
          "nys-Latn"
        ],
        "main_score": 0.09223039374500529,
        "precision": 0.08118834717195372,
        "recall": 0.13934426229508196
      },
      {
        "accuracy": 0.11475409836065574,
        "f1": 0.07970690511674117,
        "hf_subset": "nys_Latn-eng_Latn",
        "languages": [
          "nys-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07970690511674117,
        "precision": 0.07419984387197502,
        "recall": 0.11475409836065574
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008635265700483091,
        "hf_subset": "eng_Latn-nyu_Latn",
        "languages": [
          "eng-Latn",
          "nyu-Latn"
        ],
        "main_score": 0.008635265700483091,
        "precision": 0.005348915407509158,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0052399976839789236,
        "hf_subset": "nyu_Latn-eng_Latn",
        "languages": [
          "nyu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0052399976839789236,
        "precision": 0.004609119689542484,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010656242971210077,
        "hf_subset": "eng_Latn-obo_Latn",
        "languages": [
          "eng-Latn",
          "obo-Latn"
        ],
        "main_score": 0.010656242971210077,
        "precision": 0.008059106691919192,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005914701617826618,
        "hf_subset": "obo_Latn-eng_Latn",
        "languages": [
          "obo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005914701617826618,
        "precision": 0.0038881655092592596,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.07702901082835292,
        "hf_subset": "eng_Latn-okv_Latn",
        "languages": [
          "eng-Latn",
          "okv-Latn"
        ],
        "main_score": 0.07702901082835292,
        "precision": 0.06484077128271631,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.10054979200487013,
        "hf_subset": "okv_Latn-eng_Latn",
        "languages": [
          "okv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10054979200487013,
        "precision": 0.09237329434697855,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016741071428571428,
        "hf_subset": "eng_Latn-omw_Latn",
        "languages": [
          "eng-Latn",
          "omw-Latn"
        ],
        "main_score": 0.0016741071428571428,
        "precision": 0.0009765625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "omw_Latn-eng_Latn",
        "languages": [
          "omw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010778544372294372,
        "hf_subset": "eng_Latn-ong_Latn",
        "languages": [
          "eng-Latn",
          "ong-Latn"
        ],
        "main_score": 0.010778544372294372,
        "precision": 0.00962171052631579,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00768449858757062,
        "hf_subset": "ong_Latn-eng_Latn",
        "languages": [
          "ong-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00768449858757062,
        "precision": 0.005384189415708812,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017788461538461538,
        "hf_subset": "eng_Latn-ons_Latn",
        "languages": [
          "eng-Latn",
          "ons-Latn"
        ],
        "main_score": 0.017788461538461538,
        "precision": 0.012499999999999997,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009224618544600938,
        "hf_subset": "ons_Latn-eng_Latn",
        "languages": [
          "ons-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009224618544600938,
        "precision": 0.007868303571428571,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029541802402970434,
        "hf_subset": "eng_Latn-ood_Latn",
        "languages": [
          "eng-Latn",
          "ood-Latn"
        ],
        "main_score": 0.029541802402970434,
        "precision": 0.025423177083333335,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014920778006715506,
        "hf_subset": "ood_Latn-eng_Latn",
        "languages": [
          "ood-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014920778006715506,
        "precision": 0.013610119047619048,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009830729166666666,
        "hf_subset": "eng_Latn-opm_Latn",
        "languages": [
          "eng-Latn",
          "opm-Latn"
        ],
        "main_score": 0.009830729166666666,
        "precision": 0.007828000992063492,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030637254901960784,
        "hf_subset": "opm_Latn-eng_Latn",
        "languages": [
          "opm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030637254901960784,
        "precision": 0.002197265625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0028211805555555555,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0028211805555555555,
        "precision": 0.0017903645833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00022283572309589886,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.00022283572309589886,
        "precision": 0.00011343125198349729,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005971184329710145,
        "hf_subset": "eng_Latn-ote_Latn",
        "languages": [
          "eng-Latn",
          "ote-Latn"
        ],
        "main_score": 0.005971184329710145,
        "precision": 0.0036297686688311686,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005545104050538833,
        "hf_subset": "ote_Latn-eng_Latn",
        "languages": [
          "ote-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005545104050538833,
        "precision": 0.004806857638888888,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013102213541666668,
        "hf_subset": "eng_Latn-otm_Latn",
        "languages": [
          "eng-Latn",
          "otm-Latn"
        ],
        "main_score": 0.013102213541666668,
        "precision": 0.009285910087719298,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006076388888888888,
        "hf_subset": "otm_Latn-eng_Latn",
        "languages": [
          "otm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006076388888888888,
        "precision": 0.00517578125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014979054368580847,
        "hf_subset": "eng_Latn-otn_Latn",
        "languages": [
          "eng-Latn",
          "otn-Latn"
        ],
        "main_score": 0.014979054368580847,
        "precision": 0.01283906843369759,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007086833003952568,
        "hf_subset": "otn_Latn-eng_Latn",
        "languages": [
          "otn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007086833003952568,
        "precision": 0.006159002130681818,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009765625,
        "hf_subset": "eng_Latn-otq_Latn",
        "languages": [
          "eng-Latn",
          "otq-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.007693507090336134,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0118408203125,
        "hf_subset": "otq_Latn-eng_Latn",
        "languages": [
          "otq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0118408203125,
        "precision": 0.011780753968253968,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.00827653956475288,
        "hf_subset": "eng_Latn-ots_Latn",
        "languages": [
          "eng-Latn",
          "ots-Latn"
        ],
        "main_score": 0.00827653956475288,
        "precision": 0.005349269057765151,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.003983014246497539,
        "hf_subset": "ots_Latn-eng_Latn",
        "languages": [
          "ots-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003983014246497539,
        "precision": 0.002337953976880607,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0091878007852077,
        "hf_subset": "eng_Latn-pab_Latn",
        "languages": [
          "eng-Latn",
          "pab-Latn"
        ],
        "main_score": 0.0091878007852077,
        "precision": 0.006027760358602749,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012833414615846337,
        "hf_subset": "pab_Latn-eng_Latn",
        "languages": [
          "pab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012833414615846337,
        "precision": 0.011184314673466594,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006584821428571428,
        "hf_subset": "eng_Latn-pad_Latn",
        "languages": [
          "eng-Latn",
          "pad-Latn"
        ],
        "main_score": 0.006584821428571428,
        "precision": 0.005483774038461538,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004997444352210539,
        "hf_subset": "pad_Latn-eng_Latn",
        "languages": [
          "pad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004997444352210539,
        "precision": 0.0031877730711849955,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016292735042735043,
        "hf_subset": "eng_Latn-pah_Latn",
        "languages": [
          "eng-Latn",
          "pah-Latn"
        ],
        "main_score": 0.0016292735042735043,
        "precision": 0.0010102370689655173,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007779947916666667,
        "hf_subset": "pah_Latn-eng_Latn",
        "languages": [
          "pah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007779947916666667,
        "precision": 0.005143229166666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007846320346320346,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.0007846320346320346,
        "precision": 0.00042818509615384615,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.030092592592592594,
        "hf_subset": "eng_Latn-pao_Latn",
        "languages": [
          "eng-Latn",
          "pao-Latn"
        ],
        "main_score": 0.030092592592592594,
        "precision": 0.028068494496855344,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.024077654682274248,
        "hf_subset": "pao_Latn-eng_Latn",
        "languages": [
          "pao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024077654682274248,
        "precision": 0.02377130681818182,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0029994419642857145,
        "hf_subset": "eng_Latn-pes_Arab",
        "languages": [
          "eng-Latn",
          "pes-Arab"
        ],
        "main_score": 0.0029994419642857145,
        "precision": 0.0018552834440227703,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.0730519480519484e-05,
        "hf_subset": "pes_Arab-eng_Latn",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 5.0730519480519484e-05,
        "precision": 2.5531045751633988e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007529254599567098,
        "hf_subset": "eng_Latn-pib_Latn",
        "languages": [
          "eng-Latn",
          "pib-Latn"
        ],
        "main_score": 0.007529254599567098,
        "precision": 0.0053979086845466154,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006712299311926605,
        "hf_subset": "pib_Latn-eng_Latn",
        "languages": [
          "pib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006712299311926605,
        "precision": 0.005678530092592593,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01023065476190476,
        "hf_subset": "eng_Latn-pio_Latn",
        "languages": [
          "eng-Latn",
          "pio-Latn"
        ],
        "main_score": 0.01023065476190476,
        "precision": 0.009244791666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009567443964765393,
        "hf_subset": "pio_Latn-eng_Latn",
        "languages": [
          "pio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009567443964765393,
        "precision": 0.007568359375,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007572642543859648,
        "hf_subset": "eng_Latn-pir_Latn",
        "languages": [
          "eng-Latn",
          "pir-Latn"
        ],
        "main_score": 0.007572642543859648,
        "precision": 0.006206597222222222,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004600694444444445,
        "hf_subset": "pir_Latn-eng_Latn",
        "languages": [
          "pir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004600694444444445,
        "precision": 0.003159466911764706,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0028211805555555555,
        "hf_subset": "eng_Latn-piu_Latn",
        "languages": [
          "eng-Latn",
          "piu-Latn"
        ],
        "main_score": 0.0028211805555555555,
        "precision": 0.0017903645833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013706140350877192,
        "hf_subset": "piu_Latn-eng_Latn",
        "languages": [
          "piu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00013706140350877192,
        "precision": 6.975446428571428e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015807291666666667,
        "hf_subset": "eng_Latn-pjt_Latn",
        "languages": [
          "eng-Latn",
          "pjt-Latn"
        ],
        "main_score": 0.015807291666666667,
        "precision": 0.011715790719696969,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008928571428571428,
        "hf_subset": "pjt_Latn-eng_Latn",
        "languages": [
          "pjt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008928571428571428,
        "precision": 0.008463541666666666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.026767113095238094,
        "hf_subset": "eng_Latn-pls_Latn",
        "languages": [
          "eng-Latn",
          "pls-Latn"
        ],
        "main_score": 0.026767113095238094,
        "precision": 0.021809895833333332,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015257352941176472,
        "hf_subset": "pls_Latn-eng_Latn",
        "languages": [
          "pls-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015257352941176472,
        "precision": 0.012491319444444446,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008702256944444445,
        "hf_subset": "eng_Latn-plu_Latn",
        "languages": [
          "eng-Latn",
          "plu-Latn"
        ],
        "main_score": 0.008702256944444445,
        "precision": 0.0070631281271566594,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010686063218390805,
        "hf_subset": "plu_Latn-eng_Latn",
        "languages": [
          "plu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010686063218390805,
        "precision": 0.009905133928571428,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003993055555555555,
        "hf_subset": "eng_Latn-pma_Latn",
        "languages": [
          "eng-Latn",
          "pma-Latn"
        ],
        "main_score": 0.003993055555555555,
        "precision": 0.00244140625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011044864766081871,
        "hf_subset": "pma_Latn-eng_Latn",
        "languages": [
          "pma-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011044864766081871,
        "precision": 0.009819878472222222,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010859182688226806,
        "hf_subset": "eng_Latn-poe_Latn",
        "languages": [
          "eng-Latn",
          "poe-Latn"
        ],
        "main_score": 0.010859182688226806,
        "precision": 0.008412388392857142,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005271958320365183,
        "hf_subset": "poe_Latn-eng_Latn",
        "languages": [
          "poe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005271958320365183,
        "precision": 0.004684244791666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008818655303030302,
        "hf_subset": "eng_Latn-poh_Latn",
        "languages": [
          "eng-Latn",
          "poh-Latn"
        ],
        "main_score": 0.008818655303030302,
        "precision": 0.007347470238095238,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002566964285714286,
        "hf_subset": "poh_Latn-eng_Latn",
        "languages": [
          "poh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002566964285714286,
        "precision": 0.0015254799836601307,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022209821428571426,
        "hf_subset": "eng_Latn-poi_Latn",
        "languages": [
          "eng-Latn",
          "poi-Latn"
        ],
        "main_score": 0.022209821428571426,
        "precision": 0.018684895833333333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007979910714285714,
        "hf_subset": "poi_Latn-eng_Latn",
        "languages": [
          "poi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007979910714285714,
        "precision": 0.006424762378426171,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019481169871794872,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ],
        "main_score": 0.019481169871794872,
        "precision": 0.016861979166666666,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01047719995256167,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01047719995256167,
        "precision": 0.009488932291666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012761316724270352,
        "hf_subset": "eng_Latn-pon_Latn",
        "languages": [
          "eng-Latn",
          "pon-Latn"
        ],
        "main_score": 0.012761316724270352,
        "precision": 0.009933035714285714,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0045166015625,
        "hf_subset": "pon_Latn-eng_Latn",
        "languages": [
          "pon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0045166015625,
        "precision": 0.004228670634920635,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.08128009143634143,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ],
        "main_score": 0.08128009143634143,
        "precision": 0.07160517605110533,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.15625,
        "f1": 0.11169952876984127,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11169952876984127,
        "precision": 0.10045591153127917,
        "recall": 0.15625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00708219115497076,
        "hf_subset": "eng_Latn-poy_Latn",
        "languages": [
          "eng-Latn",
          "poy-Latn"
        ],
        "main_score": 0.00708219115497076,
        "precision": 0.005714088428932179,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00016983695652173913,
        "hf_subset": "poy_Latn-eng_Latn",
        "languages": [
          "poy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00016983695652173913,
        "precision": 8.680555555555556e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008663862179487178,
        "hf_subset": "eng_Latn-ppo_Latn",
        "languages": [
          "eng-Latn",
          "ppo-Latn"
        ],
        "main_score": 0.008663862179487178,
        "precision": 0.008270409688995214,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007936507936507936,
        "hf_subset": "ppo_Latn-eng_Latn",
        "languages": [
          "ppo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007936507936507936,
        "precision": 0.007875504032258064,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01584470136738906,
        "hf_subset": "eng_Latn-prf_Latn",
        "languages": [
          "eng-Latn",
          "prf-Latn"
        ],
        "main_score": 0.01584470136738906,
        "precision": 0.010842309816919192,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005005240583075336,
        "hf_subset": "prf_Latn-eng_Latn",
        "languages": [
          "prf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005005240583075336,
        "precision": 0.003367764044361526,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01953125,
        "hf_subset": "eng_Latn-pri_Latn",
        "languages": [
          "eng-Latn",
          "pri-Latn"
        ],
        "main_score": 0.01953125,
        "precision": 0.017057291666666665,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010260982789855072,
        "hf_subset": "pri_Latn-eng_Latn",
        "languages": [
          "pri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010260982789855072,
        "precision": 0.00845734126984127,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018291170634920632,
        "hf_subset": "eng_Latn-ptp_Latn",
        "languages": [
          "eng-Latn",
          "ptp-Latn"
        ],
        "main_score": 0.018291170634920632,
        "precision": 0.015950520833333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014371141975308642,
        "hf_subset": "ptp_Latn-eng_Latn",
        "languages": [
          "ptp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014371141975308642,
        "precision": 0.013696137422360248,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01118811987004104,
        "hf_subset": "eng_Latn-ptu_Latn",
        "languages": [
          "eng-Latn",
          "ptu-Latn"
        ],
        "main_score": 0.01118811987004104,
        "precision": 0.009885757688492064,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01668386399371069,
        "hf_subset": "ptu_Latn-eng_Latn",
        "languages": [
          "ptu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01668386399371069,
        "precision": 0.015183776801503093,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009450383771929824,
        "hf_subset": "eng_Latn-pwg_Latn",
        "languages": [
          "eng-Latn",
          "pwg-Latn"
        ],
        "main_score": 0.009450383771929824,
        "precision": 0.006432649113570166,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007926050665021254,
        "hf_subset": "pwg_Latn-eng_Latn",
        "languages": [
          "pwg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007926050665021254,
        "precision": 0.006615048363095238,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0101531498015873,
        "hf_subset": "eng_Latn-qub_Latn",
        "languages": [
          "eng-Latn",
          "qub-Latn"
        ],
        "main_score": 0.0101531498015873,
        "precision": 0.006527261397980244,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "qub_Latn-eng_Latn",
        "languages": [
          "qub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0043154553992796815,
        "hf_subset": "eng_Latn-quc_Latn",
        "languages": [
          "eng-Latn",
          "quc-Latn"
        ],
        "main_score": 0.0043154553992796815,
        "precision": 0.002491965868794326,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00017361111111111112,
        "hf_subset": "quc_Latn-eng_Latn",
        "languages": [
          "quc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00017361111111111112,
        "precision": 8.87784090909091e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012425595238095237,
        "hf_subset": "eng_Latn-quf_Latn",
        "languages": [
          "eng-Latn",
          "quf-Latn"
        ],
        "main_score": 0.012425595238095237,
        "precision": 0.009860899390243903,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016626602564102566,
        "hf_subset": "quf_Latn-eng_Latn",
        "languages": [
          "quf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016626602564102566,
        "precision": 0.0010272930194805195,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02145435202589808,
        "hf_subset": "eng_Latn-quh_Latn",
        "languages": [
          "eng-Latn",
          "quh-Latn"
        ],
        "main_score": 0.02145435202589808,
        "precision": 0.018097998566748565,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016262414056531702,
        "hf_subset": "quh_Latn-eng_Latn",
        "languages": [
          "quh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016262414056531702,
        "precision": 0.014356178841370072,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017717633928571425,
        "hf_subset": "eng_Latn-qul_Latn",
        "languages": [
          "eng-Latn",
          "qul-Latn"
        ],
        "main_score": 0.017717633928571425,
        "precision": 0.01488095238095238,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011214967757936508,
        "hf_subset": "qul_Latn-eng_Latn",
        "languages": [
          "qul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011214967757936508,
        "precision": 0.008705873842592592,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00308103354978355,
        "hf_subset": "eng_Latn-qup_Latn",
        "languages": [
          "eng-Latn",
          "qup-Latn"
        ],
        "main_score": 0.00308103354978355,
        "precision": 0.0018346404054916986,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.7741545893719805e-05,
        "hf_subset": "qup_Latn-eng_Latn",
        "languages": [
          "qup-Latn",
          "eng-Latn"
        ],
        "main_score": 3.7741545893719805e-05,
        "precision": 1.8962378640776697e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001171875,
        "hf_subset": "eng_Latn-qvc_Latn",
        "languages": [
          "eng-Latn",
          "qvc-Latn"
        ],
        "main_score": 0.001171875,
        "precision": 0.0006341314935064935,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001091452205882353,
        "hf_subset": "qvc_Latn-eng_Latn",
        "languages": [
          "qvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001091452205882353,
        "precision": 0.0006163379530916844,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021037625718390802,
        "hf_subset": "eng_Latn-qve_Latn",
        "languages": [
          "eng-Latn",
          "qve-Latn"
        ],
        "main_score": 0.021037625718390802,
        "precision": 0.018890487938596493,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0075917119565217395,
        "hf_subset": "qve_Latn-eng_Latn",
        "languages": [
          "qve-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0075917119565217395,
        "precision": 0.006271701388888888,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009678819444444445,
        "hf_subset": "eng_Latn-qvh_Latn",
        "languages": [
          "eng-Latn",
          "qvh-Latn"
        ],
        "main_score": 0.009678819444444445,
        "precision": 0.007825265522875817,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0018987035603715168,
        "hf_subset": "qvh_Latn-eng_Latn",
        "languages": [
          "qvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0018987035603715168,
        "precision": 0.0010951450892857143,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017159598214285712,
        "hf_subset": "eng_Latn-qvm_Latn",
        "languages": [
          "eng-Latn",
          "qvm-Latn"
        ],
        "main_score": 0.017159598214285712,
        "precision": 0.015181433150183148,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012958829365079364,
        "hf_subset": "qvm_Latn-eng_Latn",
        "languages": [
          "qvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012958829365079364,
        "precision": 0.012432795698924732,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014322916666666666,
        "hf_subset": "eng_Latn-qvn_Latn",
        "languages": [
          "eng-Latn",
          "qvn-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.012073863636363636,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011119471827192414,
        "hf_subset": "qvn_Latn-eng_Latn",
        "languages": [
          "qvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011119471827192414,
        "precision": 0.01013342201526695,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006603422619047618,
        "hf_subset": "eng_Latn-qvs_Latn",
        "languages": [
          "eng-Latn",
          "qvs-Latn"
        ],
        "main_score": 0.006603422619047618,
        "precision": 0.004701967592592593,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016369047619047617,
        "hf_subset": "qvs_Latn-eng_Latn",
        "languages": [
          "qvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016369047619047617,
        "precision": 0.0009300595238095238,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011560433496949244,
        "hf_subset": "eng_Latn-qvw_Latn",
        "languages": [
          "eng-Latn",
          "qvw-Latn"
        ],
        "main_score": 0.011560433496949244,
        "precision": 0.009185649420024419,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005106959013209013,
        "hf_subset": "qvw_Latn-eng_Latn",
        "languages": [
          "qvw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005106959013209013,
        "precision": 0.004550648384353741,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012483230744949496,
        "hf_subset": "eng_Latn-qvz_Latn",
        "languages": [
          "eng-Latn",
          "qvz-Latn"
        ],
        "main_score": 0.012483230744949496,
        "precision": 0.009602864583333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.70260663507109e-05,
        "hf_subset": "qvz_Latn-eng_Latn",
        "languages": [
          "qvz-Latn",
          "eng-Latn"
        ],
        "main_score": 3.70260663507109e-05,
        "precision": 1.8601190476190478e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005577256944444444,
        "hf_subset": "eng_Latn-qwh_Latn",
        "languages": [
          "eng-Latn",
          "qwh-Latn"
        ],
        "main_score": 0.005577256944444444,
        "precision": 0.00342157459574739,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.013671875,
        "hf_subset": "qwh_Latn-eng_Latn",
        "languages": [
          "qwh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013671875,
        "precision": 0.013020833333333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007031249999999999,
        "hf_subset": "eng_Latn-qxh_Latn",
        "languages": [
          "eng-Latn",
          "qxh-Latn"
        ],
        "main_score": 0.007031249999999999,
        "precision": 0.004557291666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010658482142857143,
        "hf_subset": "qxh_Latn-eng_Latn",
        "languages": [
          "qxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010658482142857143,
        "precision": 0.008319782362207451,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007725694444444445,
        "hf_subset": "eng_Latn-qxn_Latn",
        "languages": [
          "eng-Latn",
          "qxn-Latn"
        ],
        "main_score": 0.007725694444444445,
        "precision": 0.005391609768907563,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00898282490079365,
        "hf_subset": "qxn_Latn-eng_Latn",
        "languages": [
          "qxn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00898282490079365,
        "precision": 0.008454915679400387,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011410926823380867,
        "hf_subset": "eng_Latn-qxo_Latn",
        "languages": [
          "eng-Latn",
          "qxo-Latn"
        ],
        "main_score": 0.011410926823380867,
        "precision": 0.009070194128787878,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "qxo_Latn-eng_Latn",
        "languages": [
          "qxo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012955729166666667,
        "hf_subset": "eng_Latn-rai_Latn",
        "languages": [
          "eng-Latn",
          "rai-Latn"
        ],
        "main_score": 0.012955729166666667,
        "precision": 0.01119171626984127,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008849732327141382,
        "hf_subset": "rai_Latn-eng_Latn",
        "languages": [
          "rai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008849732327141382,
        "precision": 0.008376736111111113,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008043395748987854,
        "hf_subset": "eng_Latn-reg_Latn",
        "languages": [
          "eng-Latn",
          "reg-Latn"
        ],
        "main_score": 0.008043395748987854,
        "precision": 0.004839409722222222,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "reg_Latn-eng_Latn",
        "languages": [
          "reg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0014914772727272728,
        "hf_subset": "eng_Latn-rgu_Latn",
        "languages": [
          "eng-Latn",
          "rgu-Latn"
        ],
        "main_score": 0.0014914772727272728,
        "precision": 0.0008246527777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004464285714285714,
        "hf_subset": "rgu_Latn-eng_Latn",
        "languages": [
          "rgu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004464285714285714,
        "precision": 0.004206730769230769,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006716008771929824,
        "hf_subset": "eng_Latn-rkb_Latn",
        "languages": [
          "eng-Latn",
          "rkb-Latn"
        ],
        "main_score": 0.006716008771929824,
        "precision": 0.005964949324324324,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008567708333333333,
        "hf_subset": "rkb_Latn-eng_Latn",
        "languages": [
          "rkb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008567708333333333,
        "precision": 0.0072142454954954955,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010743071495538601,
        "hf_subset": "eng_Latn-rmc_Latn",
        "languages": [
          "eng-Latn",
          "rmc-Latn"
        ],
        "main_score": 0.010743071495538601,
        "precision": 0.008334312343358396,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013962729978354979,
        "hf_subset": "rmc_Latn-eng_Latn",
        "languages": [
          "rmc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013962729978354979,
        "precision": 0.010428390405491698,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007502480158730158,
        "hf_subset": "eng_Latn-rmy_Latn",
        "languages": [
          "eng-Latn",
          "rmy-Latn"
        ],
        "main_score": 0.007502480158730158,
        "precision": 0.006389635180995475,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017456896551724138,
        "hf_subset": "rmy_Latn-eng_Latn",
        "languages": [
          "rmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017456896551724138,
        "precision": 0.015569196428571429,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.037433491969901166,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ],
        "main_score": 0.037433491969901166,
        "precision": 0.03039031281218781,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02203596819670143,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02203596819670143,
        "precision": 0.019552951388888885,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008333859959555106,
        "hf_subset": "eng_Latn-roo_Latn",
        "languages": [
          "eng-Latn",
          "roo-Latn"
        ],
        "main_score": 0.008333859959555106,
        "precision": 0.00808306277056277,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006184895833333334,
        "hf_subset": "roo_Latn-eng_Latn",
        "languages": [
          "roo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006184895833333334,
        "precision": 0.005261990613553114,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02727105034722222,
        "hf_subset": "eng_Latn-rop_Latn",
        "languages": [
          "eng-Latn",
          "rop-Latn"
        ],
        "main_score": 0.02727105034722222,
        "precision": 0.02314498127880184,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012276785714285714,
        "hf_subset": "rop_Latn-eng_Latn",
        "languages": [
          "rop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012276785714285714,
        "precision": 0.012019230769230768,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007047164351851851,
        "hf_subset": "eng_Latn-row_Latn",
        "languages": [
          "eng-Latn",
          "row-Latn"
        ],
        "main_score": 0.007047164351851851,
        "precision": 0.005753849015567766,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004774305555555556,
        "hf_subset": "row_Latn-eng_Latn",
        "languages": [
          "row-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004774305555555556,
        "precision": 0.00439453125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008510044642857142,
        "hf_subset": "eng_Latn-rro_Latn",
        "languages": [
          "eng-Latn",
          "rro-Latn"
        ],
        "main_score": 0.008510044642857142,
        "precision": 0.005961681547619047,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004968475877192982,
        "hf_subset": "rro_Latn-eng_Latn",
        "languages": [
          "rro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004968475877192982,
        "precision": 0.003472222222222222,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004631696428571429,
        "hf_subset": "eng_Latn-ruf_Latn",
        "languages": [
          "eng-Latn",
          "ruf-Latn"
        ],
        "main_score": 0.004631696428571429,
        "precision": 0.0029296875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00022977941176470588,
        "hf_subset": "ruf_Latn-eng_Latn",
        "languages": [
          "ruf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00022977941176470588,
        "precision": 0.00011837121212121212,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02029676053113553,
        "hf_subset": "eng_Latn-rug_Latn",
        "languages": [
          "eng-Latn",
          "rug-Latn"
        ],
        "main_score": 0.02029676053113553,
        "precision": 0.016953125,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005508814102564102,
        "hf_subset": "rug_Latn-eng_Latn",
        "languages": [
          "rug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005508814102564102,
        "precision": 0.00484375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009545792748917748,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009545792748917748,
        "precision": 0.008753551136363636,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013020833333333333,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.0007102272727272727,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009824810606060606,
        "hf_subset": "eng_Latn-rwo_Latn",
        "languages": [
          "eng-Latn",
          "rwo-Latn"
        ],
        "main_score": 0.009824810606060606,
        "precision": 0.008984375000000001,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0035868226600985218,
        "hf_subset": "rwo_Latn-eng_Latn",
        "languages": [
          "rwo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035868226600985218,
        "precision": 0.002472876868770764,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0106363038003663,
        "hf_subset": "eng_Latn-sab_Latn",
        "languages": [
          "eng-Latn",
          "sab-Latn"
        ],
        "main_score": 0.0106363038003663,
        "precision": 0.008221052234299517,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007847850678733032,
        "hf_subset": "sab_Latn-eng_Latn",
        "languages": [
          "sab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007847850678733032,
        "precision": 0.007830255681818183,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005533854166666666,
        "hf_subset": "eng_Latn-san_Latn",
        "languages": [
          "eng-Latn",
          "san-Latn"
        ],
        "main_score": 0.005533854166666666,
        "precision": 0.003517316017316017,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00950028448879552,
        "hf_subset": "san_Latn-eng_Latn",
        "languages": [
          "san-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00950028448879552,
        "precision": 0.008749141483516484,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0069253663003663,
        "hf_subset": "eng_Latn-sbe_Latn",
        "languages": [
          "eng-Latn",
          "sbe-Latn"
        ],
        "main_score": 0.0069253663003663,
        "precision": 0.004242050438596491,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006658965155058904,
        "hf_subset": "sbe_Latn-eng_Latn",
        "languages": [
          "sbe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006658965155058904,
        "precision": 0.0056279874639249645,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011387310606060606,
        "hf_subset": "eng_Latn-sbk_Latn",
        "languages": [
          "eng-Latn",
          "sbk-Latn"
        ],
        "main_score": 0.011387310606060606,
        "precision": 0.008658854166666667,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008112980769230768,
        "hf_subset": "sbk_Latn-eng_Latn",
        "languages": [
          "sbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008112980769230768,
        "precision": 0.00796875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012109374999999999,
        "hf_subset": "eng_Latn-sbs_Latn",
        "languages": [
          "eng-Latn",
          "sbs-Latn"
        ],
        "main_score": 0.012109374999999999,
        "precision": 0.009267452628599975,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333332,
        "hf_subset": "sbs_Latn-eng_Latn",
        "languages": [
          "sbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.00859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009579613095238096,
        "hf_subset": "eng_Latn-seh_Latn",
        "languages": [
          "eng-Latn",
          "seh-Latn"
        ],
        "main_score": 0.009579613095238096,
        "precision": 0.0078125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003798363095238095,
        "hf_subset": "seh_Latn-eng_Latn",
        "languages": [
          "seh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003798363095238095,
        "precision": 0.0026436237373737375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01355038875598086,
        "hf_subset": "eng_Latn-sey_Latn",
        "languages": [
          "eng-Latn",
          "sey-Latn"
        ],
        "main_score": 0.01355038875598086,
        "precision": 0.011995860042735042,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012878466679968075,
        "hf_subset": "sey_Latn-eng_Latn",
        "languages": [
          "sey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012878466679968075,
        "precision": 0.010438611891385768,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.013624164154298082,
        "hf_subset": "eng_Latn-sgb_Latn",
        "languages": [
          "eng-Latn",
          "sgb-Latn"
        ],
        "main_score": 0.013624164154298082,
        "precision": 0.010242324888432307,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009226190476190475,
        "hf_subset": "sgb_Latn-eng_Latn",
        "languages": [
          "sgb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009226190476190475,
        "precision": 0.007348278985507246,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008420973557692307,
        "hf_subset": "eng_Latn-sgz_Latn",
        "languages": [
          "eng-Latn",
          "sgz-Latn"
        ],
        "main_score": 0.008420973557692307,
        "precision": 0.006180826822916667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007014448924731182,
        "hf_subset": "sgz_Latn-eng_Latn",
        "languages": [
          "sgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007014448924731182,
        "precision": 0.006119791666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03296703296703297,
        "f1": 0.013553113553113554,
        "hf_subset": "eng_Latn-shj_Latn",
        "languages": [
          "eng-Latn",
          "shj-Latn"
        ],
        "main_score": 0.013553113553113554,
        "precision": 0.008608058608058607,
        "recall": 0.03296703296703297
      },
      {
        "accuracy": 0.04395604395604396,
        "f1": 0.019623233908948195,
        "hf_subset": "shj_Latn-eng_Latn",
        "languages": [
          "shj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019623233908948195,
        "precision": 0.01715854154878545,
        "recall": 0.04395604395604396
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007120678800366299,
        "hf_subset": "eng_Latn-shp_Latn",
        "languages": [
          "eng-Latn",
          "shp-Latn"
        ],
        "main_score": 0.007120678800366299,
        "precision": 0.004268973214285714,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007743448217357415,
        "hf_subset": "shp_Latn-eng_Latn",
        "languages": [
          "shp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007743448217357415,
        "precision": 0.006510416666666667,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01292782738095238,
        "hf_subset": "eng_Latn-sim_Latn",
        "languages": [
          "eng-Latn",
          "sim-Latn"
        ],
        "main_score": 0.01292782738095238,
        "precision": 0.009458466880341881,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "sim_Latn-eng_Latn",
        "languages": [
          "sim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012930095818815329,
        "hf_subset": "eng_Latn-sja_Latn",
        "languages": [
          "eng-Latn",
          "sja-Latn"
        ],
        "main_score": 0.012930095818815329,
        "precision": 0.009162808641975308,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008343122252987004,
        "hf_subset": "sja_Latn-eng_Latn",
        "languages": [
          "sja-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008343122252987004,
        "precision": 0.008085134072751996,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016102430555555554,
        "hf_subset": "eng_Latn-sll_Latn",
        "languages": [
          "eng-Latn",
          "sll-Latn"
        ],
        "main_score": 0.016102430555555554,
        "precision": 0.014485677083333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006810897435897435,
        "hf_subset": "sll_Latn-eng_Latn",
        "languages": [
          "sll-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006810897435897435,
        "precision": 0.006015625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016953792735042734,
        "hf_subset": "eng_Latn-smk_Latn",
        "languages": [
          "eng-Latn",
          "smk-Latn"
        ],
        "main_score": 0.016953792735042734,
        "precision": 0.014067639802631579,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004645788239538239,
        "hf_subset": "smk_Latn-eng_Latn",
        "languages": [
          "smk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004645788239538239,
        "precision": 0.004289964212882039,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026381340579710144,
        "hf_subset": "eng_Latn-snc_Latn",
        "languages": [
          "eng-Latn",
          "snc-Latn"
        ],
        "main_score": 0.026381340579710144,
        "precision": 0.024049084595959596,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01134171195652174,
        "hf_subset": "snc_Latn-eng_Latn",
        "languages": [
          "snc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01134171195652174,
        "precision": 0.010260331354081354,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012116304855275442,
        "hf_subset": "eng_Latn-snn_Latn",
        "languages": [
          "eng-Latn",
          "snn-Latn"
        ],
        "main_score": 0.012116304855275442,
        "precision": 0.007803735977564102,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0004822270889487871,
        "hf_subset": "snn_Latn-eng_Latn",
        "languages": [
          "snn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004822270889487871,
        "precision": 0.000246303175990676,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006931963126159554,
        "hf_subset": "eng_Latn-snp_Latn",
        "languages": [
          "eng-Latn",
          "snp-Latn"
        ],
        "main_score": 0.006931963126159554,
        "precision": 0.00577620621565934,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013144687794672325,
        "hf_subset": "snp_Latn-eng_Latn",
        "languages": [
          "snp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013144687794672325,
        "precision": 0.012511160714285714,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.06428571428571428,
        "f1": 0.04005102040816326,
        "hf_subset": "eng_Latn-snx_Latn",
        "languages": [
          "eng-Latn",
          "snx-Latn"
        ],
        "main_score": 0.04005102040816326,
        "precision": 0.03554421768707483,
        "recall": 0.06428571428571428
      },
      {
        "accuracy": 0.06428571428571428,
        "f1": 0.03246598639455782,
        "hf_subset": "snx_Latn-eng_Latn",
        "languages": [
          "snx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03246598639455782,
        "precision": 0.026218820861678004,
        "recall": 0.06428571428571428
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008835565476190476,
        "hf_subset": "eng_Latn-sny_Latn",
        "languages": [
          "eng-Latn",
          "sny-Latn"
        ],
        "main_score": 0.008835565476190476,
        "precision": 0.007356770833333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007499992053199064,
        "hf_subset": "sny_Latn-eng_Latn",
        "languages": [
          "sny-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007499992053199064,
        "precision": 0.005382719494047618,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005991541353383459,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ],
        "main_score": 0.005991541353383459,
        "precision": 0.005074786324786325,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012178308823529412,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012178308823529412,
        "precision": 0.010791015625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-soq_Latn",
        "languages": [
          "eng-Latn",
          "soq-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "soq_Latn-eng_Latn",
        "languages": [
          "soq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004371279761904762,
        "hf_subset": "eng_Latn-soy_Latn",
        "languages": [
          "eng-Latn",
          "soy-Latn"
        ],
        "main_score": 0.004371279761904762,
        "precision": 0.002959280303030303,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.616898148148148e-05,
        "hf_subset": "soy_Latn-eng_Latn",
        "languages": [
          "soy-Latn",
          "eng-Latn"
        ],
        "main_score": 3.616898148148148e-05,
        "precision": 1.816860465116279e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.1036426875437675,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ],
        "main_score": 0.1036426875437675,
        "precision": 0.09303753439579929,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.15248088818860878,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.15248088818860878,
        "precision": 0.136927238343254,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000390625,
        "hf_subset": "eng_Latn-spl_Latn",
        "languages": [
          "eng-Latn",
          "spl-Latn"
        ],
        "main_score": 0.000390625,
        "precision": 0.00020559210526315788,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "spl_Latn-eng_Latn",
        "languages": [
          "spl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.026583880678708264,
        "hf_subset": "eng_Latn-spm_Latn",
        "languages": [
          "eng-Latn",
          "spm-Latn"
        ],
        "main_score": 0.026583880678708264,
        "precision": 0.022935312239622786,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.030584357398873524,
        "hf_subset": "spm_Latn-eng_Latn",
        "languages": [
          "spm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030584357398873524,
        "precision": 0.02600513432198722,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009188988095238094,
        "hf_subset": "eng_Latn-spp_Latn",
        "languages": [
          "eng-Latn",
          "spp-Latn"
        ],
        "main_score": 0.009188988095238094,
        "precision": 0.007486979166666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009717987804878049,
        "hf_subset": "spp_Latn-eng_Latn",
        "languages": [
          "spp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009717987804878049,
        "precision": 0.0005316840277777777,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013984375,
        "hf_subset": "eng_Latn-sps_Latn",
        "languages": [
          "eng-Latn",
          "sps-Latn"
        ],
        "main_score": 0.013984375,
        "precision": 0.01318359375,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0043108974358974355,
        "hf_subset": "sps_Latn-eng_Latn",
        "languages": [
          "sps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0043108974358974355,
        "precision": 0.004115287162162163,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004150390625,
        "hf_subset": "eng_Latn-spy_Latn",
        "languages": [
          "eng-Latn",
          "spy-Latn"
        ],
        "main_score": 0.004150390625,
        "precision": 0.004032258064516129,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0024660669191919195,
        "hf_subset": "spy_Latn-eng_Latn",
        "languages": [
          "spy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0024660669191919195,
        "precision": 0.0014204704271019678,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.021158854166666664,
        "hf_subset": "eng_Latn-sri_Latn",
        "languages": [
          "eng-Latn",
          "sri-Latn"
        ],
        "main_score": 0.021158854166666664,
        "precision": 0.019438244047619048,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007378513872485093,
        "hf_subset": "sri_Latn-eng_Latn",
        "languages": [
          "sri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007378513872485093,
        "precision": 0.0059064681743909685,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014657738095238095,
        "hf_subset": "eng_Latn-srm_Latn",
        "languages": [
          "eng-Latn",
          "srm-Latn"
        ],
        "main_score": 0.014657738095238095,
        "precision": 0.012352881493506492,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004050925925925926,
        "hf_subset": "srm_Latn-eng_Latn",
        "languages": [
          "srm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004050925925925926,
        "precision": 0.003979952830188679,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023473509996947497,
        "hf_subset": "eng_Latn-srn_Latn",
        "languages": [
          "eng-Latn",
          "srn-Latn"
        ],
        "main_score": 0.023473509996947497,
        "precision": 0.019291474128028407,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019507524707996403,
        "hf_subset": "srn_Latn-eng_Latn",
        "languages": [
          "srn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019507524707996403,
        "precision": 0.017139923878205128,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009947311046511628,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ],
        "main_score": 0.009947311046511628,
        "precision": 0.009207589285714284,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008009025621118012,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008009025621118012,
        "precision": 0.006740163143016404,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015293560606060606,
        "hf_subset": "eng_Latn-srq_Latn",
        "languages": [
          "eng-Latn",
          "srq-Latn"
        ],
        "main_score": 0.015293560606060606,
        "precision": 0.011783854166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019514606829573934,
        "hf_subset": "srq_Latn-eng_Latn",
        "languages": [
          "srq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019514606829573934,
        "precision": 0.01789331183862434,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01704840658573556,
        "hf_subset": "eng_Latn-ssd_Latn",
        "languages": [
          "eng-Latn",
          "ssd-Latn"
        ],
        "main_score": 0.01704840658573556,
        "precision": 0.014849652300824174,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005986842105263158,
        "hf_subset": "ssd_Latn-eng_Latn",
        "languages": [
          "ssd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005986842105263158,
        "precision": 0.005151147240990991,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00854838984204793,
        "hf_subset": "eng_Latn-ssg_Latn",
        "languages": [
          "eng-Latn",
          "ssg-Latn"
        ],
        "main_score": 0.00854838984204793,
        "precision": 0.006974552140567766,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007118055555555555,
        "hf_subset": "ssg_Latn-eng_Latn",
        "languages": [
          "ssg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007118055555555555,
        "precision": 0.0047774057539682535,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012454114016614014,
        "hf_subset": "eng_Latn-ssx_Latn",
        "languages": [
          "eng-Latn",
          "ssx-Latn"
        ],
        "main_score": 0.012454114016614014,
        "precision": 0.010915798611111112,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014380787037037036,
        "hf_subset": "ssx_Latn-eng_Latn",
        "languages": [
          "ssx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014380787037037036,
        "precision": 0.013701026119402986,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005918560606060606,
        "hf_subset": "eng_Latn-stp_Latn",
        "languages": [
          "eng-Latn",
          "stp-Latn"
        ],
        "main_score": 0.005918560606060606,
        "precision": 0.005078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "stp_Latn-eng_Latn",
        "languages": [
          "stp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006454613095238095,
        "hf_subset": "eng_Latn-sua_Latn",
        "languages": [
          "eng-Latn",
          "sua-Latn"
        ],
        "main_score": 0.006454613095238095,
        "precision": 0.004340277777777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003863324175824176,
        "hf_subset": "sua_Latn-eng_Latn",
        "languages": [
          "sua-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003863324175824176,
        "precision": 0.0001996527777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011632309173669468,
        "hf_subset": "eng_Latn-sue_Latn",
        "languages": [
          "eng-Latn",
          "sue-Latn"
        ],
        "main_score": 0.011632309173669468,
        "precision": 0.008991139069264069,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "sue_Latn-eng_Latn",
        "languages": [
          "sue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016276041666666665,
        "hf_subset": "eng_Latn-sus_Arab",
        "languages": [
          "eng-Latn",
          "sus-Arab"
        ],
        "main_score": 0.0016276041666666665,
        "precision": 0.0009510869565217392,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001179075460829493,
        "hf_subset": "sus_Arab-eng_Latn",
        "languages": [
          "sus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.001179075460829493,
        "precision": 0.0006827997967479674,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0017400568181818183,
        "hf_subset": "eng_Latn-suz_Latn",
        "languages": [
          "eng-Latn",
          "suz-Latn"
        ],
        "main_score": 0.0017400568181818183,
        "precision": 0.001067405523255814,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "suz_Latn-eng_Latn",
        "languages": [
          "suz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03204069683101228,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ],
        "main_score": 0.03204069683101228,
        "precision": 0.0280349775446185,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04828249007936508,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04828249007936508,
        "precision": 0.045063074945887446,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011657475490196079,
        "hf_subset": "eng_Latn-swh_Latn",
        "languages": [
          "eng-Latn",
          "swh-Latn"
        ],
        "main_score": 0.011657475490196079,
        "precision": 0.00873727509469697,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006115658068783069,
        "hf_subset": "swh_Latn-eng_Latn",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006115658068783069,
        "precision": 0.005338648482362592,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013702876984126984,
        "hf_subset": "eng_Latn-swp_Latn",
        "languages": [
          "eng-Latn",
          "swp-Latn"
        ],
        "main_score": 0.013702876984126984,
        "precision": 0.012858072916666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01716806750313889,
        "hf_subset": "swp_Latn-eng_Latn",
        "languages": [
          "swp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01716806750313889,
        "precision": 0.01543648818802462,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015531994047619048,
        "hf_subset": "eng_Latn-sxb_Latn",
        "languages": [
          "eng-Latn",
          "sxb-Latn"
        ],
        "main_score": 0.015531994047619048,
        "precision": 0.0133213141025641,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010001683186184685,
        "hf_subset": "sxb_Latn-eng_Latn",
        "languages": [
          "sxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010001683186184685,
        "precision": 0.009113077164064006,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016949152542372883,
        "hf_subset": "eng_Latn-tac_Latn",
        "languages": [
          "eng-Latn",
          "tac-Latn"
        ],
        "main_score": 0.0016949152542372883,
        "precision": 0.0010439116379310344,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000390625,
        "hf_subset": "tac_Latn-eng_Latn",
        "languages": [
          "tac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000390625,
        "precision": 0.00020559210526315788,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-taj_Deva",
        "languages": [
          "eng-Latn",
          "taj-Deva"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "taj_Deva-eng_Latn",
        "languages": [
          "taj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010557432432432433,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.00010557432432432433,
        "precision": 5.351027397260274e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010382564484126984,
        "hf_subset": "eng_Latn-tav_Latn",
        "languages": [
          "eng-Latn",
          "tav-Latn"
        ],
        "main_score": 0.010382564484126984,
        "precision": 0.008046283143939393,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002164351851851852,
        "hf_subset": "tav_Latn-eng_Latn",
        "languages": [
          "tav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002164351851851852,
        "precision": 0.0012895633012820513,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01157332251082251,
        "hf_subset": "eng_Latn-taw_Latn",
        "languages": [
          "eng-Latn",
          "taw-Latn"
        ],
        "main_score": 0.01157332251082251,
        "precision": 0.008829126602564102,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005272370218579235,
        "hf_subset": "taw_Latn-eng_Latn",
        "languages": [
          "taw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005272370218579235,
        "precision": 0.004719783057851239,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003198423766058147,
        "hf_subset": "eng_Latn-tbc_Latn",
        "languages": [
          "eng-Latn",
          "tbc-Latn"
        ],
        "main_score": 0.003198423766058147,
        "precision": 0.002265796326754386,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0037726709811441352,
        "hf_subset": "tbc_Latn-eng_Latn",
        "languages": [
          "tbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0037726709811441352,
        "precision": 0.0026305602477477478,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009802006740196078,
        "hf_subset": "eng_Latn-tbf_Latn",
        "languages": [
          "eng-Latn",
          "tbf-Latn"
        ],
        "main_score": 0.009802006740196078,
        "precision": 0.0074242001488095235,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014404296875,
        "hf_subset": "tbf_Latn-eng_Latn",
        "languages": [
          "tbf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014404296875,
        "precision": 0.012410910087719298,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0107421875,
        "hf_subset": "eng_Latn-tbg_Latn",
        "languages": [
          "eng-Latn",
          "tbg-Latn"
        ],
        "main_score": 0.0107421875,
        "precision": 0.008500744047619047,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011780753968253968,
        "hf_subset": "tbg_Latn-eng_Latn",
        "languages": [
          "tbg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011780753968253968,
        "precision": 0.000646951645869191,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009165313852813852,
        "hf_subset": "eng_Latn-tbo_Latn",
        "languages": [
          "eng-Latn",
          "tbo-Latn"
        ],
        "main_score": 0.009165313852813852,
        "precision": 0.007413736979166667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "tbo_Latn-eng_Latn",
        "languages": [
          "tbo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010491071428571428,
        "hf_subset": "eng_Latn-tbz_Latn",
        "languages": [
          "eng-Latn",
          "tbz-Latn"
        ],
        "main_score": 0.010491071428571428,
        "precision": 0.009440104166666668,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0042365049932131076,
        "hf_subset": "tbz_Latn-eng_Latn",
        "languages": [
          "tbz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0042365049932131076,
        "precision": 0.004077049595141701,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008101851851851851,
        "hf_subset": "eng_Latn-tca_Latn",
        "languages": [
          "eng-Latn",
          "tca-Latn"
        ],
        "main_score": 0.008101851851851851,
        "precision": 0.007962740384615384,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00045955882352941176,
        "hf_subset": "tca_Latn-eng_Latn",
        "languages": [
          "tca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00045955882352941176,
        "precision": 0.000244140625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03888888888888889,
        "hf_subset": "eng_Latn-tcs_Latn",
        "languages": [
          "eng-Latn",
          "tcs-Latn"
        ],
        "main_score": 0.03888888888888889,
        "precision": 0.03317987351190476,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012148373969288266,
        "hf_subset": "tcs_Latn-eng_Latn",
        "languages": [
          "tcs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012148373969288266,
        "precision": 0.00928742071071496,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.02956255276892745,
        "hf_subset": "eng_Latn-tcz_Latn",
        "languages": [
          "eng-Latn",
          "tcz-Latn"
        ],
        "main_score": 0.02956255276892745,
        "precision": 0.023704566478003977,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03759765625,
        "hf_subset": "tcz_Latn-eng_Latn",
        "languages": [
          "tcz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03759765625,
        "precision": 0.0328125,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02902462121212121,
        "hf_subset": "eng_Latn-tdt_Latn",
        "languages": [
          "eng-Latn",
          "tdt-Latn"
        ],
        "main_score": 0.02902462121212121,
        "precision": 0.02473457532051282,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014865451388888888,
        "hf_subset": "tdt_Latn-eng_Latn",
        "languages": [
          "tdt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014865451388888888,
        "precision": 0.012765066964285714,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333332,
        "hf_subset": "eng_Latn-tee_Latn",
        "languages": [
          "eng-Latn",
          "tee-Latn"
        ],
        "main_score": 0.007161458333333332,
        "precision": 0.005208333333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005580357142857143,
        "hf_subset": "tee_Latn-eng_Latn",
        "languages": [
          "tee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005580357142857143,
        "precision": 0.00030048076923076925,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011896306818181818,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.011896306818181818,
        "precision": 0.011809593023255814,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0014729398419203747,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.0014729398419203747,
        "precision": 0.0008140028156046591,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00868548768939394,
        "hf_subset": "eng_Latn-ter_Latn",
        "languages": [
          "eng-Latn",
          "ter-Latn"
        ],
        "main_score": 0.00868548768939394,
        "precision": 0.00828623670212766,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "ter_Latn-eng_Latn",
        "languages": [
          "ter-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012801001082251084,
        "hf_subset": "eng_Latn-tet_Latn",
        "languages": [
          "eng-Latn",
          "tet-Latn"
        ],
        "main_score": 0.012801001082251084,
        "precision": 0.009935897435897435,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0033733510296010297,
        "hf_subset": "tet_Latn-eng_Latn",
        "languages": [
          "tet-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0033733510296010297,
        "precision": 0.0023621127136752135,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.05997488839285714,
        "hf_subset": "eng_Latn-tew_Latn",
        "languages": [
          "eng-Latn",
          "tew-Latn"
        ],
        "main_score": 0.05997488839285714,
        "precision": 0.05280594673402578,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04750852890498304,
        "hf_subset": "tew_Latn-eng_Latn",
        "languages": [
          "tew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04750852890498304,
        "precision": 0.04242095750884814,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015206473214285714,
        "hf_subset": "eng_Latn-tfr_Latn",
        "languages": [
          "eng-Latn",
          "tfr-Latn"
        ],
        "main_score": 0.015206473214285714,
        "precision": 0.014142192725752508,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00411047286047286,
        "hf_subset": "tfr_Latn-eng_Latn",
        "languages": [
          "tfr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00411047286047286,
        "precision": 0.004009748931623931,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012360368695175438,
        "hf_subset": "eng_Latn-tgl_Latn",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ],
        "main_score": 0.012360368695175438,
        "precision": 0.009635866695468509,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010308323382771913,
        "hf_subset": "tgl_Latn-eng_Latn",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010308323382771913,
        "precision": 0.009393679237429238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01877650638907248,
        "hf_subset": "eng_Latn-tgo_Latn",
        "languages": [
          "eng-Latn",
          "tgo-Latn"
        ],
        "main_score": 0.01877650638907248,
        "precision": 0.016694779829545457,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009223090277777778,
        "hf_subset": "tgo_Latn-eng_Latn",
        "languages": [
          "tgo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009223090277777778,
        "precision": 0.0004901960784313725,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.05461977965799297,
        "hf_subset": "eng_Latn-tgp_Latn",
        "languages": [
          "eng-Latn",
          "tgp-Latn"
        ],
        "main_score": 0.05461977965799297,
        "precision": 0.04474135890151515,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04073156567600263,
        "hf_subset": "tgp_Latn-eng_Latn",
        "languages": [
          "tgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04073156567600263,
        "precision": 0.036226268481182794,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005000975800156128,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ],
        "main_score": 0.0005000975800156128,
        "precision": 0.00026041666666666666,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.3645251396648046e-05,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 4.3645251396648046e-05,
        "precision": 2.1945224719101123e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-tif_Latn",
        "languages": [
          "eng-Latn",
          "tif-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.006510416666666666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003960882867132867,
        "hf_subset": "tif_Latn-eng_Latn",
        "languages": [
          "tif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003960882867132867,
        "precision": 0.003933758802816901,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01255580357142857,
        "hf_subset": "eng_Latn-tim_Latn",
        "languages": [
          "eng-Latn",
          "tim-Latn"
        ],
        "main_score": 0.01255580357142857,
        "precision": 0.009643885501355014,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.027061855670103e-05,
        "hf_subset": "tim_Latn-eng_Latn",
        "languages": [
          "tim-Latn",
          "eng-Latn"
        ],
        "main_score": 4.027061855670103e-05,
        "precision": 2.0239637305699483e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.07441860465116279,
        "f1": 0.04278130138595255,
        "hf_subset": "eng_Latn-tiw_Latn",
        "languages": [
          "eng-Latn",
          "tiw-Latn"
        ],
        "main_score": 0.04278130138595255,
        "precision": 0.03740280714117923,
        "recall": 0.07441860465116279
      },
      {
        "accuracy": 0.06976744186046512,
        "f1": 0.048596333136935496,
        "hf_subset": "tiw_Latn-eng_Latn",
        "languages": [
          "tiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.048596333136935496,
        "precision": 0.04380366638294757,
        "recall": 0.06976744186046512
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006758432539682539,
        "hf_subset": "eng_Latn-tiy_Latn",
        "languages": [
          "eng-Latn",
          "tiy-Latn"
        ],
        "main_score": 0.006758432539682539,
        "precision": 0.005622632575757576,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003038194444444444,
        "hf_subset": "tiy_Latn-eng_Latn",
        "languages": [
          "tiy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003038194444444444,
        "precision": 0.002182904411764706,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-tke_Latn",
        "languages": [
          "eng-Latn",
          "tke-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.011857707509881422,
        "hf_subset": "tke_Latn-eng_Latn",
        "languages": [
          "tke-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011857707509881422,
        "precision": 0.011387163561076606,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01694139194139194,
        "hf_subset": "eng_Latn-tku_Latn",
        "languages": [
          "eng-Latn",
          "tku-Latn"
        ],
        "main_score": 0.01694139194139194,
        "precision": 0.011655826355661881,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014143558547430829,
        "hf_subset": "tku_Latn-eng_Latn",
        "languages": [
          "tku-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014143558547430829,
        "precision": 0.013140232951695939,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012121212121212121,
        "hf_subset": "eng_Latn-tlf_Latn",
        "languages": [
          "eng-Latn",
          "tlf-Latn"
        ],
        "main_score": 0.012121212121212121,
        "precision": 0.01070601851851852,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0024939903846153844,
        "hf_subset": "tlf_Latn-eng_Latn",
        "languages": [
          "tlf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0024939903846153844,
        "precision": 0.001584268575851393,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01061698717948718,
        "hf_subset": "eng_Latn-tmd_Latn",
        "languages": [
          "eng-Latn",
          "tmd-Latn"
        ],
        "main_score": 0.01061698717948718,
        "precision": 0.009868421052631578,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007110189881873802,
        "hf_subset": "tmd_Latn-eng_Latn",
        "languages": [
          "tmd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007110189881873802,
        "precision": 0.0057510356338481335,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015964673913043476,
        "hf_subset": "eng_Latn-tna_Latn",
        "languages": [
          "eng-Latn",
          "tna-Latn"
        ],
        "main_score": 0.015964673913043476,
        "precision": 0.013458806818181818,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0009229183771209634,
        "hf_subset": "tna_Latn-eng_Latn",
        "languages": [
          "tna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009229183771209634,
        "precision": 0.00047688052035330255,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020338067223346825,
        "hf_subset": "eng_Latn-tnc_Latn",
        "languages": [
          "eng-Latn",
          "tnc-Latn"
        ],
        "main_score": 0.020338067223346825,
        "precision": 0.01873973059275794,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0026390438988095235,
        "hf_subset": "tnc_Latn-eng_Latn",
        "languages": [
          "tnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026390438988095235,
        "precision": 0.0016747137858404673,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005737847222222222,
        "hf_subset": "eng_Latn-tnk_Latn",
        "languages": [
          "eng-Latn",
          "tnk-Latn"
        ],
        "main_score": 0.005737847222222222,
        "precision": 0.004180617559523809,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005844162157357304,
        "hf_subset": "tnk_Latn-eng_Latn",
        "languages": [
          "tnk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005844162157357304,
        "precision": 0.004984104437229437,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005687056737588652,
        "hf_subset": "eng_Latn-tnn_Latn",
        "languages": [
          "eng-Latn",
          "tnn-Latn"
        ],
        "main_score": 0.005687056737588652,
        "precision": 0.004153928894927536,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010494018151815181,
        "hf_subset": "tnn_Latn-eng_Latn",
        "languages": [
          "tnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010494018151815181,
        "precision": 0.0098046875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00662202380952381,
        "hf_subset": "eng_Latn-tnp_Latn",
        "languages": [
          "eng-Latn",
          "tnp-Latn"
        ],
        "main_score": 0.00662202380952381,
        "precision": 0.004210069444444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007918074324324325,
        "hf_subset": "tnp_Latn-eng_Latn",
        "languages": [
          "tnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007918074324324325,
        "precision": 0.007866010273972603,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010112847222222223,
        "hf_subset": "eng_Latn-toc_Latn",
        "languages": [
          "eng-Latn",
          "toc-Latn"
        ],
        "main_score": 0.010112847222222223,
        "precision": 0.009148238877118645,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004169092908902691,
        "hf_subset": "toc_Latn-eng_Latn",
        "languages": [
          "toc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004169092908902691,
        "precision": 0.0024450231481481484,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015494791666666667,
        "hf_subset": "eng_Latn-tod_Latn",
        "languages": [
          "eng-Latn",
          "tod-Latn"
        ],
        "main_score": 0.015494791666666667,
        "precision": 0.012469806763285024,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015574919871794872,
        "hf_subset": "tod_Latn-eng_Latn",
        "languages": [
          "tod-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015574919871794872,
        "precision": 0.013346354166666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016102430555555554,
        "hf_subset": "eng_Latn-tof_Latn",
        "languages": [
          "eng-Latn",
          "tof-Latn"
        ],
        "main_score": 0.016102430555555554,
        "precision": 0.013313802083333333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005119977678571428,
        "hf_subset": "tof_Latn-eng_Latn",
        "languages": [
          "tof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005119977678571428,
        "precision": 0.004606737869198313,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009579613095238096,
        "hf_subset": "eng_Latn-toj_Latn",
        "languages": [
          "eng-Latn",
          "toj-Latn"
        ],
        "main_score": 0.009579613095238096,
        "precision": 0.0078125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001238475814176245,
        "hf_subset": "toj_Latn-eng_Latn",
        "languages": [
          "toj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001238475814176245,
        "precision": 0.0006806976862905252,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005631243756243756,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ],
        "main_score": 0.005631243756243756,
        "precision": 0.004833325156985872,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01685825892857143,
        "hf_subset": "eng_Latn-too_Latn",
        "languages": [
          "eng-Latn",
          "too-Latn"
        ],
        "main_score": 0.01685825892857143,
        "precision": 0.011297263933982685,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008386748721227622,
        "hf_subset": "too_Latn-eng_Latn",
        "languages": [
          "too-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008386748721227622,
        "precision": 0.008108568948412697,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007715830176767677,
        "hf_subset": "eng_Latn-top_Latn",
        "languages": [
          "eng-Latn",
          "top-Latn"
        ],
        "main_score": 0.007715830176767677,
        "precision": 0.005218071136039885,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008963819588819588,
        "hf_subset": "top_Latn-eng_Latn",
        "languages": [
          "top-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008963819588819588,
        "precision": 0.007021037581699347,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003551136363636364,
        "hf_subset": "eng_Latn-tos_Latn",
        "languages": [
          "eng-Latn",
          "tos-Latn"
        ],
        "main_score": 0.003551136363636364,
        "precision": 0.0024658203125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004722671216475096,
        "hf_subset": "tos_Latn-eng_Latn",
        "languages": [
          "tos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004722671216475096,
        "precision": 0.002879814470069404,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.09219858156028368,
        "f1": 0.04974107846448272,
        "hf_subset": "eng_Latn-tpa_Latn",
        "languages": [
          "eng-Latn",
          "tpa-Latn"
        ],
        "main_score": 0.04974107846448272,
        "precision": 0.042651595843085206,
        "recall": 0.09219858156028368
      },
      {
        "accuracy": 0.12056737588652482,
        "f1": 0.08543066497972818,
        "hf_subset": "tpa_Latn-eng_Latn",
        "languages": [
          "tpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08543066497972818,
        "precision": 0.07761947102789823,
        "recall": 0.12056737588652482
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029940523885836384,
        "hf_subset": "eng_Latn-tpi_Latn",
        "languages": [
          "eng-Latn",
          "tpi-Latn"
        ],
        "main_score": 0.029940523885836384,
        "precision": 0.026281236178682,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.03753797813195791,
        "hf_subset": "tpi_Latn-eng_Latn",
        "languages": [
          "tpi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03753797813195791,
        "precision": 0.031241586614978157,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020241477272727272,
        "hf_subset": "eng_Latn-tpt_Latn",
        "languages": [
          "eng-Latn",
          "tpt-Latn"
        ],
        "main_score": 0.020241477272727272,
        "precision": 0.017578125,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017844848053181386,
        "hf_subset": "tpt_Latn-eng_Latn",
        "languages": [
          "tpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017844848053181386,
        "precision": 0.016109095982142857,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009461805555555557,
        "hf_subset": "eng_Latn-tpz_Latn",
        "languages": [
          "eng-Latn",
          "tpz-Latn"
        ],
        "main_score": 0.009461805555555557,
        "precision": 0.00872210251348228,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tpz_Latn-eng_Latn",
        "languages": [
          "tpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015053677721088433,
        "hf_subset": "eng_Latn-trc_Latn",
        "languages": [
          "eng-Latn",
          "trc-Latn"
        ],
        "main_score": 0.015053677721088433,
        "precision": 0.012895384254920338,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006563203828828829,
        "hf_subset": "trc_Latn-eng_Latn",
        "languages": [
          "trc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006563203828828829,
        "precision": 0.0047140731292517005,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-tsw_Latn",
        "languages": [
          "eng-Latn",
          "tsw-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.010546875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001953125,
        "hf_subset": "tsw_Latn-eng_Latn",
        "languages": [
          "tsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001953125,
        "precision": 0.00010016025641025641,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014592313218390805,
        "hf_subset": "eng_Latn-ttc_Latn",
        "languages": [
          "eng-Latn",
          "ttc-Latn"
        ],
        "main_score": 0.014592313218390805,
        "precision": 0.011858258928571428,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00019221230158730158,
        "hf_subset": "ttc_Latn-eng_Latn",
        "languages": [
          "ttc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00019221230158730158,
        "precision": 9.745762711864407e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011185851029601028,
        "hf_subset": "eng_Latn-tte_Latn",
        "languages": [
          "eng-Latn",
          "tte-Latn"
        ],
        "main_score": 0.011185851029601028,
        "precision": 0.010174612713675214,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01049890350877193,
        "hf_subset": "tte_Latn-eng_Latn",
        "languages": [
          "tte-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01049890350877193,
        "precision": 0.00980718085106383,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0076401654411764695,
        "hf_subset": "eng_Latn-tuc_Latn",
        "languages": [
          "eng-Latn",
          "tuc-Latn"
        ],
        "main_score": 0.0076401654411764695,
        "precision": 0.005027732683982683,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013350694444444443,
        "hf_subset": "tuc_Latn-eng_Latn",
        "languages": [
          "tuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013350694444444443,
        "precision": 0.01266849779684601,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019401041666666667,
        "hf_subset": "eng_Latn-tue_Latn",
        "languages": [
          "eng-Latn",
          "tue-Latn"
        ],
        "main_score": 0.019401041666666667,
        "precision": 0.016927083333333332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005976040361319967,
        "hf_subset": "tue_Latn-eng_Latn",
        "languages": [
          "tue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005976040361319967,
        "precision": 0.00386749751984127,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007631828149920255,
        "hf_subset": "eng_Latn-tuf_Latn",
        "languages": [
          "eng-Latn",
          "tuf-Latn"
        ],
        "main_score": 0.007631828149920255,
        "precision": 0.006076388888888889,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0021146930326617825,
        "hf_subset": "tuf_Latn-eng_Latn",
        "languages": [
          "tuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0021146930326617825,
        "precision": 0.0012074667515563102,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005152529761904762,
        "hf_subset": "eng_Latn-tuo_Latn",
        "languages": [
          "eng-Latn",
          "tuo-Latn"
        ],
        "main_score": 0.005152529761904762,
        "precision": 0.003168402777777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01388221153846154,
        "hf_subset": "tuo_Latn-eng_Latn",
        "languages": [
          "tuo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01388221153846154,
        "precision": 0.0129003483495671,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00108955938697318,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.00108955938697318,
        "precision": 0.0005773279706619489,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0047433208619941745,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0047433208619941745,
        "precision": 0.004346153970847599,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011284722222222222,
        "hf_subset": "eng_Latn-tvk_Latn",
        "languages": [
          "eng-Latn",
          "tvk-Latn"
        ],
        "main_score": 0.011284722222222222,
        "precision": 0.008951822916666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.005176164607868237,
        "hf_subset": "tvk_Latn-eng_Latn",
        "languages": [
          "tvk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005176164607868237,
        "precision": 0.003098529075091575,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021947616185897436,
        "hf_subset": "eng_Latn-twi_Latn",
        "languages": [
          "eng-Latn",
          "twi-Latn"
        ],
        "main_score": 0.021947616185897436,
        "precision": 0.01939608134920635,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "twi_Latn-eng_Latn",
        "languages": [
          "twi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003066378066378066,
        "hf_subset": "eng_Latn-txq_Latn",
        "languages": [
          "eng-Latn",
          "txq-Latn"
        ],
        "main_score": 0.003066378066378066,
        "precision": 0.0017252604166666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005022321428571428,
        "hf_subset": "txq_Latn-eng_Latn",
        "languages": [
          "txq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005022321428571428,
        "precision": 0.004557291666666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-txu_Latn",
        "languages": [
          "eng-Latn",
          "txu-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003472222222222222,
        "hf_subset": "txu_Latn-eng_Latn",
        "languages": [
          "txu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003472222222222222,
        "precision": 0.00244140625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.00962815567564745,
        "hf_subset": "eng_Latn-tzj_Latn",
        "languages": [
          "eng-Latn",
          "tzj-Latn"
        ],
        "main_score": 0.00962815567564745,
        "precision": 0.00640438988095238,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008798363095238095,
        "hf_subset": "tzj_Latn-eng_Latn",
        "languages": [
          "tzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008798363095238095,
        "precision": 0.005750868055555555,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0107404651675485,
        "hf_subset": "eng_Latn-tzo_Latn",
        "languages": [
          "eng-Latn",
          "tzo-Latn"
        ],
        "main_score": 0.0107404651675485,
        "precision": 0.007393078926282051,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011898965881642512,
        "hf_subset": "tzo_Latn-eng_Latn",
        "languages": [
          "tzo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011898965881642512,
        "precision": 0.01019049310064935,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.050510912698412694,
        "hf_subset": "eng_Latn-ubr_Latn",
        "languages": [
          "eng-Latn",
          "ubr-Latn"
        ],
        "main_score": 0.050510912698412694,
        "precision": 0.044709413850038855,
        "recall": 0.078125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04590548340548341,
        "hf_subset": "ubr_Latn-eng_Latn",
        "languages": [
          "ubr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04590548340548341,
        "precision": 0.041661768268353855,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019087357954545455,
        "hf_subset": "eng_Latn-ubu_Latn",
        "languages": [
          "eng-Latn",
          "ubu-Latn"
        ],
        "main_score": 0.0019087357954545455,
        "precision": 0.0011017628205128205,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013962098393574297,
        "hf_subset": "ubu_Latn-eng_Latn",
        "languages": [
          "ubu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013962098393574297,
        "precision": 0.0008288871951219513,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00938813025210084,
        "hf_subset": "eng_Latn-udu_Latn",
        "languages": [
          "eng-Latn",
          "udu-Latn"
        ],
        "main_score": 0.00938813025210084,
        "precision": 0.008707682291666668,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005760621488764045,
        "hf_subset": "udu_Latn-eng_Latn",
        "languages": [
          "udu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005760621488764045,
        "precision": 0.0003048058712121212,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010543536324786324,
        "hf_subset": "eng_Latn-uig_Latn",
        "languages": [
          "eng-Latn",
          "uig-Latn"
        ],
        "main_score": 0.010543536324786324,
        "precision": 0.00826171875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008203124999999999,
        "hf_subset": "uig_Latn-eng_Latn",
        "languages": [
          "uig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008203124999999999,
        "precision": 0.006064967105263158,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007019340187998276,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ],
        "main_score": 0.007019340187998276,
        "precision": 0.00453915550595238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001767113095238095,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.001767113095238095,
        "precision": 0.001006155303030303,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.04952721974206349,
        "hf_subset": "eng_Latn-uli_Latn",
        "languages": [
          "eng-Latn",
          "uli-Latn"
        ],
        "main_score": 0.04952721974206349,
        "precision": 0.04100437547366427,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.046144480519480516,
        "hf_subset": "uli_Latn-eng_Latn",
        "languages": [
          "uli-Latn",
          "eng-Latn"
        ],
        "main_score": 0.046144480519480516,
        "precision": 0.04178873697916667,
        "recall": 0.0625
      },
      {
        "accuracy": 0.03664921465968586,
        "f1": 0.021870004546321146,
        "hf_subset": "eng_Latn-ulk_Latn",
        "languages": [
          "eng-Latn",
          "ulk-Latn"
        ],
        "main_score": 0.021870004546321146,
        "precision": 0.019802514239687014,
        "recall": 0.03664921465968586
      },
      {
        "accuracy": 0.031413612565445025,
        "f1": 0.028795811518324606,
        "hf_subset": "ulk_Latn-eng_Latn",
        "languages": [
          "ulk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028795811518324606,
        "precision": 0.027923211169284465,
        "recall": 0.031413612565445025
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015444711538461536,
        "hf_subset": "eng_Latn-upv_Latn",
        "languages": [
          "eng-Latn",
          "upv-Latn"
        ],
        "main_score": 0.015444711538461536,
        "precision": 0.01183500744047619,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012261284722222222,
        "hf_subset": "upv_Latn-eng_Latn",
        "languages": [
          "upv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012261284722222222,
        "precision": 0.010811941964285714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007518940874504898,
        "hf_subset": "eng_Latn-ura_Latn",
        "languages": [
          "eng-Latn",
          "ura-Latn"
        ],
        "main_score": 0.007518940874504898,
        "precision": 0.0049479166666666664,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "ura_Latn-eng_Latn",
        "languages": [
          "ura-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006028476731601732,
        "hf_subset": "eng_Latn-urb_Latn",
        "languages": [
          "eng-Latn",
          "urb-Latn"
        ],
        "main_score": 0.006028476731601732,
        "precision": 0.004092261904761905,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004317434210526315,
        "hf_subset": "urb_Latn-eng_Latn",
        "languages": [
          "urb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004317434210526315,
        "precision": 0.004123263888888889,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01853608630952381,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.01853608630952381,
        "precision": 0.01631567028985507,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009982638888888888,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.009982638888888888,
        "precision": 0.00830078125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03571428571428571,
        "f1": 0.015261506722918875,
        "hf_subset": "eng_Latn-uri_Latn",
        "languages": [
          "eng-Latn",
          "uri-Latn"
        ],
        "main_score": 0.015261506722918875,
        "precision": 0.013757608306480488,
        "recall": 0.03571428571428571
      },
      {
        "accuracy": 0.015873015873015872,
        "f1": 0.005406244989578322,
        "hf_subset": "uri_Latn-eng_Latn",
        "languages": [
          "uri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005406244989578322,
        "precision": 0.003731453731453731,
        "recall": 0.015873015873015872
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009813272772226912,
        "hf_subset": "eng_Latn-urt_Latn",
        "languages": [
          "eng-Latn",
          "urt-Latn"
        ],
        "main_score": 0.009813272772226912,
        "precision": 0.0066767032099063345,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0017299107142857142,
        "hf_subset": "urt_Latn-eng_Latn",
        "languages": [
          "urt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0017299107142857142,
        "precision": 0.0009346122627372627,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03333333333333333,
        "f1": 0.016402116402116404,
        "hf_subset": "eng_Latn-urw_Latn",
        "languages": [
          "eng-Latn",
          "urw-Latn"
        ],
        "main_score": 0.016402116402116404,
        "precision": 0.011965811965811965,
        "recall": 0.03333333333333333
      },
      {
        "accuracy": 0.05555555555555555,
        "f1": 0.02959435626102293,
        "hf_subset": "urw_Latn-eng_Latn",
        "languages": [
          "urw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02959435626102293,
        "precision": 0.02432659932659933,
        "recall": 0.05555555555555555
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00706845238095238,
        "hf_subset": "eng_Latn-usa_Latn",
        "languages": [
          "eng-Latn",
          "usa-Latn"
        ],
        "main_score": 0.00706845238095238,
        "precision": 0.006159855769230769,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015024038461538462,
        "hf_subset": "usa_Latn-eng_Latn",
        "languages": [
          "usa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015024038461538462,
        "precision": 7.659313725490196e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025591077302631576,
        "hf_subset": "eng_Latn-usp_Latn",
        "languages": [
          "eng-Latn",
          "usp-Latn"
        ],
        "main_score": 0.025591077302631576,
        "precision": 0.0235546875,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014570230607966457,
        "hf_subset": "usp_Latn-eng_Latn",
        "languages": [
          "usp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014570230607966457,
        "precision": 0.01379785579004329,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008655894886363636,
        "hf_subset": "eng_Latn-uvh_Latn",
        "languages": [
          "eng-Latn",
          "uvh-Latn"
        ],
        "main_score": 0.008655894886363636,
        "precision": 0.008258928571428572,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.965736040609137e-05,
        "hf_subset": "uvh_Latn-eng_Latn",
        "languages": [
          "uvh-Latn",
          "eng-Latn"
        ],
        "main_score": 3.965736040609137e-05,
        "precision": 1.992984693877551e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006705729166666667,
        "hf_subset": "eng_Latn-uvl_Latn",
        "languages": [
          "eng-Latn",
          "uvl-Latn"
        ],
        "main_score": 0.006705729166666667,
        "precision": 0.004427083333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00623139880952381,
        "hf_subset": "uvl_Latn-eng_Latn",
        "languages": [
          "uvl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00623139880952381,
        "precision": 0.004288383152173913,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0077241443452380956,
        "hf_subset": "eng_Latn-vid_Latn",
        "languages": [
          "eng-Latn",
          "vid-Latn"
        ],
        "main_score": 0.0077241443452380956,
        "precision": 0.005143229166666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0046875,
        "hf_subset": "vid_Latn-eng_Latn",
        "languages": [
          "vid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0046875,
        "precision": 0.003168402777777778,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00048828125,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ],
        "main_score": 0.00048828125,
        "precision": 0.00026041666666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0021100201764264266,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0021100201764264266,
        "precision": 0.0012569595556630132,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01005704365079365,
        "hf_subset": "eng_Latn-viv_Latn",
        "languages": [
          "eng-Latn",
          "viv-Latn"
        ],
        "main_score": 0.01005704365079365,
        "precision": 0.007975260416666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007998511904761904,
        "hf_subset": "viv_Latn-eng_Latn",
        "languages": [
          "viv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007998511904761904,
        "precision": 0.007907774390243903,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017578125,
        "hf_subset": "eng_Latn-vmy_Latn",
        "languages": [
          "eng-Latn",
          "vmy-Latn"
        ],
        "main_score": 0.017578125,
        "precision": 0.012934027777777777,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014139983127934273,
        "hf_subset": "vmy_Latn-eng_Latn",
        "languages": [
          "vmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014139983127934273,
        "precision": 0.012149520607293551,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007651853354978355,
        "hf_subset": "eng_Latn-waj_Latn",
        "languages": [
          "eng-Latn",
          "waj-Latn"
        ],
        "main_score": 0.007651853354978355,
        "precision": 0.004987980769230769,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004902379326047359,
        "hf_subset": "waj_Latn-eng_Latn",
        "languages": [
          "waj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004902379326047359,
        "precision": 0.0044596354166666664,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0040009469696969694,
        "hf_subset": "eng_Latn-wal_Ethi",
        "languages": [
          "eng-Latn",
          "wal-Ethi"
        ],
        "main_score": 0.0040009469696969694,
        "precision": 0.0026998426463886987,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019965277777777776,
        "hf_subset": "wal_Ethi-eng_Latn",
        "languages": [
          "wal-Ethi",
          "eng-Latn"
        ],
        "main_score": 0.0019965277777777776,
        "precision": 0.001206341911764706,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.051765288229282794,
        "hf_subset": "eng_Latn-wap_Latn",
        "languages": [
          "eng-Latn",
          "wap-Latn"
        ],
        "main_score": 0.051765288229282794,
        "precision": 0.04622522298303548,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05868675595238095,
        "hf_subset": "wap_Latn-eng_Latn",
        "languages": [
          "wap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05868675595238095,
        "precision": 0.05330781874687656,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016486378205128202,
        "hf_subset": "eng_Latn-wat_Latn",
        "languages": [
          "eng-Latn",
          "wat-Latn"
        ],
        "main_score": 0.016486378205128202,
        "precision": 0.013671874999999998,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017469618055555556,
        "hf_subset": "wat_Latn-eng_Latn",
        "languages": [
          "wat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017469618055555556,
        "precision": 0.016671316964285712,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013841765873015872,
        "hf_subset": "eng_Latn-wbi_Latn",
        "languages": [
          "eng-Latn",
          "wbi-Latn"
        ],
        "main_score": 0.013841765873015872,
        "precision": 0.010297673757002801,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.013020833333333332,
        "hf_subset": "wbi_Latn-eng_Latn",
        "languages": [
          "wbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013020833333333332,
        "precision": 0.01171875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "eng_Latn-wbp_Latn",
        "languages": [
          "eng-Latn",
          "wbp-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003515625,
        "hf_subset": "wbp_Latn-eng_Latn",
        "languages": [
          "wbp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003515625,
        "precision": 0.002278645833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.0384182224025974,
        "hf_subset": "eng_Latn-wed_Latn",
        "languages": [
          "eng-Latn",
          "wed-Latn"
        ],
        "main_score": 0.0384182224025974,
        "precision": 0.03220152243589743,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04542572463768116,
        "hf_subset": "wed_Latn-eng_Latn",
        "languages": [
          "wed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04542572463768116,
        "precision": 0.039956324468193076,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-wer_Latn",
        "languages": [
          "eng-Latn",
          "wer-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00480136486813035,
        "hf_subset": "wer_Latn-eng_Latn",
        "languages": [
          "wer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00480136486813035,
        "precision": 0.00437603115295031,
        "recall": 0.015625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04465208653736614,
        "hf_subset": "eng_Latn-wim_Latn",
        "languages": [
          "eng-Latn",
          "wim-Latn"
        ],
        "main_score": 0.04465208653736614,
        "precision": 0.04016128186050061,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03331163194444445,
        "hf_subset": "wim_Latn-eng_Latn",
        "languages": [
          "wim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03331163194444445,
        "precision": 0.03122452445652174,
        "recall": 0.046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003125,
        "hf_subset": "eng_Latn-wiu_Latn",
        "languages": [
          "eng-Latn",
          "wiu-Latn"
        ],
        "main_score": 0.0003125,
        "precision": 0.00016276041666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00027901785714285713,
        "hf_subset": "wiu_Latn-eng_Latn",
        "languages": [
          "wiu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00027901785714285713,
        "precision": 0.00014467592592592592,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020488890599343185,
        "hf_subset": "eng_Latn-wiv_Latn",
        "languages": [
          "eng-Latn",
          "wiv-Latn"
        ],
        "main_score": 0.020488890599343185,
        "precision": 0.016278903388278386,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009824810606060606,
        "hf_subset": "wiv_Latn-eng_Latn",
        "languages": [
          "wiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009824810606060606,
        "precision": 0.00703125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00361328125,
        "hf_subset": "eng_Latn-wmt_Latn",
        "languages": [
          "eng-Latn",
          "wmt-Latn"
        ],
        "main_score": 0.00361328125,
        "precision": 0.0022135416666666666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.580357142857143e-05,
        "hf_subset": "wmt_Latn-eng_Latn",
        "languages": [
          "wmt-Latn",
          "eng-Latn"
        ],
        "main_score": 5.580357142857143e-05,
        "precision": 2.8102517985611512e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015299479166666666,
        "hf_subset": "eng_Latn-wmw_Latn",
        "languages": [
          "eng-Latn",
          "wmw-Latn"
        ],
        "main_score": 0.015299479166666666,
        "precision": 0.013058035714285713,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01117050438596491,
        "hf_subset": "wmw_Latn-eng_Latn",
        "languages": [
          "wmw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01117050438596491,
        "precision": 0.01017282196969697,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004225852272727273,
        "hf_subset": "eng_Latn-wnc_Latn",
        "languages": [
          "eng-Latn",
          "wnc-Latn"
        ],
        "main_score": 0.004225852272727273,
        "precision": 0.0026692708333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0033854166666666668,
        "hf_subset": "wnc_Latn-eng_Latn",
        "languages": [
          "wnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0033854166666666668,
        "precision": 0.002387152777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010352787578405017,
        "hf_subset": "eng_Latn-wnu_Latn",
        "languages": [
          "eng-Latn",
          "wnu-Latn"
        ],
        "main_score": 0.010352787578405017,
        "precision": 0.007969992866428698,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008333333333333333,
        "hf_subset": "wnu_Latn-eng_Latn",
        "languages": [
          "wnu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008333333333333333,
        "precision": 0.00556344696969697,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00846100514069264,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ],
        "main_score": 0.00846100514069264,
        "precision": 0.006525399588438382,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004504650018408904,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004504650018408904,
        "precision": 0.004214015151515152,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009602864583333334,
        "hf_subset": "eng_Latn-wos_Latn",
        "languages": [
          "eng-Latn",
          "wos-Latn"
        ],
        "main_score": 0.009602864583333334,
        "precision": 0.008854166666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016409400983494662,
        "hf_subset": "wos_Latn-eng_Latn",
        "languages": [
          "wos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016409400983494662,
        "precision": 0.014832389832389832,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0031249999999999997,
        "hf_subset": "eng_Latn-wrk_Latn",
        "languages": [
          "eng-Latn",
          "wrk-Latn"
        ],
        "main_score": 0.0031249999999999997,
        "precision": 0.002232142857142857,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "wrk_Latn-eng_Latn",
        "languages": [
          "wrk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.05926407453458506,
        "hf_subset": "eng_Latn-wro_Latn",
        "languages": [
          "eng-Latn",
          "wro-Latn"
        ],
        "main_score": 0.05926407453458506,
        "precision": 0.05337464905750319,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.050196415960451976,
        "hf_subset": "wro_Latn-eng_Latn",
        "languages": [
          "wro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.050196415960451976,
        "precision": 0.047038595085470085,
        "recall": 0.0625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008928571428571428,
        "hf_subset": "eng_Latn-wrs_Latn",
        "languages": [
          "eng-Latn",
          "wrs-Latn"
        ],
        "main_score": 0.008928571428571428,
        "precision": 0.007291666666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008138020833333334,
        "hf_subset": "wrs_Latn-eng_Latn",
        "languages": [
          "wrs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008138020833333334,
        "precision": 0.006810461956521739,
        "recall": 0.015625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06789667038690475,
        "hf_subset": "eng_Latn-wsk_Latn",
        "languages": [
          "eng-Latn",
          "wsk-Latn"
        ],
        "main_score": 0.06789667038690475,
        "precision": 0.061128612231182794,
        "recall": 0.09375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.03911645501489251,
        "hf_subset": "wsk_Latn-eng_Latn",
        "languages": [
          "wsk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03911645501489251,
        "precision": 0.03368486865068354,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06978236607142857,
        "hf_subset": "eng_Latn-wuv_Latn",
        "languages": [
          "eng-Latn",
          "wuv-Latn"
        ],
        "main_score": 0.06978236607142857,
        "precision": 0.061730912316849816,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.06630098329317079,
        "hf_subset": "wuv_Latn-eng_Latn",
        "languages": [
          "wuv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06630098329317079,
        "precision": 0.058947477672896015,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010717147435897436,
        "hf_subset": "eng_Latn-xav_Latn",
        "languages": [
          "eng-Latn",
          "xav-Latn"
        ],
        "main_score": 0.010717147435897436,
        "precision": 0.009921875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015943877551020407,
        "hf_subset": "xav_Latn-eng_Latn",
        "languages": [
          "xav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015943877551020407,
        "precision": 8.138020833333333e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013645455917874395,
        "hf_subset": "eng_Latn-xbi_Latn",
        "languages": [
          "eng-Latn",
          "xbi-Latn"
        ],
        "main_score": 0.013645455917874395,
        "precision": 0.011767811752392344,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01299208603896104,
        "hf_subset": "xbi_Latn-eng_Latn",
        "languages": [
          "xbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01299208603896104,
        "precision": 0.01242834399701176,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01579193376068376,
        "hf_subset": "eng_Latn-xed_Latn",
        "languages": [
          "eng-Latn",
          "xed-Latn"
        ],
        "main_score": 0.01579193376068376,
        "precision": 0.011555989583333334,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "xed_Latn-eng_Latn",
        "languages": [
          "xed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006975446428571428,
        "hf_subset": "eng_Latn-xla_Latn",
        "languages": [
          "eng-Latn",
          "xla-Latn"
        ],
        "main_score": 0.006975446428571428,
        "precision": 0.005859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006184895833333333,
        "hf_subset": "xla_Latn-eng_Latn",
        "languages": [
          "xla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006184895833333333,
        "precision": 0.004464285714285714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016959361869747898,
        "hf_subset": "eng_Latn-xnn_Latn",
        "languages": [
          "eng-Latn",
          "xnn-Latn"
        ],
        "main_score": 0.016959361869747898,
        "precision": 0.01376550099206349,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010255297364672365,
        "hf_subset": "xnn_Latn-eng_Latn",
        "languages": [
          "xnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010255297364672365,
        "precision": 0.009367619770580298,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.008320297316619468,
        "hf_subset": "eng_Latn-xon_Latn",
        "languages": [
          "eng-Latn",
          "xon-Latn"
        ],
        "main_score": 0.008320297316619468,
        "precision": 0.005184398934398934,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "xon_Latn-eng_Latn",
        "languages": [
          "xon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006780133928571428,
        "hf_subset": "eng_Latn-xsi_Latn",
        "languages": [
          "eng-Latn",
          "xsi-Latn"
        ],
        "main_score": 0.006780133928571428,
        "precision": 0.004377480158730159,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005270337301587301,
        "hf_subset": "xsi_Latn-eng_Latn",
        "languages": [
          "xsi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005270337301587301,
        "precision": 0.004663979245845443,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014423819350853547,
        "hf_subset": "eng_Latn-xtd_Latn",
        "languages": [
          "eng-Latn",
          "xtd-Latn"
        ],
        "main_score": 0.014423819350853547,
        "precision": 0.012055977876290376,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004216269841269841,
        "hf_subset": "xtd_Latn-eng_Latn",
        "languages": [
          "xtd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004216269841269841,
        "precision": 0.0024698247354497356,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01302864753207219,
        "hf_subset": "eng_Latn-xtm_Latn",
        "languages": [
          "eng-Latn",
          "xtm-Latn"
        ],
        "main_score": 0.01302864753207219,
        "precision": 0.011238219246031746,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011018272737022737,
        "hf_subset": "xtm_Latn-eng_Latn",
        "languages": [
          "xtm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011018272737022737,
        "precision": 0.009656374857305937,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011204769736842105,
        "hf_subset": "eng_Latn-yaa_Latn",
        "languages": [
          "eng-Latn",
          "yaa-Latn"
        ],
        "main_score": 0.011204769736842105,
        "precision": 0.009184337797619048,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003125,
        "hf_subset": "yaa_Latn-eng_Latn",
        "languages": [
          "yaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003125,
        "precision": 0.001953125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002709740990990991,
        "hf_subset": "eng_Latn-yad_Latn",
        "languages": [
          "eng-Latn",
          "yad-Latn"
        ],
        "main_score": 0.002709740990990991,
        "precision": 0.002006635273972603,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010817307692307693,
        "hf_subset": "yad_Latn-eng_Latn",
        "languages": [
          "yad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010817307692307693,
        "precision": 0.0005902777777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006199048913043478,
        "hf_subset": "eng_Latn-yal_Latn",
        "languages": [
          "eng-Latn",
          "yal-Latn"
        ],
        "main_score": 0.006199048913043478,
        "precision": 0.004214015151515151,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "yal_Latn-eng_Latn",
        "languages": [
          "yal-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028182761591478693,
        "hf_subset": "eng_Latn-yap_Latn",
        "languages": [
          "eng-Latn",
          "yap-Latn"
        ],
        "main_score": 0.028182761591478693,
        "precision": 0.02369457799145299,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.030953319610297896,
        "hf_subset": "yap_Latn-eng_Latn",
        "languages": [
          "yap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030953319610297896,
        "precision": 0.027318093185550084,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011214114832535885,
        "hf_subset": "eng_Latn-yaq_Latn",
        "languages": [
          "eng-Latn",
          "yaq-Latn"
        ],
        "main_score": 0.0011214114832535885,
        "precision": 0.0006076388888888889,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.659313725490196e-05,
        "hf_subset": "yaq_Latn-eng_Latn",
        "languages": [
          "yaq-Latn",
          "eng-Latn"
        ],
        "main_score": 7.659313725490196e-05,
        "precision": 3.8675742574257426e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011799291237113402,
        "hf_subset": "eng_Latn-yby_Latn",
        "languages": [
          "eng-Latn",
          "yby-Latn"
        ],
        "main_score": 0.011799291237113402,
        "precision": 0.011759440104166668,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003100090579710145,
        "hf_subset": "yby_Latn-eng_Latn",
        "languages": [
          "yby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003100090579710145,
        "precision": 0.00221040120593692,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008522727272727272,
        "hf_subset": "eng_Latn-ycn_Latn",
        "languages": [
          "eng-Latn",
          "ycn-Latn"
        ],
        "main_score": 0.008522727272727272,
        "precision": 0.008203125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.0879446640316203e-05,
        "hf_subset": "ycn_Latn-eng_Latn",
        "languages": [
          "ycn-Latn",
          "eng-Latn"
        ],
        "main_score": 3.0879446640316203e-05,
        "precision": 1.5500992063492063e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016867079493087557,
        "hf_subset": "eng_Latn-yka_Latn",
        "languages": [
          "eng-Latn",
          "yka-Latn"
        ],
        "main_score": 0.016867079493087557,
        "precision": 0.015099999186833201,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026834981424825172,
        "hf_subset": "yka_Latn-eng_Latn",
        "languages": [
          "yka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026834981424825172,
        "precision": 0.023418305154508615,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006807215073529412,
        "hf_subset": "eng_Latn-yle_Latn",
        "languages": [
          "eng-Latn",
          "yle-Latn"
        ],
        "main_score": 0.006807215073529412,
        "precision": 0.0055471709280303025,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "yle_Latn-eng_Latn",
        "languages": [
          "yle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010751488095238095,
        "hf_subset": "eng_Latn-yml_Latn",
        "languages": [
          "eng-Latn",
          "yml-Latn"
        ],
        "main_score": 0.010751488095238095,
        "precision": 0.008272719109195402,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004747840447154471,
        "hf_subset": "yml_Latn-eng_Latn",
        "languages": [
          "yml-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004747840447154471,
        "precision": 0.0029622395833333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01510762630837359,
        "hf_subset": "eng_Latn-yon_Latn",
        "languages": [
          "eng-Latn",
          "yon-Latn"
        ],
        "main_score": 0.01510762630837359,
        "precision": 0.013815914987789987,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004557291666666666,
        "hf_subset": "yon_Latn-eng_Latn",
        "languages": [
          "yon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004557291666666666,
        "precision": 0.003255208333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.008859647989131223,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ],
        "main_score": 0.008859647989131223,
        "precision": 0.005814927770350565,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0109375,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0109375,
        "precision": 0.010044642857142856,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008056640625,
        "hf_subset": "eng_Latn-yrb_Latn",
        "languages": [
          "eng-Latn",
          "yrb-Latn"
        ],
        "main_score": 0.008056640625,
        "precision": 0.007938508064516129,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004898313492063492,
        "hf_subset": "yrb_Latn-eng_Latn",
        "languages": [
          "yrb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004898313492063492,
        "precision": 0.0044575352822580645,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010917467948717948,
        "hf_subset": "eng_Latn-yre_Latn",
        "languages": [
          "eng-Latn",
          "yre-Latn"
        ],
        "main_score": 0.010917467948717948,
        "precision": 0.010024671052631579,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "yre_Latn-eng_Latn",
        "languages": [
          "yre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010695684523809522,
        "hf_subset": "eng_Latn-yss_Latn",
        "languages": [
          "eng-Latn",
          "yss-Latn"
        ],
        "main_score": 0.010695684523809522,
        "precision": 0.008463541666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00552952830841639,
        "hf_subset": "yss_Latn-eng_Latn",
        "languages": [
          "yss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00552952830841639,
        "precision": 0.0033854166666666668,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00752046130952381,
        "hf_subset": "eng_Latn-yuj_Latn",
        "languages": [
          "eng-Latn",
          "yuj-Latn"
        ],
        "main_score": 0.00752046130952381,
        "precision": 0.006004513236215539,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020768229166666666,
        "hf_subset": "yuj_Latn-eng_Latn",
        "languages": [
          "yuj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020768229166666666,
        "precision": 0.019112723214285712,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024792254734174964,
        "hf_subset": "eng_Latn-yut_Latn",
        "languages": [
          "eng-Latn",
          "yut-Latn"
        ],
        "main_score": 0.024792254734174964,
        "precision": 0.024149445564516127,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011848958333333331,
        "hf_subset": "yut_Latn-eng_Latn",
        "languages": [
          "yut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011848958333333331,
        "precision": 0.009548611111111112,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012174479166666665,
        "hf_subset": "eng_Latn-yuw_Latn",
        "languages": [
          "eng-Latn",
          "yuw-Latn"
        ],
        "main_score": 0.012174479166666665,
        "precision": 0.008028104707792206,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.013020833333333332,
        "hf_subset": "yuw_Latn-eng_Latn",
        "languages": [
          "yuw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013020833333333332,
        "precision": 0.0125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01098783263305322,
        "hf_subset": "eng_Latn-yva_Latn",
        "languages": [
          "eng-Latn",
          "yva-Latn"
        ],
        "main_score": 0.01098783263305322,
        "precision": 0.008457545230263158,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012178308823529412,
        "hf_subset": "yva_Latn-eng_Latn",
        "languages": [
          "yva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012178308823529412,
        "precision": 0.011962890625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012340270748987855,
        "hf_subset": "eng_Latn-zaa_Latn",
        "languages": [
          "eng-Latn",
          "zaa-Latn"
        ],
        "main_score": 0.012340270748987855,
        "precision": 0.009686710858585858,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007238194013647642,
        "hf_subset": "zaa_Latn-eng_Latn",
        "languages": [
          "zaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007238194013647642,
        "precision": 0.0062360134271099744,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009448670504385966,
        "hf_subset": "eng_Latn-zab_Latn",
        "languages": [
          "eng-Latn",
          "zab-Latn"
        ],
        "main_score": 0.009448670504385966,
        "precision": 0.007466968795093795,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012800556077694234,
        "hf_subset": "zab_Latn-eng_Latn",
        "languages": [
          "zab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012800556077694234,
        "precision": 0.010088213213213213,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.037162642045454546,
        "hf_subset": "eng_Latn-zac_Latn",
        "languages": [
          "eng-Latn",
          "zac-Latn"
        ],
        "main_score": 0.037162642045454546,
        "precision": 0.033565848214285716,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01660752218828965,
        "hf_subset": "zac_Latn-eng_Latn",
        "languages": [
          "zac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01660752218828965,
        "precision": 0.013276274681579622,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015299479166666664,
        "hf_subset": "eng_Latn-zad_Latn",
        "languages": [
          "eng-Latn",
          "zad-Latn"
        ],
        "main_score": 0.015299479166666664,
        "precision": 0.013058035714285715,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0042668269230769235,
        "hf_subset": "zad_Latn-eng_Latn",
        "languages": [
          "zad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0042668269230769235,
        "precision": 0.0029804180194805195,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021471497252747253,
        "hf_subset": "eng_Latn-zai_Latn",
        "languages": [
          "eng-Latn",
          "zai-Latn"
        ],
        "main_score": 0.021471497252747253,
        "precision": 0.018638154380341884,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00042925824175824175,
        "hf_subset": "zai_Latn-eng_Latn",
        "languages": [
          "zai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00042925824175824175,
        "precision": 0.00022126906318082788,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010771780303030302,
        "hf_subset": "eng_Latn-zaj_Latn",
        "languages": [
          "eng-Latn",
          "zaj-Latn"
        ],
        "main_score": 0.010771780303030302,
        "precision": 0.00864955357142857,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008272058823529412,
        "hf_subset": "zaj_Latn-eng_Latn",
        "languages": [
          "zaj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008272058823529412,
        "precision": 0.008056640625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018234158897934172,
        "hf_subset": "eng_Latn-zam_Latn",
        "languages": [
          "eng-Latn",
          "zam-Latn"
        ],
        "main_score": 0.018234158897934172,
        "precision": 0.014954582093253968,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00808376736111111,
        "hf_subset": "zam_Latn-eng_Latn",
        "languages": [
          "zam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00808376736111111,
        "precision": 0.007950724611622556,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007231570512820513,
        "hf_subset": "eng_Latn-zao_Latn",
        "languages": [
          "eng-Latn",
          "zao-Latn"
        ],
        "main_score": 0.007231570512820513,
        "precision": 0.006241188909774436,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007388054653679654,
        "hf_subset": "zao_Latn-eng_Latn",
        "languages": [
          "zao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007388054653679654,
        "precision": 0.005929031905594405,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012538054083813012,
        "hf_subset": "eng_Latn-zap_Latn",
        "languages": [
          "eng-Latn",
          "zap-Latn"
        ],
        "main_score": 0.012538054083813012,
        "precision": 0.009240677941849816,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006624010765830833,
        "hf_subset": "zap_Latn-eng_Latn",
        "languages": [
          "zap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006624010765830833,
        "precision": 0.005447991239006864,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005296114232209738,
        "hf_subset": "eng_Latn-zar_Latn",
        "languages": [
          "eng-Latn",
          "zar-Latn"
        ],
        "main_score": 0.005296114232209738,
        "precision": 0.004731889204545455,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008854166666666667,
        "hf_subset": "zar_Latn-eng_Latn",
        "languages": [
          "zar-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008854166666666667,
        "precision": 0.0004868149399399399,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006317311087570622,
        "hf_subset": "eng_Latn-zas_Latn",
        "languages": [
          "eng-Latn",
          "zas-Latn"
        ],
        "main_score": 0.006317311087570622,
        "precision": 0.004010801518883415,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010272285997732425,
        "hf_subset": "zas_Latn-eng_Latn",
        "languages": [
          "zas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010272285997732425,
        "precision": 0.008039730451839826,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006677350427350427,
        "hf_subset": "eng_Latn-zat_Latn",
        "languages": [
          "eng-Latn",
          "zat-Latn"
        ],
        "main_score": 0.006677350427350427,
        "precision": 0.004720052083333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004918937493665755,
        "hf_subset": "zat_Latn-eng_Latn",
        "languages": [
          "zat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004918937493665755,
        "precision": 0.004446295511817866,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010200143759426846,
        "hf_subset": "eng_Latn-zav_Latn",
        "languages": [
          "eng-Latn",
          "zav-Latn"
        ],
        "main_score": 0.010200143759426846,
        "precision": 0.008119884672619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007109484418767506,
        "hf_subset": "zav_Latn-eng_Latn",
        "languages": [
          "zav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007109484418767506,
        "precision": 0.006174538352272727,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00917376893939394,
        "hf_subset": "eng_Latn-zaw_Latn",
        "languages": [
          "eng-Latn",
          "zaw-Latn"
        ],
        "main_score": 0.00917376893939394,
        "precision": 0.007552083333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008617479086229085,
        "hf_subset": "zaw_Latn-eng_Latn",
        "languages": [
          "zaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008617479086229085,
        "precision": 0.0070507418805792095,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019156407828282828,
        "hf_subset": "eng_Latn-zca_Latn",
        "languages": [
          "eng-Latn",
          "zca-Latn"
        ],
        "main_score": 0.019156407828282828,
        "precision": 0.016479251912173726,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009091916982024599,
        "hf_subset": "zca_Latn-eng_Latn",
        "languages": [
          "zca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009091916982024599,
        "precision": 0.0074883664955070605,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013136816007060572,
        "hf_subset": "eng_Latn-zga_Latn",
        "languages": [
          "eng-Latn",
          "zga-Latn"
        ],
        "main_score": 0.013136816007060572,
        "precision": 0.011082504734848484,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014960032308377896,
        "hf_subset": "zga_Latn-eng_Latn",
        "languages": [
          "zga-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014960032308377896,
        "precision": 0.014006858648255814,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009331597222222224,
        "hf_subset": "eng_Latn-zia_Latn",
        "languages": [
          "eng-Latn",
          "zia-Latn"
        ],
        "main_score": 0.009331597222222224,
        "precision": 0.008655894886363636,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "zia_Latn-eng_Latn",
        "languages": [
          "zia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005818965517241379,
        "hf_subset": "eng_Latn-ziw_Latn",
        "languages": [
          "eng-Latn",
          "ziw-Latn"
        ],
        "main_score": 0.0005818965517241379,
        "precision": 0.00030226934523809525,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00505952380952381,
        "hf_subset": "ziw_Latn-eng_Latn",
        "languages": [
          "ziw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00505952380952381,
        "precision": 0.004535590277777777,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.018247767857142855,
        "hf_subset": "eng_Latn-zlm_Latn",
        "languages": [
          "eng-Latn",
          "zlm-Latn"
        ],
        "main_score": 0.018247767857142855,
        "precision": 0.01329844200937951,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02143429487179487,
        "hf_subset": "zlm_Latn-eng_Latn",
        "languages": [
          "zlm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02143429487179487,
        "precision": 0.0195608428030303,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0111328125,
        "hf_subset": "eng_Latn-zos_Latn",
        "languages": [
          "eng-Latn",
          "zos-Latn"
        ],
        "main_score": 0.0111328125,
        "precision": 0.0074042528195488715,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004508928571428571,
        "hf_subset": "zos_Latn-eng_Latn",
        "languages": [
          "zos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004508928571428571,
        "precision": 0.004229180481874447,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01461287242891712,
        "hf_subset": "eng_Latn-zpc_Latn",
        "languages": [
          "eng-Latn",
          "zpc-Latn"
        ],
        "main_score": 0.01461287242891712,
        "precision": 0.011098710317460316,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0021968482905982906,
        "hf_subset": "zpc_Latn-eng_Latn",
        "languages": [
          "zpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0021968482905982906,
        "precision": 0.0013091379643962848,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011851457000710733,
        "hf_subset": "eng_Latn-zpl_Latn",
        "languages": [
          "eng-Latn",
          "zpl-Latn"
        ],
        "main_score": 0.011851457000710733,
        "precision": 0.008167391134085213,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026785714285714286,
        "hf_subset": "zpl_Latn-eng_Latn",
        "languages": [
          "zpl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026785714285714286,
        "precision": 0.0016276041666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009440104166666666,
        "hf_subset": "eng_Latn-zpm_Latn",
        "languages": [
          "eng-Latn",
          "zpm-Latn"
        ],
        "main_score": 0.009440104166666666,
        "precision": 0.007719494047619047,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008465608465608466,
        "hf_subset": "zpm_Latn-eng_Latn",
        "languages": [
          "zpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008465608465608466,
        "precision": 0.00697359556384743,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017613146551724138,
        "hf_subset": "eng_Latn-zpo_Latn",
        "languages": [
          "eng-Latn",
          "zpo-Latn"
        ],
        "main_score": 0.017613146551724138,
        "precision": 0.01682079081632653,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011080109126984128,
        "hf_subset": "zpo_Latn-eng_Latn",
        "languages": [
          "zpo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011080109126984128,
        "precision": 0.009836559206582102,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003195856708742403,
        "hf_subset": "eng_Latn-zpq_Latn",
        "languages": [
          "eng-Latn",
          "zpq-Latn"
        ],
        "main_score": 0.003195856708742403,
        "precision": 0.0022608901515151513,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007288935023310023,
        "hf_subset": "zpq_Latn-eng_Latn",
        "languages": [
          "zpq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007288935023310023,
        "precision": 0.005979810826286116,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026130430242272348,
        "hf_subset": "eng_Latn-zpu_Latn",
        "languages": [
          "eng-Latn",
          "zpu-Latn"
        ],
        "main_score": 0.026130430242272348,
        "precision": 0.02370189831641312,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022194157268170422,
        "hf_subset": "zpu_Latn-eng_Latn",
        "languages": [
          "zpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022194157268170422,
        "precision": 0.01904000946969697,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01981124686716792,
        "hf_subset": "eng_Latn-zpv_Latn",
        "languages": [
          "eng-Latn",
          "zpv-Latn"
        ],
        "main_score": 0.01981124686716792,
        "precision": 0.016056095157657657,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008138020833333332,
        "hf_subset": "zpv_Latn-eng_Latn",
        "languages": [
          "zpv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008138020833333332,
        "precision": 0.006810461956521739,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011598124098124097,
        "hf_subset": "eng_Latn-zpz_Latn",
        "languages": [
          "eng-Latn",
          "zpz-Latn"
        ],
        "main_score": 0.011598124098124097,
        "precision": 0.00786532962543992,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001019264416417584,
        "hf_subset": "zpz_Latn-eng_Latn",
        "languages": [
          "zpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001019264416417584,
        "precision": 0.0005289500094713528,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008522727272727272,
        "hf_subset": "eng_Latn-zsr_Latn",
        "languages": [
          "eng-Latn",
          "zsr-Latn"
        ],
        "main_score": 0.008522727272727272,
        "precision": 0.005729166666666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009370204172564083,
        "hf_subset": "zsr_Latn-eng_Latn",
        "languages": [
          "zsr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009370204172564083,
        "precision": 0.007479467147435897,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010035091945388031,
        "hf_subset": "eng_Latn-ztq_Latn",
        "languages": [
          "eng-Latn",
          "ztq-Latn"
        ],
        "main_score": 0.010035091945388031,
        "precision": 0.007002925459956709,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009579613095238094,
        "hf_subset": "ztq_Latn-eng_Latn",
        "languages": [
          "ztq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009579613095238094,
        "precision": 0.008818655303030304,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013361791237113401,
        "hf_subset": "eng_Latn-zty_Latn",
        "languages": [
          "eng-Latn",
          "zty-Latn"
        ],
        "main_score": 0.013361791237113401,
        "precision": 0.011433919270833332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010361405835543768,
        "hf_subset": "zty_Latn-eng_Latn",
        "languages": [
          "zty-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010361405835543768,
        "precision": 0.0005503015350877193,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.013667927384024081,
        "hf_subset": "eng_Latn-zyp_Latn",
        "languages": [
          "eng-Latn",
          "zyp-Latn"
        ],
        "main_score": 0.013667927384024081,
        "precision": 0.010460867823299889,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.016927083333333332,
        "hf_subset": "zyp_Latn-eng_Latn",
        "languages": [
          "zyp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016927083333333332,
        "precision": 0.015625,
        "recall": 0.01953125
      }
    ]
  },
  "task_name": "BibleNLPBitextMining"
}