{
  "dataset_revision": "e7fc9f3d8d6c5640a26679d8a50b1666b02cc41f",
  "evaluation_time": 10.534992694854736,
  "kg_co2_emissions": 0.0016002520676395501,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.5874941009910335,
        "ap": 0.6214394893920764,
        "ap_weighted": 0.6214394893920764,
        "f1": 0.5799613105647334,
        "f1_weighted": 0.5795981983422427,
        "hf_subset": "default",
        "languages": [
          "hrv-Latn"
        ],
        "main_score": 0.5874941009910335,
        "scores_per_experiment": [
          {
            "accuracy": 0.5394053798961774,
            "ap": 0.6011350017508229,
            "ap_weighted": 0.6011350017508229,
            "f1": 0.5293982724566977,
            "f1_weighted": 0.5208808962218006
          },
          {
            "accuracy": 0.6196319018404908,
            "ap": 0.6342033194841247,
            "ap_weighted": 0.6342033194841247,
            "f1": 0.6179881185638494,
            "f1_weighted": 0.6210982984326027
          },
          {
            "accuracy": 0.6347333647947145,
            "ap": 0.6382398506137967,
            "ap_weighted": 0.6382398506137967,
            "f1": 0.6289299211572295,
            "f1_weighted": 0.6346895652200919
          },
          {
            "accuracy": 0.6380368098159509,
            "ap": 0.6454313427081312,
            "ap_weighted": 0.6454313427081312,
            "f1": 0.6355224104853241,
            "f1_weighted": 0.6392797231214312
          },
          {
            "accuracy": 0.5710240679565833,
            "ap": 0.6184476900941178,
            "ap_weighted": 0.6184476900941178,
            "f1": 0.5667691019084085,
            "f1_weighted": 0.5614402634766466
          },
          {
            "accuracy": 0.5776309579990562,
            "ap": 0.6255463907778775,
            "ap_weighted": 0.6255463907778775,
            "f1": 0.5719554238961772,
            "f1_weighted": 0.5658379424656149
          },
          {
            "accuracy": 0.4926852288815479,
            "ap": 0.5500850638597101,
            "ap_weighted": 0.5500850638597101,
            "f1": 0.47089735093877,
            "f1_weighted": 0.48422342512237593
          },
          {
            "accuracy": 0.6418121755545069,
            "ap": 0.6507017350052446,
            "ap_weighted": 0.6507017350052446,
            "f1": 0.6403740436764415,
            "f1_weighted": 0.643196645795331
          },
          {
            "accuracy": 0.633317602642756,
            "ap": 0.6510313052255849,
            "ap_weighted": 0.6510313052255849,
            "f1": 0.633262389784129,
            "f1_weighted": 0.6338208890848569
          },
          {
            "accuracy": 0.5266635205285513,
            "ap": 0.5995731944013534,
            "ap_weighted": 0.5995731944013534,
            "f1": 0.5045160727803076,
            "f1_weighted": 0.49151433448167353
          }
        ]
      }
    ]
  },
  "task_name": "FrenkHrClassification"
}