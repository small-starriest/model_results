{
  "dataset_revision": "3f756ab4572e071eb53e887ab629f19fa747d39e",
  "evaluation_time": 11.474790334701538,
  "kg_co2_emissions": 0.0017466591261676304,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.6751798561151079,
        "ap": 0.6231887482006706,
        "ap_weighted": 0.6231887482006706,
        "f1": 0.6723345700908806,
        "f1_weighted": 0.6723345700908806,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ],
        "main_score": 0.6751798561151079,
        "scores_per_experiment": [
          {
            "accuracy": 0.6443345323741008,
            "ap": 0.5941669741130173,
            "ap_weighted": 0.5941669741130173,
            "f1": 0.6440840472657123,
            "f1_weighted": 0.6440840472657123
          },
          {
            "accuracy": 0.7387589928057554,
            "ap": 0.6817103839052652,
            "ap_weighted": 0.6817103839052652,
            "f1": 0.7382814501723767,
            "f1_weighted": 0.7382814501723767
          },
          {
            "accuracy": 0.6987410071942446,
            "ap": 0.6525445503161635,
            "ap_weighted": 0.6525445503161635,
            "f1": 0.6936752474107697,
            "f1_weighted": 0.6936752474107697
          },
          {
            "accuracy": 0.6821043165467626,
            "ap": 0.6256776269125545,
            "ap_weighted": 0.6256776269125545,
            "f1": 0.6819622784699009,
            "f1_weighted": 0.6819622784699009
          },
          {
            "accuracy": 0.7050359712230215,
            "ap": 0.653664814319223,
            "ap_weighted": 0.653664814319223,
            "f1": 0.7026793713108613,
            "f1_weighted": 0.7026793713108613
          },
          {
            "accuracy": 0.6029676258992805,
            "ap": 0.564284891305197,
            "ap_weighted": 0.564284891305197,
            "f1": 0.6000175163630328,
            "f1_weighted": 0.6000175163630327
          },
          {
            "accuracy": 0.674910071942446,
            "ap": 0.6171150263747154,
            "ap_weighted": 0.6171150263747154,
            "f1": 0.6748295382502274,
            "f1_weighted": 0.6748295382502273
          },
          {
            "accuracy": 0.6366906474820144,
            "ap": 0.5827139118580653,
            "ap_weighted": 0.5827139118580653,
            "f1": 0.6283074988313455,
            "f1_weighted": 0.6283074988313455
          },
          {
            "accuracy": 0.6848021582733813,
            "ap": 0.6215021086579013,
            "ap_weighted": 0.6215021086579013,
            "f1": 0.6824104330742746,
            "f1_weighted": 0.6824104330742746
          },
          {
            "accuracy": 0.6834532374100719,
            "ap": 0.6385071942446043,
            "ap_weighted": 0.6385071942446043,
            "f1": 0.6770983197603051,
            "f1_weighted": 0.6770983197603051
          }
        ]
      }
    ]
  },
  "task_name": "DutchBookReviewSentimentClassification"
}