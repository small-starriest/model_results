{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.9981386138613861,
            "accuracy_threshold": 0.8418141603469849,
            "ap": 0.9505365589236207,
            "f1": 0.9067460317460319,
            "f1_threshold": 0.8416777849197388,
            "precision": 0.8996062992125984,
            "recall": 0.914
        },
        "dot": {
            "accuracy": 0.9981386138613861,
            "accuracy_threshold": 0.8418142199516296,
            "ap": 0.9505365589236205,
            "f1": 0.9067460317460319,
            "f1_threshold": 0.8416777849197388,
            "precision": 0.8996062992125984,
            "recall": 0.914
        },
        "euclidean": {
            "accuracy": 0.9981386138613861,
            "accuracy_threshold": 0.5624691247940063,
            "ap": 0.9505365589236205,
            "f1": 0.9067460317460319,
            "f1_threshold": 0.5627117156982422,
            "precision": 0.8996062992125984,
            "recall": 0.914
        },
        "evaluation_time": 13.68,
        "manhattan": {
            "accuracy": 0.9981782178217822,
            "accuracy_threshold": 12.42026138305664,
            "ap": 0.9504104696246076,
            "f1": 0.9086395233366436,
            "f1_threshold": 12.424188613891602,
            "precision": 0.9023668639053254,
            "recall": 0.915
        },
        "max": {
            "accuracy": 0.9981782178217822,
            "ap": 0.9505365589236207,
            "f1": 0.9086395233366436
        }
    },
    "mteb_dataset_name": "SprintDuplicateQuestions",
    "dataset_revision": "5a8256d0dff9c4bd3be3ba3e67e4e70173f802ea"
}