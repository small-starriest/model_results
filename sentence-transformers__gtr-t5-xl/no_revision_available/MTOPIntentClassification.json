{
    "mteb_version": "0.0.2",
    "test": {
        "de": {
            "accuracy": 0.5575091575091575,
            "accuracy_stderr": 0.027981344143396092,
            "f1": 0.3604213348774414,
            "f1_stderr": 0.016252197730266465,
            "main_score": 0.5575091575091575
        },
        "en": {
            "accuracy": 0.6593479252165981,
            "accuracy_stderr": 0.016371301030488915,
            "f1": 0.4861256347081396,
            "f1_stderr": 0.0071547644123287815,
            "main_score": 0.6593479252165981
        },
        "es": {
            "accuracy": 0.5773182121414276,
            "accuracy_stderr": 0.01769153794651523,
            "f1": 0.35275618460553104,
            "f1_stderr": 0.011814246904756751,
            "main_score": 0.5773182121414276
        },
        "evaluation_time": 263.92,
        "fr": {
            "accuracy": 0.5107109301597245,
            "accuracy_stderr": 0.038273742652877266,
            "f1": 0.36570849906022207,
            "f1_stderr": 0.0160859380923806,
            "main_score": 0.5107109301597245
        },
        "hi": {
            "accuracy": 0.03194693438508426,
            "accuracy_stderr": 0.013420988444392247,
            "f1": 0.010165921060074672,
            "f1_stderr": 0.003117869128411894,
            "main_score": 0.03194693438508426
        },
        "th": {
            "accuracy": 0.05547920433996384,
            "accuracy_stderr": 0.022485010617764013,
            "f1": 0.01547212880366598,
            "f1_stderr": 0.0061979774969380275,
            "main_score": 0.05547920433996384
        }
    },
    "mteb_dataset_name": "MTOPIntentClassification",
    "dataset_revision": "6299947a7777084cc2d4b64235bf7190381ce755"
}