{
  "dataset_revision": "bd1a7370caf712125fac1fda375834ca8ddefaca",
  "evaluation_time": 10.077031135559082,
  "kg_co2_emissions": 0.0015144019193919864,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.421533203125,
        "f1": 0.4113358022711401,
        "f1_weighted": 0.421844472019308,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.421533203125,
        "scores_per_experiment": [
          {
            "accuracy": 0.4404296875,
            "f1": 0.4174708858821005,
            "f1_weighted": 0.4378431197979956
          },
          {
            "accuracy": 0.44775390625,
            "f1": 0.43221854878140825,
            "f1_weighted": 0.44621649508238825
          },
          {
            "accuracy": 0.43896484375,
            "f1": 0.43292261474222826,
            "f1_weighted": 0.4434765579905921
          },
          {
            "accuracy": 0.45751953125,
            "f1": 0.4389976944762594,
            "f1_weighted": 0.45535743656276106
          },
          {
            "accuracy": 0.43896484375,
            "f1": 0.4120642622412851,
            "f1_weighted": 0.43389907656784454
          },
          {
            "accuracy": 0.35009765625,
            "f1": 0.3484814299259171,
            "f1_weighted": 0.3521821130844974
          },
          {
            "accuracy": 0.4521484375,
            "f1": 0.44880816752688624,
            "f1_weighted": 0.45605439100887674
          },
          {
            "accuracy": 0.3681640625,
            "f1": 0.3657696138886322,
            "f1_weighted": 0.36613640999618385
          },
          {
            "accuracy": 0.39404296875,
            "f1": 0.3921209575099167,
            "f1_weighted": 0.39540517928627944
          },
          {
            "accuracy": 0.42724609375,
            "f1": 0.4245038477367668,
            "f1_weighted": 0.431873940815661
          }
        ]
      }
    ]
  },
  "task_name": "KorHateClassification"
}