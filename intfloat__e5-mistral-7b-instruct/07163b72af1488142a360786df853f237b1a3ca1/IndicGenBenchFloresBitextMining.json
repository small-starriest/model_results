{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 315.1603002548218,
  "kg_co2_emissions": 0.19106595374833302,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433466,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9986824769433466,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9179841897233202,
        "f1": 0.895405138339921,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.895405138339921,
        "precision": 0.8859613212874082,
        "recall": 0.9179841897233202
      },
      {
        "accuracy": 0.9407114624505929,
        "f1": 0.9221673254281949,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9221673254281949,
        "precision": 0.9134552042160738,
        "recall": 0.9407114624505929
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9772727272727273,
        "f1": 0.9700263504611332,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9700263504611332,
        "precision": 0.9665678524374177,
        "recall": 0.9772727272727273
      },
      {
        "accuracy": 0.9752964426877471,
        "f1": 0.967391304347826,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.967391304347826,
        "precision": 0.9636034255599473,
        "recall": 0.9752964426877471
      },
      {
        "accuracy": 0.8063241106719368,
        "f1": 0.7660871846642597,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.7660871846642597,
        "precision": 0.7504858366271409,
        "recall": 0.8063241106719368
      },
      {
        "accuracy": 0.8596837944664032,
        "f1": 0.8252682100508187,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8252682100508187,
        "precision": 0.810441370223979,
        "recall": 0.8596837944664032
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768115,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9855072463768115,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768115,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9855072463768115,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9575098814229249,
        "f1": 0.9446640316205533,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9446640316205533,
        "precision": 0.9387681159420289,
        "recall": 0.9575098814229249
      },
      {
        "accuracy": 0.9752964426877471,
        "f1": 0.9670619235836627,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9670619235836627,
        "precision": 0.9629446640316206,
        "recall": 0.9752964426877471
      },
      {
        "accuracy": 0.924901185770751,
        "f1": 0.9050254093732354,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9050254093732354,
        "precision": 0.8966073781291174,
        "recall": 0.924901185770751
      },
      {
        "accuracy": 0.9426877470355731,
        "f1": 0.9259552042160737,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9259552042160737,
        "precision": 0.9182312252964426,
        "recall": 0.9426877470355731
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733861,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9947299077733861,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9545454545454546,
        "f1": 0.9416525503482025,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9416525503482025,
        "precision": 0.9359354413702241,
        "recall": 0.9545454545454546
      },
      {
        "accuracy": 0.9604743083003953,
        "f1": 0.9484519104084321,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9484519104084321,
        "precision": 0.9428524374176548,
        "recall": 0.9604743083003953
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9845191040843215,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9845191040843215,
        "precision": 0.982707509881423,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768115,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9855072463768115,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.993741765480896,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.993741765480896,
        "precision": 0.9930830039525692,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9953886693017128,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9953886693017128,
        "precision": 0.9950592885375494,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.5968379446640316,
        "f1": 0.5483803692582905,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.5483803692582905,
        "precision": 0.5329551635233454,
        "recall": 0.5968379446640316
      },
      {
        "accuracy": 0.6907114624505929,
        "f1": 0.6256219022523369,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6256219022523369,
        "precision": 0.5995071052136269,
        "recall": 0.6907114624505929
      },
      {
        "accuracy": 0.8260869565217391,
        "f1": 0.7930183041596086,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.7930183041596086,
        "precision": 0.7810452887033915,
        "recall": 0.8260869565217391
      },
      {
        "accuracy": 0.8804347826086957,
        "f1": 0.8476802183323923,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8476802183323923,
        "precision": 0.8333333333333333,
        "recall": 0.8804347826086957
      },
      {
        "accuracy": 0.8784584980237155,
        "f1": 0.8537808206286467,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8537808206286467,
        "precision": 0.8443706655663177,
        "recall": 0.8784584980237155
      },
      {
        "accuracy": 0.8685770750988142,
        "f1": 0.8340909090909091,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.8340909090909091,
        "precision": 0.8190711462450593,
        "recall": 0.8685770750988142
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768116,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9855072463768116,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9871541501976284,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9871541501976284,
        "precision": 0.9856719367588933,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9876482213438735,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9876482213438735,
        "precision": 0.9864953886693016,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.98633069828722,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.98633069828722,
        "precision": 0.9850131752305665,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.3685770750988142,
        "f1": 0.3115229331739754,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.3115229331739754,
        "precision": 0.29520281035939644,
        "recall": 0.3685770750988142
      },
      {
        "accuracy": 0.5029644268774703,
        "f1": 0.4256600788698376,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.4256600788698376,
        "precision": 0.3988765763222285,
        "recall": 0.5029644268774703
      },
      {
        "accuracy": 0.43873517786561267,
        "f1": 0.3948772190141437,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.3948772190141437,
        "precision": 0.38066164708035694,
        "recall": 0.43873517786561267
      },
      {
        "accuracy": 0.49407114624505927,
        "f1": 0.43279078190145387,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.43279078190145387,
        "precision": 0.41038533271734856,
        "recall": 0.49407114624505927
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9268774703557312,
        "f1": 0.9085638998682477,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9085638998682477,
        "precision": 0.9009552042160738,
        "recall": 0.9268774703557312
      },
      {
        "accuracy": 0.9298418972332015,
        "f1": 0.9082674571805007,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.9082674571805007,
        "precision": 0.8980895915678523,
        "recall": 0.9298418972332015
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9868247694334651,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9868247694334651,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.989459815546772,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.989459815546772,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.5266798418972332,
        "f1": 0.4873985750951523,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.4873985750951523,
        "precision": 0.4745672898421706,
        "recall": 0.5266798418972332
      },
      {
        "accuracy": 0.5988142292490118,
        "f1": 0.5436814503020037,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.5436814503020037,
        "precision": 0.5221112879215646,
        "recall": 0.5988142292490118
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9937417654808959,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9937417654808959,
        "precision": 0.9930830039525692,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9924242424242423,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9924242424242423,
        "precision": 0.991600790513834,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.020092087445317944,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.020092087445317944,
        "precision": 0.018841720422748093,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.040513833992094864,
        "f1": 0.024380949529170876,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.024380949529170876,
        "precision": 0.020857037908147486,
        "recall": 0.040513833992094864
      }
    ],
    "validation": [
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.925777331995988,
        "f1": 0.9085924439986627,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9085924439986627,
        "precision": 0.9017218321631562,
        "recall": 0.925777331995988
      },
      {
        "accuracy": 0.950852557673019,
        "f1": 0.9346372450685388,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9346372450685388,
        "precision": 0.926613172851889,
        "recall": 0.950852557673019
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9699097291875627,
        "f1": 0.9612838515546639,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9612838515546639,
        "precision": 0.9574557004346372,
        "recall": 0.9699097291875627
      },
      {
        "accuracy": 0.9799398194583752,
        "f1": 0.9735874289535272,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9735874289535272,
        "precision": 0.9704112337011033,
        "recall": 0.9799398194583752
      },
      {
        "accuracy": 0.7913741223671013,
        "f1": 0.7513491634855727,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.7513491634855727,
        "precision": 0.7365654762770021,
        "recall": 0.7913741223671013
      },
      {
        "accuracy": 0.8365095285857572,
        "f1": 0.7948177866934135,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7948177866934135,
        "precision": 0.7760615178869943,
        "recall": 0.8365095285857572
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9881310598462052,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9881310598462052,
        "precision": 0.9867937144767637,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9866265463055833,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9866265463055833,
        "precision": 0.9849548645937813,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.954864593781344,
        "f1": 0.9410565028418589,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9410565028418589,
        "precision": 0.9347208291541291,
        "recall": 0.954864593781344
      },
      {
        "accuracy": 0.9648946840521565,
        "f1": 0.9533600802407222,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9533600802407222,
        "precision": 0.947676362420595,
        "recall": 0.9648946840521565
      },
      {
        "accuracy": 0.921765295887663,
        "f1": 0.9027940965754407,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9027940965754407,
        "precision": 0.8953304357516995,
        "recall": 0.921765295887663
      },
      {
        "accuracy": 0.9368104312938816,
        "f1": 0.9180875961216984,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9180875961216984,
        "precision": 0.9092276830491475,
        "recall": 0.9368104312938816
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527917,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9933132731527917,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9478435305917753,
        "f1": 0.9341357405549984,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9341357405549984,
        "precision": 0.9280751344943923,
        "recall": 0.9478435305917753
      },
      {
        "accuracy": 0.9558676028084253,
        "f1": 0.9426278836509528,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9426278836509528,
        "precision": 0.9364760949515212,
        "recall": 0.9558676028084253
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9921430959545302,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9921430959545302,
        "precision": 0.9913072550986292,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.987128050819124,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.987128050819124,
        "precision": 0.9857907054496824,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.9842861919090605,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9842861919090605,
        "precision": 0.9824473420260782,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.6108324974924775,
        "f1": 0.5590335219221879,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.5590335219221879,
        "precision": 0.5422296505290167,
        "recall": 0.6108324974924775
      },
      {
        "accuracy": 0.7191574724172518,
        "f1": 0.6579078505357342,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6579078505357342,
        "precision": 0.6343319641464074,
        "recall": 0.7191574724172518
      },
      {
        "accuracy": 0.8415245737211635,
        "f1": 0.8075058508859912,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.8075058508859912,
        "precision": 0.7944595691837417,
        "recall": 0.8415245737211635
      },
      {
        "accuracy": 0.892678034102307,
        "f1": 0.8624205951186893,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8624205951186893,
        "precision": 0.8487963891675026,
        "recall": 0.892678034102307
      },
      {
        "accuracy": 0.8485456369107321,
        "f1": 0.8166666666666667,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8166666666666667,
        "precision": 0.8039916628445372,
        "recall": 0.8485456369107321
      },
      {
        "accuracy": 0.8545636910732196,
        "f1": 0.8147800544490613,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.8147800544490613,
        "precision": 0.7968667908487367,
        "recall": 0.8545636910732196
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444667,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9893012370444667,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9849548645937813,
        "f1": 0.9802741558007355,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9802741558007355,
        "precision": 0.9779338014042126,
        "recall": 0.9849548645937813
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9913072550986292,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9913072550986292,
        "precision": 0.9904714142427282,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9906385824139083,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9899699097291875,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9921430959545303,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9921430959545303,
        "precision": 0.9913072550986292,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527916,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9933132731527916,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.3721163490471414,
        "f1": 0.3078078316350743,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.3078078316350743,
        "precision": 0.2914046146756487,
        "recall": 0.3721163490471414
      },
      {
        "accuracy": 0.5085255767301906,
        "f1": 0.4323006982986923,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.4323006982986923,
        "precision": 0.4050584654396089,
        "recall": 0.5085255767301906
      },
      {
        "accuracy": 0.4463390170511535,
        "f1": 0.40492048409220976,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.40492048409220976,
        "precision": 0.39078343171727464,
        "recall": 0.4463390170511535
      },
      {
        "accuracy": 0.5175526579739218,
        "f1": 0.45501291668912175,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.45501291668912175,
        "precision": 0.43230982630430975,
        "recall": 0.5175526579739218
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9949849548645938,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9949849548645938,
        "precision": 0.9944834503510531,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222335,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9946506185222335,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9197592778335005,
        "f1": 0.900033433634236,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.900033433634236,
        "precision": 0.8920503936050576,
        "recall": 0.9197592778335005
      },
      {
        "accuracy": 0.9338014042126379,
        "f1": 0.9141424272818456,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.9141424272818456,
        "precision": 0.9047977265128718,
        "recall": 0.9338014042126379
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9854563691073219,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9854563691073219,
        "precision": 0.9837846873955198,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.984620528251421,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.984620528251421,
        "precision": 0.9829488465396189,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139085,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139085,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.5406218655967904,
        "f1": 0.5010848338977889,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.5010848338977889,
        "precision": 0.4885297616204623,
        "recall": 0.5406218655967904
      },
      {
        "accuracy": 0.6118355065195586,
        "f1": 0.5535017751667702,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.5535017751667702,
        "precision": 0.5292962219993314,
        "recall": 0.6118355065195586
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9936476094951522,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9936476094951522,
        "precision": 0.9929789368104313,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.020060180541624874,
        "f1": 0.01695315303709293,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.01695315303709293,
        "precision": 0.016333481884612887,
        "recall": 0.020060180541624874
      },
      {
        "accuracy": 0.029087261785356068,
        "f1": 0.017243071204956863,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.017243071204956863,
        "precision": 0.014546861874137819,
        "recall": 0.029087261785356068
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}