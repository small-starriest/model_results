{
    "test": {
        "cos_sim": {
            "accuracy": 0.8390057817249806,
            "accuracy_threshold": 0.9457884430885315,
            "ap": 0.6594999377083578,
            "f1": 0.6270176309908121,
            "f1_threshold": 0.9376586675643921,
            "precision": 0.5921669793621013,
            "recall": 0.6662269129287599
        },
        "dot": {
            "accuracy": 0.829528521189724,
            "accuracy_threshold": 184.0816650390625,
            "ap": 0.6291112569739057,
            "f1": 0.6162570888468808,
            "f1_threshold": 180.64602661132812,
            "precision": 0.5579803166452717,
            "recall": 0.6881266490765171
        },
        "euclidean": {
            "accuracy": 0.8351910353460095,
            "accuracy_threshold": 4.494647026062012,
            "ap": 0.6492280786517313,
            "f1": 0.617544731610338,
            "f1_threshold": 4.897141933441162,
            "precision": 0.5836073273837482,
            "recall": 0.6556728232189973
        },
        "evaluation_time": 9.18,
        "manhattan": {
            "accuracy": 0.8355486678190379,
            "accuracy_threshold": 100.02554321289062,
            "ap": 0.6494226703673677,
            "f1": 0.6158328055731476,
            "f1_threshold": 107.43739318847656,
            "precision": 0.5922046285018271,
            "recall": 0.641424802110818
        },
        "max": {
            "accuracy": 0.8390057817249806,
            "ap": 0.6594999377083578,
            "f1": 0.6270176309908121
        }
    },
    "mteb_version": "0.0.2",
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}