{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "evaluation_time": 190.21792554855347,
  "kg_co2_emissions": 0.028772727517528983,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.034033203125,
        "f1": 0.020618309738474425,
        "f1_weighted": 0.023318794589845114,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.034033203125,
        "scores_per_experiment": [
          {
            "accuracy": 0.02685546875,
            "f1": 0.016203974473219963,
            "f1_weighted": 0.017499705235977103
          },
          {
            "accuracy": 0.03564453125,
            "f1": 0.022981148262004654,
            "f1_weighted": 0.025145348560467334
          },
          {
            "accuracy": 0.033203125,
            "f1": 0.02668610484043379,
            "f1_weighted": 0.02477094259140908
          },
          {
            "accuracy": 0.03466796875,
            "f1": 0.017187869476653635,
            "f1_weighted": 0.024104937584031656
          },
          {
            "accuracy": 0.0341796875,
            "f1": 0.02194737994299904,
            "f1_weighted": 0.024027952142858695
          },
          {
            "accuracy": 0.0361328125,
            "f1": 0.02407437087590075,
            "f1_weighted": 0.026313184167043188
          },
          {
            "accuracy": 0.0361328125,
            "f1": 0.01931001553252634,
            "f1_weighted": 0.024084461297491776
          },
          {
            "accuracy": 0.03125,
            "f1": 0.014638343346913342,
            "f1_weighted": 0.017656074912236648
          },
          {
            "accuracy": 0.03564453125,
            "f1": 0.01967719447250434,
            "f1_weighted": 0.023916559033483786
          },
          {
            "accuracy": 0.03662109375,
            "f1": 0.023476696161588383,
            "f1_weighted": 0.025668780373451883
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.031982421875,
        "f1": 0.017884296197334608,
        "f1_weighted": 0.022893712465763227,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.031982421875,
        "scores_per_experiment": [
          {
            "accuracy": 0.02685546875,
            "f1": 0.017689693911587326,
            "f1_weighted": 0.017289380862202414
          },
          {
            "accuracy": 0.03173828125,
            "f1": 0.020178627169375508,
            "f1_weighted": 0.026493153461228887
          },
          {
            "accuracy": 0.03466796875,
            "f1": 0.023365037424101905,
            "f1_weighted": 0.028426933328749866
          },
          {
            "accuracy": 0.02783203125,
            "f1": 0.015018985740149345,
            "f1_weighted": 0.017222771749100908
          },
          {
            "accuracy": 0.03173828125,
            "f1": 0.018954763779053082,
            "f1_weighted": 0.026611227421757325
          },
          {
            "accuracy": 0.03564453125,
            "f1": 0.02051061354009296,
            "f1_weighted": 0.027772843939814176
          },
          {
            "accuracy": 0.03662109375,
            "f1": 0.019352880419508705,
            "f1_weighted": 0.025614267003893562
          },
          {
            "accuracy": 0.0283203125,
            "f1": 0.012881977630976236,
            "f1_weighted": 0.01569758295898694
          },
          {
            "accuracy": 0.03515625,
            "f1": 0.015418120633845619,
            "f1_weighted": 0.02289106623196737
          },
          {
            "accuracy": 0.03125,
            "f1": 0.015472261724655434,
            "f1_weighted": 0.020917897699930823
          }
        ]
      }
    ]
  },
  "task_name": "GreekLegalCodeClassification"
}