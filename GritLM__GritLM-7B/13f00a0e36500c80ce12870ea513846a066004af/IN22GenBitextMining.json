{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 91.49306130409241,
  "kg_co2_emissions": 0.04230592580984302,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166666,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9845377604166666,
        "precision": 0.9827473958333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.552925812251984,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.552925812251984,
        "precision": 0.5309326171875,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8888997395833333,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.8888997395833333,
        "precision": 0.878173828125,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9728190104166666,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9728190104166666,
        "precision": 0.9695638020833333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8316080729166666,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8316080729166666,
        "precision": 0.817138671875,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8464704241071429,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8464704241071429,
        "precision": 0.8326009114583333,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9700520833333333,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9700520833333333,
        "precision": 0.96630859375,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.9189453125,
        "f1": 0.8958984374999999,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.8958984374999999,
        "precision": 0.8848470052083333,
        "recall": 0.9189453125
      },
      {
        "accuracy": 0.7373046875,
        "f1": 0.686283947172619,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.686283947172619,
        "precision": 0.6663341703869048,
        "recall": 0.7373046875
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.951171875,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.951171875,
        "precision": 0.9454752604166667,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.728515625,
        "f1": 0.6759803185096154,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.6759803185096154,
        "precision": 0.6538178943452381,
        "recall": 0.728515625
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9384765625,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9384765625,
        "precision": 0.93115234375,
        "recall": 0.953125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0030153169313325563,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0030153169313325563,
        "precision": 0.002211626586967457,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9705403645833334,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9705403645833334,
        "precision": 0.9671223958333334,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7943684895833333,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.7943684895833333,
        "precision": 0.7765950520833333,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.7919921875,
        "f1": 0.7462317088293651,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.7462317088293651,
        "precision": 0.7264125279017858,
        "recall": 0.7919921875
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9597981770833333,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9597981770833333,
        "precision": 0.9549153645833334,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004271544750060375,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.004271544750060375,
        "precision": 0.0030113935814619405,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.8036830357142857,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8036830357142857,
        "precision": 0.7880859375,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.75458984375,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.75458984375,
        "precision": 0.7344563802083333,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8065755208333333,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8065755208333333,
        "precision": 0.7895833333333333,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9479166666666666,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9479166666666666,
        "precision": 0.9420572916666667,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.5966820126488095,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.5966820126488095,
        "precision": 0.577952163938492,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9513346354166666,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9513346354166666,
        "precision": 0.94580078125,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.8917643229166667,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8917643229166667,
        "precision": 0.8805338541666666,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9069661458333332,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9069661458333332,
        "precision": 0.8973795572916666,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.94189453125,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.94189453125,
        "precision": 0.93505859375,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7724144345238095,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.7724144345238095,
        "precision": 0.7536946614583333,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.810546875,
        "f1": 0.7657552083333333,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.7657552083333333,
        "precision": 0.7457139756944444,
        "recall": 0.810546875
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666666,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9820963541666666,
        "precision": 0.97998046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0036814250848896434,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0036814250848896434,
        "precision": 0.0026697330476394606,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.83642578125,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.83642578125,
        "precision": 0.820263671875,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.857421875,
        "f1": 0.821602063301282,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.821602063301282,
        "precision": 0.8058268229166666,
        "recall": 0.857421875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.004935546278304599,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.004935546278304599,
        "precision": 0.003110524073540707,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8700520833333334,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8700520833333334,
        "precision": 0.85810546875,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.873046875,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.873046875,
        "precision": 0.8606770833333333,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8809244791666666,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8809244791666666,
        "precision": 0.8685709635416667,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.5771484375,
        "f1": 0.5208550210268561,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5208550210268561,
        "precision": 0.5010306908146906,
        "recall": 0.5771484375
      },
      {
        "accuracy": 0.5927734375,
        "f1": 0.5361013309397256,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5361013309397256,
        "precision": 0.5166610154360038,
        "recall": 0.5927734375
      },
      {
        "accuracy": 0.6181640625,
        "f1": 0.5725929497126647,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5725929497126647,
        "precision": 0.5569584746037382,
        "recall": 0.6181640625
      },
      {
        "accuracy": 0.5751953125,
        "f1": 0.5192976160270177,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5192976160270177,
        "precision": 0.5001670547525902,
        "recall": 0.5751953125
      },
      {
        "accuracy": 0.6064453125,
        "f1": 0.5519970172827904,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5519970172827904,
        "precision": 0.5339748692445728,
        "recall": 0.6064453125
      },
      {
        "accuracy": 0.5087890625,
        "f1": 0.4573593492538805,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.4573593492538805,
        "precision": 0.439541406348189,
        "recall": 0.5087890625
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.5579840307148078,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5579840307148078,
        "precision": 0.5393637294860869,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.505859375,
        "f1": 0.44581465579257695,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.44581465579257695,
        "precision": 0.4257603904533477,
        "recall": 0.505859375
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.46741318035263346,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.46741318035263346,
        "precision": 0.4507923454469507,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.6171875,
        "f1": 0.5620038840995473,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5620038840995473,
        "precision": 0.543178429372277,
        "recall": 0.6171875
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.416924442830333,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.416924442830333,
        "precision": 0.39809190343714707,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.5693359375,
        "f1": 0.5147239622739394,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5147239622739394,
        "precision": 0.49587997587265165,
        "recall": 0.5693359375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005667904590813597,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005667904590813597,
        "precision": 0.004676193670334295,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.5771484375,
        "f1": 0.5224586383461463,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5224586383461463,
        "precision": 0.5040998610413534,
        "recall": 0.5771484375
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.4132115586619263,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.4132115586619263,
        "precision": 0.39295220788269203,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.4624780752917339,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4624780752917339,
        "precision": 0.44300512792902347,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.6083984375,
        "f1": 0.5511026372354497,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.5511026372354497,
        "precision": 0.5301415035845314,
        "recall": 0.6083984375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0038585816226323366,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0038585816226323366,
        "precision": 0.002898156227612602,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.6259765625,
        "f1": 0.5859740194701133,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5859740194701133,
        "precision": 0.5717579675099207,
        "recall": 0.6259765625
      },
      {
        "accuracy": 0.462890625,
        "f1": 0.4106578515183754,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4106578515183754,
        "precision": 0.39280533079117064,
        "recall": 0.462890625
      },
      {
        "accuracy": 0.5400390625,
        "f1": 0.48836859472438,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.48836859472438,
        "precision": 0.4703534895551498,
        "recall": 0.5400390625
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.48601005185991825,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.48601005185991825,
        "precision": 0.4690984163177831,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.9023111979166667,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9023111979166667,
        "precision": 0.8927408854166666,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9454752604166667,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9454752604166667,
        "precision": 0.9392903645833334,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.5967022343975469,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5967022343975469,
        "precision": 0.5781842912946429,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9746744791666667,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9746744791666667,
        "precision": 0.9720865885416667,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8780598958333334,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8780598958333334,
        "precision": 0.8670247395833333,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.856640625,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.856640625,
        "precision": 0.8423665364583334,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8836263020833333,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8836263020833333,
        "precision": 0.8717447916666667,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.7906924293154762,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7906924293154762,
        "precision": 0.7753348214285714,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.974609375,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.974609375,
        "precision": 0.9716796875,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6758146475919913,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6758146475919913,
        "precision": 0.65595703125,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9473307291666666,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9473307291666666,
        "precision": 0.9418131510416667,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003408173998782015,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003408173998782015,
        "precision": 0.0028075037969158036,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9794921875,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9794921875,
        "precision": 0.97705078125,
        "recall": 0.984375
      },
      {
        "accuracy": 0.73046875,
        "f1": 0.6799463665674603,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6799463665674603,
        "precision": 0.6590413411458333,
        "recall": 0.73046875
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8548502604166667,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8548502604166667,
        "precision": 0.8417154947916666,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.94580078125,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.94580078125,
        "precision": 0.93994140625,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0031099142015906783,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0031099142015906783,
        "precision": 0.001885243120594683,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9045247395833333,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9045247395833333,
        "precision": 0.895751953125,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.810546875,
        "f1": 0.76708984375,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.76708984375,
        "precision": 0.7474772135416667,
        "recall": 0.810546875
      },
      {
        "accuracy": 0.8564453125,
        "f1": 0.825439453125,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.825439453125,
        "precision": 0.8120698474702381,
        "recall": 0.8564453125
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96923828125,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.96923828125,
        "precision": 0.9658203125,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9482421875,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9482421875,
        "precision": 0.9420572916666667,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.587890625,
        "f1": 0.5191748681006494,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.5191748681006494,
        "precision": 0.49583966014199243,
        "recall": 0.587890625
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9601236979166667,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9601236979166667,
        "precision": 0.95556640625,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.921875,
        "f1": 0.8979166666666667,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8979166666666667,
        "precision": 0.88671875,
        "recall": 0.921875
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9056640625,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9056640625,
        "precision": 0.895263671875,
        "recall": 0.927734375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9568684895833333,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9568684895833333,
        "precision": 0.95234375,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.822265625,
        "f1": 0.7768903459821428,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.7768903459821428,
        "precision": 0.7573172433035715,
        "recall": 0.822265625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.7919921875,
        "f1": 0.7478060169380252,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7478060169380252,
        "precision": 0.7307832263764881,
        "recall": 0.7919921875
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666667,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9820963541666667,
        "precision": 0.9801432291666666,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0045396671844678315,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0045396671844678315,
        "precision": 0.003931732691498316,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.720703125,
        "f1": 0.6708245693108974,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6708245693108974,
        "precision": 0.651328138677346,
        "recall": 0.720703125
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7887772817460317,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.7887772817460317,
        "precision": 0.7712181454613096,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002428594374251543,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.002428594374251543,
        "precision": 0.001810515873015873,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.870166015625,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.870166015625,
        "precision": 0.858114769345238,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.8985026041666666,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.8985026041666666,
        "precision": 0.8885904947916666,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8712425595238096,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8712425595238096,
        "precision": 0.858837890625,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8181315104166667,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8181315104166667,
        "precision": 0.8024088541666667,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.88896484375,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.88896484375,
        "precision": 0.87841796875,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5832272219967533,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5832272219967533,
        "precision": 0.5635137648809525,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8790364583333333,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8790364583333333,
        "precision": 0.8688151041666667,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.909912109375,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.909912109375,
        "precision": 0.9017020089285714,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8137090773809523,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8137090773809523,
        "precision": 0.7996303013392858,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9200846354166666,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9200846354166666,
        "precision": 0.9119466145833333,
        "recall": 0.9375
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8114118303571428,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8114118303571428,
        "precision": 0.7964192708333333,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.7431640625,
        "f1": 0.6976515997023809,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6976515997023809,
        "precision": 0.6792317708333333,
        "recall": 0.7431640625
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9166666666666666,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9166666666666666,
        "precision": 0.90869140625,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6469029017857143,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6469029017857143,
        "precision": 0.6242536272321428,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.94677734375,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.94677734375,
        "precision": 0.94091796875,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0019114953074075998,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0019114953074075998,
        "precision": 0.0015076828553391053,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9219401041666667,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9219401041666667,
        "precision": 0.914306640625,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6411783854166666,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6411783854166666,
        "precision": 0.617138671875,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.7626953125,
        "f1": 0.7196475074404762,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7196475074404762,
        "precision": 0.7011827256944444,
        "recall": 0.7626953125
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8955729166666666,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8955729166666666,
        "precision": 0.8851725260416667,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006692341946248196,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006692341946248196,
        "precision": 0.005290303253321256,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.81357421875,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.81357421875,
        "precision": 0.7981770833333333,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.6850748697916667,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6850748697916667,
        "precision": 0.665332454004329,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.7939453125,
        "f1": 0.7530164930555555,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7530164930555555,
        "precision": 0.7350992838541667,
        "recall": 0.7939453125
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.87470703125,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.87470703125,
        "precision": 0.8641764322916667,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.8492047991071427,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8492047991071427,
        "precision": 0.8341471354166667,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8928385416666667,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.8928385416666667,
        "precision": 0.88232421875,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.4909272693452381,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.4909272693452381,
        "precision": 0.4730817522321429,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8609886532738096,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.8609886532738096,
        "precision": 0.8490397135416666,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.921875,
        "f1": 0.8982421875,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.8982421875,
        "precision": 0.8874023437499999,
        "recall": 0.921875
      },
      {
        "accuracy": 0.8505859375,
        "f1": 0.81494140625,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.81494140625,
        "precision": 0.7993001302083333,
        "recall": 0.8505859375
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9284505208333333,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9284505208333333,
        "precision": 0.9204915364583333,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8891927083333333,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.8891927083333333,
        "precision": 0.8784993489583334,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.6826171875,
        "f1": 0.6278087797619047,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.6278087797619047,
        "precision": 0.6060465494791667,
        "recall": 0.6826171875
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.89140625,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.89140625,
        "precision": 0.8810221354166667,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7428059895833333,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.7428059895833333,
        "precision": 0.7219889322916666,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9131510416666666,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9131510416666666,
        "precision": 0.904541015625,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004008905134521911,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.004008905134521911,
        "precision": 0.0030106421909041397,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9323567708333332,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9323567708333332,
        "precision": 0.9248860677083334,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.861328125,
        "f1": 0.82861328125,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.82861328125,
        "precision": 0.8138834635416667,
        "recall": 0.861328125
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8587890625,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.8587890625,
        "precision": 0.8461100260416667,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.8996419270833333,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.8996419270833333,
        "precision": 0.8902506510416667,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0035317611142963966,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.0035317611142963966,
        "precision": 0.0022541244562728937,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7912353515624999,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.7912353515624999,
        "precision": 0.7748697916666666,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.75390625,
        "f1": 0.7014997209821429,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.7014997209821429,
        "precision": 0.6791759672619048,
        "recall": 0.75390625
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8291666666666667,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.8291666666666667,
        "precision": 0.8141276041666667,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8924479166666667,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.8924479166666667,
        "precision": 0.881787109375,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9690755208333333,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9690755208333333,
        "precision": 0.96533203125,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.630859375,
        "f1": 0.5754053509424603,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5754053509424603,
        "precision": 0.5536144438244047,
        "recall": 0.630859375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9194986979166666,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9194986979166666,
        "precision": 0.9110514322916667,
        "recall": 0.9375
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9372395833333333,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9372395833333333,
        "precision": 0.9302571614583333,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9677734375,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9677734375,
        "precision": 0.9638671875,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.7998883928571429,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7998883928571429,
        "precision": 0.78125,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7760904947916667,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7760904947916667,
        "precision": 0.7570568266369048,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003051609248225152,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003051609248225152,
        "precision": 0.0023104703342162226,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.8212890625,
        "f1": 0.7769391741071429,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7769391741071429,
        "precision": 0.75791015625,
        "recall": 0.8212890625
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8637369791666667,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8637369791666667,
        "precision": 0.85078125,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.002168753896105507,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002168753896105507,
        "precision": 0.0013458596662514414,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9110351562500001,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9110351562500001,
        "precision": 0.9024251302083334,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8935546875,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8935546875,
        "precision": 0.8828125,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.921875,
        "f1": 0.8986002604166667,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8986002604166667,
        "precision": 0.8873697916666666,
        "recall": 0.921875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8899739583333333,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.8899739583333333,
        "precision": 0.87744140625,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9402669270833334,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9402669270833334,
        "precision": 0.9337565104166667,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.5537109375,
        "f1": 0.5005006820436508,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.5005006820436508,
        "precision": 0.47987157428075394,
        "recall": 0.5537109375
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.89111328125,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.89111328125,
        "precision": 0.8802083333333333,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9541015625,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9541015625,
        "precision": 0.9490885416666667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.8740234375,
        "f1": 0.8429547991071429,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.8429547991071429,
        "precision": 0.8286946614583334,
        "recall": 0.8740234375
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8865559895833333,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8865559895833333,
        "precision": 0.87451171875,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9650065104166666,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.9650065104166666,
        "precision": 0.9607747395833333,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.70703125,
        "f1": 0.6510130602904041,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.6510130602904041,
        "precision": 0.6286237444196429,
        "recall": 0.70703125
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.9228515625,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9228515625,
        "precision": 0.9148763020833333,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7894856770833334,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.7894856770833334,
        "precision": 0.7708658854166667,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9441731770833333,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.9441731770833333,
        "precision": 0.93798828125,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.00530123866052715,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.00530123866052715,
        "precision": 0.0037667947714976908,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.95263671875,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.95263671875,
        "precision": 0.9471028645833334,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.7822265625,
        "f1": 0.7349989149305556,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.7349989149305556,
        "precision": 0.7153169177827381,
        "recall": 0.7822265625
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7894903273809524,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7894903273809524,
        "precision": 0.7715657552083334,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9640299479166666,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9640299479166666,
        "precision": 0.9597981770833334,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0037783267267036125,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0037783267267036125,
        "precision": 0.0027472205129483087,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.8173828125,
        "f1": 0.7802951388888888,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.7802951388888888,
        "precision": 0.7645914713541666,
        "recall": 0.8173828125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.84658203125,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.84658203125,
        "precision": 0.8319498697916667,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9326171875,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.9326171875,
        "precision": 0.9251302083333334,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.93251953125,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.93251953125,
        "precision": 0.9248860677083333,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.7177734375,
        "f1": 0.6673351088208465,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6673351088208465,
        "precision": 0.6473395826179029,
        "recall": 0.7177734375
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7348399105235043,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7348399105235043,
        "precision": 0.7165717230902777,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.48465873861381675,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.48465873861381675,
        "precision": 0.4647134820474665,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7731631324404762,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7731631324404762,
        "precision": 0.7567778087797619,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.788028583829365,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.788028583829365,
        "precision": 0.7715912917564656,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.734375,
        "f1": 0.6920832910579005,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6920832910579005,
        "precision": 0.6751049223400297,
        "recall": 0.734375
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6062336751789876,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.6062336751789876,
        "precision": 0.5826059492807539,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7862513950892858,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.7862513950892858,
        "precision": 0.7721877325148809,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.6904296875,
        "f1": 0.6320816282242063,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.6320816282242063,
        "precision": 0.6093974764384921,
        "recall": 0.6904296875
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7977408008658009,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7977408008658009,
        "precision": 0.7820963541666666,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.5791015625,
        "f1": 0.5109630766369048,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.5109630766369048,
        "precision": 0.48594063542794014,
        "recall": 0.5791015625
      },
      {
        "accuracy": 0.78125,
        "f1": 0.736084829883658,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.736084829883658,
        "precision": 0.7187829748376622,
        "recall": 0.78125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0027997678769401332,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0027997678769401332,
        "precision": 0.002160092774680895,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7731506124084249,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7731506124084249,
        "precision": 0.7556338355654761,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.4555130687454906,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.4555130687454906,
        "precision": 0.43288164381914374,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.6416015625,
        "f1": 0.5818713042371553,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5818713042371553,
        "precision": 0.5590448288690476,
        "recall": 0.6416015625
      },
      {
        "accuracy": 0.7939453125,
        "f1": 0.7501547280844156,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7501547280844156,
        "precision": 0.7320452008928571,
        "recall": 0.7939453125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006186903916396104,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.006186903916396104,
        "precision": 0.004717146531005226,
        "recall": 0.015625
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7548131284947691,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7548131284947691,
        "precision": 0.7409435453869048,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.595703125,
        "f1": 0.53061034560058,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.53061034560058,
        "precision": 0.5065805938852813,
        "recall": 0.595703125
      },
      {
        "accuracy": 0.6708984375,
        "f1": 0.6128560061177248,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.6128560061177248,
        "precision": 0.5900603465544871,
        "recall": 0.6708984375
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.9161783854166666,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.9161783854166666,
        "precision": 0.9072591145833333,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9599609375,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9599609375,
        "precision": 0.9552408854166666,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9825846354166666,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9825846354166666,
        "precision": 0.9807942708333334,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.6337890625,
        "f1": 0.5802974640376983,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5802974640376983,
        "precision": 0.5591905734239718,
        "recall": 0.6337890625
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9783528645833334,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9783528645833334,
        "precision": 0.9759114583333334,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9225260416666667,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9225260416666667,
        "precision": 0.9152018229166666,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8881510416666666,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8881510416666666,
        "precision": 0.8768229166666666,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9203125000000001,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9203125000000001,
        "precision": 0.9117024739583334,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.849609375,
        "f1": 0.8122721354166667,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8122721354166667,
        "precision": 0.7961263020833333,
        "recall": 0.849609375
      },
      {
        "accuracy": 0.75390625,
        "f1": 0.7044433593749999,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7044433593749999,
        "precision": 0.6829520089285714,
        "recall": 0.75390625
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333333,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9778645833333333,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0029792265199419495,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029792265199419495,
        "precision": 0.0017959593032835217,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.7861328125,
        "f1": 0.7419782366071429,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7419782366071429,
        "precision": 0.7230957031249999,
        "recall": 0.7861328125
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8285481770833334,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8285481770833334,
        "precision": 0.81171875,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004760537752751549,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004760537752751549,
        "precision": 0.0034329799379887588,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8916341145833334,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8916341145833334,
        "precision": 0.8819498697916667,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8067243303571429,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8067243303571429,
        "precision": 0.7893880208333334,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8608072916666667,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8608072916666667,
        "precision": 0.8465494791666666,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9783528645833333,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9783528645833333,
        "precision": 0.9759114583333334,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6722063337053571,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.6722063337053571,
        "precision": 0.6518500434027777,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.76171875,
        "f1": 0.7130611359126984,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.7130611359126984,
        "precision": 0.6925374348958333,
        "recall": 0.76171875
      },
      {
        "accuracy": 0.509765625,
        "f1": 0.4628197784203643,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.4628197784203643,
        "precision": 0.4456000434027778,
        "recall": 0.509765625
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6744032118055556,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.6744032118055556,
        "precision": 0.6561402708619506,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.7734375,
        "f1": 0.7185833643353174,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.7185833643353174,
        "precision": 0.6960949125744047,
        "recall": 0.7734375
      },
      {
        "accuracy": 0.6787109375,
        "f1": 0.6290318784947692,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.6290318784947692,
        "precision": 0.609555677739846,
        "recall": 0.6787109375
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.745365978422619,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.745365978422619,
        "precision": 0.7270926339285715,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7333527800324675,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.7333527800324675,
        "precision": 0.7146992384785354,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7577334449404762,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.7577334449404762,
        "precision": 0.7364366319444444,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.58203125,
        "f1": 0.5232258626789876,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.5232258626789876,
        "precision": 0.5014415326427045,
        "recall": 0.58203125
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6901692708333333,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.6901692708333333,
        "precision": 0.6697916666666667,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6897382240155677,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.6897382240155677,
        "precision": 0.6695172991071427,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0025304177159645906,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.0025304177159645906,
        "precision": 0.001561994990303814,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.7587890625,
        "f1": 0.7097990225919913,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.7097990225919913,
        "precision": 0.6895345052083333,
        "recall": 0.7587890625
      },
      {
        "accuracy": 0.7265625,
        "f1": 0.6743024553571428,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.6743024553571428,
        "precision": 0.6519205729166666,
        "recall": 0.7265625
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.6481420868627901,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.6481420868627901,
        "precision": 0.629232933407738,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.8076171875,
        "f1": 0.7629115513392857,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.7629115513392857,
        "precision": 0.7445731026785714,
        "recall": 0.8076171875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.005808221726190476,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.005808221726190476,
        "precision": 0.004364912203111216,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.6057787210619242,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.6057787210619242,
        "precision": 0.5894345590390513,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.6748046875,
        "f1": 0.6233134075126263,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.6233134075126263,
        "precision": 0.6040391710069444,
        "recall": 0.6748046875
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7604204226762821,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.7604204226762821,
        "precision": 0.7421154203869047,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.755859375,
        "f1": 0.7071698646405677,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.7071698646405677,
        "precision": 0.6867606026785714,
        "recall": 0.755859375
      },
      {
        "accuracy": 0.955078125,
        "f1": 0.9425130208333332,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9425130208333332,
        "precision": 0.9366861979166667,
        "recall": 0.955078125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9837239583333333,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9837239583333333,
        "precision": 0.98193359375,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5656847492784993,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5656847492784993,
        "precision": 0.5440782335069445,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.95107421875,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.95107421875,
        "precision": 0.9458821614583333,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9451497395833333,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9451497395833333,
        "precision": 0.93896484375,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9020833333333333,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9020833333333333,
        "precision": 0.891845703125,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.9363606770833334,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9363606770833334,
        "precision": 0.9293619791666667,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.78515625,
        "f1": 0.7408389136904763,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7408389136904763,
        "precision": 0.7225446428571429,
        "recall": 0.78515625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166666,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9806315104166666,
        "precision": 0.9783528645833334,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.7705078125,
        "f1": 0.72021484375,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.72021484375,
        "precision": 0.697705078125,
        "recall": 0.7705078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004422891019570707,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004422891019570707,
        "precision": 0.0034790844844244115,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666667,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9830729166666667,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.7861328125,
        "f1": 0.740043712797619,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.740043712797619,
        "precision": 0.7200358072916666,
        "recall": 0.7861328125
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8076683407738094,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8076683407738094,
        "precision": 0.79052734375,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9739583333333333,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.9739583333333333,
        "precision": 0.970703125,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004256959945436507,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004256959945436507,
        "precision": 0.0033092251898139513,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8750325520833333,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8750325520833333,
        "precision": 0.863525390625,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8351422991071428,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8351422991071428,
        "precision": 0.8201334635416666,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8655598958333333,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8655598958333333,
        "precision": 0.852783203125,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96923828125,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.96923828125,
        "precision": 0.9656575520833333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0014841774049363335,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0014841774049363335,
        "precision": 0.0012668783785364116,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002616684402968784,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.002616684402968784,
        "precision": 0.0024476882711438417,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.002197265625,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.002197265625,
        "precision": 0.0020926339285714285,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002862621265312097,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.002862621265312097,
        "precision": 0.002588099021154203,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001808874591503268,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.001808874591503268,
        "precision": 0.0014907997532894737,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010968451593905107,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0010968451593905107,
        "precision": 0.0010380048741415369,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026163736979166663,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0026163736979166663,
        "precision": 0.002447548152515723,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001316150317455041,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.001316150317455041,
        "precision": 0.0011789376395089286,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001960305606617647,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.001960305606617647,
        "precision": 0.0014684473016605166,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009793407716927453,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0009793407716927453,
        "precision": 0.0009779536146723646,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011796448182270713,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0011796448182270713,
        "precision": 0.0010871144473076078,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003098068678253824,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.003098068678253824,
        "precision": 0.0026546698559891365,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012539985665251873,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0012539985665251873,
        "precision": 0.0011297165506448069,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004951203564062068,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.004951203564062068,
        "precision": 0.004917894806523299,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002189214316769653,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.002189214316769653,
        "precision": 0.0018273946357074816,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0032768254215994573,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0032768254215994573,
        "precision": 0.0029405863972020887,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013710859530938124,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0013710859530938124,
        "precision": 0.00122265625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005887910695162814,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.005887910695162814,
        "precision": 0.0046572463203825385,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001956452299829642,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.001956452299829642,
        "precision": 0.00195479148890785,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007096555555072188,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0007096555555072188,
        "precision": 0.0005180091141217654,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0021484375,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0021484375,
        "precision": 0.0020616319444444445,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001918604385772714,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.001918604385772714,
        "precision": 0.0016336323302469135,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.97412109375,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.97412109375,
        "precision": 0.9710286458333334,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.634765625,
        "f1": 0.5794480096726191,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5794480096726191,
        "precision": 0.5578109499007936,
        "recall": 0.634765625
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9674479166666666,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9674479166666666,
        "precision": 0.96337890625,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9219401041666666,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9219401041666666,
        "precision": 0.914306640625,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9284505208333333,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9284505208333333,
        "precision": 0.9204915364583334,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9500325520833333,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9500325520833333,
        "precision": 0.9441731770833334,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.828125,
        "f1": 0.7873961433531746,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7873961433531746,
        "precision": 0.7703206380208334,
        "recall": 0.828125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.7939453125,
        "f1": 0.7477918836805555,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7477918836805555,
        "precision": 0.7278006417410714,
        "recall": 0.7939453125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0027063816646442328,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0027063816646442328,
        "precision": 0.0016196797228506788,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.8015020461309523,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8015020461309523,
        "precision": 0.7850748697916666,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8361328125,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8361328125,
        "precision": 0.8204264322916667,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004164758199791545,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004164758199791545,
        "precision": 0.0026766703161225647,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.9189453125,
        "f1": 0.89638671875,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.89638671875,
        "precision": 0.8858235677083333,
        "recall": 0.9189453125
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8671549479166667,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8671549479166667,
        "precision": 0.8550130208333333,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.898828125,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.898828125,
        "precision": 0.8885904947916666,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7611629201961233,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.7611629201961233,
        "precision": 0.7444944351438492,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.7958984375,
        "f1": 0.7500124007936508,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.7500124007936508,
        "precision": 0.7320851159474207,
        "recall": 0.7958984375
      },
      {
        "accuracy": 0.4609375,
        "f1": 0.41799145145289296,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.41799145145289296,
        "precision": 0.40398626524243303,
        "recall": 0.4609375
      },
      {
        "accuracy": 0.6640625,
        "f1": 0.6107937635281385,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6107937635281385,
        "precision": 0.5912462022569445,
        "recall": 0.6640625
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5838077341495311,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.5838077341495311,
        "precision": 0.5612410583314765,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.589992769243114,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.589992769243114,
        "precision": 0.5697381882440475,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7576529102408008,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.7576529102408008,
        "precision": 0.7388602120535714,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.75390625,
        "f1": 0.6995675223214286,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.6995675223214286,
        "precision": 0.6790957496279761,
        "recall": 0.75390625
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6658048115079365,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.6658048115079365,
        "precision": 0.6437004320549242,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.437746001114189,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.437746001114189,
        "precision": 0.4179149192821068,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6661165638130252,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.6661165638130252,
        "precision": 0.6463102178312139,
        "recall": 0.71875
      },
      {
        "accuracy": 0.7041015625,
        "f1": 0.6489591788419913,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.6489591788419913,
        "precision": 0.625927734375,
        "recall": 0.7041015625
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6630805121527777,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.6630805121527777,
        "precision": 0.6426440042162698,
        "recall": 0.71875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.0063615518681640285,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0063615518681640285,
        "precision": 0.004811139280772117,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.76953125,
        "f1": 0.7201397343975469,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.7201397343975469,
        "precision": 0.700322033110119,
        "recall": 0.76953125
      },
      {
        "accuracy": 0.748046875,
        "f1": 0.6983948722718254,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.6983948722718254,
        "precision": 0.6791596912202381,
        "recall": 0.748046875
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.678889269367785,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.678889269367785,
        "precision": 0.6588553292410715,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005869838169642857,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.005869838169642857,
        "precision": 0.0045755405618686865,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5714190323565322,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.5714190323565322,
        "precision": 0.5536093463827839,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.49190002705627706,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.49190002705627706,
        "precision": 0.47049670069258764,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6560694839015151,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.6560694839015151,
        "precision": 0.6343704201614357,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6141889740034271,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.6141889740034271,
        "precision": 0.595458984375,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.7424967447916666,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.7424967447916666,
        "precision": 0.7229910714285714,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.7993815104166666,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.7993815104166666,
        "precision": 0.7800618489583333,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.5103755890376984,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.5103755890376984,
        "precision": 0.49476027715773807,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8390516493055555,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.8390516493055555,
        "precision": 0.8264567057291667,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7929796006944444,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.7929796006944444,
        "precision": 0.7756998697916666,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.7529296875,
        "f1": 0.7035311259920635,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.7035311259920635,
        "precision": 0.68388671875,
        "recall": 0.7529296875
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8664388020833333,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.8664388020833333,
        "precision": 0.8541666666666667,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.8596028645833333,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.8596028645833333,
        "precision": 0.8458170572916667,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7533877418154762,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.7533877418154762,
        "precision": 0.7328706287202381,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.65625,
        "f1": 0.6085573226686508,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.6085573226686508,
        "precision": 0.590107654389881,
        "recall": 0.65625
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.7961286272321428,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.7961286272321428,
        "precision": 0.7787690662202382,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.6390848572000916,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.6390848572000916,
        "precision": 0.6154552641369048,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.837890625,
        "f1": 0.7974198598710318,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.7974198598710318,
        "precision": 0.780453636532738,
        "recall": 0.837890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0022703061643893963,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.0022703061643893963,
        "precision": 0.0014259031059312673,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8372612847222222,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.8372612847222222,
        "precision": 0.8235595703125,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.787109375,
        "f1": 0.7392469618055555,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.7392469618055555,
        "precision": 0.7180908203124999,
        "recall": 0.787109375
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7773111979166667,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7773111979166667,
        "precision": 0.7569173177083334,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002995517936924187,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.002995517936924187,
        "precision": 0.0019922053857600736,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.7612498449900793,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.7612498449900793,
        "precision": 0.746283965058379,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.6748046875,
        "f1": 0.6185607686584249,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.6185607686584249,
        "precision": 0.5962239583333334,
        "recall": 0.6748046875
      },
      {
        "accuracy": 0.7626953125,
        "f1": 0.7164279513888889,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.7164279513888889,
        "precision": 0.6972435360863094,
        "recall": 0.7626953125
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.8441483754960317,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.8441483754960317,
        "precision": 0.8296630859374999,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9580078125,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9580078125,
        "precision": 0.9532877604166666,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9847005208333333,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9847005208333333,
        "precision": 0.98291015625,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.642578125,
        "f1": 0.5878379216269841,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5878379216269841,
        "precision": 0.5666934058779762,
        "recall": 0.642578125
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.94697265625,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.94697265625,
        "precision": 0.9419759114583333,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9189453125,
        "f1": 0.8972981770833334,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8972981770833334,
        "precision": 0.88720703125,
        "recall": 0.9189453125
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.89384765625,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.89384765625,
        "precision": 0.8831380208333333,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9658203125,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9658203125,
        "precision": 0.9620768229166667,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.7538736979166666,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7538736979166666,
        "precision": 0.7347819010416666,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9742838541666666,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9742838541666666,
        "precision": 0.9713541666666667,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.7864908854166668,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7864908854166668,
        "precision": 0.7681803385416666,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333333,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9807942708333333,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0024546651037193803,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0024546651037193803,
        "precision": 0.0015507295332662981,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.78515625,
        "f1": 0.733251953125,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.733251953125,
        "precision": 0.7103934151785715,
        "recall": 0.78515625
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.8022135416666666,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8022135416666666,
        "precision": 0.7853298611111111,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0037379662061217764,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0037379662061217764,
        "precision": 0.00261105128008829,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8597842261904762,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8597842261904762,
        "precision": 0.84716796875,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.85927734375,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.85927734375,
        "precision": 0.844970703125,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8949869791666667,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8949869791666667,
        "precision": 0.8844401041666666,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0028105522906763714,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0028105522906763714,
        "precision": 0.0025535840761470425,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005099138098569652,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.005099138098569652,
        "precision": 0.0049987488612389715,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00506095185367454,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.00506095185367454,
        "precision": 0.004727802579365079,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.005211180454324588,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.005211180454324588,
        "precision": 0.005079550638686131,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004563228216818642,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.004563228216818642,
        "precision": 0.004397508574695122,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004801432291666666,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.004801432291666666,
        "precision": 0.004534040178571428,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003976950513371538,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.003976950513371538,
        "precision": 0.0036649155890804597,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00311279296875,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.00311279296875,
        "precision": 0.0027772066885964914,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002931819732532751,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.002931819732532751,
        "precision": 0.0029307547814207647,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0034734593206272894,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0034734593206272894,
        "precision": 0.003256663717088922,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022430673999768733,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0022430673999768733,
        "precision": 0.0021159911352826156,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002462429470486111,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.002462429470486111,
        "precision": 0.0022598233706113335,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004574730282738095,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.004574730282738095,
        "precision": 0.004403329110360361,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007495325854700854,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.007495325854700854,
        "precision": 0.006450303126662676,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.006269235321969696,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.006269235321969696,
        "precision": 0.005837605397337235,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0048177083333333336,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0048177083333333336,
        "precision": 0.004258897569444444,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004533497991405082,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.004533497991405082,
        "precision": 0.0043059242277992274,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004707532051282051,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.004707532051282051,
        "precision": 0.004475911458333334,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003981359352453103,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.003981359352453103,
        "precision": 0.003944429520759956,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002310704703282828,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.002310704703282828,
        "precision": 0.0021510532924107146,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0049479166666666664,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0049479166666666664,
        "precision": 0.004638671875,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.7929578993055555,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7929578993055555,
        "precision": 0.7753824869791667,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.8477213541666666,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8477213541666666,
        "precision": 0.8338053385416666,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.65234375,
        "f1": 0.6038157101145383,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6038157101145383,
        "precision": 0.5841808500744048,
        "recall": 0.65234375
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8903645833333333,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8903645833333333,
        "precision": 0.8811360677083333,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8760253906250001,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8760253906250001,
        "precision": 0.8656451512896826,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.8515625,
        "f1": 0.8186686197916666,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8186686197916666,
        "precision": 0.8046642485119047,
        "recall": 0.8515625
      },
      {
        "accuracy": 0.818359375,
        "f1": 0.7785016741071429,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7785016741071429,
        "precision": 0.7620442708333334,
        "recall": 0.818359375
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9268120659722222,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9268120659722222,
        "precision": 0.9190673828125,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.7943568638392857,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7943568638392857,
        "precision": 0.7786876860119047,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.7744140625,
        "f1": 0.730633060515873,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.730633060515873,
        "precision": 0.712890625,
        "recall": 0.7744140625
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8858072916666666,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8858072916666666,
        "precision": 0.8744303385416667,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.6137362041170635,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6137362041170635,
        "precision": 0.5928369915674603,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8707194010416666,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8707194010416666,
        "precision": 0.8598563058035713,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0024922018086080584,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0024922018086080584,
        "precision": 0.001591282894736842,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8910342261904762,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8910342261904762,
        "precision": 0.8817057291666666,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.66015625,
        "f1": 0.6010943700396825,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6010943700396825,
        "precision": 0.5771809895833333,
        "recall": 0.66015625
      },
      {
        "accuracy": 0.7958984375,
        "f1": 0.7528645833333334,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7528645833333334,
        "precision": 0.73408203125,
        "recall": 0.7958984375
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8503929501488094,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.8503929501488094,
        "precision": 0.8375418526785714,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0035867458939449364,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0035867458939449364,
        "precision": 0.0023410939646291208,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6621279761904761,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6621279761904761,
        "precision": 0.6414659288194444,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.7587890625,
        "f1": 0.7114769345238096,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7114769345238096,
        "precision": 0.6923014322916666,
        "recall": 0.7587890625
      },
      {
        "accuracy": 0.921875,
        "f1": 0.9037434895833333,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9037434895833333,
        "precision": 0.8960611979166666,
        "recall": 0.921875
      },
      {
        "accuracy": 0.7890625,
        "f1": 0.7467944653003247,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7467944653003247,
        "precision": 0.728915550595238,
        "recall": 0.7890625
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.869921875,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.869921875,
        "precision": 0.857421875,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.48046875,
        "f1": 0.43633742559523814,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.43633742559523814,
        "precision": 0.419788566468254,
        "recall": 0.48046875
      },
      {
        "accuracy": 0.7783203125,
        "f1": 0.7334007626488095,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.7334007626488095,
        "precision": 0.7151622953869048,
        "recall": 0.7783203125
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9030273437499999,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9030273437499999,
        "precision": 0.8935058593749999,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.7197265625,
        "f1": 0.6734569466991343,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.6734569466991343,
        "precision": 0.6546223958333333,
        "recall": 0.7197265625
      },
      {
        "accuracy": 0.7666015625,
        "f1": 0.7159877232142857,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7159877232142857,
        "precision": 0.6952962239583333,
        "recall": 0.7666015625
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8904947916666667,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.8904947916666667,
        "precision": 0.880126953125,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8453776041666666,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.8453776041666666,
        "precision": 0.8306477864583334,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.6142578125,
        "f1": 0.5577962239583333,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5577962239583333,
        "precision": 0.5359956287202381,
        "recall": 0.6142578125
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.8015159970238095,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.8015159970238095,
        "precision": 0.784423828125,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6506401909722221,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.6506401909722221,
        "precision": 0.6317158400410353,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8293503534226191,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.8293503534226191,
        "precision": 0.8149181547619047,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0028079816520448888,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0028079816520448888,
        "precision": 0.001685794150772599,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8489908854166666,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8489908854166666,
        "precision": 0.834912109375,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.5908203125,
        "f1": 0.5320591517857143,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.5320591517857143,
        "precision": 0.5099950749120671,
        "recall": 0.5908203125
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.6400910612824675,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.6400910612824675,
        "precision": 0.6182942708333332,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8556640625,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.8556640625,
        "precision": 0.8422688802083333,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004950699799332612,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.004950699799332612,
        "precision": 0.0033322638172344297,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.703125,
        "f1": 0.6575272817460318,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.6575272817460318,
        "precision": 0.6388989997632575,
        "recall": 0.703125
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.7567382812499999,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.7567382812499999,
        "precision": 0.738671875,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.86396484375,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.86396484375,
        "precision": 0.850537109375,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8039713541666667,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8039713541666667,
        "precision": 0.7870117187500001,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8564778645833333,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8564778645833333,
        "precision": 0.8432454427083333,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.578125,
        "f1": 0.533030359397547,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.533030359397547,
        "precision": 0.5161400204613096,
        "recall": 0.578125
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8182152157738096,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.8182152157738096,
        "precision": 0.80322265625,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8791341145833333,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8791341145833333,
        "precision": 0.866943359375,
        "recall": 0.90625
      },
      {
        "accuracy": 0.787109375,
        "f1": 0.7462100074404762,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.7462100074404762,
        "precision": 0.7290852864583333,
        "recall": 0.787109375
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8285667782738094,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8285667782738094,
        "precision": 0.812744140625,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.921875,
        "f1": 0.9000325520833332,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9000325520833332,
        "precision": 0.8900065104166667,
        "recall": 0.921875
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.91845703125,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.91845703125,
        "precision": 0.9097005208333333,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.677734375,
        "f1": 0.6241009424603174,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6241009424603174,
        "precision": 0.6029378255208333,
        "recall": 0.677734375
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.86650390625,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.86650390625,
        "precision": 0.8536783854166666,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.8212890625,
        "f1": 0.7840169270833333,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.7840169270833333,
        "precision": 0.7685872395833333,
        "recall": 0.8212890625
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8566080729166666,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8566080729166666,
        "precision": 0.8437011718749999,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004531327504960317,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.004531327504960317,
        "precision": 0.0035191899635066432,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8888346354166666,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8888346354166666,
        "precision": 0.8771158854166667,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7071289062499999,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.7071289062499999,
        "precision": 0.6864420572916666,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.765625,
        "f1": 0.7211100260416666,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.7211100260416666,
        "precision": 0.7022251674107143,
        "recall": 0.765625
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8880208333333333,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.8880208333333333,
        "precision": 0.8758138020833333,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004759850051526292,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.004759850051526292,
        "precision": 0.00346661873859927,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.7568359375,
        "f1": 0.7123597864808802,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.7123597864808802,
        "precision": 0.6949788411458333,
        "recall": 0.7568359375
      },
      {
        "accuracy": 0.78125,
        "f1": 0.7320963541666667,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.7320963541666667,
        "precision": 0.7111979166666667,
        "recall": 0.78125
      },
      {
        "accuracy": 0.873046875,
        "f1": 0.8410807291666667,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.8410807291666667,
        "precision": 0.8268229166666666,
        "recall": 0.873046875
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9514973958333333,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9514973958333333,
        "precision": 0.94580078125,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.6083984375,
        "f1": 0.5469075520833333,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.5469075520833333,
        "precision": 0.5219889322916667,
        "recall": 0.6083984375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.96484375,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.96484375,
        "precision": 0.96044921875,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8943359375,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.8943359375,
        "precision": 0.88427734375,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9007161458333333,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9007161458333333,
        "precision": 0.8896484375,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9396809895833333,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.9396809895833333,
        "precision": 0.9326985677083333,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9283854166666667,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.9283854166666667,
        "precision": 0.9200846354166666,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9742838541666667,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9742838541666667,
        "precision": 0.97119140625,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.7463076636904762,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.7463076636904762,
        "precision": 0.72548828125,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9755859375,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9755859375,
        "precision": 0.97265625,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028730364119114605,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0028730364119114605,
        "precision": 0.001841321812667413,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.74609375,
        "f1": 0.6927594866071429,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.6927594866071429,
        "precision": 0.669677734375,
        "recall": 0.74609375
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8657877604166666,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8657877604166666,
        "precision": 0.8524576822916667,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005031093580898268,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.005031093580898268,
        "precision": 0.003974877119408369,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.902734375,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.902734375,
        "precision": 0.8929850260416667,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8767903645833333,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8767903645833333,
        "precision": 0.86376953125,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8669270833333333,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8669270833333333,
        "precision": 0.8534342447916667,
        "recall": 0.8955078125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}