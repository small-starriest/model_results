{
  "dataset_revision": "673a610d6d3dd91a547a0d57ae1b56f37ebbf6a1",
  "evaluation_time": 13.72523307800293,
  "kg_co2_emissions": 0.002058204292593623,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.100830078125,
        "f1": 0.09356076336374516,
        "f1_weighted": 0.09357892511532087,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.100830078125,
        "scores_per_experiment": [
          {
            "accuracy": 0.10888671875,
            "f1": 0.10378047162690941,
            "f1_weighted": 0.10381801038522
          },
          {
            "accuracy": 0.099609375,
            "f1": 0.09710068879297311,
            "f1_weighted": 0.09718185869544421
          },
          {
            "accuracy": 0.091796875,
            "f1": 0.08421404827427538,
            "f1_weighted": 0.08422534293480703
          },
          {
            "accuracy": 0.09375,
            "f1": 0.08908177731779057,
            "f1_weighted": 0.08903968775550902
          },
          {
            "accuracy": 0.103515625,
            "f1": 0.09029956339227342,
            "f1_weighted": 0.09030259000320233
          },
          {
            "accuracy": 0.1181640625,
            "f1": 0.1069047311985869,
            "f1_weighted": 0.10689342667514089
          },
          {
            "accuracy": 0.10205078125,
            "f1": 0.09668201684078173,
            "f1_weighted": 0.0967226295774728
          },
          {
            "accuracy": 0.09228515625,
            "f1": 0.0844640676337131,
            "f1_weighted": 0.08450052662146249
          },
          {
            "accuracy": 0.09228515625,
            "f1": 0.085707027857304,
            "f1_weighted": 0.08572523475655111
          },
          {
            "accuracy": 0.10595703125,
            "f1": 0.09737324070284406,
            "f1_weighted": 0.0973799437483989
          }
        ]
      }
    ]
  },
  "task_name": "RuSciBenchGRNTIClassification"
}