{
    "mteb_version": "0.0.2",
    "test": {
        "de": {
            "accuracy": 0.6341504649196958,
            "accuracy_stderr": 0.018427467614080702,
            "f1": 0.4163114148000764,
            "f1_stderr": 0.007743892384694605,
            "main_score": 0.6341504649196958
        },
        "en": {
            "accuracy": 0.6303237574099407,
            "accuracy_stderr": 0.01912881597880458,
            "f1": 0.4374099628750949,
            "f1_stderr": 0.012950665614568868,
            "main_score": 0.6303237574099407
        },
        "es": {
            "accuracy": 0.6443962641761174,
            "accuracy_stderr": 0.01775722879034857,
            "f1": 0.4364827222150966,
            "f1_stderr": 0.010558242527759958,
            "main_score": 0.6443962641761174
        },
        "evaluation_time": 93.52,
        "fr": {
            "accuracy": 0.6200751644221736,
            "accuracy_stderr": 0.02677373543479654,
            "f1": 0.43427273194455474,
            "f1_stderr": 0.012759597991935557,
            "main_score": 0.6200751644221736
        },
        "hi": {
            "accuracy": 0.62577984940839,
            "accuracy_stderr": 0.015087349192334863,
            "f1": 0.4171975815599544,
            "f1_stderr": 0.012445276422989133,
            "main_score": 0.62577984940839
        },
        "th": {
            "accuracy": 0.6460759493670886,
            "accuracy_stderr": 0.01926496426429429,
            "f1": 0.445247204260894,
            "f1_stderr": 0.011538761920842237,
            "main_score": 0.6460759493670886
        }
    },
    "mteb_dataset_name": "MTOPIntentClassification",
    "dataset_revision": "6299947a7777084cc2d4b64235bf7190381ce755"
}