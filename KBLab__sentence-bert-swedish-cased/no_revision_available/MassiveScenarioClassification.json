{
  "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
  "mteb_dataset_name": "MassiveScenarioClassification",
  "mteb_version": "1.0.3.dev0",
  "test": {
    "da": {
      "accuracy": 0.4964021519838601,
      "accuracy_stderr": 0.013060130811491842,
      "f1": 0.48223918173555036,
      "f1_stderr": 0.010102691330202264,
      "main_score": 0.4964021519838601
    },
    "evaluation_time": 96.51,
    "nb": {
      "accuracy": 0.4948890383322125,
      "accuracy_stderr": 0.012910151752994623,
      "f1": 0.4762622480394999,
      "f1_stderr": 0.013032592130554148,
      "main_score": 0.4948890383322125
    },
    "sv": {
      "accuracy": 0.7595830531271015,
      "accuracy_stderr": 0.01613987895090787,
      "f1": 0.7530102836662811,
      "f1_stderr": 0.013497075103297649,
      "main_score": 0.7595830531271015
    }
  },
  "validation": {
    "da": {
      "accuracy": 0.4839153959665518,
      "accuracy_stderr": 0.014893283251851328,
      "f1": 0.47993061683580346,
      "f1_stderr": 0.009001209409920241,
      "main_score": 0.4839153959665518
    },
    "evaluation_time": 76.3,
    "nb": {
      "accuracy": 0.4876537137235612,
      "accuracy_stderr": 0.016442760386247854,
      "f1": 0.47836717177080584,
      "f1_stderr": 0.01701335424758461,
      "main_score": 0.4876537137235612
    },
    "sv": {
      "accuracy": 0.7597638957206099,
      "accuracy_stderr": 0.01596040140251522,
      "f1": 0.7522981424769389,
      "f1_stderr": 0.014776787598212729,
      "main_score": 0.7597638957206099
    }
  }
}