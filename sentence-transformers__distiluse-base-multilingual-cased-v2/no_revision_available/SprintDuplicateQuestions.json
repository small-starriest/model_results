{
  "dataset_revision": "d66bd1f72af766a5cc4b0ca5e00c162f89e8cc46",
  "mteb_dataset_name": "SprintDuplicateQuestions",
  "mteb_version": "1.0.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.9962079207920792,
      "accuracy_threshold": 0.6402517557144165,
      "ap": 0.8714976457350163,
      "f1": 0.8107317073170732,
      "f1_threshold": 0.63487708568573,
      "precision": 0.7914285714285715,
      "recall": 0.831
    },
    "dot": {
      "accuracy": 0.9957722772277228,
      "accuracy_threshold": 0.5670002102851868,
      "ap": 0.8407833605976549,
      "f1": 0.7788461538461539,
      "f1_threshold": 0.5344296097755432,
      "precision": 0.75,
      "recall": 0.81
    },
    "euclidean": {
      "accuracy": 0.9961287128712871,
      "accuracy_threshold": 0.7639181017875671,
      "ap": 0.8694165408325188,
      "f1": 0.8033596837944663,
      "f1_threshold": 0.7781314849853516,
      "precision": 0.7939453125,
      "recall": 0.813
    },
    "evaluation_time": 3.96,
    "manhattan": {
      "accuracy": 0.9964653465346535,
      "accuracy_threshold": 13.177294731140137,
      "ap": 0.8843495903247095,
      "f1": 0.817193675889328,
      "f1_threshold": 13.655448913574219,
      "precision": 0.8076171875,
      "recall": 0.827
    },
    "max": {
      "accuracy": 0.9964653465346535,
      "ap": 0.8843495903247095,
      "f1": 0.817193675889328
    }
  },
  "validation": {
    "cos_sim": {
      "accuracy": 0.9962673267326733,
      "accuracy_threshold": 0.6435202360153198,
      "ap": 0.8654947393156018,
      "f1": 0.808780487804878,
      "f1_threshold": 0.625939130783081,
      "precision": 0.7895238095238095,
      "recall": 0.829
    },
    "dot": {
      "accuracy": 0.995990099009901,
      "accuracy_threshold": 0.5402953624725342,
      "ap": 0.8619092379785963,
      "f1": 0.7924161400097229,
      "f1_threshold": 0.5242564678192139,
      "precision": 0.771050141911069,
      "recall": 0.815
    },
    "euclidean": {
      "accuracy": 0.996009900990099,
      "accuracy_threshold": 0.7580994367599487,
      "ap": 0.8482742572952514,
      "f1": 0.7965200579990334,
      "f1_threshold": 0.7885181307792664,
      "precision": 0.7708138447146866,
      "recall": 0.824
    },
    "evaluation_time": 5.48,
    "manhattan": {
      "accuracy": 0.9963861386138614,
      "accuracy_threshold": 13.252960205078125,
      "ap": 0.8715435403229772,
      "f1": 0.8145985401459853,
      "f1_threshold": 13.848575592041016,
      "precision": 0.7933649289099526,
      "recall": 0.837
    },
    "max": {
      "accuracy": 0.9963861386138614,
      "ap": 0.8715435403229772,
      "f1": 0.8145985401459853
    }
  }
}