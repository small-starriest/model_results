{
  "dataset_revision": "46958b007a63fdbf239b7672c25d0bea67b5ea1a",
  "evaluation_time": 19.918139457702637,
  "kg_co2_emissions": 0.002985086192036481,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.4121,
        "f1": 0.41084702956300206,
        "f1_weighted": 0.41084702956300206,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.4121,
        "scores_per_experiment": [
          {
            "accuracy": 0.41433333333333333,
            "f1": 0.4143081241132687,
            "f1_weighted": 0.4143081241132688
          },
          {
            "accuracy": 0.405,
            "f1": 0.3993811609568652,
            "f1_weighted": 0.39938116095686527
          },
          {
            "accuracy": 0.41533333333333333,
            "f1": 0.4159396630148542,
            "f1_weighted": 0.41593966301485413
          },
          {
            "accuracy": 0.393,
            "f1": 0.3932991120207919,
            "f1_weighted": 0.3932991120207919
          },
          {
            "accuracy": 0.41233333333333333,
            "f1": 0.4119128257295108,
            "f1_weighted": 0.4119128257295108
          },
          {
            "accuracy": 0.429,
            "f1": 0.4259981959540779,
            "f1_weighted": 0.4259981959540779
          },
          {
            "accuracy": 0.404,
            "f1": 0.4032320453211324,
            "f1_weighted": 0.4032320453211323
          },
          {
            "accuracy": 0.42633333333333334,
            "f1": 0.42532914655756965,
            "f1_weighted": 0.42532914655756965
          },
          {
            "accuracy": 0.41433333333333333,
            "f1": 0.413980312775778,
            "f1_weighted": 0.41398031277577807
          },
          {
            "accuracy": 0.4073333333333333,
            "f1": 0.40508970918617165,
            "f1_weighted": 0.40508970918617165
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.40519999999999995,
        "f1": 0.40407915158051233,
        "f1_weighted": 0.40407915158051233,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.40519999999999995,
        "scores_per_experiment": [
          {
            "accuracy": 0.4073333333333333,
            "f1": 0.40758867095219414,
            "f1_weighted": 0.4075886709521942
          },
          {
            "accuracy": 0.38166666666666665,
            "f1": 0.3761018825796154,
            "f1_weighted": 0.37610188257961535
          },
          {
            "accuracy": 0.411,
            "f1": 0.4106768329315306,
            "f1_weighted": 0.4106768329315306
          },
          {
            "accuracy": 0.402,
            "f1": 0.4018602599440923,
            "f1_weighted": 0.4018602599440923
          },
          {
            "accuracy": 0.4196666666666667,
            "f1": 0.41906660361238696,
            "f1_weighted": 0.419066603612387
          },
          {
            "accuracy": 0.4246666666666667,
            "f1": 0.42224090747462667,
            "f1_weighted": 0.42224090747462667
          },
          {
            "accuracy": 0.39366666666666666,
            "f1": 0.39353786497170873,
            "f1_weighted": 0.39353786497170873
          },
          {
            "accuracy": 0.399,
            "f1": 0.39871216285450534,
            "f1_weighted": 0.39871216285450534
          },
          {
            "accuracy": 0.4116666666666667,
            "f1": 0.4115740740740741,
            "f1_weighted": 0.41157407407407404
          },
          {
            "accuracy": 0.4013333333333333,
            "f1": 0.3994322564103898,
            "f1_weighted": 0.3994322564103898
          }
        ]
      }
    ]
  },
  "task_name": "MultilingualSentiment"
}