{
    "mteb_version": "0.0.2",
    "test": {
        "de": {
            "accuracy": 0.5464919695688927,
            "accuracy_stderr": 0.02475381651484224,
            "f1": 0.35941824686975055,
            "f1_stderr": 0.013125119323718237,
            "main_score": 0.5464919695688927
        },
        "en": {
            "accuracy": 0.6814865481076151,
            "accuracy_stderr": 0.01157054240527242,
            "f1": 0.49755269962335136,
            "f1_stderr": 0.012274233776363422,
            "main_score": 0.6814865481076151
        },
        "es": {
            "accuracy": 0.5738492328218813,
            "accuracy_stderr": 0.02145476336964587,
            "f1": 0.381008046822733,
            "f1_stderr": 0.010455756552895533,
            "main_score": 0.5738492328218813
        },
        "evaluation_time": 265.15,
        "fr": {
            "accuracy": 0.5439085499530223,
            "accuracy_stderr": 0.03002530487747548,
            "f1": 0.3847145341526472,
            "f1_stderr": 0.010606278791698726,
            "main_score": 0.5439085499530223
        },
        "hi": {
            "accuracy": 0.032771602724991036,
            "accuracy_stderr": 0.012569977332083076,
            "f1": 0.011239791529838419,
            "f1_stderr": 0.003473287413707504,
            "main_score": 0.032771602724991036
        },
        "th": {
            "accuracy": 0.050813743218806516,
            "accuracy_stderr": 0.01832764237632083,
            "f1": 0.014749937326616844,
            "f1_stderr": 0.004930771456184472,
            "main_score": 0.050813743218806516
        }
    },
    "mteb_dataset_name": "MTOPIntentClassification",
    "dataset_revision": "6299947a7777084cc2d4b64235bf7190381ce755"
}