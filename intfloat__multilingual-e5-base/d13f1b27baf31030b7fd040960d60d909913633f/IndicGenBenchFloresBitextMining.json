{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 145.7260937690735,
  "kg_co2_emissions": 0.024690706936477326,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433466,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433466,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433466,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9986824769433466,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.9973649538866931,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9973649538866931,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733861,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9947299077733861,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.989459815546772,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.989459815546772,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768116,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9855072463768116,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9909420289855073,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9909420289855073,
        "precision": 0.9899538866930172,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9841897233201581,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9841897233201581,
        "precision": 0.9822134387351779,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9950592885375494,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9950592885375494,
        "precision": 0.9945652173913043,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9924242424242423,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9924242424242423,
        "precision": 0.991600790513834,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.9894598155467721,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9894598155467721,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9883069828722002,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9883069828722002,
        "precision": 0.9869894598155468,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.958498023715415,
        "f1": 0.9452239789196311,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9452239789196311,
        "precision": 0.9388175230566534,
        "recall": 0.958498023715415
      },
      {
        "accuracy": 0.9723320158102767,
        "f1": 0.9637681159420289,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9637681159420289,
        "precision": 0.9594861660079052,
        "recall": 0.9723320158102767
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9874835309617918,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9874835309617918,
        "precision": 0.9861660079051383,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9879776021080369,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9879776021080369,
        "precision": 0.9869894598155466,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9830368906455863,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9830368906455863,
        "precision": 0.9810606060606061,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.06719367588932806,
        "f1": 0.05629588900339888,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.05629588900339888,
        "precision": 0.05337736083058715,
        "recall": 0.06719367588932806
      },
      {
        "accuracy": 0.15118577075098813,
        "f1": 0.11348098196180577,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.11348098196180577,
        "precision": 0.10514562540758832,
        "recall": 0.15118577075098813
      },
      {
        "accuracy": 0.2183794466403162,
        "f1": 0.1864079396653682,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.1864079396653682,
        "precision": 0.17870605910338672,
        "recall": 0.2183794466403162
      },
      {
        "accuracy": 0.3359683794466403,
        "f1": 0.27366599086213433,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.27366599086213433,
        "precision": 0.2546963797123946,
        "recall": 0.3359683794466403
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.9894598155467721,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9894598155467721,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9856719367588933,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9856719367588933,
        "precision": 0.9840250329380764,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.8893280632411067,
        "f1": 0.8614687958067405,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8614687958067405,
        "precision": 0.8499188311688312,
        "recall": 0.8893280632411067
      },
      {
        "accuracy": 0.9258893280632411,
        "f1": 0.9037220026350461,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.9037220026350461,
        "precision": 0.8936923583662715,
        "recall": 0.9258893280632411
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9868247694334651,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9868247694334651,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768115,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9855072463768115,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.986824769433465,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.986824769433465,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.36363636363636365,
        "f1": 0.3229355159316961,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.3229355159316961,
        "precision": 0.3126499833436332,
        "recall": 0.36363636363636365
      },
      {
        "accuracy": 0.5079051383399209,
        "f1": 0.44237035198003577,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.44237035198003577,
        "precision": 0.42088222767570593,
        "recall": 0.5079051383399209
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9868247694334651,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9868247694334651,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9845191040843214,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9845191040843214,
        "precision": 0.982707509881423,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.011201024093631417,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.011201024093631417,
        "precision": 0.010870605367172872,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.012970495705348934,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.012970495705348934,
        "precision": 0.010216185841035464,
        "recall": 0.03260869565217391
      }
    ],
    "validation": [
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305584,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305584,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527917,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9933132731527917,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9923102641257106,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9923102641257106,
        "precision": 0.9914744232698094,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9809428284854563,
        "f1": 0.9749247743229689,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9749247743229689,
        "precision": 0.9720829154129054,
        "recall": 0.9809428284854563
      },
      {
        "accuracy": 0.9809428284854563,
        "f1": 0.9745904379806083,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9745904379806083,
        "precision": 0.9714142427281846,
        "recall": 0.9809428284854563
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.9839518555667001,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9839518555667001,
        "precision": 0.9819458375125376,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9896355733868271,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9896355733868271,
        "precision": 0.9884653961885657,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9909729187562688,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9909729187562688,
        "precision": 0.9899699097291875,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611167,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611167,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9809428284854563,
        "f1": 0.9752591106653292,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9752591106653292,
        "precision": 0.9724172517552658,
        "recall": 0.9809428284854563
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.9839518555667001,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9839518555667001,
        "precision": 0.9819458375125376,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.9598796389167502,
        "f1": 0.9472417251755265,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9472417251755265,
        "precision": 0.9412403878301571,
        "recall": 0.9598796389167502
      },
      {
        "accuracy": 0.9638916750250752,
        "f1": 0.9525242393848211,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9525242393848211,
        "precision": 0.9470076897358742,
        "recall": 0.9638916750250752
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9899699097291875,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9899699097291875,
        "precision": 0.9889669007021064,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9926446004680709,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9926446004680709,
        "precision": 0.9919759277833501,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9883650952858576,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9883650952858576,
        "precision": 0.9872116349047142,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9852892009361417,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9852892009361417,
        "precision": 0.9834503510531595,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.08625877632898696,
        "f1": 0.07333721445794507,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.07333721445794507,
        "precision": 0.07020180582927647,
        "recall": 0.08625877632898696
      },
      {
        "accuracy": 0.1534603811434303,
        "f1": 0.1139674783943445,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.1139674783943445,
        "precision": 0.10426007089772955,
        "recall": 0.1534603811434303
      },
      {
        "accuracy": 0.24373119358074222,
        "f1": 0.20675939210929917,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.20675939210929917,
        "precision": 0.1987227990321505,
        "recall": 0.24373119358074222
      },
      {
        "accuracy": 0.34503510531594783,
        "f1": 0.2806692330336793,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.2806692330336793,
        "precision": 0.2613069122087556,
        "recall": 0.34503510531594783
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9867937144767636,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9867937144767636,
        "precision": 0.9852892009361418,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9869608826479438,
        "f1": 0.9826145101972584,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9826145101972584,
        "precision": 0.9804413239719157,
        "recall": 0.9869608826479438
      },
      {
        "accuracy": 0.9007021063189569,
        "f1": 0.8777021039809404,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8777021039809404,
        "precision": 0.8685055165496489,
        "recall": 0.9007021063189569
      },
      {
        "accuracy": 0.9047141424272819,
        "f1": 0.8779003677699766,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8779003677699766,
        "precision": 0.86613172851889,
        "recall": 0.9047141424272819
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9849548645937813,
        "f1": 0.9799398194583752,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9799398194583752,
        "precision": 0.977432296890672,
        "recall": 0.9849548645937813
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9852892009361417,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9852892009361417,
        "precision": 0.9834503510531595,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.3881644934804413,
        "f1": 0.3457307383449297,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.3457307383449297,
        "precision": 0.3341099524404892,
        "recall": 0.3881644934804413
      },
      {
        "accuracy": 0.5165496489468405,
        "f1": 0.45891153313420113,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.45891153313420113,
        "precision": 0.43850093066672335,
        "recall": 0.5165496489468405
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527917,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9933132731527917,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9854563691073219,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9854563691073219,
        "precision": 0.9837846873955198,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9849548645937813,
        "f1": 0.9801069876295553,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9801069876295553,
        "precision": 0.9777666332330325,
        "recall": 0.9849548645937813
      },
      {
        "accuracy": 0.012036108324974924,
        "f1": 0.009490375889573483,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.009490375889573483,
        "precision": 0.009309727582297644,
        "recall": 0.012036108324974924
      },
      {
        "accuracy": 0.029087261785356068,
        "f1": 0.011534601135091837,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.011534601135091837,
        "precision": 0.009675047303220613,
        "recall": 0.029087261785356068
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}