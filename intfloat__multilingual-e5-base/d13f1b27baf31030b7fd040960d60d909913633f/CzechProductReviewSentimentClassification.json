{
  "dataset_revision": "2e6fedf42c9c104e83dfd95c3a453721e683e244",
  "evaluation_time": 10.99406886100769,
  "kg_co2_emissions": 0.001665163405823596,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.544970703125,
        "f1": 0.5248473236392261,
        "f1_weighted": 0.5247956153246319,
        "hf_subset": "default",
        "languages": [
          "ces-Latn"
        ],
        "main_score": 0.544970703125,
        "scores_per_experiment": [
          {
            "accuracy": 0.552734375,
            "f1": 0.5539732274977468,
            "f1_weighted": 0.553963723458439
          },
          {
            "accuracy": 0.525390625,
            "f1": 0.5049983549688172,
            "f1_weighted": 0.5049447754771094
          },
          {
            "accuracy": 0.54345703125,
            "f1": 0.505816980858789,
            "f1_weighted": 0.5057454539892986
          },
          {
            "accuracy": 0.53173828125,
            "f1": 0.5052148757681972,
            "f1_weighted": 0.5051630280689968
          },
          {
            "accuracy": 0.55810546875,
            "f1": 0.5328821331007153,
            "f1_weighted": 0.5328380382410003
          },
          {
            "accuracy": 0.533203125,
            "f1": 0.5057260897952035,
            "f1_weighted": 0.5056574299448033
          },
          {
            "accuracy": 0.5703125,
            "f1": 0.5666779075155454,
            "f1_weighted": 0.5666330632071827
          },
          {
            "accuracy": 0.55517578125,
            "f1": 0.5257533280881805,
            "f1_weighted": 0.5256991143203583
          },
          {
            "accuracy": 0.53662109375,
            "f1": 0.5279757351434347,
            "f1_weighted": 0.5279324164464421
          },
          {
            "accuracy": 0.54296875,
            "f1": 0.519454603655631,
            "f1_weighted": 0.5193791100926891
          }
        ]
      }
    ]
  },
  "task_name": "CzechProductReviewSentimentClassification"
}