{
  "dataset_revision": "317f262bf1e6126357bbe89e875451e4b0938fe4",
  "evaluation_time": 32.29903292655945,
  "kg_co2_emissions": 0.00493503540002305,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "f1_weighted": 0.0,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.0,
        "scores_per_experiment": [
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.46597999999999995,
        "f1": 0.4511109022294466,
        "f1_weighted": 0.46935497856753194,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.46597999999999995,
        "scores_per_experiment": [
          {
            "accuracy": 0.4738,
            "f1": 0.45870186145064545,
            "f1_weighted": 0.4804724159306132
          },
          {
            "accuracy": 0.4601,
            "f1": 0.4454963948115575,
            "f1_weighted": 0.45985664382482067
          },
          {
            "accuracy": 0.4787,
            "f1": 0.4592582663091868,
            "f1_weighted": 0.4832756574831218
          },
          {
            "accuracy": 0.4673,
            "f1": 0.4507334274768155,
            "f1_weighted": 0.46464685992887916
          },
          {
            "accuracy": 0.4624,
            "f1": 0.45269410806442745,
            "f1_weighted": 0.47317740132986885
          },
          {
            "accuracy": 0.4798,
            "f1": 0.464628375861615,
            "f1_weighted": 0.48457219946528923
          },
          {
            "accuracy": 0.4525,
            "f1": 0.433643917027421,
            "f1_weighted": 0.44995504952521276
          },
          {
            "accuracy": 0.4607,
            "f1": 0.4431761123180228,
            "f1_weighted": 0.45785225624767173
          },
          {
            "accuracy": 0.4536,
            "f1": 0.4429297077450402,
            "f1_weighted": 0.45905281576887863
          },
          {
            "accuracy": 0.4709,
            "f1": 0.4598468512297346,
            "f1_weighted": 0.4806884861709632
          }
        ]
      }
    ]
  },
  "task_name": "TNews"
}