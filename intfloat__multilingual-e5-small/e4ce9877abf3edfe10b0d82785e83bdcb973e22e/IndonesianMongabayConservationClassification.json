{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 17.156453847885132,
  "kg_co2_emissions": 0.0026271342057052173,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.2586489252814739,
        "f1": 0.2569591018194918,
        "f1_weighted": 0.2613227111921535,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.2569591018194918,
        "scores_per_experiment": [
          {
            "accuracy": 0.26202661207778916,
            "f1": 0.26441130698112375,
            "f1_weighted": 0.25917907818442787
          },
          {
            "accuracy": 0.2507676560900716,
            "f1": 0.24968078594724083,
            "f1_weighted": 0.2584146523958466
          },
          {
            "accuracy": 0.3029682702149437,
            "f1": 0.29868051457754624,
            "f1_weighted": 0.3071574617878363
          },
          {
            "accuracy": 0.22313203684749233,
            "f1": 0.2237017052671524,
            "f1_weighted": 0.23381637366827251
          },
          {
            "accuracy": 0.3070624360286592,
            "f1": 0.30548273919580543,
            "f1_weighted": 0.31560660449936917
          },
          {
            "accuracy": 0.23336745138178097,
            "f1": 0.2354031077612252,
            "f1_weighted": 0.2395135319975249
          },
          {
            "accuracy": 0.2610030706243603,
            "f1": 0.2631264392061734,
            "f1_weighted": 0.26377180881953444
          },
          {
            "accuracy": 0.2610030706243603,
            "f1": 0.2624942608061918,
            "f1_weighted": 0.2567221619535899
          },
          {
            "accuracy": 0.2569089048106448,
            "f1": 0.24593878253280863,
            "f1_weighted": 0.2529128121085903
          },
          {
            "accuracy": 0.22824974411463664,
            "f1": 0.22067137591965036,
            "f1_weighted": 0.22613262650654267
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.26097560975609757,
        "f1": 0.2563339349684149,
        "f1_weighted": 0.2652277783642535,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.2563339349684149,
        "scores_per_experiment": [
          {
            "accuracy": 0.2764227642276423,
            "f1": 0.2764672905543631,
            "f1_weighted": 0.278446382995518
          },
          {
            "accuracy": 0.26422764227642276,
            "f1": 0.2604423995935555,
            "f1_weighted": 0.27130690337322494
          },
          {
            "accuracy": 0.2865853658536585,
            "f1": 0.2774847433219851,
            "f1_weighted": 0.29062627718130457
          },
          {
            "accuracy": 0.2073170731707317,
            "f1": 0.2079543978213597,
            "f1_weighted": 0.21845208123091148
          },
          {
            "accuracy": 0.2886178861788618,
            "f1": 0.28845326620564604,
            "f1_weighted": 0.2995560929973467
          },
          {
            "accuracy": 0.23170731707317074,
            "f1": 0.2332903233324181,
            "f1_weighted": 0.24092674627989327
          },
          {
            "accuracy": 0.27235772357723576,
            "f1": 0.2733639499068592,
            "f1_weighted": 0.27623498017750053
          },
          {
            "accuracy": 0.2682926829268293,
            "f1": 0.26191049704875374,
            "f1_weighted": 0.26369113193012617
          },
          {
            "accuracy": 0.2865853658536585,
            "f1": 0.2692765223595244,
            "f1_weighted": 0.2861067140380398
          },
          {
            "accuracy": 0.22764227642276422,
            "f1": 0.21469595953968343,
            "f1_weighted": 0.2269304734386694
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}