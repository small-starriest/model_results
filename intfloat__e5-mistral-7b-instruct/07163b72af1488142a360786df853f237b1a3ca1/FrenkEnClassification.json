{
  "dataset_revision": "52483dba0ff23291271ee9249839865e3c3e7e50",
  "evaluation_time": 35.026126861572266,
  "kg_co2_emissions": 0.00897730896782424,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.7086918730986527,
        "ap": 0.5424868804398942,
        "ap_weighted": 0.5424868804398942,
        "f1": 0.6963394651016726,
        "f1_weighted": 0.7066270357905124,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7086918730986527,
        "scores_per_experiment": [
          {
            "accuracy": 0.7075184702303347,
            "ap": 0.5250462991075946,
            "ap_weighted": 0.5250462991075946,
            "f1": 0.6897953386760405,
            "f1_weighted": 0.707550694105888
          },
          {
            "accuracy": 0.7062146892655368,
            "ap": 0.506920822460183,
            "ap_weighted": 0.506920822460183,
            "f1": 0.6444561271977545,
            "f1_weighted": 0.6799399308467097
          },
          {
            "accuracy": 0.7392438070404173,
            "ap": 0.5558480439836372,
            "ap_weighted": 0.5558480439836372,
            "f1": 0.7081554136895953,
            "f1_weighted": 0.730964607745924
          },
          {
            "accuracy": 0.6527596697088223,
            "ap": 0.5019848926967572,
            "ap_weighted": 0.5019848926967572,
            "f1": 0.6525389053637174,
            "f1_weighted": 0.6546361666422135
          },
          {
            "accuracy": 0.6962190352020861,
            "ap": 0.5429160332839733,
            "ap_weighted": 0.5429160332839733,
            "f1": 0.6960516357266164,
            "f1_weighted": 0.6977597303744643
          },
          {
            "accuracy": 0.6983920034767492,
            "ap": 0.5467740152490761,
            "ap_weighted": 0.5467740152490761,
            "f1": 0.6983504701284806,
            "f1_weighted": 0.699198058087592
          },
          {
            "accuracy": 0.7192524989135158,
            "ap": 0.5592861260606092,
            "ap_weighted": 0.5592861260606092,
            "f1": 0.7177298311444653,
            "f1_weighted": 0.7226942686636776
          },
          {
            "accuracy": 0.7335940895262929,
            "ap": 0.5632657793534473,
            "ap_weighted": 0.5632657793534473,
            "f1": 0.7260436030459864,
            "f1_weighted": 0.736934487995329
          },
          {
            "accuracy": 0.6897001303780965,
            "ap": 0.5416624569230487,
            "ap_weighted": 0.5416624569230487,
            "f1": 0.689663496774447,
            "f1_weighted": 0.6888560921500132
          },
          {
            "accuracy": 0.7440243372446762,
            "ap": 0.5811643352806164,
            "ap_weighted": 0.5811643352806164,
            "f1": 0.740609829269623,
            "f1_weighted": 0.7477363212933136
          }
        ]
      }
    ]
  },
  "task_name": "FrenkEnClassification"
}