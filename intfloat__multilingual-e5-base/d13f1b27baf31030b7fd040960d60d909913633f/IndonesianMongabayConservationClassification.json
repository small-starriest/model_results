{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 20.68579888343811,
  "kg_co2_emissions": 0.003356856311889332,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.23551688843398155,
        "f1": 0.23268152624058264,
        "f1_weighted": 0.23659954694363874,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.23268152624058264,
        "scores_per_experiment": [
          {
            "accuracy": 0.23132036847492324,
            "f1": 0.2288000547901822,
            "f1_weighted": 0.21361940232341037
          },
          {
            "accuracy": 0.23029682702149437,
            "f1": 0.2342210715789571,
            "f1_weighted": 0.23688330189999077
          },
          {
            "accuracy": 0.3111566018423746,
            "f1": 0.3019693393405899,
            "f1_weighted": 0.3089682337406777
          },
          {
            "accuracy": 0.20880245649948823,
            "f1": 0.21037428297485317,
            "f1_weighted": 0.22032103474826817
          },
          {
            "accuracy": 0.300921187308086,
            "f1": 0.302867749882483,
            "f1_weighted": 0.3119851565862793
          },
          {
            "accuracy": 0.1862845445240532,
            "f1": 0.18273230594265208,
            "f1_weighted": 0.18944439373358135
          },
          {
            "accuracy": 0.22313203684749233,
            "f1": 0.22673580128162452,
            "f1_weighted": 0.23172877905123274
          },
          {
            "accuracy": 0.2262026612077789,
            "f1": 0.2223699475775718,
            "f1_weighted": 0.22698871428125555
          },
          {
            "accuracy": 0.23336745138178097,
            "f1": 0.21747836952068514,
            "f1_weighted": 0.22324473407216644
          },
          {
            "accuracy": 0.20368474923234392,
            "f1": 0.1992663395162275,
            "f1_weighted": 0.20281171899952477
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.2416666666666667,
        "f1": 0.235584286696428,
        "f1_weighted": 0.24443562245116252,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.235584286696428,
        "scores_per_experiment": [
          {
            "accuracy": 0.23170731707317074,
            "f1": 0.22623328930990905,
            "f1_weighted": 0.21820746816953476
          },
          {
            "accuracy": 0.25,
            "f1": 0.25288894489368985,
            "f1_weighted": 0.25828198301884037
          },
          {
            "accuracy": 0.3150406504065041,
            "f1": 0.30389361721627445,
            "f1_weighted": 0.3110122305501566
          },
          {
            "accuracy": 0.22154471544715448,
            "f1": 0.22192065646104644,
            "f1_weighted": 0.2343585988534694
          },
          {
            "accuracy": 0.28252032520325204,
            "f1": 0.2870647469573406,
            "f1_weighted": 0.30225939514801814
          },
          {
            "accuracy": 0.18089430894308944,
            "f1": 0.1730542238225272,
            "f1_weighted": 0.17549750604813025
          },
          {
            "accuracy": 0.21951219512195122,
            "f1": 0.21934079035295548,
            "f1_weighted": 0.2304016579839117
          },
          {
            "accuracy": 0.241869918699187,
            "f1": 0.23527749474161105,
            "f1_weighted": 0.24871359641986418
          },
          {
            "accuracy": 0.26422764227642276,
            "f1": 0.23517391059247983,
            "f1_weighted": 0.2524840196397905
          },
          {
            "accuracy": 0.20934959349593496,
            "f1": 0.20099519261644602,
            "f1_weighted": 0.21313976867990955
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}