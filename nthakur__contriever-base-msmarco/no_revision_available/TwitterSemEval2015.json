{
    "test": {
        "cos_sim": {
            "accuracy": 0.8392442033736663,
            "accuracy_threshold": 0.734542965888977,
            "ap": 0.6684972822513366,
            "f1": 0.6383709519136408,
            "f1_threshold": 0.6785071492195129,
            "precision": 0.5965153599266392,
            "recall": 0.6865435356200528
        },
        "dot": {
            "accuracy": 0.8328068188591524,
            "accuracy_threshold": 1.87443208694458,
            "ap": 0.6444375630413068,
            "f1": 0.6283929858275282,
            "f1_threshold": 1.7224515676498413,
            "precision": 0.5767195767195767,
            "recall": 0.6902374670184697
        },
        "euclidean": {
            "accuracy": 0.8326876080348096,
            "accuracy_threshold": 1.1394844055175781,
            "ap": 0.6399533869061542,
            "f1": 0.6061209256033839,
            "f1_threshold": 1.264004111289978,
            "precision": 0.5734463276836158,
            "recall": 0.6427440633245383
        },
        "evaluation_time": 9.47,
        "manhattan": {
            "accuracy": 0.8326876080348096,
            "accuracy_threshold": 24.373188018798828,
            "ap": 0.6391149854158247,
            "f1": 0.6068386322735454,
            "f1_threshold": 28.325220108032227,
            "precision": 0.5564356435643565,
            "recall": 0.6672823218997361
        },
        "max": {
            "accuracy": 0.8392442033736663,
            "ap": 0.6684972822513366,
            "f1": 0.6383709519136408
        }
    },
    "mteb_version": "0.0.2",
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}