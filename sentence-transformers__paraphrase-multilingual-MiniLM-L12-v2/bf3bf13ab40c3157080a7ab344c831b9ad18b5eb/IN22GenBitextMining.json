{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 17.90776228904724,
  "kg_co2_emissions": 0.002754302125684094,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.158203125,
        "f1": 0.1307616860290767,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.1307616860290767,
        "precision": 0.12243671719990079,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0062941391022994135,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0062941391022994135,
        "precision": 0.005836818590660167,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.029830216711773237,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.029830216711773237,
        "precision": 0.027912778881083684,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.04397120374764764,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.04397120374764764,
        "precision": 0.042632509784005346,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.015976082616707618,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.015976082616707618,
        "precision": 0.014940347519742724,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02964609558679467,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.02964609558679467,
        "precision": 0.027183314732142857,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.03816609172077922,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.03816609172077922,
        "precision": 0.03723596643518519,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.05495101992851653,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.05495101992851653,
        "precision": 0.048323734912251386,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01961937079124579,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.01961937079124579,
        "precision": 0.018920240739613764,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.0231593119524154,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0231593119524154,
        "precision": 0.022117996618567063,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.051890686879628736,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.051890686879628736,
        "precision": 0.046023577204403546,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.028010405544749973,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.028010405544749973,
        "precision": 0.02696568850190477,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002910683879922161,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.002910683879922161,
        "precision": 0.0022625240446720518,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02830952920117322,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.02830952920117322,
        "precision": 0.027103559261845146,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10270879836309524,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.10270879836309524,
        "precision": 0.09417902518488455,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.05895612805049482,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.05895612805049482,
        "precision": 0.05465970307393791,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.021000339673913043,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.021000339673913043,
        "precision": 0.019975155860955492,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003938802083333333,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.003938802083333333,
        "precision": 0.0032660590277777775,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.021163354454685097,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.021163354454685097,
        "precision": 0.020436085833070893,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.05213628533772661,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.05213628533772661,
        "precision": 0.046525081363948555,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.047711765843983914,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.047711765843983914,
        "precision": 0.043587743864619194,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.032038864068483996,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.032038864068483996,
        "precision": 0.031043512494019477,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.153936392383658,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.153936392383658,
        "precision": 0.1398060525514781,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.01304471005283094,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.01304471005283094,
        "precision": 0.011196799986276238,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.07128101933282602,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.07128101933282602,
        "precision": 0.06850033890157944,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.1545230841463366,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.1545230841463366,
        "precision": 0.1487409947552827,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.04610586623405952,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.04610586623405952,
        "precision": 0.04316106832252358,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.08004478748119406,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.08004478748119406,
        "precision": 0.07517082846366518,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.11027690276649957,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.11027690276649957,
        "precision": 0.1074995684891297,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.0532927878393588,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0532927878393588,
        "precision": 0.04511258495094537,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.04349010303785006,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.04349010303785006,
        "precision": 0.0414506591249065,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.08281245193490833,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.08281245193490833,
        "precision": 0.08062131904260955,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.10736383854148251,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.10736383854148251,
        "precision": 0.09679422034317584,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.08894170133415533,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.08894170133415533,
        "precision": 0.08444652606906786,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002008888759435699,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.002008888759435699,
        "precision": 0.0016060682118848825,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.103619148070524,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.103619148070524,
        "precision": 0.0995466800164855,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.09624357038069725,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.09624357038069725,
        "precision": 0.08629099307810245,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.1260248066087497,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.1260248066087497,
        "precision": 0.11451666482573646,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.052189391825622294,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.052189391825622294,
        "precision": 0.04973946521982342,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0035143476511998173,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0035143476511998173,
        "precision": 0.0028974705116421567,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.05244140625,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.05244140625,
        "precision": 0.05093238467261905,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.10863020500830703,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.10863020500830703,
        "precision": 0.09825429482327719,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.10148584054834055,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.10148584054834055,
        "precision": 0.0904650814318783,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.12965890739569474,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.12965890739569474,
        "precision": 0.1261998011533996,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.014304260144037323,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.014304260144037323,
        "precision": 0.012126848845598845,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02796721049937546,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.02796721049937546,
        "precision": 0.023830599196810135,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.0907442477670416,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0907442477670416,
        "precision": 0.08813500497855392,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06911394421423725,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06911394421423725,
        "precision": 0.0660779551917113,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.09375,
        "f1": 0.08095552465160141,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08095552465160141,
        "precision": 0.07783018924899505,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.050033117242154,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.050033117242154,
        "precision": 0.04713820683131338,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.08127809848780093,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.08127809848780093,
        "precision": 0.07852927021162093,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006507287487136399,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.006507287487136399,
        "precision": 0.004578800547456821,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.0605222773731203,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0605222773731203,
        "precision": 0.05703512524801588,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.08097733376887341,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08097733376887341,
        "precision": 0.07871178760170613,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05053794798882613,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.05053794798882613,
        "precision": 0.04539420059293996,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06776443563651288,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06776443563651288,
        "precision": 0.06346878173887338,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011755351624800638,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0011755351624800638,
        "precision": 0.0007796999007936508,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.07244058056511612,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07244058056511612,
        "precision": 0.06885826727553669,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015481850410618794,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.015481850410618794,
        "precision": 0.011790597098214286,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.0407431232040099,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0407431232040099,
        "precision": 0.03530581918327248,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06489442335106066,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.06489442335106066,
        "precision": 0.0606358904917086,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008489209976105137,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008489209976105137,
        "precision": 0.0005227161788586452,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.10544537927350428,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.10544537927350428,
        "precision": 0.10133114769345239,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.05511335363018945,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.05511335363018945,
        "precision": 0.04933469310876476,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05349054441520409,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.05349054441520409,
        "precision": 0.04883852952731312,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.06780009906369025,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.06780009906369025,
        "precision": 0.06493464905267149,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.04393132888621956,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.04393132888621956,
        "precision": 0.0357389043790411,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.11322837047934703,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.11322837047934703,
        "precision": 0.09537633924789012,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11073182631056808,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11073182631056808,
        "precision": 0.10070366103080947,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.685546875,
        "f1": 0.6447458559565812,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6447458559565812,
        "precision": 0.6307540603927322,
        "recall": 0.685546875
      },
      {
        "accuracy": 0.4853515625,
        "f1": 0.4368629092261905,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4368629092261905,
        "precision": 0.41816060633989177,
        "recall": 0.4853515625
      },
      {
        "accuracy": 0.453125,
        "f1": 0.39132397550366305,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.39132397550366305,
        "precision": 0.36859538844402123,
        "recall": 0.453125
      },
      {
        "accuracy": 0.6904296875,
        "f1": 0.6595582380260996,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6595582380260996,
        "precision": 0.6478461374817461,
        "recall": 0.6904296875
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.017989851499244036,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.017989851499244036,
        "precision": 0.013628726217079737,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.248046875,
        "f1": 0.19989970153544373,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.19989970153544373,
        "precision": 0.18387445516608758,
        "recall": 0.248046875
      },
      {
        "accuracy": 0.6484375,
        "f1": 0.6119849795386905,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6119849795386905,
        "precision": 0.5985912045739348,
        "recall": 0.6484375
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.10569042622369391,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.10569042622369391,
        "precision": 0.09178778031924689,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.560546875,
        "f1": 0.5141935050626456,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5141935050626456,
        "precision": 0.496812996031746,
        "recall": 0.560546875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005067391339239856,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0005067391339239856,
        "precision": 0.0002777550289579937,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.564453125,
        "f1": 0.519234476461039,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.519234476461039,
        "precision": 0.5014051649305555,
        "recall": 0.564453125
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.06041510517933875,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.06041510517933875,
        "precision": 0.049950255406896446,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.2197265625,
        "f1": 0.15388134452309032,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.15388134452309032,
        "precision": 0.1364925415316645,
        "recall": 0.2197265625
      },
      {
        "accuracy": 0.3642578125,
        "f1": 0.3142027839781746,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.3142027839781746,
        "precision": 0.29459751674107143,
        "recall": 0.3642578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 5.6779857127997226e-05,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 5.6779857127997226e-05,
        "precision": 2.877012365616383e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.4970703125,
        "f1": 0.4437779017857143,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4437779017857143,
        "precision": 0.4226748511904762,
        "recall": 0.4970703125
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.11006046672095762,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11006046672095762,
        "precision": 0.09697902373316841,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.197265625,
        "f1": 0.12864027514475584,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.12864027514475584,
        "precision": 0.11153206592931772,
        "recall": 0.197265625
      },
      {
        "accuracy": 0.6572265625,
        "f1": 0.615472724555642,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.615472724555642,
        "precision": 0.5999645667540114,
        "recall": 0.6572265625
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.06770665457633206,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.06770665457633206,
        "precision": 0.054511202257776725,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.1545569962806291,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.1545569962806291,
        "precision": 0.12968665263715634,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.08703963579708851,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.08703963579708851,
        "precision": 0.07555266043007614,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6479104662698412,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.6479104662698412,
        "precision": 0.6218343098958333,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.60546875,
        "f1": 0.5278715587797619,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.5278715587797619,
        "precision": 0.4970741877480158,
        "recall": 0.60546875
      },
      {
        "accuracy": 0.68359375,
        "f1": 0.6005945335046898,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.6005945335046898,
        "precision": 0.5657633463541667,
        "recall": 0.68359375
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9720052083333333,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9720052083333333,
        "precision": 0.9690755208333334,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.029908060050129998,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.029908060050129998,
        "precision": 0.023728111978027173,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.30078125,
        "f1": 0.2145723306795651,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.2145723306795651,
        "precision": 0.18931345753855522,
        "recall": 0.30078125
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8273949032738095,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8273949032738095,
        "precision": 0.8128580729166667,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.11642216416643329,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.11642216416643329,
        "precision": 0.09936856045287923,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.810546875,
        "f1": 0.7598361545138889,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.7598361545138889,
        "precision": 0.7372407459077381,
        "recall": 0.810546875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00016297179383116886,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.00016297179383116886,
        "precision": 8.439254687198765e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.7744140625,
        "f1": 0.7186275421626984,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.7186275421626984,
        "precision": 0.6943277994791667,
        "recall": 0.7744140625
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.0951128235696274,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0951128235696274,
        "precision": 0.07619749176751822,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.2666015625,
        "f1": 0.1731641512467566,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.1731641512467566,
        "precision": 0.1490008439751374,
        "recall": 0.2666015625
      },
      {
        "accuracy": 0.51953125,
        "f1": 0.4384517609126984,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.4384517609126984,
        "precision": 0.4088883040787338,
        "recall": 0.51953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00019049422648076463,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00019049422648076463,
        "precision": 9.877767931197094e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.5693359375,
        "f1": 0.4943607390873016,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.4943607390873016,
        "precision": 0.46634854403409093,
        "recall": 0.5693359375
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.10863027033263967,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.10863027033263967,
        "precision": 0.09169816314255122,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.234375,
        "f1": 0.13950737945271824,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.13950737945271824,
        "precision": 0.1174602229373399,
        "recall": 0.234375
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9484700520833333,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9484700520833333,
        "precision": 0.943310546875,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.0457439666607714,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0457439666607714,
        "precision": 0.036369558032730134,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.09850953083374958,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.09850953083374958,
        "precision": 0.08258192274305556,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.11184058703589954,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11184058703589954,
        "precision": 0.10314243861607142,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.45386207217261904,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.45386207217261904,
        "precision": 0.4335216703869047,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.5849609375,
        "f1": 0.5372141487359026,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5372141487359026,
        "precision": 0.5201209256238554,
        "recall": 0.5849609375
      },
      {
        "accuracy": 0.416015625,
        "f1": 0.349136475503663,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.349136475503663,
        "precision": 0.32508567821067824,
        "recall": 0.416015625
      },
      {
        "accuracy": 0.60546875,
        "f1": 0.5622268455615942,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5622268455615942,
        "precision": 0.5455839191190754,
        "recall": 0.60546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.014742475529939045,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.014742475529939045,
        "precision": 0.011175917028994196,
        "recall": 0.046875
      },
      {
        "accuracy": 0.2353515625,
        "f1": 0.18704078932709445,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.18704078932709445,
        "precision": 0.1715213428684171,
        "recall": 0.2353515625
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.5171685112847222,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5171685112847222,
        "precision": 0.5030289290787338,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.0953984637914074,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0953984637914074,
        "precision": 0.08143454106764197,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.576171875,
        "f1": 0.5259944590999278,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5259944590999278,
        "precision": 0.5068863509537338,
        "recall": 0.576171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00041697964233741464,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00041697964233741464,
        "precision": 0.00024194830339097117,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.4439221314709596,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4439221314709596,
        "precision": 0.4259556361607143,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.049307159854034846,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.049307159854034846,
        "precision": 0.038009937445492456,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.12899943968791625,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12899943968791625,
        "precision": 0.11326509628558411,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.3330078125,
        "f1": 0.2830101376488095,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.2830101376488095,
        "precision": 0.26307896205357145,
        "recall": 0.3330078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000621964271931596,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.000621964271931596,
        "precision": 0.0003579954117063492,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.408203125,
        "f1": 0.36576915922619047,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.36576915922619047,
        "precision": 0.3488444010416667,
        "recall": 0.408203125
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.08731168325334801,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.08731168325334801,
        "precision": 0.07385558102076595,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.11917566618494352,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11917566618494352,
        "precision": 0.10067110919807729,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.560546875,
        "f1": 0.51307040796683,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.51307040796683,
        "precision": 0.49644005330889673,
        "recall": 0.560546875
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.07074536520337302,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.07074536520337302,
        "precision": 0.05840775610852587,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.14321529557894386,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.14321529557894386,
        "precision": 0.12637923328841297,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06342231986763236,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.06342231986763236,
        "precision": 0.05792690172806511,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.4814453125,
        "f1": 0.43892319183579653,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.43892319183579653,
        "precision": 0.42148744024922635,
        "recall": 0.4814453125
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.699954409013995,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.699954409013995,
        "precision": 0.6925472673570946,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.400390625,
        "f1": 0.3585384359335839,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.3585384359335839,
        "precision": 0.3407769097222222,
        "recall": 0.400390625
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6985675149896864,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.6985675149896864,
        "precision": 0.6950928745309265,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.05531286138254866,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.05531286138254866,
        "precision": 0.04516409284314694,
        "recall": 0.109375
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.14987515739468865,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.14987515739468865,
        "precision": 0.1354976382762458,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5746837954194725,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.5746837954194725,
        "precision": 0.5643073033602841,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.1046548427224973,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.1046548427224973,
        "precision": 0.0913844000762494,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.5529173704954955,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.5529173704954955,
        "precision": 0.5400661892361112,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000424890350877193,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.000424890350877193,
        "precision": 0.00026157924107142856,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.5341796875,
        "f1": 0.5015950520833333,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.5015950520833333,
        "precision": 0.4871744791666667,
        "recall": 0.5341796875
      },
      {
        "accuracy": 0.197265625,
        "f1": 0.13245723189570846,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.13245723189570846,
        "precision": 0.11451862753132284,
        "recall": 0.197265625
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.16102288904161607,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.16102288904161607,
        "precision": 0.14301963092246295,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.3623046875,
        "f1": 0.31817866606620715,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.31817866606620715,
        "precision": 0.3006951703711854,
        "recall": 0.3623046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002857603092783505,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.0002857603092783505,
        "precision": 0.00015496516913077272,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.361328125,
        "f1": 0.31701853918650796,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.31701853918650796,
        "precision": 0.30038248697916664,
        "recall": 0.361328125
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.11377306620097291,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.11377306620097291,
        "precision": 0.1005050843795961,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.13254580143623898,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.13254580143623898,
        "precision": 0.11400550173312696,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.6865234375,
        "f1": 0.6681036086309524,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.6681036086309524,
        "precision": 0.6600623497596154,
        "recall": 0.6865234375
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.06921422641289793,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06921422641289793,
        "precision": 0.05629087467953899,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.25390625,
        "f1": 0.15473224948416264,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.15473224948416264,
        "precision": 0.12826931775906386,
        "recall": 0.25390625
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.10459407129329004,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.10459407129329004,
        "precision": 0.09139723842827613,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.736328125,
        "f1": 0.6746171254960318,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6746171254960318,
        "precision": 0.6480875651041667,
        "recall": 0.736328125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97314453125,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.97314453125,
        "precision": 0.9700520833333333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5498767671130953,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5498767671130953,
        "precision": 0.5207395523313492,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.7060546875,
        "f1": 0.628862072172619,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.628862072172619,
        "precision": 0.5965425037202381,
        "recall": 0.7060546875
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.028387156834171055,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.028387156834171055,
        "precision": 0.021563324671154262,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.30859375,
        "f1": 0.22214820498511903,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.22214820498511903,
        "precision": 0.19606676051557714,
        "recall": 0.30859375
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.869140625,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.869140625,
        "precision": 0.85595703125,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.11611358379550676,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11611358379550676,
        "precision": 0.09762994366266545,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.7997907366071428,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7997907366071428,
        "precision": 0.7788899739583334,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00010848370457628329,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00010848370457628329,
        "precision": 5.5312486234866215e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7532374526515151,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7532374526515151,
        "precision": 0.7315755208333332,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.09647197259932835,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.09647197259932835,
        "precision": 0.07863778653851534,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.271484375,
        "f1": 0.17209467955052193,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.17209467955052193,
        "precision": 0.1464408580079734,
        "recall": 0.271484375
      },
      {
        "accuracy": 0.5517578125,
        "f1": 0.47541239684794373,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.47541239684794373,
        "precision": 0.4452241443452381,
        "recall": 0.5517578125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0003307093677246901,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0003307093677246901,
        "precision": 0.0001737246782253576,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.6044921875,
        "f1": 0.5347693810096154,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5347693810096154,
        "precision": 0.5070967769209956,
        "recall": 0.6044921875
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.12164119507889123,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.12164119507889123,
        "precision": 0.10385420099638693,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.14530008508265632,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.14530008508265632,
        "precision": 0.12287691131777595,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9449869791666667,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9449869791666667,
        "precision": 0.9388020833333333,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.0435915773609511,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0435915773609511,
        "precision": 0.041533290226591024,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.0253574469150641,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0253574469150641,
        "precision": 0.02421577492817248,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006078381794388039,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.006078381794388039,
        "precision": 0.005680850437947518,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.021558207947530862,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.021558207947530862,
        "precision": 0.02124460864798905,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.057670230653416796,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.057670230653416796,
        "precision": 0.056773037695191715,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.009444776714513556,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.009444776714513556,
        "precision": 0.0092796856264988,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023179842503911335,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.023179842503911335,
        "precision": 0.02193912231092201,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.04000875797132719,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.04000875797132719,
        "precision": 0.039458900369623656,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.007874131892946131,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.007874131892946131,
        "precision": 0.007843969565278244,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.028021634916166167,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.028021634916166167,
        "precision": 0.027845526578481727,
        "recall": 0.03125
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.041656160240515466,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.041656160240515466,
        "precision": 0.037340564871677556,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.024101587942357793,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.024101587942357793,
        "precision": 0.023444052725979544,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002276543913465913,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.002276543913465913,
        "precision": 0.0021264585211246633,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.02091373735900428,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.02091373735900428,
        "precision": 0.020744955948208722,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.058215751262626264,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.058215751262626264,
        "precision": 0.053835956525408436,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.035244913354175046,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.035244913354175046,
        "precision": 0.034312084860438186,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01432499667199148,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.01432499667199148,
        "precision": 0.01416119736140725,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024843472960992905,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0024843472960992905,
        "precision": 0.0020668542038027333,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.011871122617148136,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.011871122617148136,
        "precision": 0.011801197489754098,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.05035726981096925,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.05035726981096925,
        "precision": 0.04489754223640942,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06339119449367121,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.06339119449367121,
        "precision": 0.058030517017280354,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.03537531980994152,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.03537531980994152,
        "precision": 0.03527934935623024,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.031309890196608944,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.031309890196608944,
        "precision": 0.025949083468614714,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06986960872817949,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.06986960872817949,
        "precision": 0.0607951904869477,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05771072669059993,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.05771072669059993,
        "precision": 0.053467301558462535,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.17388477971959587,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.17388477971959587,
        "precision": 0.16706486039972868,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.28515625,
        "f1": 0.25433955696221544,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.25433955696221544,
        "precision": 0.2459800694161333,
        "recall": 0.28515625
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.16256166630678348,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.16256166630678348,
        "precision": 0.15520798271565572,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.14016826819415323,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.14016826819415323,
        "precision": 0.1314593926768125,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.255859375,
        "f1": 0.23033083119222666,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.23033083119222666,
        "precision": 0.22336203164386453,
        "recall": 0.255859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01196513533882836,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.01196513533882836,
        "precision": 0.008726816167102878,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.234375,
        "f1": 0.20738265933818573,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.20738265933818573,
        "precision": 0.1980269399562302,
        "recall": 0.234375
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.07375330917781152,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07375330917781152,
        "precision": 0.06428279743152333,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.16906254372074686,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.16906254372074686,
        "precision": 0.16160590819770507,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0006631617677580584,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0006631617677580584,
        "precision": 0.00038663437371808725,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.16889783100280045,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.16889783100280045,
        "precision": 0.16262258991630488,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.036108622009500914,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.036108622009500914,
        "precision": 0.03042557505977033,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.08812375439443454,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.08812375439443454,
        "precision": 0.07913113366975352,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.11015861037833694,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.11015861037833694,
        "precision": 0.10450758774517965,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0011033579448850319,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0011033579448850319,
        "precision": 0.0007384347646061465,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.1734434006797583,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.1734434006797583,
        "precision": 0.1668145006035631,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08230579144118959,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.08230579144118959,
        "precision": 0.07553147176722953,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.09300973007027694,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.09300973007027694,
        "precision": 0.08363928079858649,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.2681480466851591,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.2681480466851591,
        "precision": 0.2589788358343046,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.047680680322281885,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.047680680322281885,
        "precision": 0.035969144058013616,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.208984375,
        "f1": 0.12375860178594553,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.12375860178594553,
        "precision": 0.10188986902854091,
        "recall": 0.208984375
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.09248686426420802,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.09248686426420802,
        "precision": 0.08190804529671718,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.68359375,
        "f1": 0.6255068824404761,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6255068824404761,
        "precision": 0.5999348958333334,
        "recall": 0.68359375
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8149739583333333,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8149739583333333,
        "precision": 0.8023111979166666,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.5212014818948413,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5212014818948413,
        "precision": 0.4967808314732143,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.603515625,
        "f1": 0.523686290922619,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.523686290922619,
        "precision": 0.492454117063492,
        "recall": 0.603515625
      },
      {
        "accuracy": 0.875,
        "f1": 0.8518330627705627,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8518330627705627,
        "precision": 0.8428043798649267,
        "recall": 0.875
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.018808093426020453,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.018808093426020453,
        "precision": 0.014547200820158689,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.2783203125,
        "f1": 0.20715920364357865,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.20715920364357865,
        "precision": 0.1853046476093351,
        "recall": 0.2783203125
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.10123488593077525,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.10123488593077525,
        "precision": 0.0851072345083218,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.720703125,
        "f1": 0.6644391741071429,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6644391741071429,
        "precision": 0.6400173611111112,
        "recall": 0.720703125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0006856711771523686,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0006856711771523686,
        "precision": 0.0003778569301494814,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.728515625,
        "f1": 0.6816266741071428,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6816266741071428,
        "precision": 0.661474609375,
        "recall": 0.728515625
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.07906900254113536,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.07906900254113536,
        "precision": 0.06330966385411979,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.2197265625,
        "f1": 0.14097756977754677,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.14097756977754677,
        "precision": 0.12164898130043465,
        "recall": 0.2197265625
      },
      {
        "accuracy": 0.48828125,
        "f1": 0.4216238839285714,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.4216238839285714,
        "precision": 0.3955729166666666,
        "recall": 0.48828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003620868973676837,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0003620868973676837,
        "precision": 0.0002051525764862066,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.5126953125,
        "f1": 0.44760277157738093,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.44760277157738093,
        "precision": 0.4235192677331349,
        "recall": 0.5126953125
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.1001239929075978,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1001239929075978,
        "precision": 0.0854502316456965,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.208984375,
        "f1": 0.1285730425856865,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1285730425856865,
        "precision": 0.10965749269674871,
        "recall": 0.208984375
      },
      {
        "accuracy": 0.81640625,
        "f1": 0.778240482390873,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.778240482390873,
        "precision": 0.7632254464285715,
        "recall": 0.81640625
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06566101145107434,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.06566101145107434,
        "precision": 0.059418015252976186,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.09497965603443478,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.09497965603443478,
        "precision": 0.09001518669763806,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.03327430992665529,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.03327430992665529,
        "precision": 0.030836018910025513,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.07626045105771581,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.07626045105771581,
        "precision": 0.07463750055694172,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.16794133538832198,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.16794133538832198,
        "precision": 0.16568010208936795,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.05128479279490372,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.05128479279490372,
        "precision": 0.05032449909935133,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05949671183425081,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.05949671183425081,
        "precision": 0.05689908846036776,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.12749236307639206,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.12749236307639206,
        "precision": 0.12657775069211885,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.05793748258082497,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.05793748258082497,
        "precision": 0.05048655500315656,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.06030657191799528,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.06030657191799528,
        "precision": 0.0585072894906839,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.08451388104201576,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.08451388104201576,
        "precision": 0.08384261214339339,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.07510610433641823,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.07510610433641823,
        "precision": 0.07305027494990168,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0001394631015438942,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.0001394631015438942,
        "precision": 7.206364366660125e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.06948929478638458,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.06948929478638458,
        "precision": 0.06816119547328996,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.0727609623576995,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.0727609623576995,
        "precision": 0.06715006510416667,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.12565026761626796,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.12565026761626796,
        "precision": 0.11982855615912096,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.07177304150097184,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.07177304150097184,
        "precision": 0.07026308320096122,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002747158611673414,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.002747158611673414,
        "precision": 0.0024425177552448627,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.05631767745388669,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.05631767745388669,
        "precision": 0.055665350841029027,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.208984375,
        "f1": 0.18701714409722223,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.18701714409722223,
        "precision": 0.17807733444940477,
        "recall": 0.208984375
      },
      {
        "accuracy": 0.251953125,
        "f1": 0.22693684895833333,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.22693684895833333,
        "precision": 0.2171425471230159,
        "recall": 0.251953125
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.13518977303916674,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.13518977303916674,
        "precision": 0.134027454515883,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.057300296166736535,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.057300296166736535,
        "precision": 0.04565391777793366,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.23046875,
        "f1": 0.14940839054608585,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.14940839054608585,
        "precision": 0.12750532345258908,
        "recall": 0.23046875
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.08842782663672061,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.08842782663672061,
        "precision": 0.07924710466342869,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.5771484375,
        "f1": 0.5195728443287038,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5195728443287038,
        "precision": 0.4966016195319519,
        "recall": 0.5771484375
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.8043776210768399,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8043776210768399,
        "precision": 0.7911295572916667,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.5859375,
        "f1": 0.5343982514880952,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5343982514880952,
        "precision": 0.5134602864583333,
        "recall": 0.5859375
      },
      {
        "accuracy": 0.5947265625,
        "f1": 0.528515625,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.528515625,
        "precision": 0.5010765438988095,
        "recall": 0.5947265625
      },
      {
        "accuracy": 0.837890625,
        "f1": 0.82060546875,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.82060546875,
        "precision": 0.8128580729166668,
        "recall": 0.837890625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.021207300144664393,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.021207300144664393,
        "precision": 0.015550388357974902,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.2412109375,
        "f1": 0.18246045133252164,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.18246045133252164,
        "precision": 0.16414969308035712,
        "recall": 0.2412109375
      },
      {
        "accuracy": 0.748046875,
        "f1": 0.7158040364583333,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7158040364583333,
        "precision": 0.7010997953869047,
        "recall": 0.748046875
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.1134602992748673,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1134602992748673,
        "precision": 0.09638356638916011,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0003028194296900283,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0003028194296900283,
        "precision": 0.00015960765597650885,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.7041015625,
        "f1": 0.6590731534090908,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6590731534090908,
        "precision": 0.6386207217261904,
        "recall": 0.7041015625
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.09375903863208551,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.09375903863208551,
        "precision": 0.0771034915174822,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.2412109375,
        "f1": 0.15703231752431757,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.15703231752431757,
        "precision": 0.13382374596974206,
        "recall": 0.2412109375
      },
      {
        "accuracy": 0.4697265625,
        "f1": 0.40698094678059393,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.40698094678059393,
        "precision": 0.38335441131275877,
        "recall": 0.4697265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00032545494759712087,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00032545494759712087,
        "precision": 0.0001864547902494331,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.4736328125,
        "f1": 0.4180438810321622,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4180438810321622,
        "precision": 0.39726721032873374,
        "recall": 0.4736328125
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.10350623252105329,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.10350623252105329,
        "precision": 0.08839246212855156,
        "recall": 0.1689453125
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.12936728065260922,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.12936728065260922,
        "precision": 0.10992849206891721,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.796875,
        "f1": 0.7632067259996947,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7632067259996947,
        "precision": 0.7489578082997311,
        "recall": 0.796875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009011130136986302,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0009011130136986302,
        "precision": 0.0006200456841097109,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.289717348927874e-05,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 9.289717348927874e-05,
        "precision": 4.7949058919803604e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009793056530898877,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0009793056530898877,
        "precision": 0.000977936005625879,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.513122441577284e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 9.513122441577284e-05,
        "precision": 4.989191857298475e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.019777662874871e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.019777662874871e-06,
        "precision": 1.010934265010352e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.5012071883711668e-05,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 1.5012071883711668e-05,
        "precision": 7.548437926412277e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.923622529683398e-05,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 4.923622529683398e-05,
        "precision": 2.4834060993609685e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9472831505483548e-06,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 1.9472831505483548e-06,
        "precision": 9.746132734530937e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00022117833451788674,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.00022117833451788674,
        "precision": 0.000124156984508547,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 7.632649194039855e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 7.632649194039855e-06,
        "precision": 3.823813948508521e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009791459986772486,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0009791459986772486,
        "precision": 0.0009778559602649007,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00014586305973280598,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.00014586305973280598,
        "precision": 7.70580535854675e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.1268941208405187e-05,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 2.1268941208405187e-05,
        "precision": 1.0730416621825227e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00017980696219103477,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.00017980696219103477,
        "precision": 9.878261966551327e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0002664697443000765,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0002664697443000765,
        "precision": 0.00014069435457563856,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.2674459586466166e-05,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 3.2674459586466166e-05,
        "precision": 1.6521057347670253e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000978482976892822,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.000978482976892822,
        "precision": 0.0009775236835629921,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.047017065392494714,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.047017065392494714,
        "precision": 0.04065923632574023,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1653270509977827e-06,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 2.1653270509977827e-06,
        "precision": 1.0838651498335183e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002899315983160019,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0002899315983160019,
        "precision": 0.00016823610371831008,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003984617902143675,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0003984617902143675,
        "precision": 0.00021856070941608433,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9054878048780488e-06,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 1.9054878048780488e-06,
        "precision": 9.5367431640625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.06648380644962676,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06648380644962676,
        "precision": 0.055354244436298036,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.15964555543771997,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.15964555543771997,
        "precision": 0.1352185497528156,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09003552599744005,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.09003552599744005,
        "precision": 0.07981550959635748,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.48955736917162695,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.48955736917162695,
        "precision": 0.47013462611607143,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.736328125,
        "f1": 0.695902813549298,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.695902813549298,
        "precision": 0.6820458331701651,
        "recall": 0.736328125
      },
      {
        "accuracy": 0.4794921875,
        "f1": 0.4248434399801587,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4248434399801587,
        "precision": 0.40407812312109187,
        "recall": 0.4794921875
      },
      {
        "accuracy": 0.5322265625,
        "f1": 0.4667417151817851,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.4667417151817851,
        "precision": 0.4428075396825397,
        "recall": 0.5322265625
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.7060808769872132,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7060808769872132,
        "precision": 0.6960419975969372,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.021492890001788237,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.021492890001788237,
        "precision": 0.01592094756044944,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.2236328125,
        "f1": 0.1724590820782227,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1724590820782227,
        "precision": 0.15718855525984432,
        "recall": 0.2236328125
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.630248964721621,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.630248964721621,
        "precision": 0.6155532781021062,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.11335685904448331,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11335685904448331,
        "precision": 0.09781357780655911,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.6728515625,
        "f1": 0.6207278073489011,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6207278073489011,
        "precision": 0.6001069568452382,
        "recall": 0.6728515625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00041592237617652883,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00041592237617652883,
        "precision": 0.00021740777524672657,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.0929658628903078,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0929658628903078,
        "precision": 0.07775220493482213,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.240234375,
        "f1": 0.16892027856897304,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.16892027856897304,
        "precision": 0.14921339511183263,
        "recall": 0.240234375
      },
      {
        "accuracy": 0.4638671875,
        "f1": 0.39971682135025055,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.39971682135025055,
        "precision": 0.37477213541666665,
        "recall": 0.4638671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004744264793200416,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004744264793200416,
        "precision": 0.0002644751238019074,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.4130859375,
        "f1": 0.36975833953373016,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.36975833953373016,
        "precision": 0.35429532490079363,
        "recall": 0.4130859375
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.10594102955230023,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.10594102955230023,
        "precision": 0.09230685948034975,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.13629846193069153,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.13629846193069153,
        "precision": 0.11846553386996544,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.693359375,
        "f1": 0.6552983228764478,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6552983228764478,
        "precision": 0.6412816314183502,
        "recall": 0.693359375
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10625,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.10625,
        "precision": 0.09921612850869513,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.09354225974810214,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.09354225974810214,
        "precision": 0.08933026957231756,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.01212244593507264,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.01212244593507264,
        "precision": 0.011197497846615688,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.04780046988224637,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.04780046988224637,
        "precision": 0.0465371378629795,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.1054954664681969,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.1054954664681969,
        "precision": 0.10241054410472741,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03115198538109181,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.03115198538109181,
        "precision": 0.02921642941030579,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.07262199414658055,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.07262199414658055,
        "precision": 0.06853310184691369,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.0951384489342612,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0951384489342612,
        "precision": 0.09243728994098577,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.09494512648809522,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.09494512648809522,
        "precision": 0.08277390693639844,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.025034373329924073,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.025034373329924073,
        "precision": 0.023770945600873485,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.0668986619572557,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0668986619572557,
        "precision": 0.065129852379917,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06489168994414969,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.06489168994414969,
        "precision": 0.06002415783002488,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.07389343499825421,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.07389343499825421,
        "precision": 0.07229984199905576,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0037792403562312837,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0037792403562312837,
        "precision": 0.003425049753911678,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.07119479121533795,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.07119479121533795,
        "precision": 0.06941901312934028,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.07565472315228175,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.07565472315228175,
        "precision": 0.07066697961005752,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.04508730727029184,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.04508730727029184,
        "precision": 0.043254178665940224,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003898652030892448,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.003898652030892448,
        "precision": 0.003024102633477633,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.03476896367521368,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.03476896367521368,
        "precision": 0.03306916351550609,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04971881863540871,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.04971881863540871,
        "precision": 0.044326788662726165,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.0737085522755753,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.0737085522755753,
        "precision": 0.0662756893713925,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.09073308225973037,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.09073308225973037,
        "precision": 0.08825817552940672,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08064371744791665,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.08064371744791665,
        "precision": 0.07142984651017666,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.12652631467850328,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.12652631467850328,
        "precision": 0.11811331472928747,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.04017873402639027,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.04017873402639027,
        "precision": 0.03727513605304008,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.133872043115019,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.133872043115019,
        "precision": 0.13046442438077663,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.2314453125,
        "f1": 0.20781223767609208,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.20781223767609208,
        "precision": 0.20170898058453712,
        "recall": 0.2314453125
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.09027212620117882,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.09027212620117882,
        "precision": 0.08666082777437634,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.12921164049093736,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.12921164049093736,
        "precision": 0.12302138895330861,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.19808087411743286,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.19808087411743286,
        "precision": 0.19357797117479153,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.0407699981274463,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.0407699981274463,
        "precision": 0.0345962603012447,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07976520124781931,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.07976520124781931,
        "precision": 0.07475139395690303,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.14760460070830936,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.14760460070830936,
        "precision": 0.1440242587999055,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.1271785869295962,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.1271785869295962,
        "precision": 0.11600556697615669,
        "recall": 0.1689453125
      },
      {
        "accuracy": 0.15625,
        "f1": 0.14436642278439152,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.14436642278439152,
        "precision": 0.14089782288024474,
        "recall": 0.15625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00143366006336996,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.00143366006336996,
        "precision": 0.0009131303504547887,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.140625,
        "f1": 0.13145256159185892,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.13145256159185892,
        "precision": 0.1288625321740255,
        "recall": 0.140625
      },
      {
        "accuracy": 0.15625,
        "f1": 0.11702940072080698,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.11702940072080698,
        "precision": 0.10470704263184732,
        "recall": 0.15625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.1013596415855894,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.1013596415855894,
        "precision": 0.09724286612817795,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018704530423280423,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0018704530423280423,
        "precision": 0.0012989533253205125,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.0910915798611111,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.0910915798611111,
        "precision": 0.08892463235294118,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.13933843984997013,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.13933843984997013,
        "precision": 0.12793293945637696,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.12943103548418566,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.12943103548418566,
        "precision": 0.11845793253874308,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.18523593919101733,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.18523593919101733,
        "precision": 0.18169397558964492,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.038725993771087985,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.038725993771087985,
        "precision": 0.0317941524977458,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.09512380683883265,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.09512380683883265,
        "precision": 0.08015970730819218,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.07072360509860509,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.07072360509860509,
        "precision": 0.06423326891992706,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.2835362517028841,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2835362517028841,
        "precision": 0.2693820529513889,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.4560546875,
        "f1": 0.3996714178093825,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.3996714178093825,
        "precision": 0.3813359287655068,
        "recall": 0.4560546875
      },
      {
        "accuracy": 0.2783203125,
        "f1": 0.23845302546731412,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.23845302546731412,
        "precision": 0.22534800811168,
        "recall": 0.2783203125
      },
      {
        "accuracy": 0.326171875,
        "f1": 0.2742714045936702,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2742714045936702,
        "precision": 0.25618049028822054,
        "recall": 0.326171875
      },
      {
        "accuracy": 0.4404296875,
        "f1": 0.40006978693589285,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.40006978693589285,
        "precision": 0.38699790753329844,
        "recall": 0.4404296875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.013589212371884953,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.013589212371884953,
        "precision": 0.009650687695422202,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.12622368408501222,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12622368408501222,
        "precision": 0.11607251516617142,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.400390625,
        "f1": 0.359461122767673,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.359461122767673,
        "precision": 0.34675779668153106,
        "recall": 0.400390625
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.08670129737167165,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08670129737167165,
        "precision": 0.07380422895026736,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.4033203125,
        "f1": 0.3617227385244963,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3617227385244963,
        "precision": 0.3474155970982143,
        "recall": 0.4033203125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0007085451123656155,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0007085451123656155,
        "precision": 0.00038724272299075574,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.4375,
        "f1": 0.3897178044394841,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3897178044394841,
        "precision": 0.3726438844358766,
        "recall": 0.4375
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.0585745751868456,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0585745751868456,
        "precision": 0.04844157704522116,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.1195903333049329,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1195903333049329,
        "precision": 0.10608308249909812,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008261614574545561,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008261614574545561,
        "precision": 0.0005792598094699114,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2607421875,
        "f1": 0.21222718253968254,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.21222718253968254,
        "precision": 0.19630605397206957,
        "recall": 0.2607421875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.0839912407801966,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0839912407801966,
        "precision": 0.07315109582610203,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.166015625,
        "f1": 0.11266274681255714,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11266274681255714,
        "precision": 0.09904775665284182,
        "recall": 0.166015625
      },
      {
        "accuracy": 0.423828125,
        "f1": 0.38213309978913745,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.38213309978913745,
        "precision": 0.3679829985930827,
        "recall": 0.423828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015084575333717865,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.00015084575333717865,
        "precision": 7.75739847560992e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011359133751122517,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0011359133751122517,
        "precision": 0.0010589725741002678,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001088782609843684,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.001088782609843684,
        "precision": 0.0010358674719887955,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009787619650900902,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0009787619650900902,
        "precision": 0.000977663472378805,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9492265469061875e-06,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 1.9492265469061875e-06,
        "precision": 9.75586913086913e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.7918577981651377e-05,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 1.7918577981651377e-05,
        "precision": 9.04224537037037e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.786271141649049e-05,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 9.786271141649049e-05,
        "precision": 5.088636784239172e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.918590373280943e-06,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 1.918590373280943e-06,
        "precision": 9.602384464110128e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00022405979437229437,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.00022405979437229437,
        "precision": 0.00012147484756097561,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009844751808824926,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0009844751808824926,
        "precision": 0.0009805271519245297,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009788602941176471,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0009788602941176471,
        "precision": 0.000977712750294464,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.314318347789694e-05,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 3.314318347789694e-05,
        "precision": 1.6701080214251065e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006530889675052411,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0006530889675052411,
        "precision": 0.0004893059745540399,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.04158993675595238,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.04158993675595238,
        "precision": 0.03573492650898078,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002816860606947697,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0002816860606947697,
        "precision": 0.00016409634347925217,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011006400966076186,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0011006400966076186,
        "precision": 0.0010399500955385087,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001267002140768588,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.001267002140768588,
        "precision": 0.0011450674019607844,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785001240079365,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0009785001240079365,
        "precision": 0.00097753227408143,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.25534064665127e-06,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 2.25534064665127e-06,
        "precision": 1.1289739884393064e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009898108697037498,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0009898108697037498,
        "precision": 0.0009832179535733381,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007622682844754863,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0007622682844754863,
        "precision": 0.0004444769159103734,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9073486328125e-06,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 1.9073486328125e-06,
        "precision": 9.546065493646139e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.04626716408081298,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.04626716408081298,
        "precision": 0.03810930677083414,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.0907722323249667,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0907722323249667,
        "precision": 0.07708235726819136,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.15625,
        "f1": 0.12296694171089487,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12296694171089487,
        "precision": 0.11144341362847221,
        "recall": 0.15625
      },
      {
        "accuracy": 0.4794921875,
        "f1": 0.4338573373241342,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4338573373241342,
        "precision": 0.41635784462932895,
        "recall": 0.4794921875
      },
      {
        "accuracy": 0.5087890625,
        "f1": 0.46611839457226634,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.46611839457226634,
        "precision": 0.45112147916102996,
        "recall": 0.5087890625
      },
      {
        "accuracy": 0.3876953125,
        "f1": 0.34618989903891395,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.34618989903891395,
        "precision": 0.3316069455717893,
        "recall": 0.3876953125
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.2895245000225469,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2895245000225469,
        "precision": 0.2720470309233378,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.5322265625,
        "f1": 0.49671817259707884,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.49671817259707884,
        "precision": 0.48507504431332554,
        "recall": 0.5322265625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.015505046434288438,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.015505046434288438,
        "precision": 0.011488561187638947,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.2333984375,
        "f1": 0.19160471324512596,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.19160471324512596,
        "precision": 0.17768114318407285,
        "recall": 0.2333984375
      },
      {
        "accuracy": 0.4677734375,
        "f1": 0.43330531230921854,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.43330531230921854,
        "precision": 0.421609873416514,
        "recall": 0.4677734375
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.09549726561614261,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.09549726561614261,
        "precision": 0.08175278332214342,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.419921875,
        "f1": 0.3730172939401455,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3730172939401455,
        "precision": 0.35664005925184444,
        "recall": 0.419921875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0010755407078707987,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0010755407078707987,
        "precision": 0.0006498829852152274,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.423828125,
        "f1": 0.38173506181318684,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.38173506181318684,
        "precision": 0.3660884796626984,
        "recall": 0.423828125
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.05889026117679279,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.05889026117679279,
        "precision": 0.047890550189062374,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.13214362548886602,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.13214362548886602,
        "precision": 0.11808642371360539,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.29296875,
        "f1": 0.24635106646825394,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.24635106646825394,
        "precision": 0.22986230891504328,
        "recall": 0.29296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001054707412423219,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001054707412423219,
        "precision": 0.0006188481798237895,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.1012231172865315,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1012231172865315,
        "precision": 0.08878978876104604,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.11945012123887083,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11945012123887083,
        "precision": 0.10465871479745636,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.4619140625,
        "f1": 0.4244839752774323,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4244839752774323,
        "precision": 0.411467646727799,
        "recall": 0.4619140625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.06769016336803244,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.06769016336803244,
        "precision": 0.06122200491546708,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.10424777208468614,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.10424777208468614,
        "precision": 0.09826632088855308,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03621468109575451,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.03621468109575451,
        "precision": 0.03402978822718484,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.08227045475277185,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.08227045475277185,
        "precision": 0.08036050640788997,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.14832787070667844,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.14832787070667844,
        "precision": 0.14507395267715037,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.062008766657151215,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.062008766657151215,
        "precision": 0.061026456823449496,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.06765731383318385,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.06765731383318385,
        "precision": 0.0646401721982934,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.125,
        "f1": 0.1211636929294317,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.1211636929294317,
        "precision": 0.1201533633524886,
        "recall": 0.125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.059235526300955986,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.059235526300955986,
        "precision": 0.05274939452185546,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.07609827662773234,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.07609827662773234,
        "precision": 0.07349847359700831,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.09232455021641109,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.09232455021641109,
        "precision": 0.09067741806557342,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.21523260248241502,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.21523260248241502,
        "precision": 0.205194576202877,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.08974102362875787,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.08974102362875787,
        "precision": 0.08849500230815574,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000556485615079365,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.000556485615079365,
        "precision": 0.0003603120432538595,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.08353193557418376,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.08353193557418376,
        "precision": 0.0826247888017531,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07429503367003366,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.07429503367003366,
        "precision": 0.06726134465520772,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.14750472678309917,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.14750472678309917,
        "precision": 0.14235771159123567,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.059736573140680996,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.059736573140680996,
        "precision": 0.057944461587372834,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003011067708333333,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003011067708333333,
        "precision": 0.002613467261904762,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.05762927032458282,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.05762927032458282,
        "precision": 0.05633736398589621,
        "recall": 0.0625
      },
      {
        "accuracy": 0.24609375,
        "f1": 0.2126788576007326,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.2126788576007326,
        "precision": 0.20196842924870267,
        "recall": 0.24609375
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.12693227883825942,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.12693227883825942,
        "precision": 0.12559715767175694,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.08179098462301587,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.08179098462301587,
        "precision": 0.0739841448337542,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.12984442752056496,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.12984442752056496,
        "precision": 0.12304309509212619,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.04559740789153638,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.04559740789153638,
        "precision": 0.043384663969766285,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.10613335615022251,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.10613335615022251,
        "precision": 0.10433623872179587,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.2158253732540902,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.2158253732540902,
        "precision": 0.21314501883611703,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.08832980703141682,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.08832980703141682,
        "precision": 0.08667041618984439,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.0908615048718033,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.0908615048718033,
        "precision": 0.08747527661634863,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.17212370808330923,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.17212370808330923,
        "precision": 0.17123886497855534,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.085808841765873,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.085808841765873,
        "precision": 0.0759575416977348,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.08737471347847789,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.08737471347847789,
        "precision": 0.08493382085417907,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.13433737291466122,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.13433737291466122,
        "precision": 0.13268002998426504,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.298828125,
        "f1": 0.271117259837963,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.271117259837963,
        "precision": 0.26151033382735683,
        "recall": 0.298828125
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.11648763020833333,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.11648763020833333,
        "precision": 0.11516229538690476,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0006510416666666666,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.00048828125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.10890784289313335,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.10890784289313335,
        "precision": 0.10730582292446358,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08043114700219192,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.08043114700219192,
        "precision": 0.0726413085357249,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.1543886208192849,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.1543886208192849,
        "precision": 0.14849994962177576,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.09180043260473589,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.09180043260473589,
        "precision": 0.09020360496502432,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003956221515008644,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.003956221515008644,
        "precision": 0.0033156652644733267,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.09944466196419322,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.09944466196419322,
        "precision": 0.09787736966164409,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.2822265625,
        "f1": 0.2589175269717262,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.2589175269717262,
        "precision": 0.2495984940404607,
        "recall": 0.2822265625
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.17227053023467476,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.17227053023467476,
        "precision": 0.17082222428902116,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.06972774860290082,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.06972774860290082,
        "precision": 0.05595580627365739,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.2373046875,
        "f1": 0.14013086331560595,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.14013086331560595,
        "precision": 0.11522350302437045,
        "recall": 0.2373046875
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.07675768354310919,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.07675768354310919,
        "precision": 0.06606383254332474,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.6787109375,
        "f1": 0.6093501984126984,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6093501984126984,
        "precision": 0.5803955078125,
        "recall": 0.6787109375
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9557291666666667,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9557291666666667,
        "precision": 0.9501953125,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.509060400320166,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.509060400320166,
        "precision": 0.47907017299107146,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.681640625,
        "f1": 0.59921875,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.59921875,
        "precision": 0.5644694010416667,
        "recall": 0.681640625
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9583333333333333,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9583333333333333,
        "precision": 0.953125,
        "recall": 0.96875
      },
      {
        "accuracy": 0.078125,
        "f1": 0.027416818571992744,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.027416818571992744,
        "precision": 0.021074778707093837,
        "recall": 0.078125
      },
      {
        "accuracy": 0.341796875,
        "f1": 0.25592617018398267,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.25592617018398267,
        "precision": 0.22945854330131674,
        "recall": 0.341796875
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.7943033854166667,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7943033854166667,
        "precision": 0.7762858072916666,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.10619621377831615,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.10619621377831615,
        "precision": 0.08764027168265842,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.796875,
        "f1": 0.7434895833333334,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7434895833333334,
        "precision": 0.719677734375,
        "recall": 0.796875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019155388503158672,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0019155388503158672,
        "precision": 0.0015302770673864424,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.6981608072916667,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.6981608072916667,
        "precision": 0.6737885974702381,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.09052760413347737,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.09052760413347737,
        "precision": 0.07232073762008258,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.2626953125,
        "f1": 0.16452276022588522,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.16452276022588522,
        "precision": 0.13868725489947736,
        "recall": 0.2626953125
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.4394245186237373,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.4394245186237373,
        "precision": 0.4085205078125,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00033349096016566473,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00033349096016566473,
        "precision": 0.000176570752228647,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.459295169890873,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.459295169890873,
        "precision": 0.42919683398199016,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.11035676497426905,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.11035676497426905,
        "precision": 0.09351245640947575,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.14156911487322368,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.14156911487322368,
        "precision": 0.11831146780714541,
        "recall": 0.23828125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}