{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 122.13927125930786,
  "kg_co2_emissions": 0.04386223965067073,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.7844311377245509,
        "f1": 0.7430852580553178,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.7430852580553178,
        "precision": 0.7257374140607673,
        "recall": 0.7844311377245509
      },
      {
        "accuracy": 0.19028609447771125,
        "f1": 0.1538743100619348,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.1538743100619348,
        "precision": 0.14145829589941367,
        "recall": 0.19028609447771125
      },
      {
        "accuracy": 0.5535595475715236,
        "f1": 0.4973841158471896,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.4973841158471896,
        "precision": 0.47667495696437806,
        "recall": 0.5535595475715236
      },
      {
        "accuracy": 0.7704590818363274,
        "f1": 0.727403922314102,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.727403922314102,
        "precision": 0.7105165330714233,
        "recall": 0.7704590818363274
      },
      {
        "accuracy": 0.4278110445775116,
        "f1": 0.36738305495790524,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.36738305495790524,
        "precision": 0.34596960353867584,
        "recall": 0.4278110445775116
      },
      {
        "accuracy": 0.541583499667332,
        "f1": 0.4865690751918297,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.4865690751918297,
        "precision": 0.4651004462381707,
        "recall": 0.541583499667332
      },
      {
        "accuracy": 0.7431803060545575,
        "f1": 0.6985912734415728,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.6985912734415728,
        "precision": 0.681242565374302,
        "recall": 0.7431803060545575
      },
      {
        "accuracy": 0.5016633399866933,
        "f1": 0.4434824434824435,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.4434824434824435,
        "precision": 0.4217699521591737,
        "recall": 0.5016633399866933
      },
      {
        "accuracy": 0.2894211576846307,
        "f1": 0.23997366877259266,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.23997366877259266,
        "precision": 0.22336575304639175,
        "recall": 0.2894211576846307
      },
      {
        "accuracy": 0.6087824351297405,
        "f1": 0.5580273795842658,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.5580273795842658,
        "precision": 0.537387418525143,
        "recall": 0.6087824351297405
      },
      {
        "accuracy": 0.37391882900864937,
        "f1": 0.3193533997866509,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.3193533997866509,
        "precision": 0.2993073857095813,
        "recall": 0.37391882900864937
      },
      {
        "accuracy": 0.6260811709913506,
        "f1": 0.5758240133489634,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.5758240133489634,
        "precision": 0.5557583246206,
        "recall": 0.6260811709913506
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0026190455881074646,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0026190455881074646,
        "precision": 0.002352460141720331,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.6722168605402139,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.6722168605402139,
        "precision": 0.6528672813103951,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.47837658017298734,
        "f1": 0.42216378153914846,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.42216378153914846,
        "precision": 0.3999103644562726,
        "recall": 0.47837658017298734
      },
      {
        "accuracy": 0.49434464404524286,
        "f1": 0.43708878539217855,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.43708878539217855,
        "precision": 0.41581944336435356,
        "recall": 0.49434464404524286
      },
      {
        "accuracy": 0.6553559547571524,
        "f1": 0.601492253588062,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.601492253588062,
        "precision": 0.5798160293170272,
        "recall": 0.6553559547571524
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.003894278057030008,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.003894278057030008,
        "precision": 0.0030785883531105765,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.4278110445775116,
        "f1": 0.37707788930994696,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.37707788930994696,
        "precision": 0.35865211154632315,
        "recall": 0.4278110445775116
      },
      {
        "accuracy": 0.43912175648702595,
        "f1": 0.3816852734018402,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.3816852734018402,
        "precision": 0.359865742300872,
        "recall": 0.43912175648702595
      },
      {
        "accuracy": 0.38988689288090483,
        "f1": 0.33959197924363566,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.33959197924363566,
        "precision": 0.3221887086191087,
        "recall": 0.38988689288090483
      },
      {
        "accuracy": 0.6666666666666666,
        "f1": 0.614939681794208,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.614939681794208,
        "precision": 0.5940803578029127,
        "recall": 0.6666666666666666
      },
      {
        "accuracy": 0.761144377910845,
        "f1": 0.7183679926194896,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.7183679926194896,
        "precision": 0.7014911974991815,
        "recall": 0.761144377910845
      },
      {
        "accuracy": 0.22554890219560877,
        "f1": 0.19100641671463517,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.19100641671463517,
        "precision": 0.17899521897447102,
        "recall": 0.22554890219560877
      },
      {
        "accuracy": 0.6640053226879574,
        "f1": 0.6058610292642229,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6058610292642229,
        "precision": 0.583735703196781,
        "recall": 0.6640053226879574
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9046351740962518,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9046351740962518,
        "precision": 0.8966178753603904,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.48502994011976047,
        "f1": 0.4315244838697932,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.4315244838697932,
        "precision": 0.41107203582253476,
        "recall": 0.48502994011976047
      },
      {
        "accuracy": 0.6427145708582834,
        "f1": 0.5877483128980134,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.5877483128980134,
        "precision": 0.5664488317182929,
        "recall": 0.6427145708582834
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8618540696385009,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.8618540696385009,
        "precision": 0.8507096917276559,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.5703417747329923,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.5703417747329923,
        "precision": 0.549997623800019,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.3466400532268796,
        "f1": 0.2936610682244801,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.2936610682244801,
        "precision": 0.27596856220385024,
        "recall": 0.3466400532268796
      },
      {
        "accuracy": 0.7005988023952096,
        "f1": 0.6563260203978768,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.6563260203978768,
        "precision": 0.639376273907212,
        "recall": 0.7005988023952096
      },
      {
        "accuracy": 0.46640053226879574,
        "f1": 0.410570117824031,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.410570117824031,
        "precision": 0.39043448235065,
        "recall": 0.46640053226879574
      },
      {
        "accuracy": 0.7218895542248835,
        "f1": 0.6763077020562049,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.6763077020562049,
        "precision": 0.6578243224949811,
        "recall": 0.7218895542248835
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0019951123743538915,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0019951123743538915,
        "precision": 0.0015750459720112752,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.7843873100360127,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.7843873100360127,
        "precision": 0.7713913442955359,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.5302727877578177,
        "f1": 0.47024157553099666,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.47024157553099666,
        "precision": 0.44775026666244233,
        "recall": 0.5302727877578177
      },
      {
        "accuracy": 0.5894876912840985,
        "f1": 0.5316583763689552,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.5316583763689552,
        "precision": 0.5090454492650102,
        "recall": 0.5894876912840985
      },
      {
        "accuracy": 0.7731204258150366,
        "f1": 0.7326637729831343,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7326637729831343,
        "precision": 0.715640940341539,
        "recall": 0.7731204258150366
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001460222892358621,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.001460222892358621,
        "precision": 0.0011133668925516335,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.5262807717897539,
        "f1": 0.4677982781460037,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.4677982781460037,
        "precision": 0.44696616867275557,
        "recall": 0.5262807717897539
      },
      {
        "accuracy": 0.5994677312042581,
        "f1": 0.5387175384680374,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.5387175384680374,
        "precision": 0.5153330904328909,
        "recall": 0.5994677312042581
      },
      {
        "accuracy": 0.46174318030605455,
        "f1": 0.40243616549827654,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.40243616549827654,
        "precision": 0.3811834077802142,
        "recall": 0.46174318030605455
      },
      {
        "accuracy": 0.8196939454424484,
        "f1": 0.785810917846846,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.785810917846846,
        "precision": 0.7717184678262522,
        "recall": 0.8196939454424484
      },
      {
        "accuracy": 0.19760479041916168,
        "f1": 0.15989773705310373,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.15989773705310373,
        "precision": 0.14673303705239835,
        "recall": 0.19760479041916168
      },
      {
        "accuracy": 0.2375249500998004,
        "f1": 0.2003035217253839,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2003035217253839,
        "precision": 0.1884860139675509,
        "recall": 0.2375249500998004
      },
      {
        "accuracy": 0.24750499001996007,
        "f1": 0.20926898431301388,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.20926898431301388,
        "precision": 0.19734987696564543,
        "recall": 0.24750499001996007
      },
      {
        "accuracy": 0.23087159015302727,
        "f1": 0.19176703388280236,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.19176703388280236,
        "precision": 0.17932610552434844,
        "recall": 0.23087159015302727
      },
      {
        "accuracy": 0.22954091816367264,
        "f1": 0.1972421820196858,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.1972421820196858,
        "precision": 0.1862641239886749,
        "recall": 0.22954091816367264
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.14101612282603243,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.14101612282603243,
        "precision": 0.13053081948511716,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.22630374726183106,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.22630374726183106,
        "precision": 0.2122883861905818,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.19294743845642048,
        "f1": 0.16047623921875417,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.16047623921875417,
        "precision": 0.14960607884759583,
        "recall": 0.19294743845642048
      },
      {
        "accuracy": 0.18829008649367932,
        "f1": 0.15006324041060162,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.15006324041060162,
        "precision": 0.13875221207724392,
        "recall": 0.18829008649367932
      },
      {
        "accuracy": 0.22554890219560877,
        "f1": 0.19559762491588184,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.19559762491588184,
        "precision": 0.18607288749357553,
        "recall": 0.22554890219560877
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.1430426784718202,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1430426784718202,
        "precision": 0.13200558959041991,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.20159680638722555,
        "f1": 0.17455835360026978,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.17455835360026978,
        "precision": 0.16540252827677976,
        "recall": 0.20159680638722555
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.00197394699694448,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00197394699694448,
        "precision": 0.0014757665419755873,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.24417831004657353,
        "f1": 0.20631691440074673,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.20631691440074673,
        "precision": 0.19455613808368563,
        "recall": 0.24417831004657353
      },
      {
        "accuracy": 0.18097139055222888,
        "f1": 0.14129090752098603,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.14129090752098603,
        "precision": 0.12964452740107313,
        "recall": 0.18097139055222888
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.13584644637538845,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.13584644637538845,
        "precision": 0.1255033745993004,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.19228210246174318,
        "f1": 0.15574496029585846,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.15574496029585846,
        "precision": 0.14420725521944136,
        "recall": 0.19228210246174318
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002784655211071728,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002784655211071728,
        "precision": 0.0018948721581192487,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.24750499001996007,
        "f1": 0.21600544880580552,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.21600544880580552,
        "precision": 0.20585644287154312,
        "recall": 0.24750499001996007
      },
      {
        "accuracy": 0.14703925482368596,
        "f1": 0.11090687659281076,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11090687659281076,
        "precision": 0.10046663646669517,
        "recall": 0.14703925482368596
      },
      {
        "accuracy": 0.20093147039254824,
        "f1": 0.16351384556815798,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16351384556815798,
        "precision": 0.152584009470237,
        "recall": 0.20093147039254824
      },
      {
        "accuracy": 0.1996007984031936,
        "f1": 0.16343826477233286,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.16343826477233286,
        "precision": 0.15205762664354253,
        "recall": 0.1996007984031936
      },
      {
        "accuracy": 0.5668662674650699,
        "f1": 0.514157975535221,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.514157975535221,
        "precision": 0.49417329362439144,
        "recall": 0.5668662674650699
      },
      {
        "accuracy": 0.6846307385229541,
        "f1": 0.6388403088003887,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6388403088003887,
        "precision": 0.6199978350177952,
        "recall": 0.6846307385229541
      },
      {
        "accuracy": 0.25482368596141053,
        "f1": 0.217973015378205,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.217973015378205,
        "precision": 0.2058300980456669,
        "recall": 0.25482368596141053
      },
      {
        "accuracy": 0.7624750499001997,
        "f1": 0.7217744405369156,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7217744405369156,
        "precision": 0.7062496699722249,
        "recall": 0.7624750499001997
      },
      {
        "accuracy": 0.4823685961410512,
        "f1": 0.4337703621136755,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4337703621136755,
        "precision": 0.4162368864963675,
        "recall": 0.4823685961410512
      },
      {
        "accuracy": 0.5302727877578177,
        "f1": 0.47728938467461424,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.47728938467461424,
        "precision": 0.4567061883928151,
        "recall": 0.5302727877578177
      },
      {
        "accuracy": 0.7984031936127745,
        "f1": 0.7616813991065489,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7616813991065489,
        "precision": 0.7467424938482822,
        "recall": 0.7984031936127745
      },
      {
        "accuracy": 0.5176314038589488,
        "f1": 0.4689187762042053,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4689187762042053,
        "precision": 0.4507714729271615,
        "recall": 0.5176314038589488
      },
      {
        "accuracy": 0.3606121091151031,
        "f1": 0.3125290826828927,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3125290826828927,
        "precision": 0.29606981600494575,
        "recall": 0.3606121091151031
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.645346468594091,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.645346468594091,
        "precision": 0.6297963836636491,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.3759148369926813,
        "f1": 0.3250631013106063,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3250631013106063,
        "precision": 0.3067663208381771,
        "recall": 0.3759148369926813
      },
      {
        "accuracy": 0.626746506986028,
        "f1": 0.5764317924996567,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5764317924996567,
        "precision": 0.5564656401482748,
        "recall": 0.626746506986028
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0009832313437646326,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009832313437646326,
        "precision": 0.0005687731008600331,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6921316097962805,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6921316097962805,
        "precision": 0.6752608779554887,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.40652029274783763,
        "f1": 0.3550216558265677,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3550216558265677,
        "precision": 0.33683331527642907,
        "recall": 0.40652029274783763
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5556297938034466,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5556297938034466,
        "precision": 0.5334030351994423,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.6194278110445776,
        "f1": 0.5619781600819526,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.5619781600819526,
        "precision": 0.540223281191345,
        "recall": 0.6194278110445776
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.003797639213031339,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003797639213031339,
        "precision": 0.003125755309720712,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.5868263473053892,
        "f1": 0.535095993678828,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.535095993678828,
        "precision": 0.515146162701053,
        "recall": 0.5868263473053892
      },
      {
        "accuracy": 0.45109780439121755,
        "f1": 0.39577912477114074,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.39577912477114074,
        "precision": 0.37458205282556584,
        "recall": 0.45109780439121755
      },
      {
        "accuracy": 0.4098469727212242,
        "f1": 0.36367522844568756,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.36367522844568756,
        "precision": 0.3465244114944714,
        "recall": 0.4098469727212242
      },
      {
        "accuracy": 0.729208250166334,
        "f1": 0.6824245356181484,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6824245356181484,
        "precision": 0.6640282926211071,
        "recall": 0.729208250166334
      },
      {
        "accuracy": 0.6646706586826348,
        "f1": 0.6184740710131106,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.6184740710131106,
        "precision": 0.6028049963322893,
        "recall": 0.6646706586826348
      },
      {
        "accuracy": 0.8642714570858283,
        "f1": 0.8339907486614074,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.8339907486614074,
        "precision": 0.8223523851767364,
        "recall": 0.8642714570858283
      },
      {
        "accuracy": 0.18496340652029275,
        "f1": 0.1519851586854128,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.1519851586854128,
        "precision": 0.14146376598114488,
        "recall": 0.18496340652029275
      },
      {
        "accuracy": 0.6367265469061876,
        "f1": 0.5830771027601152,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.5830771027601152,
        "precision": 0.5637148269294895,
        "recall": 0.6367265469061876
      },
      {
        "accuracy": 0.4471057884231537,
        "f1": 0.3948471689333373,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.3948471689333373,
        "precision": 0.37746384140674333,
        "recall": 0.4471057884231537
      },
      {
        "accuracy": 0.5941450432468397,
        "f1": 0.5423402180900054,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.5423402180900054,
        "precision": 0.5251250903413683,
        "recall": 0.5941450432468397
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9050491609373844,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9050491609373844,
        "precision": 0.8974440008871146,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.5081697330092645,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.5081697330092645,
        "precision": 0.4916372727631929,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.30073186959414505,
        "f1": 0.25727935797504936,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.25727935797504936,
        "precision": 0.24414842799417466,
        "recall": 0.30073186959414505
      },
      {
        "accuracy": 0.6679973386560213,
        "f1": 0.6245657641490213,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.6245657641490213,
        "precision": 0.6092988604058569,
        "recall": 0.6679973386560213
      },
      {
        "accuracy": 0.41317365269461076,
        "f1": 0.3633081913160962,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.3633081913160962,
        "precision": 0.3486615367655123,
        "recall": 0.41317365269461076
      },
      {
        "accuracy": 0.7105788423153693,
        "f1": 0.6663071286508623,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.6663071286508623,
        "precision": 0.6509151871397968,
        "recall": 0.7105788423153693
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001340374573557978,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0001340374573557978,
        "precision": 7.00602547226148e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.8243512974051896,
        "f1": 0.7912444619031445,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.7912444619031445,
        "precision": 0.7793666875004202,
        "recall": 0.8243512974051896
      },
      {
        "accuracy": 0.37059214903526283,
        "f1": 0.3219975207107687,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.3219975207107687,
        "precision": 0.30767522521378143,
        "recall": 0.37059214903526283
      },
      {
        "accuracy": 0.5256154357950765,
        "f1": 0.4765363244704562,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.4765363244704562,
        "precision": 0.4599042071540323,
        "recall": 0.5256154357950765
      },
      {
        "accuracy": 0.812375249500998,
        "f1": 0.7776452386232826,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7776452386232826,
        "precision": 0.7643154675589805,
        "recall": 0.812375249500998
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0008099820885033515,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0008099820885033515,
        "precision": 0.0004672938016040247,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.48170326014637393,
        "f1": 0.43281652822802724,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.43281652822802724,
        "precision": 0.41715533172492136,
        "recall": 0.48170326014637393
      },
      {
        "accuracy": 0.5755156353958749,
        "f1": 0.5248250105905383,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.5248250105905383,
        "precision": 0.5085983456341149,
        "recall": 0.5755156353958749
      },
      {
        "accuracy": 0.4098469727212242,
        "f1": 0.3579374177784531,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.3579374177784531,
        "precision": 0.3418794792353295,
        "recall": 0.4098469727212242
      },
      {
        "accuracy": 0.8556220891550232,
        "f1": 0.8268463073852296,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.8268463073852296,
        "precision": 0.8164691374272213,
        "recall": 0.8556220891550232
      },
      {
        "accuracy": 0.42248835662009315,
        "f1": 0.37034118814968875,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.37034118814968875,
        "precision": 0.3520946682872831,
        "recall": 0.42248835662009315
      },
      {
        "accuracy": 0.48369926813040587,
        "f1": 0.4308070683789834,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.4308070683789834,
        "precision": 0.41091898232616797,
        "recall": 0.48369926813040587
      },
      {
        "accuracy": 0.21756487025948104,
        "f1": 0.184307412850327,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.184307412850327,
        "precision": 0.17303968301972292,
        "recall": 0.21756487025948104
      },
      {
        "accuracy": 0.48303393213572854,
        "f1": 0.43221582882261517,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.43221582882261517,
        "precision": 0.41272032654268187,
        "recall": 0.48303393213572854
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.47716033624868137,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.47716033624868137,
        "precision": 0.45864809456048033,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.4031936127744511,
        "f1": 0.35143037385394776,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.35143037385394776,
        "precision": 0.33250958400659,
        "recall": 0.4031936127744511
      },
      {
        "accuracy": 0.5469061876247505,
        "f1": 0.4974486720494705,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4974486720494705,
        "precision": 0.47888051735357123,
        "recall": 0.5469061876247505
      },
      {
        "accuracy": 0.4098469727212242,
        "f1": 0.3632252385745399,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.3632252385745399,
        "precision": 0.34558313166097593,
        "recall": 0.4098469727212242
      },
      {
        "accuracy": 0.2488356620093147,
        "f1": 0.2120360984317282,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2120360984317282,
        "precision": 0.1991112845903265,
        "recall": 0.2488356620093147
      },
      {
        "accuracy": 0.5049900199600799,
        "f1": 0.45856410207120546,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.45856410207120546,
        "precision": 0.44123565039233703,
        "recall": 0.5049900199600799
      },
      {
        "accuracy": 0.28476380572188953,
        "f1": 0.2417138934105002,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2417138934105002,
        "precision": 0.22661969508276894,
        "recall": 0.28476380572188953
      },
      {
        "accuracy": 0.6407185628742516,
        "f1": 0.5888841992634407,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5888841992634407,
        "precision": 0.5691930952908997,
        "recall": 0.6407185628742516
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0031322587620009755,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0031322587620009755,
        "precision": 0.0026428259598747263,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.5242847638057219,
        "f1": 0.4749559082892416,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4749559082892416,
        "precision": 0.45624408488679946,
        "recall": 0.5242847638057219
      },
      {
        "accuracy": 0.28476380572188953,
        "f1": 0.23851438130879246,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.23851438130879246,
        "precision": 0.22371716342108894,
        "recall": 0.28476380572188953
      },
      {
        "accuracy": 0.34597471723220224,
        "f1": 0.29905263650518243,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.29905263650518243,
        "precision": 0.2820765977203103,
        "recall": 0.34597471723220224
      },
      {
        "accuracy": 0.4856952761144378,
        "f1": 0.4300742312902203,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.4300742312902203,
        "precision": 0.40992802754279806,
        "recall": 0.4856952761144378
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.004249367251614084,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004249367251614084,
        "precision": 0.0036312877500221117,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.41184298070525616,
        "f1": 0.36427356926358917,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.36427356926358917,
        "precision": 0.3467374774261002,
        "recall": 0.41184298070525616
      },
      {
        "accuracy": 0.30805056553559546,
        "f1": 0.26208341317534695,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.26208341317534695,
        "precision": 0.24637328277547835,
        "recall": 0.30805056553559546
      },
      {
        "accuracy": 0.3413173652694611,
        "f1": 0.2994407677042408,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.2994407677042408,
        "precision": 0.2843339369287473,
        "recall": 0.3413173652694611
      },
      {
        "accuracy": 0.44510978043912175,
        "f1": 0.3928070801823297,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.3928070801823297,
        "precision": 0.3736289566129885,
        "recall": 0.44510978043912175
      },
      {
        "accuracy": 0.562874251497006,
        "f1": 0.5112532030695704,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.5112532030695704,
        "precision": 0.49200039075288576,
        "recall": 0.562874251497006
      },
      {
        "accuracy": 0.6640053226879574,
        "f1": 0.6097667099663108,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.6097667099663108,
        "precision": 0.5880627633621646,
        "recall": 0.6640053226879574
      },
      {
        "accuracy": 0.18562874251497005,
        "f1": 0.1552392569358637,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.1552392569358637,
        "precision": 0.14504570916453036,
        "recall": 0.18562874251497005
      },
      {
        "accuracy": 0.5335994677312043,
        "f1": 0.4768837985404851,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.4768837985404851,
        "precision": 0.45469695529575765,
        "recall": 0.5335994677312043
      },
      {
        "accuracy": 0.7312042581503659,
        "f1": 0.6828855996520666,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.6828855996520666,
        "precision": 0.663872255489022,
        "recall": 0.7312042581503659
      },
      {
        "accuracy": 0.43912175648702595,
        "f1": 0.38493311597104013,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.38493311597104013,
        "precision": 0.3655776230127527,
        "recall": 0.43912175648702595
      },
      {
        "accuracy": 0.739853626081171,
        "f1": 0.691909831131388,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.691909831131388,
        "precision": 0.6730950796819061,
        "recall": 0.739853626081171
      },
      {
        "accuracy": 0.5083166999334664,
        "f1": 0.45223125178214996,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.45223125178214996,
        "precision": 0.4312156111058307,
        "recall": 0.5083166999334664
      },
      {
        "accuracy": 0.26214238190286093,
        "f1": 0.21633450442087035,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.21633450442087035,
        "precision": 0.20162154046884587,
        "recall": 0.26214238190286093
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.4980536281933488,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.4980536281933488,
        "precision": 0.4787570435774029,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.46107784431137727,
        "f1": 0.40310904442640966,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.40310904442640966,
        "precision": 0.3802775401577797,
        "recall": 0.46107784431137727
      },
      {
        "accuracy": 0.6620093147039254,
        "f1": 0.6075858864282018,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.6075858864282018,
        "precision": 0.5853768653169851,
        "recall": 0.6620093147039254
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0018305742208751215,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0018305742208751215,
        "precision": 0.0014309468166070975,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.6553559547571524,
        "f1": 0.6073503786078636,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.6073503786078636,
        "precision": 0.5883095835191644,
        "recall": 0.6553559547571524
      },
      {
        "accuracy": 0.5249500998003992,
        "f1": 0.46582017819542776,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.46582017819542776,
        "precision": 0.44318205693875407,
        "recall": 0.5249500998003992
      },
      {
        "accuracy": 0.656686626746507,
        "f1": 0.5956314883460592,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.5956314883460592,
        "precision": 0.5698610715077781,
        "recall": 0.656686626746507
      },
      {
        "accuracy": 0.6001330671989354,
        "f1": 0.548579608459848,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.548579608459848,
        "precision": 0.5288475958136637,
        "recall": 0.6001330671989354
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0028137196099446036,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.0028137196099446036,
        "precision": 0.0022816636037562604,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.44045242847638055,
        "f1": 0.38381050572745606,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.38381050572745606,
        "precision": 0.36247331344636735,
        "recall": 0.44045242847638055
      },
      {
        "accuracy": 0.45575515635395875,
        "f1": 0.3935033880143661,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.3935033880143661,
        "precision": 0.3702930118598781,
        "recall": 0.45575515635395875
      },
      {
        "accuracy": 0.43313373253493015,
        "f1": 0.3792509232313834,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.3792509232313834,
        "precision": 0.3601804327852232,
        "recall": 0.43313373253493015
      },
      {
        "accuracy": 0.6593479707252162,
        "f1": 0.6056781098697266,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.6056781098697266,
        "precision": 0.584868118500853,
        "recall": 0.6593479707252162
      },
      {
        "accuracy": 0.7159015302727878,
        "f1": 0.6694916231842379,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6694916231842379,
        "precision": 0.6514083425261069,
        "recall": 0.7159015302727878
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8482938884136488,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8482938884136488,
        "precision": 0.8368374362386338,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.25748502994011974,
        "f1": 0.2144981762259811,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2144981762259811,
        "precision": 0.19996194018150107,
        "recall": 0.25748502994011974
      },
      {
        "accuracy": 0.7504990019960079,
        "f1": 0.7084333977547551,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7084333977547551,
        "precision": 0.6924917361045105,
        "recall": 0.7504990019960079
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.934752716788645,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.934752716788645,
        "precision": 0.9300953648259038,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.5489021956087824,
        "f1": 0.4922164998879989,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4922164998879989,
        "precision": 0.47092082938665636,
        "recall": 0.5489021956087824
      },
      {
        "accuracy": 0.6979374584165003,
        "f1": 0.6452902904000709,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6452902904000709,
        "precision": 0.6255198431346136,
        "recall": 0.6979374584165003
      },
      {
        "accuracy": 0.6174318030605456,
        "f1": 0.5646469926909049,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5646469926909049,
        "precision": 0.5447687258536149,
        "recall": 0.6174318030605456
      },
      {
        "accuracy": 0.39188290086493677,
        "f1": 0.33265625111932495,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.33265625111932495,
        "precision": 0.31269003268280576,
        "recall": 0.39188290086493677
      },
      {
        "accuracy": 0.7438456420492349,
        "f1": 0.7013492777905131,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7013492777905131,
        "precision": 0.6845379347125854,
        "recall": 0.7438456420492349
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.4461898713395719,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4461898713395719,
        "precision": 0.4256709665861949,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.7638057218895542,
        "f1": 0.7239035637239231,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7239035637239231,
        "precision": 0.7080402686690113,
        "recall": 0.7638057218895542
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001211726992518351,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001211726992518351,
        "precision": 0.0009759825643801257,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.8449767132401863,
        "f1": 0.8166091098226828,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8166091098226828,
        "precision": 0.8052672432911954,
        "recall": 0.8449767132401863
      },
      {
        "accuracy": 0.5016633399866933,
        "f1": 0.44410640423027414,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.44410640423027414,
        "precision": 0.42391539482389745,
        "recall": 0.5016633399866933
      },
      {
        "accuracy": 0.6826347305389222,
        "f1": 0.6299909080348202,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6299909080348202,
        "precision": 0.609289909838812,
        "recall": 0.6826347305389222
      },
      {
        "accuracy": 0.7984031936127745,
        "f1": 0.7597281627221747,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.7597281627221747,
        "precision": 0.7441783100465735,
        "recall": 0.7984031936127745
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0023496390359438457,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0023496390359438457,
        "precision": 0.0017182786103278453,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.6207584830339321,
        "f1": 0.5685681546958993,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5685681546958993,
        "precision": 0.5485312443895278,
        "recall": 0.6207584830339321
      },
      {
        "accuracy": 0.64604125083167,
        "f1": 0.5957735323004784,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5957735323004784,
        "precision": 0.5759522469103308,
        "recall": 0.64604125083167
      },
      {
        "accuracy": 0.4870259481037924,
        "f1": 0.4342163464169452,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.4342163464169452,
        "precision": 0.4155820021479195,
        "recall": 0.4870259481037924
      },
      {
        "accuracy": 0.8922155688622755,
        "f1": 0.8709802616988247,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8709802616988247,
        "precision": 0.8621376295028989,
        "recall": 0.8922155688622755
      },
      {
        "accuracy": 0.5163007318695941,
        "f1": 0.46490568646257274,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.46490568646257274,
        "precision": 0.44424618775916175,
        "recall": 0.5163007318695941
      },
      {
        "accuracy": 0.6207584830339321,
        "f1": 0.5676982494846766,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.5676982494846766,
        "precision": 0.5465373485832568,
        "recall": 0.6207584830339321
      },
      {
        "accuracy": 0.19693945442448438,
        "f1": 0.16668937257759614,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.16668937257759614,
        "precision": 0.15607699944027287,
        "recall": 0.19693945442448438
      },
      {
        "accuracy": 0.5242847638057219,
        "f1": 0.4693497084714649,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.4693497084714649,
        "precision": 0.44717417017816224,
        "recall": 0.5242847638057219
      },
      {
        "accuracy": 0.6653359946773121,
        "f1": 0.6198471263341522,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.6198471263341522,
        "precision": 0.6028728257770174,
        "recall": 0.6653359946773121
      },
      {
        "accuracy": 0.4138389886892881,
        "f1": 0.364070156379655,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.364070156379655,
        "precision": 0.34452987963467,
        "recall": 0.4138389886892881
      },
      {
        "accuracy": 0.49833666001330673,
        "f1": 0.44243998774936893,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.44243998774936893,
        "precision": 0.4200823842511056,
        "recall": 0.49833666001330673
      },
      {
        "accuracy": 0.6440452428476381,
        "f1": 0.5993731300118526,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.5993731300118526,
        "precision": 0.5824726208957746,
        "recall": 0.6440452428476381
      },
      {
        "accuracy": 0.26081170991350633,
        "f1": 0.2206544582792088,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.2206544582792088,
        "precision": 0.20649549866116731,
        "recall": 0.26081170991350633
      },
      {
        "accuracy": 0.5029940119760479,
        "f1": 0.4566666446847262,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.4566666446847262,
        "precision": 0.43882743430148613,
        "recall": 0.5029940119760479
      },
      {
        "accuracy": 0.44510978043912175,
        "f1": 0.393313421257533,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.393313421257533,
        "precision": 0.3731233540614778,
        "recall": 0.44510978043912175
      },
      {
        "accuracy": 0.5854956753160346,
        "f1": 0.5352892579439485,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.5352892579439485,
        "precision": 0.5155659580310279,
        "recall": 0.5854956753160346
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0018548724364203378,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0018548724364203378,
        "precision": 0.0014060813812546494,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.6174318030605456,
        "f1": 0.5696347232275375,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.5696347232275375,
        "precision": 0.551111005502223,
        "recall": 0.6174318030605456
      },
      {
        "accuracy": 0.3872255489021956,
        "f1": 0.3347859835883788,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.3347859835883788,
        "precision": 0.31565621301150243,
        "recall": 0.3872255489021956
      },
      {
        "accuracy": 0.4597471723220226,
        "f1": 0.40472837393995076,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.40472837393995076,
        "precision": 0.3839638423969762,
        "recall": 0.4597471723220226
      },
      {
        "accuracy": 0.5861610113107119,
        "f1": 0.5354973554574353,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.5354973554574353,
        "precision": 0.5156234742562088,
        "recall": 0.5861610113107119
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0031713401936077153,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0031713401936077153,
        "precision": 0.0024906509990207477,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.4031936127744511,
        "f1": 0.35374583278774896,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.35374583278774896,
        "precision": 0.33564854418147827,
        "recall": 0.4031936127744511
      },
      {
        "accuracy": 0.5116433799068529,
        "f1": 0.4515513945653666,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.4515513945653666,
        "precision": 0.4285690523714476,
        "recall": 0.5116433799068529
      },
      {
        "accuracy": 0.5542248835662009,
        "f1": 0.4944840477774609,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.4944840477774609,
        "precision": 0.47103729049836834,
        "recall": 0.5542248835662009
      },
      {
        "accuracy": 0.5695276114437791,
        "f1": 0.5184741295519738,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.5184741295519738,
        "precision": 0.4985457656116339,
        "recall": 0.5695276114437791
      },
      {
        "accuracy": 0.3040585495675316,
        "f1": 0.25987265235610646,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.25987265235610646,
        "precision": 0.24429735880255896,
        "recall": 0.3040585495675316
      },
      {
        "accuracy": 0.3685961410512309,
        "f1": 0.3164816858679134,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.3164816858679134,
        "precision": 0.2987151633206086,
        "recall": 0.3685961410512309
      },
      {
        "accuracy": 0.1823020625415835,
        "f1": 0.15212450556761933,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.15212450556761933,
        "precision": 0.14208648350071384,
        "recall": 0.1823020625415835
      },
      {
        "accuracy": 0.36327345309381237,
        "f1": 0.3192805562662198,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3192805562662198,
        "precision": 0.3033107066290699,
        "recall": 0.36327345309381237
      },
      {
        "accuracy": 0.3985362608117099,
        "f1": 0.34317985419267844,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.34317985419267844,
        "precision": 0.32467458915396374,
        "recall": 0.3985362608117099
      },
      {
        "accuracy": 0.28077178975382566,
        "f1": 0.23601616712062484,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.23601616712062484,
        "precision": 0.22037394910070607,
        "recall": 0.28077178975382566
      },
      {
        "accuracy": 0.2554890219560878,
        "f1": 0.2060580955583005,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.2060580955583005,
        "precision": 0.1896874517882502,
        "recall": 0.2554890219560878
      },
      {
        "accuracy": 0.4091816367265469,
        "f1": 0.3553594736619991,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.3553594736619991,
        "precision": 0.33798477895284285,
        "recall": 0.4091816367265469
      },
      {
        "accuracy": 0.27811044577511645,
        "f1": 0.2348547203777919,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.2348547203777919,
        "precision": 0.21957584100504143,
        "recall": 0.27811044577511645
      },
      {
        "accuracy": 0.3466400532268796,
        "f1": 0.3066461391049995,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.3066461391049995,
        "precision": 0.2928317394884261,
        "recall": 0.3466400532268796
      },
      {
        "accuracy": 0.20958083832335328,
        "f1": 0.1695402446555313,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.1695402446555313,
        "precision": 0.15682161806160946,
        "recall": 0.20958083832335328
      },
      {
        "accuracy": 0.2994011976047904,
        "f1": 0.2525637577101213,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.2525637577101213,
        "precision": 0.2365966073550904,
        "recall": 0.2994011976047904
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0015942717739124924,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0015942717739124924,
        "precision": 0.0010123337254788639,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.36194278110445777,
        "f1": 0.3146414792857202,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3146414792857202,
        "precision": 0.298569912580697,
        "recall": 0.36194278110445777
      },
      {
        "accuracy": 0.18695941450432468,
        "f1": 0.1490305824733743,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.1490305824733743,
        "precision": 0.13689759268601584,
        "recall": 0.18695941450432468
      },
      {
        "accuracy": 0.26081170991350633,
        "f1": 0.2158280264867091,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.2158280264867091,
        "precision": 0.20099431506617133,
        "recall": 0.26081170991350633
      },
      {
        "accuracy": 0.3193612774451098,
        "f1": 0.26867617117118114,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.26867617117118114,
        "precision": 0.25273464656524625,
        "recall": 0.3193612774451098
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.005667368965772159,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.005667368965772159,
        "precision": 0.004657883389469454,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.3373253493013972,
        "f1": 0.28758231492762426,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.28758231492762426,
        "precision": 0.2704841879492578,
        "recall": 0.3373253493013972
      },
      {
        "accuracy": 0.21290751829673984,
        "f1": 0.17017697432945367,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.17017697432945367,
        "precision": 0.15614760176412734,
        "recall": 0.21290751829673984
      },
      {
        "accuracy": 0.25349301397205587,
        "f1": 0.20771083841784543,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.20771083841784543,
        "precision": 0.19171880328977894,
        "recall": 0.25349301397205587
      },
      {
        "accuracy": 0.4916833000665336,
        "f1": 0.4393297247588665,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.4393297247588665,
        "precision": 0.41985461311808614,
        "recall": 0.4916833000665336
      },
      {
        "accuracy": 0.6200931470392548,
        "f1": 0.562922351545106,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.562922351545106,
        "precision": 0.5406567816747457,
        "recall": 0.6200931470392548
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6914061247394581,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6914061247394581,
        "precision": 0.6749648850447253,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.2328675981370592,
        "f1": 0.1967527106813751,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1967527106813751,
        "precision": 0.18501186659869293,
        "recall": 0.2328675981370592
      },
      {
        "accuracy": 0.6979374584165003,
        "f1": 0.6438134313383814,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6438134313383814,
        "precision": 0.6218626239584323,
        "recall": 0.6979374584165003
      },
      {
        "accuracy": 0.8183632734530938,
        "f1": 0.7836079164422477,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7836079164422477,
        "precision": 0.7702209577958081,
        "recall": 0.8183632734530938
      },
      {
        "accuracy": 0.5136393878908849,
        "f1": 0.45850341164712416,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.45850341164712416,
        "precision": 0.43801223784677923,
        "recall": 0.5136393878908849
      },
      {
        "accuracy": 0.5588822355289421,
        "f1": 0.5056378492506236,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5056378492506236,
        "precision": 0.485595171074213,
        "recall": 0.5588822355289421
      },
      {
        "accuracy": 0.782435129740519,
        "f1": 0.7445051695550697,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7445051695550697,
        "precision": 0.7295343176081699,
        "recall": 0.782435129740519
      },
      {
        "accuracy": 0.5069860279441117,
        "f1": 0.45498526756011787,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.45498526756011787,
        "precision": 0.43656364519637975,
        "recall": 0.5069860279441117
      },
      {
        "accuracy": 0.364604125083167,
        "f1": 0.3110361486415772,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3110361486415772,
        "precision": 0.29308289385634695,
        "recall": 0.364604125083167
      },
      {
        "accuracy": 0.35994677312042583,
        "f1": 0.30507929692055713,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.30507929692055713,
        "precision": 0.2865220976997424,
        "recall": 0.35994677312042583
      },
      {
        "accuracy": 0.6786427145708582,
        "f1": 0.6256766077125359,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6256766077125359,
        "precision": 0.6050029570488652,
        "recall": 0.6786427145708582
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0006721818232571602,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0006721818232571602,
        "precision": 0.0004017295634062101,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.782435129740519,
        "f1": 0.7428529665056611,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7428529665056611,
        "precision": 0.7266086873871305,
        "recall": 0.782435129740519
      },
      {
        "accuracy": 0.4091816367265469,
        "f1": 0.34951643553850903,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.34951643553850903,
        "precision": 0.32865301102873945,
        "recall": 0.4091816367265469
      },
      {
        "accuracy": 0.5302727877578177,
        "f1": 0.4685707949181003,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4685707949181003,
        "precision": 0.44554282488414226,
        "recall": 0.5302727877578177
      },
      {
        "accuracy": 0.6899534264803726,
        "f1": 0.6402977594594361,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.6402977594594361,
        "precision": 0.6205792119464774,
        "recall": 0.6899534264803726
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0016689206916595276,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0016689206916595276,
        "precision": 0.0010593939292062942,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.5369261477045908,
        "f1": 0.48410054867140695,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.48410054867140695,
        "precision": 0.4637870243159664,
        "recall": 0.5369261477045908
      },
      {
        "accuracy": 0.42248835662009315,
        "f1": 0.36547813463981127,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.36547813463981127,
        "precision": 0.3450931064204517,
        "recall": 0.42248835662009315
      },
      {
        "accuracy": 0.38855622089155023,
        "f1": 0.3425142142391853,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3425142142391853,
        "precision": 0.3252275465349318,
        "recall": 0.38855622089155023
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.6703798899407681,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6703798899407681,
        "precision": 0.6510439438583151,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.38922155688622756,
        "f1": 0.3360634141014556,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.3360634141014556,
        "precision": 0.3173943866808138,
        "recall": 0.38922155688622756
      },
      {
        "accuracy": 0.49434464404524286,
        "f1": 0.4327652055196965,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.4327652055196965,
        "precision": 0.41030029887315317,
        "recall": 0.49434464404524286
      },
      {
        "accuracy": 0.18629407850964738,
        "f1": 0.156482753588542,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.156482753588542,
        "precision": 0.14713107055089755,
        "recall": 0.18629407850964738
      },
      {
        "accuracy": 0.38988689288090483,
        "f1": 0.33623802456137786,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.33623802456137786,
        "precision": 0.3174804551551058,
        "recall": 0.38988689288090483
      },
      {
        "accuracy": 0.5469061876247505,
        "f1": 0.49128014237207607,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.49128014237207607,
        "precision": 0.47087951810712175,
        "recall": 0.5469061876247505
      },
      {
        "accuracy": 0.30206254158349966,
        "f1": 0.2588458829042878,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.2588458829042878,
        "precision": 0.24373168784346425,
        "recall": 0.30206254158349966
      },
      {
        "accuracy": 0.44843646041250834,
        "f1": 0.39635121291807923,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.39635121291807923,
        "precision": 0.37712095261701933,
        "recall": 0.44843646041250834
      },
      {
        "accuracy": 0.5355954757152362,
        "f1": 0.48103982031127734,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.48103982031127734,
        "precision": 0.4605997861956533,
        "recall": 0.5355954757152362
      },
      {
        "accuracy": 0.46107784431137727,
        "f1": 0.4055233448447021,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.4055233448447021,
        "precision": 0.3847519487240046,
        "recall": 0.46107784431137727
      },
      {
        "accuracy": 0.2055888223552894,
        "f1": 0.17231691442681227,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.17231691442681227,
        "precision": 0.1614825204865712,
        "recall": 0.2055888223552894
      },
      {
        "accuracy": 0.3666001330671989,
        "f1": 0.32012826999520283,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.32012826999520283,
        "precision": 0.30335798103683387,
        "recall": 0.3666001330671989
      },
      {
        "accuracy": 0.42980705256154356,
        "f1": 0.37840891512959146,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.37840891512959146,
        "precision": 0.3599366322669716,
        "recall": 0.42980705256154356
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004523700687894041,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.004523700687894041,
        "precision": 0.0040387982278395,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.46041250831669994,
        "f1": 0.40256291169464814,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.40256291169464814,
        "precision": 0.3819932826761275,
        "recall": 0.46041250831669994
      },
      {
        "accuracy": 0.3992015968063872,
        "f1": 0.34637291074416815,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.34637291074416815,
        "precision": 0.32658890722469447,
        "recall": 0.3992015968063872
      },
      {
        "accuracy": 0.3985362608117099,
        "f1": 0.3444278882203034,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.3444278882203034,
        "precision": 0.3239550240548244,
        "recall": 0.3985362608117099
      },
      {
        "accuracy": 0.44510978043912175,
        "f1": 0.38965778436836324,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.38965778436836324,
        "precision": 0.36973086793446075,
        "recall": 0.44510978043912175
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.003585921228436532,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.003585921228436532,
        "precision": 0.002796022390167433,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.3107119095143047,
        "f1": 0.27145713383238335,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.27145713383238335,
        "precision": 0.2569754670553074,
        "recall": 0.3107119095143047
      },
      {
        "accuracy": 0.4504324683965403,
        "f1": 0.3914971206329666,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.3914971206329666,
        "precision": 0.370028665612498,
        "recall": 0.4504324683965403
      },
      {
        "accuracy": 0.44045242847638055,
        "f1": 0.38745199872944386,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.38745199872944386,
        "precision": 0.36766859037318117,
        "recall": 0.44045242847638055
      },
      {
        "accuracy": 0.4743845642049235,
        "f1": 0.4183494457630396,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.4183494457630396,
        "precision": 0.39866663852114004,
        "recall": 0.4743845642049235
      },
      {
        "accuracy": 0.6260811709913506,
        "f1": 0.5746459462028324,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5746459462028324,
        "precision": 0.5537483474609224,
        "recall": 0.6260811709913506
      },
      {
        "accuracy": 0.7485029940119761,
        "f1": 0.7053612352015546,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7053612352015546,
        "precision": 0.6876551130543147,
        "recall": 0.7485029940119761
      },
      {
        "accuracy": 0.20891550232867598,
        "f1": 0.17730865330078666,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.17730865330078666,
        "precision": 0.1665511569453685,
        "recall": 0.20891550232867598
      },
      {
        "accuracy": 0.624750499001996,
        "f1": 0.5672079602219323,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5672079602219323,
        "precision": 0.5452056205050217,
        "recall": 0.624750499001996
      },
      {
        "accuracy": 0.8150365934797072,
        "f1": 0.7814424061929052,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7814424061929052,
        "precision": 0.7676554298809788,
        "recall": 0.8150365934797072
      },
      {
        "accuracy": 0.6387225548902196,
        "f1": 0.5812369969056596,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5812369969056596,
        "precision": 0.5584689434831256,
        "recall": 0.6387225548902196
      },
      {
        "accuracy": 0.6520292747837658,
        "f1": 0.6007292293719438,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6007292293719438,
        "precision": 0.5802181351582548,
        "recall": 0.6520292747837658
      },
      {
        "accuracy": 0.782435129740519,
        "f1": 0.7436824763172069,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7436824763172069,
        "precision": 0.7278506479105282,
        "recall": 0.782435129740519
      },
      {
        "accuracy": 0.5728542914171657,
        "f1": 0.516789749025278,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.516789749025278,
        "precision": 0.49579597418918775,
        "recall": 0.5728542914171657
      },
      {
        "accuracy": 0.3047238855622089,
        "f1": 0.25197476619632303,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.25197476619632303,
        "precision": 0.2334300368565172,
        "recall": 0.3047238855622089
      },
      {
        "accuracy": 0.667332002661344,
        "f1": 0.6215410928983782,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6215410928983782,
        "precision": 0.6030642012677941,
        "recall": 0.667332002661344
      },
      {
        "accuracy": 0.4045242847638057,
        "f1": 0.34944530408602265,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.34944530408602265,
        "precision": 0.32832932019558764,
        "recall": 0.4045242847638057
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002541867837953272,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002541867837953272,
        "precision": 0.0022969366624162294,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.7465069860279441,
        "f1": 0.7026365258900189,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7026365258900189,
        "precision": 0.6850468615438674,
        "recall": 0.7465069860279441
      },
      {
        "accuracy": 0.4431137724550898,
        "f1": 0.3900140851238655,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3900140851238655,
        "precision": 0.3710380825650287,
        "recall": 0.4431137724550898
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.46841713398599627,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.46841713398599627,
        "precision": 0.4443100571344084,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.7092481703260146,
        "f1": 0.6647546177486298,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.6647546177486298,
        "precision": 0.6468586636251307,
        "recall": 0.7092481703260146
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0033895954093509646,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0033895954093509646,
        "precision": 0.0028547266384092726,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.4963406520292748,
        "f1": 0.4391587676018813,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4391587676018813,
        "precision": 0.41726575708611635,
        "recall": 0.4963406520292748
      },
      {
        "accuracy": 0.4863606121091151,
        "f1": 0.4279536645804111,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4279536645804111,
        "precision": 0.40604166596887037,
        "recall": 0.4863606121091151
      },
      {
        "accuracy": 0.4251497005988024,
        "f1": 0.36747546827387145,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.36747546827387145,
        "precision": 0.3470516638680311,
        "recall": 0.4251497005988024
      },
      {
        "accuracy": 0.7119095143047239,
        "f1": 0.6655144736981065,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6655144736981065,
        "precision": 0.6466844089598581,
        "recall": 0.7119095143047239
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0016849097823614678,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0016849097823614678,
        "precision": 0.0012607717214021847,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0012975362553983092,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0012975362553983092,
        "precision": 0.0010256243756534768,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0038031887787548877,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0038031887787548877,
        "precision": 0.0031342638377208076,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0019584157138835016,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0019584157138835016,
        "precision": 0.001521224311467255,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0016516751263080107,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0016516751263080107,
        "precision": 0.0012875747337302566,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.002590263498811529,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.002590263498811529,
        "precision": 0.0020715066219304163,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0018685573701302891,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0018685573701302891,
        "precision": 0.0017119491480628362,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0023084059025265564,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0023084059025265564,
        "precision": 0.001913816515430913,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0048658093704842306,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0048658093704842306,
        "precision": 0.004298820074101809,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.004120252499580799,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.004120252499580799,
        "precision": 0.003514591846443957,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0017228464493026278,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0017228464493026278,
        "precision": 0.001556643009133569,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0036400760659811597,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0036400760659811597,
        "precision": 0.0032604709648851454,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0015855710209565427,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0015855710209565427,
        "precision": 0.0012602051756602623,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0038564977991601525,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0038564977991601525,
        "precision": 0.003421462481247687,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0023993175205050347,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0023993175205050347,
        "precision": 0.0017467008591254187,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0032268795741849637,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0032268795741849637,
        "precision": 0.0025476727536023576,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0028309902561399567,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0028309902561399567,
        "precision": 0.0022959519140435918,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0064113955727437555,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.0064113955727437555,
        "precision": 0.0053092990608422826,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0019879423493248476,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0019879423493248476,
        "precision": 0.0017241153569701295,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002260361241493024,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.002260361241493024,
        "precision": 0.001678790480963558,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002946060585620176,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.002946060585620176,
        "precision": 0.00222710966305744,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003064615159391125,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.003064615159391125,
        "precision": 0.0026974952013763278,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.7039254823685961,
        "f1": 0.6560877911177312,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6560877911177312,
        "precision": 0.6366441719735133,
        "recall": 0.7039254823685961
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.7789817191014796,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7789817191014796,
        "precision": 0.7632180084275894,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.23020625415834997,
        "f1": 0.1914991368026474,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1914991368026474,
        "precision": 0.17887441807102483,
        "recall": 0.23020625415834997
      },
      {
        "accuracy": 0.7059214903526281,
        "f1": 0.6558919678680157,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6558919678680157,
        "precision": 0.6356931639366769,
        "recall": 0.7059214903526281
      },
      {
        "accuracy": 0.8915502328675982,
        "f1": 0.8660805373380224,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8660805373380224,
        "precision": 0.8550232867598136,
        "recall": 0.8915502328675982
      },
      {
        "accuracy": 0.520292747837658,
        "f1": 0.46572995883786067,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.46572995883786067,
        "precision": 0.4462132828121439,
        "recall": 0.520292747837658
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5765981745023661,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5765981745023661,
        "precision": 0.5574097836073884,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.867598137059215,
        "f1": 0.8388830804000464,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8388830804000464,
        "precision": 0.8270292747837659,
        "recall": 0.867598137059215
      },
      {
        "accuracy": 0.5894876912840985,
        "f1": 0.540578996666821,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.540578996666821,
        "precision": 0.5219756254686394,
        "recall": 0.5894876912840985
      },
      {
        "accuracy": 0.34331337325349304,
        "f1": 0.29014774683437355,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.29014774683437355,
        "precision": 0.27179816930315936,
        "recall": 0.34331337325349304
      },
      {
        "accuracy": 0.7531603459747173,
        "f1": 0.7157531977891259,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7157531977891259,
        "precision": 0.7015774921463545,
        "recall": 0.7531603459747173
      },
      {
        "accuracy": 0.4424484364604125,
        "f1": 0.3829477623573643,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3829477623573643,
        "precision": 0.3608090696913052,
        "recall": 0.4424484364604125
      },
      {
        "accuracy": 0.7478376580172987,
        "f1": 0.703186268156328,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.703186268156328,
        "precision": 0.684892120520863,
        "recall": 0.7478376580172987
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0010420031937100104,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0010420031937100104,
        "precision": 0.0006373877959563213,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.49567531603459747,
        "f1": 0.43475655711184646,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.43475655711184646,
        "precision": 0.41350155167520436,
        "recall": 0.49567531603459747
      },
      {
        "accuracy": 0.6280771789753826,
        "f1": 0.5692118888725676,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5692118888725676,
        "precision": 0.546521426012444,
        "recall": 0.6280771789753826
      },
      {
        "accuracy": 0.7864271457085829,
        "f1": 0.7478091436175268,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7478091436175268,
        "precision": 0.7316050438804929,
        "recall": 0.7864271457085829
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.00277440017454603,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00277440017454603,
        "precision": 0.0020705176393799145,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.47821021294075183,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.47821021294075183,
        "precision": 0.4577202331194347,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.5382568196939455,
        "f1": 0.47772045172244776,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.47772045172244776,
        "precision": 0.4552353446066021,
        "recall": 0.5382568196939455
      },
      {
        "accuracy": 0.46041250831669994,
        "f1": 0.4060214322374214,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.4060214322374214,
        "precision": 0.3856287665169901,
        "recall": 0.46041250831669994
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7876680981471401,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7876680981471401,
        "precision": 0.7734150746126793,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.490352628077179,
        "f1": 0.4295361657637107,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.4295361657637107,
        "precision": 0.4071975097424199,
        "recall": 0.490352628077179
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.4951547122205805,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.4951547122205805,
        "precision": 0.4723220226214238,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.18163672654690619,
        "f1": 0.15219219917318,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.15219219917318,
        "precision": 0.14302886069353135,
        "recall": 0.18163672654690619
      },
      {
        "accuracy": 0.4218230206254158,
        "f1": 0.35623255653195773,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.35623255653195773,
        "precision": 0.33339347316393225,
        "recall": 0.4218230206254158
      },
      {
        "accuracy": 0.499001996007984,
        "f1": 0.43172931710855855,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.43172931710855855,
        "precision": 0.4084629996306643,
        "recall": 0.499001996007984
      },
      {
        "accuracy": 0.30671989354624085,
        "f1": 0.2542699063598441,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.2542699063598441,
        "precision": 0.23679218042990496,
        "recall": 0.30671989354624085
      },
      {
        "accuracy": 0.5163007318695941,
        "f1": 0.45439747286054666,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.45439747286054666,
        "precision": 0.4310817758422549,
        "recall": 0.5163007318695941
      },
      {
        "accuracy": 0.5548902195608783,
        "f1": 0.49416515693960805,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.49416515693960805,
        "precision": 0.471098807675654,
        "recall": 0.5548902195608783
      },
      {
        "accuracy": 0.3819028609447771,
        "f1": 0.32399694635223575,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.32399694635223575,
        "precision": 0.3031727550190624,
        "recall": 0.3819028609447771
      },
      {
        "accuracy": 0.18097139055222888,
        "f1": 0.14594258234182284,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.14594258234182284,
        "precision": 0.13515941440093135,
        "recall": 0.18097139055222888
      },
      {
        "accuracy": 0.38456420492348636,
        "f1": 0.33106960802222457,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.33106960802222457,
        "precision": 0.31239946753918807,
        "recall": 0.38456420492348636
      },
      {
        "accuracy": 0.3865602129075183,
        "f1": 0.3281986772006732,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.3281986772006732,
        "precision": 0.30595343704126143,
        "recall": 0.3865602129075183
      },
      {
        "accuracy": 0.4397870924817033,
        "f1": 0.3814539419329839,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.3814539419329839,
        "precision": 0.3602865697177075,
        "recall": 0.4397870924817033
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0028877203469195954,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0028877203469195954,
        "precision": 0.0021426540046908,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.5129740518962076,
        "f1": 0.4486994265437379,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.4486994265437379,
        "precision": 0.4236505824330176,
        "recall": 0.5129740518962076
      },
      {
        "accuracy": 0.5129740518962076,
        "f1": 0.4455543938577871,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.4455543938577871,
        "precision": 0.4188321769160092,
        "recall": 0.5129740518962076
      },
      {
        "accuracy": 0.4038589487691284,
        "f1": 0.3457684173436878,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.3457684173436878,
        "precision": 0.32503087398296976,
        "recall": 0.4038589487691284
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0039037433303699535,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0039037433303699535,
        "precision": 0.0030445921449628317,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.3040585495675316,
        "f1": 0.25351497582036503,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.25351497582036503,
        "precision": 0.23654837991165334,
        "recall": 0.3040585495675316
      },
      {
        "accuracy": 0.3439787092481703,
        "f1": 0.2871057308183057,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.2871057308183057,
        "precision": 0.2670703160224118,
        "recall": 0.3439787092481703
      },
      {
        "accuracy": 0.34930139720558884,
        "f1": 0.2957863776168344,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.2957863776168344,
        "precision": 0.27703154297465676,
        "recall": 0.34930139720558884
      },
      {
        "accuracy": 0.4637391882900865,
        "f1": 0.3998533758954094,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.3998533758954094,
        "precision": 0.37764885092729406,
        "recall": 0.4637391882900865
      },
      {
        "accuracy": 0.5063206919494344,
        "f1": 0.45325486592951664,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.45325486592951664,
        "precision": 0.43235228888627975,
        "recall": 0.5063206919494344
      },
      {
        "accuracy": 0.614105123087159,
        "f1": 0.5558187857090052,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.5558187857090052,
        "precision": 0.5334410543991382,
        "recall": 0.614105123087159
      },
      {
        "accuracy": 0.17431803060545575,
        "f1": 0.15039555328976484,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.15039555328976484,
        "precision": 0.1424558530845956,
        "recall": 0.17431803060545575
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5534909017942949,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.5534909017942949,
        "precision": 0.5314881060390042,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.6560212907518297,
        "f1": 0.60251930002429,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.60251930002429,
        "precision": 0.5826324404638366,
        "recall": 0.6560212907518297
      },
      {
        "accuracy": 0.34930139720558884,
        "f1": 0.301991750394944,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.301991750394944,
        "precision": 0.2852730953205443,
        "recall": 0.34930139720558884
      },
      {
        "accuracy": 0.6433799068529608,
        "f1": 0.5857059330113222,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.5857059330113222,
        "precision": 0.5626054362581309,
        "recall": 0.6433799068529608
      },
      {
        "accuracy": 0.6999334664005322,
        "f1": 0.6433165415201344,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.6433165415201344,
        "precision": 0.6209501631657319,
        "recall": 0.6999334664005322
      },
      {
        "accuracy": 0.42714570858283435,
        "f1": 0.37216788164891956,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.37216788164891956,
        "precision": 0.35190228009589286,
        "recall": 0.42714570858283435
      },
      {
        "accuracy": 0.26214238190286093,
        "f1": 0.21445449279780618,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.21445449279780618,
        "precision": 0.19877995001024806,
        "recall": 0.26214238190286093
      },
      {
        "accuracy": 0.4717232202262142,
        "f1": 0.418945749478801,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.418945749478801,
        "precision": 0.39999422625092335,
        "recall": 0.4717232202262142
      },
      {
        "accuracy": 0.37192282102461743,
        "f1": 0.31560802857620984,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.31560802857620984,
        "precision": 0.2949582498077613,
        "recall": 0.37192282102461743
      },
      {
        "accuracy": 0.5515635395874917,
        "f1": 0.4904139292362845,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.4904139292362845,
        "precision": 0.4671067917075901,
        "recall": 0.5515635395874917
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002454941668619576,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.002454941668619576,
        "precision": 0.001995545168610802,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.6387225548902196,
        "f1": 0.5865142730412192,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.5865142730412192,
        "precision": 0.5664311182275253,
        "recall": 0.6387225548902196
      },
      {
        "accuracy": 0.48502994011976047,
        "f1": 0.42753862165039813,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.42753862165039813,
        "precision": 0.4067146131018386,
        "recall": 0.48502994011976047
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.4681858172876137,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.4681858172876137,
        "precision": 0.44446532620185314,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.002574530708983453,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.002574530708983453,
        "precision": 0.0018762137321072085,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.41783100465735196,
        "f1": 0.3650331611908458,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.3650331611908458,
        "precision": 0.3458371690407619,
        "recall": 0.41783100465735196
      },
      {
        "accuracy": 0.40585495675316036,
        "f1": 0.3476548734033765,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.3476548734033765,
        "precision": 0.3267288796201559,
        "recall": 0.40585495675316036
      },
      {
        "accuracy": 0.3865602129075183,
        "f1": 0.3337954202225659,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.3337954202225659,
        "precision": 0.31556545398860764,
        "recall": 0.3865602129075183
      },
      {
        "accuracy": 0.6580172987358616,
        "f1": 0.5977606115330666,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.5977606115330666,
        "precision": 0.5749366346671736,
        "recall": 0.6580172987358616
      },
      {
        "accuracy": 0.6473719228210246,
        "f1": 0.5916249511558893,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5916249511558893,
        "precision": 0.5695878085099643,
        "recall": 0.6473719228210246
      },
      {
        "accuracy": 0.7724550898203593,
        "f1": 0.7336823707083188,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7336823707083188,
        "precision": 0.7179205081899692,
        "recall": 0.7724550898203593
      },
      {
        "accuracy": 0.18829008649367932,
        "f1": 0.15487408097188535,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.15487408097188535,
        "precision": 0.14327520204100377,
        "recall": 0.18829008649367932
      },
      {
        "accuracy": 0.6014637391882901,
        "f1": 0.539283510335524,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.539283510335524,
        "precision": 0.5152505834891065,
        "recall": 0.6014637391882901
      },
      {
        "accuracy": 0.8822355289421158,
        "f1": 0.8571132866542049,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8571132866542049,
        "precision": 0.8467453980927034,
        "recall": 0.8822355289421158
      },
      {
        "accuracy": 0.4863606121091151,
        "f1": 0.4283922269635055,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4283922269635055,
        "precision": 0.4071534254168985,
        "recall": 0.4863606121091151
      },
      {
        "accuracy": 0.5801729873586161,
        "f1": 0.521963388674085,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.521963388674085,
        "precision": 0.49974118833605746,
        "recall": 0.5801729873586161
      },
      {
        "accuracy": 0.8110445775116434,
        "f1": 0.7765854534317609,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7765854534317609,
        "precision": 0.7627261350315242,
        "recall": 0.8110445775116434
      },
      {
        "accuracy": 0.5748502994011976,
        "f1": 0.5188732019071339,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5188732019071339,
        "precision": 0.49782275798070297,
        "recall": 0.5748502994011976
      },
      {
        "accuracy": 0.3100465735196274,
        "f1": 0.2607945367111246,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2607945367111246,
        "precision": 0.24498224656035972,
        "recall": 0.3100465735196274
      },
      {
        "accuracy": 0.6660013306719893,
        "f1": 0.6203635752721791,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6203635752721791,
        "precision": 0.6030222863556197,
        "recall": 0.6660013306719893
      },
      {
        "accuracy": 0.4258150365934797,
        "f1": 0.36715907234282247,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.36715907234282247,
        "precision": 0.3452088475134489,
        "recall": 0.4258150365934797
      },
      {
        "accuracy": 0.7145708582834331,
        "f1": 0.6703439681483593,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6703439681483593,
        "precision": 0.652613027912429,
        "recall": 0.7145708582834331
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.002112568530609641,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002112568530609641,
        "precision": 0.0018080948753953889,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.7764471057884231,
        "f1": 0.7384399698770956,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7384399698770956,
        "precision": 0.7226641954186863,
        "recall": 0.7764471057884231
      },
      {
        "accuracy": 0.4204923486360612,
        "f1": 0.36333369447141894,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.36333369447141894,
        "precision": 0.3439195262673307,
        "recall": 0.4204923486360612
      },
      {
        "accuracy": 0.5249500998003992,
        "f1": 0.4685133340821963,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4685133340821963,
        "precision": 0.4487656961209855,
        "recall": 0.5249500998003992
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001533445572426434,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001533445572426434,
        "precision": 0.0010292546220689932,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.47238855622089154,
        "f1": 0.4139366866853071,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4139366866853071,
        "precision": 0.3930408231739779,
        "recall": 0.47238855622089154
      },
      {
        "accuracy": 0.5316034597471723,
        "f1": 0.4744843646041251,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4744843646041251,
        "precision": 0.4528165484253308,
        "recall": 0.5316034597471723
      },
      {
        "accuracy": 0.4364604125083167,
        "f1": 0.3827228104299349,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3827228104299349,
        "precision": 0.3642483766456409,
        "recall": 0.4364604125083167
      },
      {
        "accuracy": 0.7578176979374585,
        "f1": 0.7147287435710589,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7147287435710589,
        "precision": 0.6973243988214046,
        "recall": 0.7578176979374585
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0023154577425213564,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0023154577425213564,
        "precision": 0.001974987641232994,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0021461455212484666,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0021461455212484666,
        "precision": 0.0017934309755401605,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.003958819993962823,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.003958819993962823,
        "precision": 0.0032757888858928677,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0017917772984063596,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0017917772984063596,
        "precision": 0.0014148569456373845,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0023329926208738062,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0023329926208738062,
        "precision": 0.001793752808789575,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0029649263857758406,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0029649263857758406,
        "precision": 0.0024620227332449946,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0041561399255478785,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0041561399255478785,
        "precision": 0.003791219609582883,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00138679366122761,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.00138679366122761,
        "precision": 0.0011072812966937372,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0018302241364446996,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0018302241364446996,
        "precision": 0.001427259441231497,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0037589723236942122,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0037589723236942122,
        "precision": 0.0033434620511504504,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.004542851753617102,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.004542851753617102,
        "precision": 0.0041033266431307214,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.001185213324393541,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.001185213324393541,
        "precision": 0.0007601966944586597,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0032396037592502193,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0032396037592502193,
        "precision": 0.002602724905541073,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.009235680044063277,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.009235680044063277,
        "precision": 0.007512414981686963,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0021093287102445257,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0021093287102445257,
        "precision": 0.0016023936089121533,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0018852589994194256,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0018852589994194256,
        "precision": 0.0014741866773868345,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.005696955236507564,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.005696955236507564,
        "precision": 0.005069906262258401,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0021173280215447607,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0021173280215447607,
        "precision": 0.0016309517026950086,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0022410557259449648,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0022410557259449648,
        "precision": 0.0019262467873262467,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0014141990189894382,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0014141990189894382,
        "precision": 0.0009050424495396619,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0020714179085165097,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0020714179085165097,
        "precision": 0.0018208266859351787,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002387213848360464,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.002387213848360464,
        "precision": 0.0018138927497860062,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.4244843646041251,
        "f1": 0.37464010448042384,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.37464010448042384,
        "precision": 0.35715135385794067,
        "recall": 0.4244843646041251
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.47583124349591416,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.47583124349591416,
        "precision": 0.45640252222088545,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.24085163007318697,
        "f1": 0.2101141632079756,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2101141632079756,
        "precision": 0.19907168672764414,
        "recall": 0.24085163007318697
      },
      {
        "accuracy": 0.5608782435129741,
        "f1": 0.5077531952781454,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5077531952781454,
        "precision": 0.4885007356065241,
        "recall": 0.5608782435129741
      },
      {
        "accuracy": 0.5874916833000665,
        "f1": 0.5399698363320139,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5399698363320139,
        "precision": 0.5231782263718391,
        "recall": 0.5874916833000665
      },
      {
        "accuracy": 0.40652029274783763,
        "f1": 0.3597205903277969,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3597205903277969,
        "precision": 0.3434586715994489,
        "recall": 0.40652029274783763
      },
      {
        "accuracy": 0.41583499667332,
        "f1": 0.36618489812102584,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.36618489812102584,
        "precision": 0.3482774291498948,
        "recall": 0.41583499667332
      },
      {
        "accuracy": 0.6240851630073186,
        "f1": 0.5769370497913412,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5769370497913412,
        "precision": 0.5589957650835894,
        "recall": 0.6240851630073186
      },
      {
        "accuracy": 0.3772455089820359,
        "f1": 0.33615678695519013,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.33615678695519013,
        "precision": 0.32010661217248043,
        "recall": 0.3772455089820359
      },
      {
        "accuracy": 0.3260146373918829,
        "f1": 0.2769572114881496,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2769572114881496,
        "precision": 0.2601048325441644,
        "recall": 0.3260146373918829
      },
      {
        "accuracy": 0.5182967398536261,
        "f1": 0.4713612819688047,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4713612819688047,
        "precision": 0.454469609016784,
        "recall": 0.5182967398536261
      },
      {
        "accuracy": 0.29740518962075846,
        "f1": 0.2536426454780351,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2536426454780351,
        "precision": 0.23879251616277564,
        "recall": 0.29740518962075846
      },
      {
        "accuracy": 0.4870259481037924,
        "f1": 0.4407558742572924,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4407558742572924,
        "precision": 0.4237722560576852,
        "recall": 0.4870259481037924
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0006845248775182012,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0006845248775182012,
        "precision": 0.0003818596781209631,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.4866177124167538,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4866177124167538,
        "precision": 0.47058215957916555,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.2867598137059215,
        "f1": 0.24426140503984814,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.24426140503984814,
        "precision": 0.2304406772224334,
        "recall": 0.2867598137059215
      },
      {
        "accuracy": 0.4038589487691284,
        "f1": 0.3569379759000517,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.3569379759000517,
        "precision": 0.3408683976019893,
        "recall": 0.4038589487691284
      },
      {
        "accuracy": 0.45442448436460414,
        "f1": 0.4047570820650049,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.4047570820650049,
        "precision": 0.3868396804275048,
        "recall": 0.45442448436460414
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0023260668206071516,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0023260668206071516,
        "precision": 0.001794240555523959,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.3226879574184963,
        "f1": 0.27380899576508355,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.27380899576508355,
        "precision": 0.25686462572690116,
        "recall": 0.3226879574184963
      },
      {
        "accuracy": 0.3147039254823686,
        "f1": 0.27979117799477077,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.27979117799477077,
        "precision": 0.2673243460169608,
        "recall": 0.3147039254823686
      },
      {
        "accuracy": 0.5489021956087824,
        "f1": 0.497440950104045,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.497440950104045,
        "precision": 0.47817483204835437,
        "recall": 0.5489021956087824
      },
      {
        "accuracy": 0.4564204923486361,
        "f1": 0.39697578388197147,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.39697578388197147,
        "precision": 0.3751908474463364,
        "recall": 0.4564204923486361
      },
      {
        "accuracy": 0.6094477711244178,
        "f1": 0.5501642218209085,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.5501642218209085,
        "precision": 0.5264101426776078,
        "recall": 0.6094477711244178
      },
      {
        "accuracy": 0.1550232867598137,
        "f1": 0.12686776266459004,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.12686776266459004,
        "precision": 0.11724672348424844,
        "recall": 0.1550232867598137
      },
      {
        "accuracy": 0.4397870924817033,
        "f1": 0.38477528292310487,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.38477528292310487,
        "precision": 0.3647938730523561,
        "recall": 0.4397870924817033
      },
      {
        "accuracy": 0.6786427145708582,
        "f1": 0.6273400769408753,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.6273400769408753,
        "precision": 0.6068220701454233,
        "recall": 0.6786427145708582
      },
      {
        "accuracy": 0.30538922155688625,
        "f1": 0.25640624991922395,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.25640624991922395,
        "precision": 0.2393485970801927,
        "recall": 0.30538922155688625
      },
      {
        "accuracy": 0.4258150365934797,
        "f1": 0.3724133743095819,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.3724133743095819,
        "precision": 0.352012905406119,
        "recall": 0.4258150365934797
      },
      {
        "accuracy": 0.6653359946773121,
        "f1": 0.6152398905891919,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.6152398905891919,
        "precision": 0.5951395743311911,
        "recall": 0.6653359946773121
      },
      {
        "accuracy": 0.5043246839654025,
        "f1": 0.4414493763795161,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.4414493763795161,
        "precision": 0.41845121685441045,
        "recall": 0.5043246839654025
      },
      {
        "accuracy": 0.21490352628077178,
        "f1": 0.175876407373049,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.175876407373049,
        "precision": 0.16318810402848208,
        "recall": 0.21490352628077178
      },
      {
        "accuracy": 0.42381902860944776,
        "f1": 0.37192856691271625,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.37192856691271625,
        "precision": 0.3524455058137693,
        "recall": 0.42381902860944776
      },
      {
        "accuracy": 0.4324683965402528,
        "f1": 0.3725595613819167,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.3725595613819167,
        "precision": 0.3503007213087053,
        "recall": 0.4324683965402528
      },
      {
        "accuracy": 0.48502994011976047,
        "f1": 0.4312542598969744,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.4312542598969744,
        "precision": 0.41103192594915033,
        "recall": 0.48502994011976047
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028964997694205944,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0028964997694205944,
        "precision": 0.00259442721577276,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.5389221556886228,
        "f1": 0.48264996259008236,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.48264996259008236,
        "precision": 0.4614108384538113,
        "recall": 0.5389221556886228
      },
      {
        "accuracy": 0.3359946773120426,
        "f1": 0.28288456756520625,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.28288456756520625,
        "precision": 0.2652203976383204,
        "recall": 0.3359946773120426
      },
      {
        "accuracy": 0.40252827677977376,
        "f1": 0.34747277930910664,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.34747277930910664,
        "precision": 0.32753199709287534,
        "recall": 0.40252827677977376
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.49830053697319165,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.49830053697319165,
        "precision": 0.47711011358715943,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0018401431611852874,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0018401431611852874,
        "precision": 0.001230719917813815,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.3213572854291417,
        "f1": 0.2729460559400679,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.2729460559400679,
        "precision": 0.2556139284682199,
        "recall": 0.3213572854291417
      },
      {
        "accuracy": 0.4171656686626746,
        "f1": 0.356526332025334,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.356526332025334,
        "precision": 0.33513969951095696,
        "recall": 0.4171656686626746
      },
      {
        "accuracy": 0.5861610113107119,
        "f1": 0.5294137074576196,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.5294137074576196,
        "precision": 0.5073073429859857,
        "recall": 0.5861610113107119
      },
      {
        "accuracy": 0.40652029274783763,
        "f1": 0.3608111486354999,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.3608111486354999,
        "precision": 0.344167708538966,
        "recall": 0.40652029274783763
      },
      {
        "accuracy": 0.49700598802395207,
        "f1": 0.4436893408949297,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.4436893408949297,
        "precision": 0.4236645756106834,
        "recall": 0.49700598802395207
      },
      {
        "accuracy": 0.20691949434464404,
        "f1": 0.17059489938437922,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.17059489938437922,
        "precision": 0.15797563861436117,
        "recall": 0.20691949434464404
      },
      {
        "accuracy": 0.4251497005988024,
        "f1": 0.37644284819933527,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.37644284819933527,
        "precision": 0.35860923655334837,
        "recall": 0.4251497005988024
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.48640673476002816,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.48640673476002816,
        "precision": 0.4695863003372698,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.3579507651363939,
        "f1": 0.31028275893545354,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.31028275893545354,
        "precision": 0.2928109629706436,
        "recall": 0.3579507651363939
      },
      {
        "accuracy": 0.4384564204923486,
        "f1": 0.3900802531541054,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.3900802531541054,
        "precision": 0.3719743053575389,
        "recall": 0.4384564204923486
      },
      {
        "accuracy": 0.541583499667332,
        "f1": 0.49407961374029247,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.49407961374029247,
        "precision": 0.47626046608082534,
        "recall": 0.541583499667332
      },
      {
        "accuracy": 0.5542248835662009,
        "f1": 0.4993462809830075,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.4993462809830075,
        "precision": 0.4777109801560899,
        "recall": 0.5542248835662009
      },
      {
        "accuracy": 0.23619427811044577,
        "f1": 0.1979937911574638,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.1979937911574638,
        "precision": 0.1846574047671852,
        "recall": 0.23619427811044577
      },
      {
        "accuracy": 0.40119760479041916,
        "f1": 0.36025559788034833,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.36025559788034833,
        "precision": 0.3453548650654439,
        "recall": 0.40119760479041916
      },
      {
        "accuracy": 0.4411177644710579,
        "f1": 0.3883941592524426,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.3883941592524426,
        "precision": 0.36796750414514884,
        "recall": 0.4411177644710579
      },
      {
        "accuracy": 0.4457751164337991,
        "f1": 0.3991292214845109,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.3991292214845109,
        "precision": 0.38219115659235414,
        "recall": 0.4457751164337991
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.002802037357925581,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.002802037357925581,
        "precision": 0.0021194019036806767,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.48902195608782434,
        "f1": 0.4402961273220754,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.4402961273220754,
        "precision": 0.4219070036934308,
        "recall": 0.48902195608782434
      },
      {
        "accuracy": 0.35662009314703924,
        "f1": 0.3051511977600976,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.3051511977600976,
        "precision": 0.2864785841552896,
        "recall": 0.35662009314703924
      },
      {
        "accuracy": 0.3978709248170326,
        "f1": 0.3449629988552144,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.3449629988552144,
        "precision": 0.32484660309011604,
        "recall": 0.3978709248170326
      },
      {
        "accuracy": 0.46174318030605455,
        "f1": 0.40874812701160007,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.40874812701160007,
        "precision": 0.3889144178066334,
        "recall": 0.46174318030605455
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0036367402232021875,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0036367402232021875,
        "precision": 0.0032914688962183015,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.3320026613439787,
        "f1": 0.289530341027347,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.289530341027347,
        "precision": 0.2738894697377731,
        "recall": 0.3320026613439787
      },
      {
        "accuracy": 0.43313373253493015,
        "f1": 0.3799469843382019,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.3799469843382019,
        "precision": 0.36043893454073095,
        "recall": 0.43313373253493015
      },
      {
        "accuracy": 0.479707252162342,
        "f1": 0.4294195159464621,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.4294195159464621,
        "precision": 0.411158882516168,
        "recall": 0.479707252162342
      },
      {
        "accuracy": 0.6899534264803726,
        "f1": 0.6379146468966829,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6379146468966829,
        "precision": 0.6172990072690671,
        "recall": 0.6899534264803726
      },
      {
        "accuracy": 0.846307385229541,
        "f1": 0.8156845040078573,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.8156845040078573,
        "precision": 0.8027009473117258,
        "recall": 0.846307385229541
      },
      {
        "accuracy": 0.2109115103127079,
        "f1": 0.175719549936633,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.175719549936633,
        "precision": 0.16357443842473782,
        "recall": 0.2109115103127079
      },
      {
        "accuracy": 0.7238855622089155,
        "f1": 0.6725247916864683,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6725247916864683,
        "precision": 0.6525533182718811,
        "recall": 0.7238855622089155
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9120330767037353,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9120330767037353,
        "precision": 0.9055999112885341,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.4657351962741184,
        "f1": 0.4052977073935158,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.4052977073935158,
        "precision": 0.3833312451575925,
        "recall": 0.4657351962741184
      },
      {
        "accuracy": 0.6580172987358616,
        "f1": 0.5987485346766784,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5987485346766784,
        "precision": 0.575998003992016,
        "recall": 0.6580172987358616
      },
      {
        "accuracy": 0.9068529607451763,
        "f1": 0.8855843867819916,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.8855843867819916,
        "precision": 0.8759702816589043,
        "recall": 0.9068529607451763
      },
      {
        "accuracy": 0.5755156353958749,
        "f1": 0.5186810749685001,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.5186810749685001,
        "precision": 0.49703133415708267,
        "recall": 0.5755156353958749
      },
      {
        "accuracy": 0.49966733200266134,
        "f1": 0.44460332858536455,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.44460332858536455,
        "precision": 0.42463461475143993,
        "recall": 0.49966733200266134
      },
      {
        "accuracy": 0.7159015302727878,
        "f1": 0.6720517598761111,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.6720517598761111,
        "precision": 0.6553314246927022,
        "recall": 0.7159015302727878
      },
      {
        "accuracy": 0.4524284763805722,
        "f1": 0.3925637759411389,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.3925637759411389,
        "precision": 0.370871992586896,
        "recall": 0.4524284763805722
      },
      {
        "accuracy": 0.7305389221556886,
        "f1": 0.680655091932537,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.680655091932537,
        "precision": 0.6613870143311261,
        "recall": 0.7305389221556886
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0025834197111299787,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0025834197111299787,
        "precision": 0.0021226047734575672,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.8210246174318031,
        "f1": 0.7873190127681146,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7873190127681146,
        "precision": 0.7730602287488515,
        "recall": 0.8210246174318031
      },
      {
        "accuracy": 0.46773120425815035,
        "f1": 0.4059595575563639,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.4059595575563639,
        "precision": 0.383902315662325,
        "recall": 0.46773120425815035
      },
      {
        "accuracy": 0.6906187624750499,
        "f1": 0.634023487416701,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.634023487416701,
        "precision": 0.6110361288005999,
        "recall": 0.6906187624750499
      },
      {
        "accuracy": 0.7764471057884231,
        "f1": 0.7357829794955544,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.7357829794955544,
        "precision": 0.7187070303836771,
        "recall": 0.7764471057884231
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.003258163605968944,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.003258163605968944,
        "precision": 0.002589720687735185,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.5582168995342648,
        "f1": 0.49955418395380574,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.49955418395380574,
        "precision": 0.47793275882098235,
        "recall": 0.5582168995342648
      },
      {
        "accuracy": 0.5954757152361942,
        "f1": 0.537322445056976,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.537322445056976,
        "precision": 0.5143178517272434,
        "recall": 0.5954757152361942
      },
      {
        "accuracy": 0.47704590818363274,
        "f1": 0.42120075649858196,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.42120075649858196,
        "precision": 0.40100356996271047,
        "recall": 0.47704590818363274
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}