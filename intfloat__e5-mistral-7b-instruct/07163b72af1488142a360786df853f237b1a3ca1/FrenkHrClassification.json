{
  "dataset_revision": "e7fc9f3d8d6c5640a26679d8a50b1666b02cc41f",
  "evaluation_time": 36.7889142036438,
  "kg_co2_emissions": 0.00894771252885463,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.6301085417649835,
        "ap": 0.641298301882817,
        "ap_weighted": 0.641298301882817,
        "f1": 0.6238854018840195,
        "f1_weighted": 0.6278161583325697,
        "hf_subset": "default",
        "languages": [
          "hrv-Latn"
        ],
        "main_score": 0.6301085417649835,
        "scores_per_experiment": [
          {
            "accuracy": 0.6243511090136857,
            "ap": 0.6479562030373291,
            "ap_weighted": 0.6479562030373291,
            "f1": 0.6242599806819762,
            "f1_weighted": 0.6235337154928969
          },
          {
            "accuracy": 0.6323737612081171,
            "ap": 0.650956276625124,
            "ap_weighted": 0.650956276625124,
            "f1": 0.6323528003376464,
            "f1_weighted": 0.6326973446460084
          },
          {
            "accuracy": 0.6724870221802737,
            "ap": 0.6500579234836052,
            "ap_weighted": 0.6500579234836052,
            "f1": 0.6489209217047527,
            "f1_weighted": 0.6602103286720788
          },
          {
            "accuracy": 0.6559697970740915,
            "ap": 0.6624467566243661,
            "ap_weighted": 0.6624467566243661,
            "f1": 0.6548629383919293,
            "f1_weighted": 0.6572888036703348
          },
          {
            "accuracy": 0.6328456819254366,
            "ap": 0.6454992533467221,
            "ap_weighted": 0.6454992533467221,
            "f1": 0.6318716114222425,
            "f1_weighted": 0.634221891627197
          },
          {
            "accuracy": 0.661160924964606,
            "ap": 0.6513312253116549,
            "ap_weighted": 0.6513312253116549,
            "f1": 0.6504457188019814,
            "f1_weighted": 0.658041673574947
          },
          {
            "accuracy": 0.5644171779141104,
            "ap": 0.5848859834010756,
            "ap_weighted": 0.5848859834010756,
            "f1": 0.5393830845771145,
            "f1_weighted": 0.5527109520824383
          },
          {
            "accuracy": 0.6446436998584237,
            "ap": 0.6586923372928328,
            "ap_weighted": 0.6586923372928328,
            "f1": 0.6444904165900773,
            "f1_weighted": 0.6454066324895117
          },
          {
            "accuracy": 0.6380368098159509,
            "ap": 0.6509356002104026,
            "ap_weighted": 0.6509356002104026,
            "f1": 0.637467112637335,
            "f1_weighted": 0.6392508073751443
          },
          {
            "accuracy": 0.5747994336951392,
            "ap": 0.6102214594950568,
            "ap_weighted": 0.6102214594950568,
            "f1": 0.5747994336951392,
            "f1_weighted": 0.5747994336951392
          }
        ]
      }
    ]
  },
  "task_name": "FrenkHrClassification"
}