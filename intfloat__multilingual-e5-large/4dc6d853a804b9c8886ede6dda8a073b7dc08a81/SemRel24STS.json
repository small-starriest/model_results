{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 16.923221349716187,
  "kg_co2_emissions": 0.002967602102305631,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8224801589461157,
        "cosine_spearman": 0.8097434761569621,
        "euclidean_pearson": 0.8041788012445611,
        "euclidean_spearman": 0.8097434761569621,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.8097434761569621,
        "manhattan_pearson": 0.803357897397969,
        "manhattan_spearman": 0.8083310323133623,
        "pearson": 0.8224801589461157,
        "spearman": 0.8097434761569621
      },
      {
        "cosine_pearson": 0.7598139234332244,
        "cosine_spearman": 0.7392471671303881,
        "euclidean_pearson": 0.7627469766471087,
        "euclidean_spearman": 0.7392471671303881,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7392471671303881,
        "manhattan_pearson": 0.7617477854582929,
        "manhattan_spearman": 0.734373685354654,
        "pearson": 0.7598139234332244,
        "spearman": 0.7392471671303881
      },
      {
        "cosine_pearson": 0.544330602792533,
        "cosine_spearman": 0.55237907563976,
        "euclidean_pearson": 0.5598509941609713,
        "euclidean_spearman": 0.55237907563976,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.55237907563976,
        "manhattan_pearson": 0.5550640169399599,
        "manhattan_spearman": 0.5465780168398393,
        "pearson": 0.544330602792533,
        "spearman": 0.55237907563976
      },
      {
        "cosine_pearson": 0.5026214238177609,
        "cosine_spearman": 0.474820008075818,
        "euclidean_pearson": 0.5121129147615925,
        "euclidean_spearman": 0.474820008075818,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.474820008075818,
        "manhattan_pearson": 0.5082895131400622,
        "manhattan_spearman": 0.47144401740854186,
        "pearson": 0.5026214238177609,
        "spearman": 0.474820008075818
      },
      {
        "cosine_pearson": 0.47243122587434977,
        "cosine_spearman": 0.46964946642967637,
        "euclidean_pearson": 0.4761211865006443,
        "euclidean_spearman": 0.46964946642967637,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.46964946642967637,
        "manhattan_pearson": 0.47508826412874533,
        "manhattan_spearman": 0.4683300756402552,
        "pearson": 0.47243122587434977,
        "spearman": 0.46964946642967637
      },
      {
        "cosine_pearson": 0.8144809341676879,
        "cosine_spearman": 0.8009170521315604,
        "euclidean_pearson": 0.8150317325753615,
        "euclidean_spearman": 0.8009169006769268,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8009170521315604,
        "manhattan_pearson": 0.8145702522537848,
        "manhattan_spearman": 0.8006367060531441,
        "pearson": 0.8144809341676879,
        "spearman": 0.8009170521315604
      },
      {
        "cosine_pearson": 0.4745183801431283,
        "cosine_spearman": 0.46054342578353613,
        "euclidean_pearson": 0.47856933011156,
        "euclidean_spearman": 0.46054342578353613,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.46054342578353613,
        "manhattan_pearson": 0.4799892062149571,
        "manhattan_spearman": 0.46221610196268037,
        "pearson": 0.4745183801431283,
        "spearman": 0.46054342578353613
      },
      {
        "cosine_pearson": 0.7467408385244673,
        "cosine_spearman": 0.7501287468018092,
        "euclidean_pearson": 0.7271082031419832,
        "euclidean_spearman": 0.7501287468018092,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7501287468018092,
        "manhattan_pearson": 0.7259850267491705,
        "manhattan_spearman": 0.748112510064956,
        "pearson": 0.7467408385244673,
        "spearman": 0.7501287468018092
      },
      {
        "cosine_pearson": 0.3280429022498912,
        "cosine_spearman": 0.41612976270621405,
        "euclidean_pearson": 0.4055397313543397,
        "euclidean_spearman": 0.41612976270621405,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.41612976270621405,
        "manhattan_pearson": 0.4060846059921538,
        "manhattan_spearman": 0.4171929260720007,
        "pearson": 0.3280429022498912,
        "spearman": 0.41612976270621405
      },
      {
        "cosine_pearson": 0.4964580272904521,
        "cosine_spearman": 0.5130567560911481,
        "euclidean_pearson": 0.5000855874652178,
        "euclidean_spearman": 0.5130567560911481,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5130567560911481,
        "manhattan_pearson": 0.49719286402955093,
        "manhattan_spearman": 0.5076236408428384,
        "pearson": 0.4964580272904521,
        "spearman": 0.5130567560911481
      },
      {
        "cosine_pearson": 0.7941576228023771,
        "cosine_spearman": 0.7686272756786886,
        "euclidean_pearson": 0.7862601244514403,
        "euclidean_spearman": 0.7686272756786886,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7686272756786886,
        "manhattan_pearson": 0.7861137912778352,
        "manhattan_spearman": 0.7700339557531798,
        "pearson": 0.7941576228023771,
        "spearman": 0.7686272756786886
      },
      {
        "cosine_pearson": 0.7911745657094168,
        "cosine_spearman": 0.7639408616952107,
        "euclidean_pearson": 0.7751928886245538,
        "euclidean_spearman": 0.7639408616952107,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7639408616952107,
        "manhattan_pearson": 0.7741299229213364,
        "manhattan_spearman": 0.761086059636311,
        "pearson": 0.7911745657094168,
        "spearman": 0.7639408616952107
      }
    ]
  },
  "task_name": "SemRel24STS"
}