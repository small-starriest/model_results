{
    "test": {
        "cos_sim": {
            "accuracy": 0.8829945759074924,
            "accuracy_threshold": 0.8747134208679199,
            "ap": 0.802843387858549,
            "f1": 0.7429755276446977,
            "f1_threshold": 0.8691627383232117,
            "precision": 0.7294685990338164,
            "recall": 0.7569920844327177
        },
        "dot": {
            "accuracy": 0.8829945759074924,
            "accuracy_threshold": 0.8747134804725647,
            "ap": 0.8028433896701894,
            "f1": 0.7429755276446977,
            "f1_threshold": 0.8691627383232117,
            "precision": 0.7294685990338164,
            "recall": 0.7569920844327177
        },
        "euclidean": {
            "accuracy": 0.8829945759074924,
            "accuracy_threshold": 0.5005728006362915,
            "ap": 0.8028432804161058,
            "f1": 0.7429755276446977,
            "f1_threshold": 0.5115413069725037,
            "precision": 0.7294685990338164,
            "recall": 0.7569920844327177
        },
        "evaluation_time": 232.74,
        "manhattan": {
            "accuracy": 0.882517732610121,
            "accuracy_threshold": 10.91767692565918,
            "ap": 0.8022075985629025,
            "f1": 0.7422344689378758,
            "f1_threshold": 11.502824783325195,
            "precision": 0.7064854554124941,
            "recall": 0.7817941952506596
        },
        "max": {
            "accuracy": 0.8829945759074924,
            "ap": 0.8028433896701894,
            "f1": 0.7429755276446977
        }
    },
    "mteb_version": "0.0.2",
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}