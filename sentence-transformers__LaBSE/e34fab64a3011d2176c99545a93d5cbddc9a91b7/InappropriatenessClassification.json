{
  "dataset_revision": "601651fdc45ef243751676e62dd7a19f491c0285",
  "evaluation_time": 10.797861099243164,
  "kg_co2_emissions": 0.0016168918790990152,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.585205078125,
        "ap": 0.5517746235480152,
        "ap_weighted": 0.5517746235480152,
        "f1": 0.582824263213296,
        "f1_weighted": 0.582824263213296,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.585205078125,
        "scores_per_experiment": [
          {
            "accuracy": 0.607421875,
            "ap": 0.5728313359627832,
            "ap_weighted": 0.5728313359627832,
            "f1": 0.5913624329564102,
            "f1_weighted": 0.5913624329564102
          },
          {
            "accuracy": 0.59228515625,
            "ap": 0.5544879822069378,
            "ap_weighted": 0.5544879822069378,
            "f1": 0.5922422835462198,
            "f1_weighted": 0.5922422835462198
          },
          {
            "accuracy": 0.5673828125,
            "ap": 0.5377986624889576,
            "ap_weighted": 0.5377986624889576,
            "f1": 0.5661763862058413,
            "f1_weighted": 0.5661763862058413
          },
          {
            "accuracy": 0.5439453125,
            "ap": 0.5239661432081654,
            "ap_weighted": 0.5239661432081654,
            "f1": 0.5438339438339439,
            "f1_weighted": 0.5438339438339439
          },
          {
            "accuracy": 0.57568359375,
            "ap": 0.5445146962101821,
            "ap_weighted": 0.5445146962101821,
            "f1": 0.5735458856213543,
            "f1_weighted": 0.5735458856213543
          },
          {
            "accuracy": 0.54443359375,
            "ap": 0.5240497329725748,
            "ap_weighted": 0.5240497329725748,
            "f1": 0.5437547142915472,
            "f1_weighted": 0.5437547142915472
          },
          {
            "accuracy": 0.64453125,
            "ap": 0.5925989187262357,
            "ap_weighted": 0.5925989187262357,
            "f1": 0.6444647933001393,
            "f1_weighted": 0.6444647933001393
          },
          {
            "accuracy": 0.611328125,
            "ap": 0.5675920758928571,
            "ap_weighted": 0.5675920758928571,
            "f1": 0.6111798018653356,
            "f1_weighted": 0.6111798018653356
          },
          {
            "accuracy": 0.55810546875,
            "ap": 0.5326805154774397,
            "ap_weighted": 0.5326805154774397,
            "f1": 0.5575737307492988,
            "f1_weighted": 0.5575737307492988
          },
          {
            "accuracy": 0.60693359375,
            "ap": 0.5672261723340188,
            "ap_weighted": 0.5672261723340188,
            "f1": 0.6041086597628695,
            "f1_weighted": 0.6041086597628695
          }
        ]
      }
    ]
  },
  "task_name": "InappropriatenessClassification"
}