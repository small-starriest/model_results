{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 76.6232054233551,
  "kg_co2_emissions": 0.037376867074466184,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.7964071856287425,
        "f1": 0.7584513512657225,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.7584513512657225,
        "precision": 0.7426923929917941,
        "recall": 0.7964071856287425
      },
      {
        "accuracy": 0.22355289421157684,
        "f1": 0.18745366410037068,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.18745366410037068,
        "precision": 0.1762591219677048,
        "recall": 0.22355289421157684
      },
      {
        "accuracy": 0.6314038589487692,
        "f1": 0.579035579634382,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.579035579634382,
        "precision": 0.5582168995342648,
        "recall": 0.6314038589487692
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7818881237044909,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.7818881237044909,
        "precision": 0.7674399877493691,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.47571523619427813,
        "f1": 0.42022847042807127,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.42022847042807127,
        "precision": 0.4004854962439793,
        "recall": 0.47571523619427813
      },
      {
        "accuracy": 0.6087824351297405,
        "f1": 0.545501589413765,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.545501589413765,
        "precision": 0.5198187873337573,
        "recall": 0.6087824351297405
      },
      {
        "accuracy": 0.7884231536926147,
        "f1": 0.7502011849317239,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.7502011849317239,
        "precision": 0.7341391291491093,
        "recall": 0.7884231536926147
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.4774910496467382,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.4774910496467382,
        "precision": 0.4554565472230143,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.32335329341317365,
        "f1": 0.2727977094244559,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.2727977094244559,
        "precision": 0.25497759429895156,
        "recall": 0.32335329341317365
      },
      {
        "accuracy": 0.6626746506986028,
        "f1": 0.6179709844380503,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.6179709844380503,
        "precision": 0.6006571753078739,
        "recall": 0.6626746506986028
      },
      {
        "accuracy": 0.4145043246839654,
        "f1": 0.35991014351136214,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.35991014351136214,
        "precision": 0.34049625616491885,
        "recall": 0.4145043246839654
      },
      {
        "accuracy": 0.6793080505655356,
        "f1": 0.6303498822460898,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.6303498822460898,
        "precision": 0.6109225992459526,
        "recall": 0.6793080505655356
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.008615598797773148,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.008615598797773148,
        "precision": 0.006511107907044847,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.7744510978043913,
        "f1": 0.7327202737382378,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.7327202737382378,
        "precision": 0.7152937105032914,
        "recall": 0.7744510978043913
      },
      {
        "accuracy": 0.4810379241516966,
        "f1": 0.4156802796523355,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.4156802796523355,
        "precision": 0.3902935111018943,
        "recall": 0.4810379241516966
      },
      {
        "accuracy": 0.5389221556886228,
        "f1": 0.47223169378858004,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.47223169378858004,
        "precision": 0.44575293856730985,
        "recall": 0.5389221556886228
      },
      {
        "accuracy": 0.6966067864271457,
        "f1": 0.6468312053142392,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.6468312053142392,
        "precision": 0.6264027500554445,
        "recall": 0.6966067864271457
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.008589617671453999,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.008589617671453999,
        "precision": 0.0072413614329782,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.48436460412508314,
        "f1": 0.42750213857998287,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.42750213857998287,
        "precision": 0.4066853066354065,
        "recall": 0.48436460412508314
      },
      {
        "accuracy": 0.5149700598802395,
        "f1": 0.4503420915596564,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.4503420915596564,
        "precision": 0.42497306973354876,
        "recall": 0.5149700598802395
      },
      {
        "accuracy": 0.42980705256154356,
        "f1": 0.3702215098422683,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.3702215098422683,
        "precision": 0.3486521905683582,
        "recall": 0.42980705256154356
      },
      {
        "accuracy": 0.7471723220226214,
        "f1": 0.700998003992016,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.700998003992016,
        "precision": 0.6810711909514304,
        "recall": 0.7471723220226214
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7590960935272313,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.7590960935272313,
        "precision": 0.742953774989703,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.23619427811044577,
        "f1": 0.19690504752880006,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.19690504752880006,
        "precision": 0.1841948470854987,
        "recall": 0.23619427811044577
      },
      {
        "accuracy": 0.7365269461077845,
        "f1": 0.6886074412022515,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6886074412022515,
        "precision": 0.6691656369800082,
        "recall": 0.7365269461077845
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9223331115546685,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9223331115546685,
        "precision": 0.9161898425371479,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.5000931186060926,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.5000931186060926,
        "precision": 0.48047795702486323,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.7112441783100466,
        "f1": 0.6586436074460027,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.6586436074460027,
        "precision": 0.6367151773339398,
        "recall": 0.7112441783100466
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8878243512974051,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.8878243512974051,
        "precision": 0.8786981592370814,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.6640053226879574,
        "f1": 0.6142772655746708,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.6142772655746708,
        "precision": 0.594750669600969,
        "recall": 0.6640053226879574
      },
      {
        "accuracy": 0.3772455089820359,
        "f1": 0.3263705393445912,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.3263705393445912,
        "precision": 0.3078404659712632,
        "recall": 0.3772455089820359
      },
      {
        "accuracy": 0.7485029940119761,
        "f1": 0.7084809217543748,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.7084809217543748,
        "precision": 0.6925767512593859,
        "recall": 0.7485029940119761
      },
      {
        "accuracy": 0.5422488356620093,
        "f1": 0.4815793899567529,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.4815793899567529,
        "precision": 0.4580778918353769,
        "recall": 0.5422488356620093
      },
      {
        "accuracy": 0.7757817697937458,
        "f1": 0.7369404049044768,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.7369404049044768,
        "precision": 0.7209422424991287,
        "recall": 0.7757817697937458
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.006990182921849,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.006990182921849,
        "precision": 0.005714303317461794,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.8695941450432468,
        "f1": 0.8427921933909958,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8427921933909958,
        "precision": 0.8316430630801888,
        "recall": 0.8695941450432468
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.47030335673050244,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.47030335673050244,
        "precision": 0.444623451509679,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.633399866932801,
        "f1": 0.5709067822840278,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.5709067822840278,
        "precision": 0.5462054726525785,
        "recall": 0.633399866932801
      },
      {
        "accuracy": 0.8376580172987359,
        "f1": 0.8051373443589013,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.8051373443589013,
        "precision": 0.7911462788708298,
        "recall": 0.8376580172987359
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005121656328919222,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.005121656328919222,
        "precision": 0.0038382207507371814,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.5828343313373253,
        "f1": 0.5282989724107489,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.5282989724107489,
        "precision": 0.5072442416753794,
        "recall": 0.5828343313373253
      },
      {
        "accuracy": 0.677977378576181,
        "f1": 0.6234340842125273,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.6234340842125273,
        "precision": 0.6009378069258308,
        "recall": 0.677977378576181
      },
      {
        "accuracy": 0.5568862275449101,
        "f1": 0.49530832514864453,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.49530832514864453,
        "precision": 0.47200862824615314,
        "recall": 0.5568862275449101
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.854136172100244,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.854136172100244,
        "precision": 0.8434464404524283,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.21756487025948104,
        "f1": 0.1857855717137154,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.1857855717137154,
        "precision": 0.17540977534118188,
        "recall": 0.21756487025948104
      },
      {
        "accuracy": 0.2428476380572189,
        "f1": 0.2059299722380883,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2059299722380883,
        "precision": 0.19447770312288415,
        "recall": 0.2428476380572189
      },
      {
        "accuracy": 0.2481703260146374,
        "f1": 0.22081833170959267,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.22081833170959267,
        "precision": 0.21205679670001024,
        "recall": 0.2481703260146374
      },
      {
        "accuracy": 0.26214238190286093,
        "f1": 0.2224283606930079,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2224283606930079,
        "precision": 0.21014430703654205,
        "recall": 0.26214238190286093
      },
      {
        "accuracy": 0.21889554224883567,
        "f1": 0.19136361098089816,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.19136361098089816,
        "precision": 0.1833123242674728,
        "recall": 0.21889554224883567
      },
      {
        "accuracy": 0.17232202262142382,
        "f1": 0.13854606934410818,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.13854606934410818,
        "precision": 0.12894375747077785,
        "recall": 0.17232202262142382
      },
      {
        "accuracy": 0.2827677977378576,
        "f1": 0.24054046662251305,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.24054046662251305,
        "precision": 0.2276336542631539,
        "recall": 0.2827677977378576
      },
      {
        "accuracy": 0.18695941450432468,
        "f1": 0.15720106124004207,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.15720106124004207,
        "precision": 0.14768995414762703,
        "recall": 0.18695941450432468
      },
      {
        "accuracy": 0.18429807052561545,
        "f1": 0.1512155404597729,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1512155404597729,
        "precision": 0.14145480695801108,
        "recall": 0.18429807052561545
      },
      {
        "accuracy": 0.2328675981370592,
        "f1": 0.19908154417644205,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.19908154417644205,
        "precision": 0.18899978299234987,
        "recall": 0.2328675981370592
      },
      {
        "accuracy": 0.18163672654690619,
        "f1": 0.1444451619785163,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1444451619785163,
        "precision": 0.13353852660239884,
        "recall": 0.18163672654690619
      },
      {
        "accuracy": 0.22554890219560877,
        "f1": 0.19066275741748323,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.19066275741748323,
        "precision": 0.17997116697541937,
        "recall": 0.22554890219560877
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.009395266948581373,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009395266948581373,
        "precision": 0.008016089107341716,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.25016633399866933,
        "f1": 0.21403062773540207,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.21403062773540207,
        "precision": 0.20270875221332363,
        "recall": 0.25016633399866933
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.14512777288735668,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.14512777288735668,
        "precision": 0.13433674012151206,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.15834996673320026,
        "f1": 0.1243956435373601,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1243956435373601,
        "precision": 0.11472113493071577,
        "recall": 0.15834996673320026
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.16484020895198537,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.16484020895198537,
        "precision": 0.15331559592743108,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.01015281069584228,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.01015281069584228,
        "precision": 0.00856650364660207,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.2528276779773786,
        "f1": 0.21535182667981007,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.21535182667981007,
        "precision": 0.2044472957580952,
        "recall": 0.2528276779773786
      },
      {
        "accuracy": 0.15768463073852296,
        "f1": 0.12354563002275087,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.12354563002275087,
        "precision": 0.11402776592231777,
        "recall": 0.15768463073852296
      },
      {
        "accuracy": 0.2055888223552894,
        "f1": 0.1702167722127802,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1702167722127802,
        "precision": 0.1586964740129,
        "recall": 0.2055888223552894
      },
      {
        "accuracy": 0.22887558216899534,
        "f1": 0.18691620273525544,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.18691620273525544,
        "precision": 0.17562369236797448,
        "recall": 0.22887558216899534
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.5994635068487365,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5994635068487365,
        "precision": 0.5796034914298387,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6871051547698255,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6871051547698255,
        "precision": 0.6675149700598803,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.22999375070884226,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.22999375070884226,
        "precision": 0.21550810327961908,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.8063872255489022,
        "f1": 0.7614506436861727,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7614506436861727,
        "precision": 0.7424146656182584,
        "recall": 0.8063872255489022
      },
      {
        "accuracy": 0.5003326679973387,
        "f1": 0.4513111011115003,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4513111011115003,
        "precision": 0.4327081767201528,
        "recall": 0.5003326679973387
      },
      {
        "accuracy": 0.5582168995342648,
        "f1": 0.494926482551233,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.494926482551233,
        "precision": 0.4709858061654469,
        "recall": 0.5582168995342648
      },
      {
        "accuracy": 0.8097139055222887,
        "f1": 0.7682523841206477,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7682523841206477,
        "precision": 0.7507952349269714,
        "recall": 0.8097139055222887
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.47818547608966777,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.47818547608966777,
        "precision": 0.4574850299401197,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.39188290086493677,
        "f1": 0.3373727920634108,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3373727920634108,
        "precision": 0.31772164222264015,
        "recall": 0.39188290086493677
      },
      {
        "accuracy": 0.7139055222887558,
        "f1": 0.6649700598802396,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6649700598802396,
        "precision": 0.6447021301312719,
        "recall": 0.7139055222887558
      },
      {
        "accuracy": 0.4231536926147705,
        "f1": 0.3615925411019433,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3615925411019433,
        "precision": 0.33930129159670075,
        "recall": 0.4231536926147705
      },
      {
        "accuracy": 0.6660013306719893,
        "f1": 0.6156031851640634,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6156031851640634,
        "precision": 0.5958923422995279,
        "recall": 0.6660013306719893
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.009589897307145738,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009589897307145738,
        "precision": 0.0070204369576214115,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.7558216899534265,
        "f1": 0.7109443450760815,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7109443450760815,
        "precision": 0.6920381459303616,
        "recall": 0.7558216899534265
      },
      {
        "accuracy": 0.42248835662009315,
        "f1": 0.3619089530267175,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3619089530267175,
        "precision": 0.3402665568334231,
        "recall": 0.42248835662009315
      },
      {
        "accuracy": 0.603459747172322,
        "f1": 0.5377092376094371,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5377092376094371,
        "precision": 0.5119689193042486,
        "recall": 0.603459747172322
      },
      {
        "accuracy": 0.6833000665335994,
        "f1": 0.6271484448131154,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.6271484448131154,
        "precision": 0.6042718795213805,
        "recall": 0.6833000665335994
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.010906460656959658,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.010906460656959658,
        "precision": 0.008580153490333132,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.605455755156354,
        "f1": 0.5536261291750314,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5536261291750314,
        "precision": 0.5333188361132473,
        "recall": 0.605455755156354
      },
      {
        "accuracy": 0.4916833000665336,
        "f1": 0.42480387949449827,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.42480387949449827,
        "precision": 0.3994083262047333,
        "recall": 0.4916833000665336
      },
      {
        "accuracy": 0.4431137724550898,
        "f1": 0.3886127696506938,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3886127696506938,
        "precision": 0.36900893391333567,
        "recall": 0.4431137724550898
      },
      {
        "accuracy": 0.7638057218895542,
        "f1": 0.713783544023065,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.713783544023065,
        "precision": 0.6920555713968888,
        "recall": 0.7638057218895542
      },
      {
        "accuracy": 0.8097139055222887,
        "f1": 0.773598834077876,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.773598834077876,
        "precision": 0.7597902319459205,
        "recall": 0.8097139055222887
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9079951208693724,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9079951208693724,
        "precision": 0.9007382061274277,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.2654690618762475,
        "f1": 0.21948919742824682,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.21948919742824682,
        "precision": 0.2048772861647113,
        "recall": 0.2654690618762475
      },
      {
        "accuracy": 0.8010645375914837,
        "f1": 0.7610345446672793,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.7610345446672793,
        "precision": 0.7450876025726326,
        "recall": 0.8010645375914837
      },
      {
        "accuracy": 0.5868263473053892,
        "f1": 0.5364879188232482,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.5364879188232482,
        "precision": 0.5179374296140763,
        "recall": 0.5868263473053892
      },
      {
        "accuracy": 0.7524950099800399,
        "f1": 0.7044930969082667,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.7044930969082667,
        "precision": 0.6851775359260389,
        "recall": 0.7524950099800399
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9351962741184299,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9351962741184299,
        "precision": 0.9298514082945221,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.6846307385229541,
        "f1": 0.6312633991276705,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.6312633991276705,
        "precision": 0.6106458873424941,
        "recall": 0.6846307385229541
      },
      {
        "accuracy": 0.40652029274783763,
        "f1": 0.3462149628557988,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.3462149628557988,
        "precision": 0.3251024753611685,
        "recall": 0.40652029274783763
      },
      {
        "accuracy": 0.7957418496340652,
        "f1": 0.7566471194215706,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.7566471194215706,
        "precision": 0.7420629640190518,
        "recall": 0.7957418496340652
      },
      {
        "accuracy": 0.5808383233532934,
        "f1": 0.5213980436285826,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.5213980436285826,
        "precision": 0.49984798323604585,
        "recall": 0.5808383233532934
      },
      {
        "accuracy": 0.8243512974051896,
        "f1": 0.7871621835693693,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.7871621835693693,
        "precision": 0.7717837053166394,
        "recall": 0.8243512974051896
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.006873011276751768,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.006873011276751768,
        "precision": 0.005255121092392253,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8793597989206773,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.8793597989206773,
        "precision": 0.8702927478376581,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.520292747837658,
        "f1": 0.451622518089584,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.451622518089584,
        "precision": 0.4271327548772658,
        "recall": 0.520292747837658
      },
      {
        "accuracy": 0.6766467065868264,
        "f1": 0.6135781827398593,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.6135781827398593,
        "precision": 0.5885853113398024,
        "recall": 0.6766467065868264
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.8712463960966955,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.8712463960966955,
        "precision": 0.8609732915122136,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007829146901003187,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.007829146901003187,
        "precision": 0.006234515938254242,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.614105123087159,
        "f1": 0.5590153987359576,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.5590153987359576,
        "precision": 0.5389604869145788,
        "recall": 0.614105123087159
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6860427293561027,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.6860427293561027,
        "precision": 0.6665613218008428,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.5974717232202262,
        "f1": 0.5359852205161586,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.5359852205161586,
        "precision": 0.5133146405601495,
        "recall": 0.5974717232202262
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.903627665304312,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.903627665304312,
        "precision": 0.8956642271013529,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.4624085163007319,
        "f1": 0.40956658112346733,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.40956658112346733,
        "precision": 0.3909202998524356,
        "recall": 0.4624085163007319
      },
      {
        "accuracy": 0.5515635395874917,
        "f1": 0.49785983588378796,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.49785983588378796,
        "precision": 0.47798899555386576,
        "recall": 0.5515635395874917
      },
      {
        "accuracy": 0.2322022621423819,
        "f1": 0.19453887539627823,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.19453887539627823,
        "precision": 0.18149962703838823,
        "recall": 0.2322022621423819
      },
      {
        "accuracy": 0.49966733200266134,
        "f1": 0.45025821373126756,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.45025821373126756,
        "precision": 0.43198525987947145,
        "recall": 0.49966733200266134
      },
      {
        "accuracy": 0.5828343313373253,
        "f1": 0.5286186553152621,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5286186553152621,
        "precision": 0.5098139699437104,
        "recall": 0.5828343313373253
      },
      {
        "accuracy": 0.4357950765136394,
        "f1": 0.378942298553077,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.378942298553077,
        "precision": 0.35866466460278834,
        "recall": 0.4357950765136394
      },
      {
        "accuracy": 0.5588822355289421,
        "f1": 0.5087429739625349,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5087429739625349,
        "precision": 0.48997687165351844,
        "recall": 0.5588822355289421
      },
      {
        "accuracy": 0.4204923486360612,
        "f1": 0.3751920683997706,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.3751920683997706,
        "precision": 0.3583289036973773,
        "recall": 0.4204923486360612
      },
      {
        "accuracy": 0.27811044577511645,
        "f1": 0.2370665669068863,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2370665669068863,
        "precision": 0.2223298738668,
        "recall": 0.27811044577511645
      },
      {
        "accuracy": 0.5056553559547572,
        "f1": 0.4570197192577819,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4570197192577819,
        "precision": 0.43850511597517583,
        "recall": 0.5056553559547572
      },
      {
        "accuracy": 0.3180306054557552,
        "f1": 0.2708603956108946,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2708603956108946,
        "precision": 0.25398513477355794,
        "recall": 0.3180306054557552
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.566573778849228,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.566573778849228,
        "precision": 0.5443465162028036,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.009277755779489154,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009277755779489154,
        "precision": 0.007501121312613372,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.5402528276779773,
        "f1": 0.492156835919311,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.492156835919311,
        "precision": 0.4748088072938373,
        "recall": 0.5402528276779773
      },
      {
        "accuracy": 0.2827677977378576,
        "f1": 0.2283265882009571,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2283265882009571,
        "precision": 0.20995878613144084,
        "recall": 0.2827677977378576
      },
      {
        "accuracy": 0.3499667332002661,
        "f1": 0.29492805191407984,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.29492805191407984,
        "precision": 0.27608486730243215,
        "recall": 0.3499667332002661
      },
      {
        "accuracy": 0.5176314038589488,
        "f1": 0.45984436693670394,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.45984436693670394,
        "precision": 0.43841300083815055,
        "recall": 0.5176314038589488
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.00706792283638591,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00706792283638591,
        "precision": 0.005264867091214397,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.43912175648702595,
        "f1": 0.39130046784737404,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.39130046784737404,
        "precision": 0.3748075518035598,
        "recall": 0.43912175648702595
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.3052556743175505,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3052556743175505,
        "precision": 0.2878761070377837,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.37258815701929476,
        "f1": 0.3274892709707291,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3274892709707291,
        "precision": 0.3111631068716897,
        "recall": 0.37258815701929476
      },
      {
        "accuracy": 0.4810379241516966,
        "f1": 0.42237796209852096,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.42237796209852096,
        "precision": 0.4007643443272185,
        "recall": 0.4810379241516966
      },
      {
        "accuracy": 0.5941450432468397,
        "f1": 0.5378232952085247,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.5378232952085247,
        "precision": 0.5152309378357283,
        "recall": 0.5941450432468397
      },
      {
        "accuracy": 0.7172322022621423,
        "f1": 0.6688109739007942,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.6688109739007942,
        "precision": 0.6485536862782372,
        "recall": 0.7172322022621423
      },
      {
        "accuracy": 0.16699933466400532,
        "f1": 0.1368712087899101,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.1368712087899101,
        "precision": 0.12715894993252044,
        "recall": 0.16699933466400532
      },
      {
        "accuracy": 0.541583499667332,
        "f1": 0.4874653290820955,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.4874653290820955,
        "precision": 0.4677132507471829,
        "recall": 0.541583499667332
      },
      {
        "accuracy": 0.7451763140385895,
        "f1": 0.6965825443869357,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.6965825443869357,
        "precision": 0.6771332995384891,
        "recall": 0.7451763140385895
      },
      {
        "accuracy": 0.3972055888223553,
        "f1": 0.351996320010292,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.351996320010292,
        "precision": 0.33554005505103307,
        "recall": 0.3972055888223553
      },
      {
        "accuracy": 0.7458416500332667,
        "f1": 0.696674904159934,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.696674904159934,
        "precision": 0.6766807654532205,
        "recall": 0.7458416500332667
      },
      {
        "accuracy": 0.5143047238855623,
        "f1": 0.45828184900041186,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.45828184900041186,
        "precision": 0.4374666011891561,
        "recall": 0.5143047238855623
      },
      {
        "accuracy": 0.24085163007318697,
        "f1": 0.20340519058083925,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.20340519058083925,
        "precision": 0.1912281497610839,
        "recall": 0.24085163007318697
      },
      {
        "accuracy": 0.543579507651364,
        "f1": 0.491193845878594,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.491193845878594,
        "precision": 0.47190763974696115,
        "recall": 0.543579507651364
      },
      {
        "accuracy": 0.46041250831669994,
        "f1": 0.40750245540664704,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.40750245540664704,
        "precision": 0.38711624370306996,
        "recall": 0.46041250831669994
      },
      {
        "accuracy": 0.6699933466400533,
        "f1": 0.6185956130067907,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.6185956130067907,
        "precision": 0.5981341789725023,
        "recall": 0.6699933466400533
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.010704649127086891,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.010704649127086891,
        "precision": 0.008741550036383178,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.7025948103792415,
        "f1": 0.6509826907032495,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.6509826907032495,
        "precision": 0.6306073039106971,
        "recall": 0.7025948103792415
      },
      {
        "accuracy": 0.5103127079174984,
        "f1": 0.45213805193845114,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.45213805193845114,
        "precision": 0.4294257638569015,
        "recall": 0.5103127079174984
      },
      {
        "accuracy": 0.6626746506986028,
        "f1": 0.6042042898330323,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.6042042898330323,
        "precision": 0.5800636821594906,
        "recall": 0.6626746506986028
      },
      {
        "accuracy": 0.6393878908848969,
        "f1": 0.5848974009652652,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.5848974009652652,
        "precision": 0.5638429084037866,
        "recall": 0.6393878908848969
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.005293165472806192,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.005293165472806192,
        "precision": 0.004338413120848251,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.41650033266799735,
        "f1": 0.366837753065298,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.366837753065298,
        "precision": 0.3489769138970735,
        "recall": 0.41650033266799735
      },
      {
        "accuracy": 0.500998003992016,
        "f1": 0.43753498294416454,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.43753498294416454,
        "precision": 0.4133608444486688,
        "recall": 0.500998003992016
      },
      {
        "accuracy": 0.46107784431137727,
        "f1": 0.41166714190666287,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.41166714190666287,
        "precision": 0.3932276281548326,
        "recall": 0.46107784431137727
      },
      {
        "accuracy": 0.7152361942781105,
        "f1": 0.6623456790123456,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.6623456790123456,
        "precision": 0.6400651078794791,
        "recall": 0.7152361942781105
      },
      {
        "accuracy": 0.7870924817032602,
        "f1": 0.7456156470128525,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7456156470128525,
        "precision": 0.728627665304312,
        "recall": 0.7870924817032602
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8942448436460414,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8942448436460414,
        "precision": 0.8854354782498496,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.28476380572188953,
        "f1": 0.2395946565292085,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2395946565292085,
        "precision": 0.22359667797068858,
        "recall": 0.28476380572188953
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7575109041176905,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7575109041176905,
        "precision": 0.7406602139636073,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.9554224883566201,
        "f1": 0.9454202705699712,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9454202705699712,
        "precision": 0.9410512308715903,
        "recall": 0.9554224883566201
      },
      {
        "accuracy": 0.6021290751829674,
        "f1": 0.5473043479031503,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5473043479031503,
        "precision": 0.5265920133684605,
        "recall": 0.6021290751829674
      },
      {
        "accuracy": 0.7471723220226214,
        "f1": 0.6999477716044582,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6999477716044582,
        "precision": 0.6805124793148746,
        "recall": 0.7471723220226214
      },
      {
        "accuracy": 0.6846307385229541,
        "f1": 0.6317132929907381,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6317132929907381,
        "precision": 0.6112489547120286,
        "recall": 0.6846307385229541
      },
      {
        "accuracy": 0.42847638057218895,
        "f1": 0.3705872020926123,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3705872020926123,
        "precision": 0.349417038937997,
        "recall": 0.42847638057218895
      },
      {
        "accuracy": 0.7864271457085829,
        "f1": 0.7455770997687164,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7455770997687164,
        "precision": 0.7296892986513744,
        "recall": 0.7864271457085829
      },
      {
        "accuracy": 0.5795076513639388,
        "f1": 0.520652346101448,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.520652346101448,
        "precision": 0.4969896426483253,
        "recall": 0.5795076513639388
      },
      {
        "accuracy": 0.8097139055222887,
        "f1": 0.7732619417250156,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7732619417250156,
        "precision": 0.7581115546684408,
        "recall": 0.8097139055222887
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007688951588748893,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007688951588748893,
        "precision": 0.005911474441723151,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.8862275449101796,
        "f1": 0.8595824224566739,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8595824224566739,
        "precision": 0.8478487469505434,
        "recall": 0.8862275449101796
      },
      {
        "accuracy": 0.552228875582169,
        "f1": 0.4878628985415412,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.4878628985415412,
        "precision": 0.46318553369451576,
        "recall": 0.552228875582169
      },
      {
        "accuracy": 0.7178975382568197,
        "f1": 0.6634799184699385,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6634799184699385,
        "precision": 0.6414008202930358,
        "recall": 0.7178975382568197
      },
      {
        "accuracy": 0.852960745176314,
        "f1": 0.8205271995691157,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.8205271995691157,
        "precision": 0.8062430694167221,
        "recall": 0.852960745176314
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007834350343449792,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007834350343449792,
        "precision": 0.005714034893176609,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.5975937014859171,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5975937014859171,
        "precision": 0.5768011429688076,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.7145708582834331,
        "f1": 0.6637919927341085,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6637919927341085,
        "precision": 0.6425537813262363,
        "recall": 0.7145708582834331
      },
      {
        "accuracy": 0.5961410512308716,
        "f1": 0.5336110847088891,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5336110847088891,
        "precision": 0.5089463929284288,
        "recall": 0.5961410512308716
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8931913949878022,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8931913949878022,
        "precision": 0.8845863827899756,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.5429141716566867,
        "f1": 0.49559458800975764,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.49559458800975764,
        "precision": 0.478087763866207,
        "recall": 0.5429141716566867
      },
      {
        "accuracy": 0.669328010645376,
        "f1": 0.6212559489006594,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.6212559489006594,
        "precision": 0.6023461014478979,
        "recall": 0.669328010645376
      },
      {
        "accuracy": 0.19228210246174318,
        "f1": 0.16230229813064143,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.16230229813064143,
        "precision": 0.15182047871375098,
        "recall": 0.19228210246174318
      },
      {
        "accuracy": 0.5256154357950765,
        "f1": 0.47738491271425393,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.47738491271425393,
        "precision": 0.459208326972798,
        "recall": 0.5256154357950765
      },
      {
        "accuracy": 0.6773120425815037,
        "f1": 0.6297389828327952,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.6297389828327952,
        "precision": 0.612069797296403,
        "recall": 0.6773120425815037
      },
      {
        "accuracy": 0.4278110445775116,
        "f1": 0.3778648348134762,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.3778648348134762,
        "precision": 0.3602748281141495,
        "recall": 0.4278110445775116
      },
      {
        "accuracy": 0.5236194278110445,
        "f1": 0.465616650297289,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.465616650297289,
        "precision": 0.44348206683536023,
        "recall": 0.5236194278110445
      },
      {
        "accuracy": 0.6600133067198936,
        "f1": 0.61702512760397,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.61702512760397,
        "precision": 0.5999667332002662,
        "recall": 0.6600133067198936
      },
      {
        "accuracy": 0.25149700598802394,
        "f1": 0.21806492834436944,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.21806492834436944,
        "precision": 0.2057152538502532,
        "recall": 0.25149700598802394
      },
      {
        "accuracy": 0.5109780439121756,
        "f1": 0.4649842358425193,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.4649842358425193,
        "precision": 0.44773414469023254,
        "recall": 0.5109780439121756
      },
      {
        "accuracy": 0.46640053226879574,
        "f1": 0.41305114638447976,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.41305114638447976,
        "precision": 0.39307840086283197,
        "recall": 0.46640053226879574
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.5203856024215305,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.5203856024215305,
        "precision": 0.5022372836744093,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.006749448504174346,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.006749448504174346,
        "precision": 0.005163753966149176,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.6294078509647372,
        "f1": 0.5821608106538246,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.5821608106538246,
        "precision": 0.5642036033752601,
        "recall": 0.6294078509647372
      },
      {
        "accuracy": 0.37258815701929476,
        "f1": 0.317948854575601,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.317948854575601,
        "precision": 0.29799343112716364,
        "recall": 0.37258815701929476
      },
      {
        "accuracy": 0.4424484364604125,
        "f1": 0.3871019865031841,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.3871019865031841,
        "precision": 0.36676915279416156,
        "recall": 0.4424484364604125
      },
      {
        "accuracy": 0.6074517631403858,
        "f1": 0.5543154339561525,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.5543154339561525,
        "precision": 0.5331150109593223,
        "recall": 0.6074517631403858
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.006868219408655778,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.006868219408655778,
        "precision": 0.005159241586387295,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.42248835662009315,
        "f1": 0.37982277942357784,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.37982277942357784,
        "precision": 0.36412646826818473,
        "recall": 0.42248835662009315
      },
      {
        "accuracy": 0.5389221556886228,
        "f1": 0.4794347812311884,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.4794347812311884,
        "precision": 0.45615887033052704,
        "recall": 0.5389221556886228
      },
      {
        "accuracy": 0.5622089155023287,
        "f1": 0.5090459293054104,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.5090459293054104,
        "precision": 0.4872706967018344,
        "recall": 0.5622089155023287
      },
      {
        "accuracy": 0.6134397870924817,
        "f1": 0.5588241986445579,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.5588241986445579,
        "precision": 0.5382687006938504,
        "recall": 0.6134397870924817
      },
      {
        "accuracy": 0.32934131736526945,
        "f1": 0.2802652848429716,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.2802652848429716,
        "precision": 0.26382024311166025,
        "recall": 0.32934131736526945
      },
      {
        "accuracy": 0.3925482368596141,
        "f1": 0.33774437656673184,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.33774437656673184,
        "precision": 0.318784075604645,
        "recall": 0.3925482368596141
      },
      {
        "accuracy": 0.18496340652029275,
        "f1": 0.15422776836545043,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.15422776836545043,
        "precision": 0.14317175932857615,
        "recall": 0.18496340652029275
      },
      {
        "accuracy": 0.38589487691284097,
        "f1": 0.33856310023974695,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.33856310023974695,
        "precision": 0.3211694683592992,
        "recall": 0.38589487691284097
      },
      {
        "accuracy": 0.4244843646041251,
        "f1": 0.3676094634861312,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.3676094634861312,
        "precision": 0.34849664821475584,
        "recall": 0.4244843646041251
      },
      {
        "accuracy": 0.27877578176979373,
        "f1": 0.23985572865812385,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.23985572865812385,
        "precision": 0.22727402338180783,
        "recall": 0.27877578176979373
      },
      {
        "accuracy": 0.2481703260146374,
        "f1": 0.20068581525667353,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.20068581525667353,
        "precision": 0.18597441559343839,
        "recall": 0.2481703260146374
      },
      {
        "accuracy": 0.4364604125083167,
        "f1": 0.3774802609816792,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.3774802609816792,
        "precision": 0.3576239296299176,
        "recall": 0.4364604125083167
      },
      {
        "accuracy": 0.2721224218230206,
        "f1": 0.23126798905242016,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.23126798905242016,
        "precision": 0.21732590283763797,
        "recall": 0.2721224218230206
      },
      {
        "accuracy": 0.38389886892880903,
        "f1": 0.33475957081240787,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.33475957081240787,
        "precision": 0.3177621982512202,
        "recall": 0.38389886892880903
      },
      {
        "accuracy": 0.19494344644045242,
        "f1": 0.16071237434518382,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.16071237434518382,
        "precision": 0.150011674975877,
        "recall": 0.19494344644045242
      },
      {
        "accuracy": 0.313373253493014,
        "f1": 0.26253066681621334,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.26253066681621334,
        "precision": 0.24627265516114752,
        "recall": 0.313373253493014
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.008486055989675752,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.008486055989675752,
        "precision": 0.006900321248683348,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.3812375249500998,
        "f1": 0.3325105440873904,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3325105440873904,
        "precision": 0.31631099550261227,
        "recall": 0.3812375249500998
      },
      {
        "accuracy": 0.1709913506320692,
        "f1": 0.13158222349839116,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.13158222349839116,
        "precision": 0.11957207730367293,
        "recall": 0.1709913506320692
      },
      {
        "accuracy": 0.2648037258815702,
        "f1": 0.20987688477708438,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.20987688477708438,
        "precision": 0.1922115919121907,
        "recall": 0.2648037258815702
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.29640248123282054,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.29640248123282054,
        "precision": 0.27508451849769217,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.009316188037007268,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.009316188037007268,
        "precision": 0.007465756318051728,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.3526280771789754,
        "f1": 0.30642380462739743,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.30642380462739743,
        "precision": 0.29033815485911296,
        "recall": 0.3526280771789754
      },
      {
        "accuracy": 0.2215568862275449,
        "f1": 0.1813699496334227,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.1813699496334227,
        "precision": 0.16783921334819538,
        "recall": 0.2215568862275449
      },
      {
        "accuracy": 0.23952095808383234,
        "f1": 0.19925674421682404,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.19925674421682404,
        "precision": 0.18636250826869585,
        "recall": 0.23952095808383234
      },
      {
        "accuracy": 0.49234863606121093,
        "f1": 0.43030153294624357,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.43030153294624357,
        "precision": 0.4089398163749461,
        "recall": 0.49234863606121093
      },
      {
        "accuracy": 0.6713240186294078,
        "f1": 0.6196844406425245,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6196844406425245,
        "precision": 0.5989093242087253,
        "recall": 0.6713240186294078
      },
      {
        "accuracy": 0.7551563539587491,
        "f1": 0.7119018576603408,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7119018576603408,
        "precision": 0.6940468269809588,
        "recall": 0.7551563539587491
      },
      {
        "accuracy": 0.2554890219560878,
        "f1": 0.2126031554507935,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2126031554507935,
        "precision": 0.19889943582934957,
        "recall": 0.2554890219560878
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6866219941070241,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6866219941070241,
        "precision": 0.6673937838608497,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.8196939454424484,
        "f1": 0.786168451936915,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.786168451936915,
        "precision": 0.7732690703249585,
        "recall": 0.8196939454424484
      },
      {
        "accuracy": 0.530938123752495,
        "f1": 0.4744620469611663,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4744620469611663,
        "precision": 0.45400604388549554,
        "recall": 0.530938123752495
      },
      {
        "accuracy": 0.564870259481038,
        "f1": 0.50350283079824,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.50350283079824,
        "precision": 0.4809827435076936,
        "recall": 0.564870259481038
      },
      {
        "accuracy": 0.810379241516966,
        "f1": 0.7742414641616239,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7742414641616239,
        "precision": 0.7598422203212621,
        "recall": 0.810379241516966
      },
      {
        "accuracy": 0.5163007318695941,
        "f1": 0.4623563119072101,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4623563119072101,
        "precision": 0.4429799420502225,
        "recall": 0.5163007318695941
      },
      {
        "accuracy": 0.3958749168330007,
        "f1": 0.33881782314328984,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.33881782314328984,
        "precision": 0.3185094337539447,
        "recall": 0.3958749168330007
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.2974326146980838,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2974326146980838,
        "precision": 0.2787217433395665,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.6806387225548902,
        "f1": 0.62766324013829,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.62766324013829,
        "precision": 0.6064524390372694,
        "recall": 0.6806387225548902
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007990765265346537,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007990765265346537,
        "precision": 0.006194994524585343,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.782435129740519,
        "f1": 0.7402850383888309,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7402850383888309,
        "precision": 0.7235159551027814,
        "recall": 0.782435129740519
      },
      {
        "accuracy": 0.37658017298735863,
        "f1": 0.3175005282873756,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3175005282873756,
        "precision": 0.29806806066849006,
        "recall": 0.37658017298735863
      },
      {
        "accuracy": 0.5069860279441117,
        "f1": 0.44241703258669324,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.44241703258669324,
        "precision": 0.4191064960027036,
        "recall": 0.5069860279441117
      },
      {
        "accuracy": 0.7112441783100466,
        "f1": 0.6634181852744727,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.6634181852744727,
        "precision": 0.6440387044150107,
        "recall": 0.7112441783100466
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.00978030325886338,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00978030325886338,
        "precision": 0.007497727008705052,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.564870259481038,
        "f1": 0.5033646991730824,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5033646991730824,
        "precision": 0.4795662236780001,
        "recall": 0.564870259481038
      },
      {
        "accuracy": 0.48170326014637393,
        "f1": 0.42624775725416547,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.42624775725416547,
        "precision": 0.4054084951789543,
        "recall": 0.48170326014637393
      },
      {
        "accuracy": 0.42714570858283435,
        "f1": 0.37227763365487915,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.37227763365487915,
        "precision": 0.3525538869351244,
        "recall": 0.42714570858283435
      },
      {
        "accuracy": 0.7385229540918163,
        "f1": 0.6864894549525289,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6864894549525289,
        "precision": 0.665198967145075,
        "recall": 0.7385229540918163
      },
      {
        "accuracy": 0.38988689288090483,
        "f1": 0.33694849782087066,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.33694849782087066,
        "precision": 0.3181484913770343,
        "recall": 0.38988689288090483
      },
      {
        "accuracy": 0.5103127079174984,
        "f1": 0.4496388176028895,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.4496388176028895,
        "precision": 0.4270846788311858,
        "recall": 0.5103127079174984
      },
      {
        "accuracy": 0.16101131071190952,
        "f1": 0.13540397559858636,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.13540397559858636,
        "precision": 0.12731583954621747,
        "recall": 0.16101131071190952
      },
      {
        "accuracy": 0.37658017298735863,
        "f1": 0.32669652554882095,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.32669652554882095,
        "precision": 0.31076424803676184,
        "recall": 0.37658017298735863
      },
      {
        "accuracy": 0.5469061876247505,
        "f1": 0.48450560676109583,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.48450560676109583,
        "precision": 0.4623287409714555,
        "recall": 0.5469061876247505
      },
      {
        "accuracy": 0.2940785096473719,
        "f1": 0.2518296314210879,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.2518296314210879,
        "precision": 0.23847020965284435,
        "recall": 0.2940785096473719
      },
      {
        "accuracy": 0.46506986027944114,
        "f1": 0.40612845053962815,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.40612845053962815,
        "precision": 0.3837212034787472,
        "recall": 0.46506986027944114
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.489513085421269,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.489513085421269,
        "precision": 0.46789815242615523,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.4491017964071856,
        "f1": 0.4020752146500649,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.4020752146500649,
        "precision": 0.384738459588759,
        "recall": 0.4491017964071856
      },
      {
        "accuracy": 0.19028609447771125,
        "f1": 0.16103686326241215,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.16103686326241215,
        "precision": 0.15196721044730907,
        "recall": 0.19028609447771125
      },
      {
        "accuracy": 0.3320026613439787,
        "f1": 0.2890407361031331,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.2890407361031331,
        "precision": 0.27392655389788056,
        "recall": 0.3320026613439787
      },
      {
        "accuracy": 0.41783100465735196,
        "f1": 0.3656137460528678,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.3656137460528678,
        "precision": 0.34772998495553387,
        "recall": 0.41783100465735196
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.0061416577325935084,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.0061416577325935084,
        "precision": 0.0042725697736405045,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.4750499001996008,
        "f1": 0.4189004441998454,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.4189004441998454,
        "precision": 0.3999979118242591,
        "recall": 0.4750499001996008
      },
      {
        "accuracy": 0.3579507651363939,
        "f1": 0.3093579703360142,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.3093579703360142,
        "precision": 0.29078588854037957,
        "recall": 0.3579507651363939
      },
      {
        "accuracy": 0.39055222887558216,
        "f1": 0.3350317882753013,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.3350317882753013,
        "precision": 0.31530964045934107,
        "recall": 0.39055222887558216
      },
      {
        "accuracy": 0.46506986027944114,
        "f1": 0.4015914927092572,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.4015914927092572,
        "precision": 0.3787061014077569,
        "recall": 0.46506986027944114
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.005025974986054826,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.005025974986054826,
        "precision": 0.003992279990283982,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.2801064537591484,
        "f1": 0.24121919700762018,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.24121919700762018,
        "precision": 0.2280832514864451,
        "recall": 0.2801064537591484
      },
      {
        "accuracy": 0.4644045242847638,
        "f1": 0.40684403199373254,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.40684403199373254,
        "precision": 0.38494096463158334,
        "recall": 0.4644045242847638
      },
      {
        "accuracy": 0.4384564204923486,
        "f1": 0.39060988172764616,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.39060988172764616,
        "precision": 0.37303837702745773,
        "recall": 0.4384564204923486
      },
      {
        "accuracy": 0.5043246839654025,
        "f1": 0.4399324007108438,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.4399324007108438,
        "precision": 0.41633507876022846,
        "recall": 0.5043246839654025
      },
      {
        "accuracy": 0.6952761144377911,
        "f1": 0.642161708329373,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.642161708329373,
        "precision": 0.6198998827741343,
        "recall": 0.6952761144377911
      },
      {
        "accuracy": 0.7817697937458417,
        "f1": 0.7399328327472041,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7399328327472041,
        "precision": 0.7215457972943001,
        "recall": 0.7817697937458417
      },
      {
        "accuracy": 0.2322022621423819,
        "f1": 0.1910227312422921,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1910227312422921,
        "precision": 0.17763492513991513,
        "recall": 0.2322022621423819
      },
      {
        "accuracy": 0.6586826347305389,
        "f1": 0.6032448330851524,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6032448330851524,
        "precision": 0.5809700704411283,
        "recall": 0.6586826347305389
      },
      {
        "accuracy": 0.8290086493679308,
        "f1": 0.792267317217417,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.792267317217417,
        "precision": 0.777450150204641,
        "recall": 0.8290086493679308
      },
      {
        "accuracy": 0.6473719228210246,
        "f1": 0.5987559753028815,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5987559753028815,
        "precision": 0.5794640876976206,
        "recall": 0.6473719228210246
      },
      {
        "accuracy": 0.669328010645376,
        "f1": 0.6144187814846497,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6144187814846497,
        "precision": 0.5910433102049869,
        "recall": 0.669328010645376
      },
      {
        "accuracy": 0.8130405854956753,
        "f1": 0.7790324113677407,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7790324113677407,
        "precision": 0.7646152140164116,
        "recall": 0.8130405854956753
      },
      {
        "accuracy": 0.5761809713905522,
        "f1": 0.519997570995575,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.519997570995575,
        "precision": 0.4978693406837119,
        "recall": 0.5761809713905522
      },
      {
        "accuracy": 0.3260146373918829,
        "f1": 0.2751941523398609,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2751941523398609,
        "precision": 0.2573788357720494,
        "recall": 0.3260146373918829
      },
      {
        "accuracy": 0.6719893546240852,
        "f1": 0.6256571513058539,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6256571513058539,
        "precision": 0.6071980857909002,
        "recall": 0.6719893546240852
      },
      {
        "accuracy": 0.44843646041250834,
        "f1": 0.3866990885952961,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3866990885952961,
        "precision": 0.36380994624507595,
        "recall": 0.44843646041250834
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.009574064613845577,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009574064613845577,
        "precision": 0.0078088277621819226,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.7984031936127745,
        "f1": 0.7622326775021385,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7622326775021385,
        "precision": 0.74709733971211,
        "recall": 0.7984031936127745
      },
      {
        "accuracy": 0.4683965402528277,
        "f1": 0.3983118419246164,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3983118419246164,
        "precision": 0.3713892321177751,
        "recall": 0.4683965402528277
      },
      {
        "accuracy": 0.552228875582169,
        "f1": 0.4816695613102799,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4816695613102799,
        "precision": 0.45362238485990986,
        "recall": 0.552228875582169
      },
      {
        "accuracy": 0.7511643379906853,
        "f1": 0.7093073113033194,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.7093073113033194,
        "precision": 0.6911122200044355,
        "recall": 0.7511643379906853
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.009471067854301386,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009471067854301386,
        "precision": 0.0076170410501747825,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.5316034597471723,
        "f1": 0.47552408410691843,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.47552408410691843,
        "precision": 0.4531289273305242,
        "recall": 0.5316034597471723
      },
      {
        "accuracy": 0.5555555555555556,
        "f1": 0.4923982722385916,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4923982722385916,
        "precision": 0.4672857987728247,
        "recall": 0.5555555555555556
      },
      {
        "accuracy": 0.48769128409846974,
        "f1": 0.4332028251189928,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.4332028251189928,
        "precision": 0.41223690185766027,
        "recall": 0.48769128409846974
      },
      {
        "accuracy": 0.7791084497671324,
        "f1": 0.7342331210594685,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7342331210594685,
        "precision": 0.7145265025504547,
        "recall": 0.7791084497671324
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.001604880428980074,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.001604880428980074,
        "precision": 0.0009222942034292306,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0030266630004203996,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0030266630004203996,
        "precision": 0.0023123956551021852,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.00334592821735345,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.00334592821735345,
        "precision": 0.0024211471301241383,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.003288665689066548,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.003288665689066548,
        "precision": 0.0022645042657345846,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.003930983936998986,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.003930983936998986,
        "precision": 0.003237138573677232,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.004167043864336836,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.004167043864336836,
        "precision": 0.0034021845223425433,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002360791886842905,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.002360791886842905,
        "precision": 0.0017698732001833117,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.003850656972465437,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.003850656972465437,
        "precision": 0.0030896784357082687,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004231673162952104,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.004231673162952104,
        "precision": 0.0033790941955160417,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.004429267278253752,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.004429267278253752,
        "precision": 0.003780562685037181,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.003794281124625895,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.003794281124625895,
        "precision": 0.0031052512595241403,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0039343752950838345,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0039343752950838345,
        "precision": 0.003674977872325466,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0037040964300458787,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0037040964300458787,
        "precision": 0.003316102682775581,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.002831172893494,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.002831172893494,
        "precision": 0.0022133999087817226,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0030128809576296326,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0030128809576296326,
        "precision": 0.0023764592692299947,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005957513332613551,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.005957513332613551,
        "precision": 0.004759381902522093,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0023205518514899754,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0023205518514899754,
        "precision": 0.0017115154445011538,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.017916104551086606,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.017916104551086606,
        "precision": 0.014137040488144249,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.003642848587521325,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.003642848587521325,
        "precision": 0.003063264276724975,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.003420708211926244,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.003420708211926244,
        "precision": 0.002585768076166829,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0026595199104365733,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0026595199104365733,
        "precision": 0.0021771126357558175,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.002859853581509045,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.002859853581509045,
        "precision": 0.0022559690128933344,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.7631403858948769,
        "f1": 0.7171149763964135,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7171149763964135,
        "precision": 0.6980277540157779,
        "recall": 0.7631403858948769
      },
      {
        "accuracy": 0.8762475049900199,
        "f1": 0.8480816145486804,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8480816145486804,
        "precision": 0.8356730982479486,
        "recall": 0.8762475049900199
      },
      {
        "accuracy": 0.2435129740518962,
        "f1": 0.20477370137461715,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.20477370137461715,
        "precision": 0.19148609743919123,
        "recall": 0.2435129740518962
      },
      {
        "accuracy": 0.7478376580172987,
        "f1": 0.7011991889237399,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7011991889237399,
        "precision": 0.6818981085448153,
        "recall": 0.7478376580172987
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8922377467287647,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8922377467287647,
        "precision": 0.8825792858726991,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.5602129075182968,
        "f1": 0.5116116972404398,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5116116972404398,
        "precision": 0.49293531743631547,
        "recall": 0.5602129075182968
      },
      {
        "accuracy": 0.7132401862940785,
        "f1": 0.660136869118905,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.660136869118905,
        "precision": 0.6377736590311441,
        "recall": 0.7132401862940785
      },
      {
        "accuracy": 0.8862275449101796,
        "f1": 0.8589630263282959,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8589630263282959,
        "precision": 0.8467905458923423,
        "recall": 0.8862275449101796
      },
      {
        "accuracy": 0.6440452428476381,
        "f1": 0.5908865290102815,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5908865290102815,
        "precision": 0.5701929474384564,
        "recall": 0.6440452428476381
      },
      {
        "accuracy": 0.37791084497671323,
        "f1": 0.3234628626345193,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3234628626345193,
        "precision": 0.3046552877890203,
        "recall": 0.37791084497671323
      },
      {
        "accuracy": 0.7691284098469727,
        "f1": 0.7313769286823179,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7313769286823179,
        "precision": 0.7161961790704305,
        "recall": 0.7691284098469727
      },
      {
        "accuracy": 0.5049900199600799,
        "f1": 0.44701448473903566,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.44701448473903566,
        "precision": 0.4248481872234367,
        "recall": 0.5049900199600799
      },
      {
        "accuracy": 0.7950765136393879,
        "f1": 0.7562055782614665,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7562055782614665,
        "precision": 0.7394884833507587,
        "recall": 0.7950765136393879
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.009425641261968608,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009425641261968608,
        "precision": 0.007659254944359532,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.5103127079174984,
        "f1": 0.4452883074639562,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.4452883074639562,
        "precision": 0.4210285777651048,
        "recall": 0.5103127079174984
      },
      {
        "accuracy": 0.6613439787092482,
        "f1": 0.5995141991149975,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5995141991149975,
        "precision": 0.5739977310336591,
        "recall": 0.6613439787092482
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.7990146690745493,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7990146690745493,
        "precision": 0.7846861831891772,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.006655198870767733,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006655198870767733,
        "precision": 0.005105947218780376,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.5608782435129741,
        "f1": 0.5000972081810405,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5000972081810405,
        "precision": 0.47672512118619903,
        "recall": 0.5608782435129741
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.5627681145645218,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5627681145645218,
        "precision": 0.5374610567225337,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.5482368596141052,
        "f1": 0.48939422741817945,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.48939422741817945,
        "precision": 0.4664823791570299,
        "recall": 0.5482368596141052
      },
      {
        "accuracy": 0.8789088489687292,
        "f1": 0.8506320691949435,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8506320691949435,
        "precision": 0.8383122643601686,
        "recall": 0.8789088489687292
      },
      {
        "accuracy": 0.4351297405189621,
        "f1": 0.3726661875863473,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.3726661875863473,
        "precision": 0.35141146278870833,
        "recall": 0.4351297405189621
      },
      {
        "accuracy": 0.5149700598802395,
        "f1": 0.44940428463382553,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.44940428463382553,
        "precision": 0.4263753231318101,
        "recall": 0.5149700598802395
      },
      {
        "accuracy": 0.14570858283433133,
        "f1": 0.11914915905211175,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.11914915905211175,
        "precision": 0.11110124336566188,
        "recall": 0.14570858283433133
      },
      {
        "accuracy": 0.36793080505655357,
        "f1": 0.31123964616391525,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.31123964616391525,
        "precision": 0.2925782273836166,
        "recall": 0.36793080505655357
      },
      {
        "accuracy": 0.4697272122421823,
        "f1": 0.401319064786248,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.401319064786248,
        "precision": 0.37949557796775124,
        "recall": 0.4697272122421823
      },
      {
        "accuracy": 0.21889554224883567,
        "f1": 0.1827195641132984,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.1827195641132984,
        "precision": 0.17123788949842725,
        "recall": 0.21889554224883567
      },
      {
        "accuracy": 0.4823685961410512,
        "f1": 0.4154589957983172,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.4154589957983172,
        "precision": 0.3914087169576192,
        "recall": 0.4823685961410512
      },
      {
        "accuracy": 0.5056553559547572,
        "f1": 0.44422914132905916,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.44422914132905916,
        "precision": 0.42359404567488407,
        "recall": 0.5056553559547572
      },
      {
        "accuracy": 0.34464404524284764,
        "f1": 0.2959395105044982,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.2959395105044982,
        "precision": 0.2795946946895051,
        "recall": 0.34464404524284764
      },
      {
        "accuracy": 0.14703925482368596,
        "f1": 0.11855192680384402,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.11855192680384402,
        "precision": 0.11005267003270995,
        "recall": 0.14703925482368596
      },
      {
        "accuracy": 0.3253493013972056,
        "f1": 0.2733578272684271,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.2733578272684271,
        "precision": 0.256967330370524,
        "recall": 0.3253493013972056
      },
      {
        "accuracy": 0.3366600133067199,
        "f1": 0.2874537883461213,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.2874537883461213,
        "precision": 0.2695211428993864,
        "recall": 0.3366600133067199
      },
      {
        "accuracy": 0.38988689288090483,
        "f1": 0.3309238000854767,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.3309238000854767,
        "precision": 0.3104829616306662,
        "recall": 0.38988689288090483
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.010384394847264772,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.010384394847264772,
        "precision": 0.007965838981494146,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.4737192282102462,
        "f1": 0.41187468605127564,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.41187468605127564,
        "precision": 0.39147576871834244,
        "recall": 0.4737192282102462
      },
      {
        "accuracy": 0.48303393213572854,
        "f1": 0.4183521845198492,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.4183521845198492,
        "precision": 0.39442198593895206,
        "recall": 0.48303393213572854
      },
      {
        "accuracy": 0.38922155688622756,
        "f1": 0.32517012631783093,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.32517012631783093,
        "precision": 0.3041042469156829,
        "recall": 0.38922155688622756
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.009561324681085162,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.009561324681085162,
        "precision": 0.007990632491630496,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.2322022621423819,
        "f1": 0.1879149354067938,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.1879149354067938,
        "precision": 0.17476872392042053,
        "recall": 0.2322022621423819
      },
      {
        "accuracy": 0.3180306054557552,
        "f1": 0.2656029211418433,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.2656029211418433,
        "precision": 0.24786965270997208,
        "recall": 0.3180306054557552
      },
      {
        "accuracy": 0.3093812375249501,
        "f1": 0.2588402559959446,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.2588402559959446,
        "precision": 0.24183290339399177,
        "recall": 0.3093812375249501
      },
      {
        "accuracy": 0.4644045242847638,
        "f1": 0.3926368338543987,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.3926368338543987,
        "precision": 0.36771561033038075,
        "recall": 0.4644045242847638
      },
      {
        "accuracy": 0.49833666001330673,
        "f1": 0.4359422611359913,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.4359422611359913,
        "precision": 0.4135272698396451,
        "recall": 0.49833666001330673
      },
      {
        "accuracy": 0.626746506986028,
        "f1": 0.5585680970910512,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.5585680970910512,
        "precision": 0.531468280370476,
        "recall": 0.626746506986028
      },
      {
        "accuracy": 0.16167664670658682,
        "f1": 0.13553154910440338,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.13553154910440338,
        "precision": 0.12750734575506084,
        "recall": 0.16167664670658682
      },
      {
        "accuracy": 0.5688622754491018,
        "f1": 0.5030351182047789,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.5030351182047789,
        "precision": 0.4790371877697227,
        "recall": 0.5688622754491018
      },
      {
        "accuracy": 0.6473719228210246,
        "f1": 0.5850785682123008,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.5850785682123008,
        "precision": 0.5629679793851451,
        "recall": 0.6473719228210246
      },
      {
        "accuracy": 0.3200266134397871,
        "f1": 0.2753510388337508,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.2753510388337508,
        "precision": 0.2605145070185578,
        "recall": 0.3200266134397871
      },
      {
        "accuracy": 0.6367265469061876,
        "f1": 0.5784008702172375,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.5784008702172375,
        "precision": 0.5550039725189426,
        "recall": 0.6367265469061876
      },
      {
        "accuracy": 0.6966067864271457,
        "f1": 0.6377859000613492,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.6377859000613492,
        "precision": 0.61485124988119,
        "recall": 0.6966067864271457
      },
      {
        "accuracy": 0.4337990685296075,
        "f1": 0.37910321732677016,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.37910321732677016,
        "precision": 0.3594886539497318,
        "recall": 0.4337990685296075
      },
      {
        "accuracy": 0.2262142381902861,
        "f1": 0.18287922988521788,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.18287922988521788,
        "precision": 0.16922770620375407,
        "recall": 0.2262142381902861
      },
      {
        "accuracy": 0.4524284763805722,
        "f1": 0.3940487113824649,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.3940487113824649,
        "precision": 0.37448098031930366,
        "recall": 0.4524284763805722
      },
      {
        "accuracy": 0.38256819693945443,
        "f1": 0.3268884844733148,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.3268884844733148,
        "precision": 0.30725638669750444,
        "recall": 0.38256819693945443
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.4714655345393868,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.4714655345393868,
        "precision": 0.4473582176675989,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.012940506546715184,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.012940506546715184,
        "precision": 0.010716474543658885,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.6214238190286094,
        "f1": 0.5609669549789309,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.5609669549789309,
        "precision": 0.5380846772064336,
        "recall": 0.6214238190286094
      },
      {
        "accuracy": 0.47704590818363274,
        "f1": 0.4117573562683344,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.4117573562683344,
        "precision": 0.3864886222670654,
        "recall": 0.47704590818363274
      },
      {
        "accuracy": 0.5269461077844312,
        "f1": 0.45920122237487504,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.45920122237487504,
        "precision": 0.43469753614464185,
        "recall": 0.5269461077844312
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.010439610832941818,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.010439610832941818,
        "precision": 0.008588246786849583,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.37258815701929476,
        "f1": 0.31342811841813834,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.31342811841813834,
        "precision": 0.2940877984291158,
        "recall": 0.37258815701929476
      },
      {
        "accuracy": 0.42381902860944776,
        "f1": 0.3616703581773442,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.3616703581773442,
        "precision": 0.33942302984219147,
        "recall": 0.42381902860944776
      },
      {
        "accuracy": 0.3772455089820359,
        "f1": 0.32273500137771594,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.32273500137771594,
        "precision": 0.30393604325740053,
        "recall": 0.3772455089820359
      },
      {
        "accuracy": 0.6999334664005322,
        "f1": 0.6425292272597661,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.6425292272597661,
        "precision": 0.6195133542438931,
        "recall": 0.6999334664005322
      },
      {
        "accuracy": 0.6739853626081171,
        "f1": 0.6234753146870089,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6234753146870089,
        "precision": 0.6032969774736242,
        "recall": 0.6739853626081171
      },
      {
        "accuracy": 0.8343313373253493,
        "f1": 0.8015682919874536,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8015682919874536,
        "precision": 0.7878592022304598,
        "recall": 0.8343313373253493
      },
      {
        "accuracy": 0.19494344644045242,
        "f1": 0.16041060553587225,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.16041060553587225,
        "precision": 0.14924758863129264,
        "recall": 0.19494344644045242
      },
      {
        "accuracy": 0.6387225548902196,
        "f1": 0.5819816355744499,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5819816355744499,
        "precision": 0.560664649536905,
        "recall": 0.6387225548902196
      },
      {
        "accuracy": 0.895542248835662,
        "f1": 0.8735338846117289,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8735338846117289,
        "precision": 0.8646326394829388,
        "recall": 0.895542248835662
      },
      {
        "accuracy": 0.5109780439121756,
        "f1": 0.46039155878888177,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.46039155878888177,
        "precision": 0.44257372238909165,
        "recall": 0.5109780439121756
      },
      {
        "accuracy": 0.6314038589487692,
        "f1": 0.571216393571683,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.571216393571683,
        "precision": 0.5483519973040931,
        "recall": 0.6314038589487692
      },
      {
        "accuracy": 0.8489687292082502,
        "f1": 0.8189953426480371,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8189953426480371,
        "precision": 0.8063935620821847,
        "recall": 0.8489687292082502
      },
      {
        "accuracy": 0.5801729873586161,
        "f1": 0.5228907744875809,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5228907744875809,
        "precision": 0.5016195122981549,
        "recall": 0.5801729873586161
      },
      {
        "accuracy": 0.31137724550898205,
        "f1": 0.2631206752405531,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2631206752405531,
        "precision": 0.2474306917670191,
        "recall": 0.31137724550898205
      },
      {
        "accuracy": 0.688622754491018,
        "f1": 0.6407565820739474,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6407565820739474,
        "precision": 0.6220680572476979,
        "recall": 0.688622754491018
      },
      {
        "accuracy": 0.46640053226879574,
        "f1": 0.40445938330169867,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.40445938330169867,
        "precision": 0.38149573868136744,
        "recall": 0.46640053226879574
      },
      {
        "accuracy": 0.7391882900864937,
        "f1": 0.6954804676361563,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6954804676361563,
        "precision": 0.6779187656433164,
        "recall": 0.7391882900864937
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.006650365096012501,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006650365096012501,
        "precision": 0.005312503694820373,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.78334917466654,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.78334917466654,
        "precision": 0.7695783037100402,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.41783100465735196,
        "f1": 0.35198650318410796,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.35198650318410796,
        "precision": 0.32792407008973873,
        "recall": 0.41783100465735196
      },
      {
        "accuracy": 0.5489021956087824,
        "f1": 0.48769190815098995,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.48769190815098995,
        "precision": 0.46456164150774926,
        "recall": 0.5489021956087824
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.00882200245972701,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00882200245972701,
        "precision": 0.007169624040720557,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.5089820359281437,
        "f1": 0.454779426236512,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.454779426236512,
        "precision": 0.43501177059061297,
        "recall": 0.5089820359281437
      },
      {
        "accuracy": 0.5868263473053892,
        "f1": 0.5294907539418517,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5294907539418517,
        "precision": 0.5058224820200868,
        "recall": 0.5868263473053892
      },
      {
        "accuracy": 0.49101796407185627,
        "f1": 0.4316087069580083,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.4316087069580083,
        "precision": 0.4101527104521116,
        "recall": 0.49101796407185627
      },
      {
        "accuracy": 0.812375249500998,
        "f1": 0.7744510978043913,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7744510978043913,
        "precision": 0.7583848176662548,
        "recall": 0.812375249500998
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0038064478586276773,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0038064478586276773,
        "precision": 0.0029610919027679597,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0040448675367826216,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0040448675367826216,
        "precision": 0.003513547507602408,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.003491945553041695,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.003491945553041695,
        "precision": 0.0026976394074561378,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.004161209515084461,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.004161209515084461,
        "precision": 0.0033294915986266053,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.005632904046521589,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.005632904046521589,
        "precision": 0.005063536097745789,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004896955940611477,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.004896955940611477,
        "precision": 0.004322014124706628,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0024842266168883706,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0024842266168883706,
        "precision": 0.002044885191990747,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.003483553809618623,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.003483553809618623,
        "precision": 0.002559494855273966,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0031658544058638647,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0031658544058638647,
        "precision": 0.0024992511462493872,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.004418579876037233,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.004418579876037233,
        "precision": 0.0039396666769952364,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.004160035847685621,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.004160035847685621,
        "precision": 0.0037906124613439987,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0024161181628597683,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0024161181628597683,
        "precision": 0.0018392389412508964,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0030309477065290605,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0030309477065290605,
        "precision": 0.0028606143022417577,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.022455875653345902,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.022455875653345902,
        "precision": 0.019533031204253974,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0016525301857861568,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0016525301857861568,
        "precision": 0.0010510949946659737,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004335850847873386,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.004335850847873386,
        "precision": 0.0036549447175916144,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.004588327808554023,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.004588327808554023,
        "precision": 0.003477764106333258,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004368514263577368,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.004368514263577368,
        "precision": 0.0035480568219781695,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0023991387294306733,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0023991387294306733,
        "precision": 0.0020013677107429797,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.005180165062306159,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.005180165062306159,
        "precision": 0.004139428013018099,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0025321918540420914,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0025321918540420914,
        "precision": 0.0020917701864357216,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.002430264825500014,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.002430264825500014,
        "precision": 0.0020208434141024056,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.49700598802395207,
        "f1": 0.4430903439570315,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4430903439570315,
        "precision": 0.4235080344361781,
        "recall": 0.49700598802395207
      },
      {
        "accuracy": 0.5894876912840985,
        "f1": 0.5276648242716107,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5276648242716107,
        "precision": 0.5038623810579899,
        "recall": 0.5894876912840985
      },
      {
        "accuracy": 0.26147704590818366,
        "f1": 0.22304812673487087,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.22304812673487087,
        "precision": 0.20944363816120307,
        "recall": 0.26147704590818366
      },
      {
        "accuracy": 0.5988023952095808,
        "f1": 0.5489735296122522,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5489735296122522,
        "precision": 0.5293043542544541,
        "recall": 0.5988023952095808
      },
      {
        "accuracy": 0.633399866932801,
        "f1": 0.5785886380197757,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5785886380197757,
        "precision": 0.5584178684478085,
        "recall": 0.633399866932801
      },
      {
        "accuracy": 0.45109780439121755,
        "f1": 0.40592506719664173,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.40592506719664173,
        "precision": 0.39010273104584486,
        "recall": 0.45109780439121755
      },
      {
        "accuracy": 0.4471057884231537,
        "f1": 0.38356819863805885,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.38356819863805885,
        "precision": 0.36018285698924424,
        "recall": 0.4471057884231537
      },
      {
        "accuracy": 0.6453759148369926,
        "f1": 0.592070884685655,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.592070884685655,
        "precision": 0.5723274371947613,
        "recall": 0.6453759148369926
      },
      {
        "accuracy": 0.4258150365934797,
        "f1": 0.3792857261603978,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.3792857261603978,
        "precision": 0.3615208975987419,
        "recall": 0.4258150365934797
      },
      {
        "accuracy": 0.3592814371257485,
        "f1": 0.3082624356018744,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3082624356018744,
        "precision": 0.288853113878064,
        "recall": 0.3592814371257485
      },
      {
        "accuracy": 0.5482368596141052,
        "f1": 0.49522863844221127,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.49522863844221127,
        "precision": 0.4754015777967874,
        "recall": 0.5482368596141052
      },
      {
        "accuracy": 0.31869594145043245,
        "f1": 0.2675379399930298,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.2675379399930298,
        "precision": 0.249463920100907,
        "recall": 0.31869594145043245
      },
      {
        "accuracy": 0.5316034597471723,
        "f1": 0.4772947611270964,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4772947611270964,
        "precision": 0.4576598126498326,
        "recall": 0.5316034597471723
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.007227709669817934,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007227709669817934,
        "precision": 0.00570600215845807,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.5708582834331337,
        "f1": 0.5182309065483893,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5182309065483893,
        "precision": 0.49840416569458484,
        "recall": 0.5708582834331337
      },
      {
        "accuracy": 0.2934131736526946,
        "f1": 0.24032070908318412,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.24032070908318412,
        "precision": 0.22333082272204027,
        "recall": 0.2934131736526946
      },
      {
        "accuracy": 0.40585495675316036,
        "f1": 0.3416907406927367,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.3416907406927367,
        "precision": 0.31866776307894074,
        "recall": 0.40585495675316036
      },
      {
        "accuracy": 0.5262807717897539,
        "f1": 0.4701557683094609,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.4701557683094609,
        "precision": 0.44890093762055716,
        "recall": 0.5262807717897539
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.00665556813261404,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00665556813261404,
        "precision": 0.004870505901776693,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.37192282102461743,
        "f1": 0.31575799819312794,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.31575799819312794,
        "precision": 0.2958099673668536,
        "recall": 0.37192282102461743
      },
      {
        "accuracy": 0.3479707252162342,
        "f1": 0.29854682170051433,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.29854682170051433,
        "precision": 0.28049578926246643,
        "recall": 0.3479707252162342
      },
      {
        "accuracy": 0.5874916833000665,
        "f1": 0.5282650003208885,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5282650003208885,
        "precision": 0.5059283789323709,
        "recall": 0.5874916833000665
      },
      {
        "accuracy": 0.5043246839654025,
        "f1": 0.4463871199400142,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.4463871199400142,
        "precision": 0.42427252151225253,
        "recall": 0.5043246839654025
      },
      {
        "accuracy": 0.6799733865602129,
        "f1": 0.6270918480499319,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.6270918480499319,
        "precision": 0.6048791306276335,
        "recall": 0.6799733865602129
      },
      {
        "accuracy": 0.15036593479707253,
        "f1": 0.1259589767074797,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.1259589767074797,
        "precision": 0.11715672296862857,
        "recall": 0.15036593479707253
      },
      {
        "accuracy": 0.48436460412508314,
        "f1": 0.43043129709796374,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.43043129709796374,
        "precision": 0.4103925146340316,
        "recall": 0.48436460412508314
      },
      {
        "accuracy": 0.7172322022621423,
        "f1": 0.6656385641415581,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.6656385641415581,
        "precision": 0.6448735045541433,
        "recall": 0.7172322022621423
      },
      {
        "accuracy": 0.3273453093812375,
        "f1": 0.2828902708144225,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.2828902708144225,
        "precision": 0.2680791362769512,
        "recall": 0.3273453093812375
      },
      {
        "accuracy": 0.47837658017298734,
        "f1": 0.41933901834101434,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.41933901834101434,
        "precision": 0.39671925989291257,
        "recall": 0.47837658017298734
      },
      {
        "accuracy": 0.7032601463739189,
        "f1": 0.6529708260247183,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.6529708260247183,
        "precision": 0.6317550085015154,
        "recall": 0.7032601463739189
      },
      {
        "accuracy": 0.5528942115768463,
        "f1": 0.49574237767850543,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.49574237767850543,
        "precision": 0.47288835028355986,
        "recall": 0.5528942115768463
      },
      {
        "accuracy": 0.21689953426480374,
        "f1": 0.17931577668945037,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.17931577668945037,
        "precision": 0.16714776315574717,
        "recall": 0.21689953426480374
      },
      {
        "accuracy": 0.4564204923486361,
        "f1": 0.40896091415053487,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.40896091415053487,
        "precision": 0.39096040722787223,
        "recall": 0.4564204923486361
      },
      {
        "accuracy": 0.48369926813040587,
        "f1": 0.4287862614209919,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.4287862614209919,
        "precision": 0.40725849887526533,
        "recall": 0.48369926813040587
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.47710127161224963,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.47710127161224963,
        "precision": 0.45533456895732344,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.007353430064414485,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.007353430064414485,
        "precision": 0.005549735292137281,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.6180971390552229,
        "f1": 0.5628489053638753,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.5628489053638753,
        "precision": 0.5403874790102335,
        "recall": 0.6180971390552229
      },
      {
        "accuracy": 0.35395874916833003,
        "f1": 0.29439648840846444,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.29439648840846444,
        "precision": 0.2726055092164978,
        "recall": 0.35395874916833003
      },
      {
        "accuracy": 0.4417831004657352,
        "f1": 0.3765948769940786,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.3765948769940786,
        "precision": 0.35271467646717153,
        "recall": 0.4417831004657352
      },
      {
        "accuracy": 0.582168995342648,
        "f1": 0.5260273104584482,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.5260273104584482,
        "precision": 0.5024815688488343,
        "recall": 0.582168995342648
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.006735092363834879,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.006735092363834879,
        "precision": 0.0052559143377506655,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.35063206919494344,
        "f1": 0.30098533092545066,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.30098533092545066,
        "precision": 0.28273060199207906,
        "recall": 0.35063206919494344
      },
      {
        "accuracy": 0.4637391882900865,
        "f1": 0.40473233427325245,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.40473233427325245,
        "precision": 0.381499699014669,
        "recall": 0.4637391882900865
      },
      {
        "accuracy": 0.6473719228210246,
        "f1": 0.5920676351814076,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.5920676351814076,
        "precision": 0.5686257115398832,
        "recall": 0.6473719228210246
      },
      {
        "accuracy": 0.41317365269461076,
        "f1": 0.36514906694547417,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.36514906694547417,
        "precision": 0.34766924322812554,
        "recall": 0.41317365269461076
      },
      {
        "accuracy": 0.541583499667332,
        "f1": 0.4840530579053533,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.4840530579053533,
        "precision": 0.4634297542481175,
        "recall": 0.541583499667332
      },
      {
        "accuracy": 0.18296739853626082,
        "f1": 0.15774218758250694,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.15774218758250694,
        "precision": 0.14919609784585716,
        "recall": 0.18296739853626082
      },
      {
        "accuracy": 0.4098469727212242,
        "f1": 0.364791595629919,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.364791595629919,
        "precision": 0.3483794316129645,
        "recall": 0.4098469727212242
      },
      {
        "accuracy": 0.571523619427811,
        "f1": 0.5164449840098542,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.5164449840098542,
        "precision": 0.4956660752568936,
        "recall": 0.571523619427811
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.3169656308320157,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.3169656308320157,
        "precision": 0.3041954690906787,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.4517631403858949,
        "f1": 0.3979944059784379,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.3979944059784379,
        "precision": 0.3773981378272795,
        "recall": 0.4517631403858949
      },
      {
        "accuracy": 0.5768463073852296,
        "f1": 0.519590151476379,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.519590151476379,
        "precision": 0.4981719556540503,
        "recall": 0.5768463073852296
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.4984623345900791,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.4984623345900791,
        "precision": 0.47775163957798683,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.21956087824351297,
        "f1": 0.18779225807012337,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.18779225807012337,
        "precision": 0.17763837404555965,
        "recall": 0.21956087824351297
      },
      {
        "accuracy": 0.4111776447105788,
        "f1": 0.3672432099577808,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.3672432099577808,
        "precision": 0.3517935029412075,
        "recall": 0.4111776447105788
      },
      {
        "accuracy": 0.42980705256154356,
        "f1": 0.3742969568318869,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.3742969568318869,
        "precision": 0.3539424037927032,
        "recall": 0.42980705256154356
      },
      {
        "accuracy": 0.46640053226879574,
        "f1": 0.42019467558389717,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.42019467558389717,
        "precision": 0.40358861401775575,
        "recall": 0.46640053226879574
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.008558064246687001,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.008558064246687001,
        "precision": 0.00683884989907092,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.5276114437791084,
        "f1": 0.4747275290688464,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.4747275290688464,
        "precision": 0.4548618719119822,
        "recall": 0.5276114437791084
      },
      {
        "accuracy": 0.33998669328010644,
        "f1": 0.2872234847284747,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.2872234847284747,
        "precision": 0.26780222623536,
        "recall": 0.33998669328010644
      },
      {
        "accuracy": 0.38589487691284097,
        "f1": 0.3324736769846551,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.3324736769846551,
        "precision": 0.312737711390406,
        "recall": 0.38589487691284097
      },
      {
        "accuracy": 0.5123087159015303,
        "f1": 0.4538468517510433,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.4538468517510433,
        "precision": 0.43174209541475006,
        "recall": 0.5123087159015303
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.009063930820417846,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.009063930820417846,
        "precision": 0.007738755293645513,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.31736526946107785,
        "f1": 0.2852224603222607,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.2852224603222607,
        "precision": 0.27391086772324297,
        "recall": 0.31736526946107785
      },
      {
        "accuracy": 0.4577511643379907,
        "f1": 0.40148337284065816,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.40148337284065816,
        "precision": 0.3801102762023026,
        "recall": 0.4577511643379907
      },
      {
        "accuracy": 0.5209580838323353,
        "f1": 0.4600675808260638,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.4600675808260638,
        "precision": 0.43820190307216256,
        "recall": 0.5209580838323353
      },
      {
        "accuracy": 0.7604790419161677,
        "f1": 0.7170500269302664,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.7170500269302664,
        "precision": 0.6991857554731806,
        "recall": 0.7604790419161677
      },
      {
        "accuracy": 0.8802395209580839,
        "f1": 0.8561432690175205,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.8561432690175205,
        "precision": 0.8457592751005925,
        "recall": 0.8802395209580839
      },
      {
        "accuracy": 0.22554890219560877,
        "f1": 0.18817795422585842,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.18817795422585842,
        "precision": 0.17583023508997647,
        "recall": 0.22554890219560877
      },
      {
        "accuracy": 0.7638057218895542,
        "f1": 0.7162056838703544,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7162056838703544,
        "precision": 0.6966954978931026,
        "recall": 0.7638057218895542
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9068973164781547,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9068973164781547,
        "precision": 0.8987802173430917,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.49500998003992014,
        "f1": 0.4436725394809227,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.4436725394809227,
        "precision": 0.4246969024913137,
        "recall": 0.49500998003992014
      },
      {
        "accuracy": 0.720558882235529,
        "f1": 0.6672701882282721,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.6672701882282721,
        "precision": 0.6449545353736971,
        "recall": 0.720558882235529
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.8999999999999999,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.8999999999999999,
        "precision": 0.8920714127300954,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.6280771789753826,
        "f1": 0.5726256481745504,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.5726256481745504,
        "precision": 0.5512889564785771,
        "recall": 0.6280771789753826
      },
      {
        "accuracy": 0.4856952761144378,
        "f1": 0.43116924474209906,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.43116924474209906,
        "precision": 0.41057655224028355,
        "recall": 0.4856952761144378
      },
      {
        "accuracy": 0.7445109780439122,
        "f1": 0.7022785117595497,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7022785117595497,
        "precision": 0.685319044450781,
        "recall": 0.7445109780439122
      },
      {
        "accuracy": 0.5216234198270127,
        "f1": 0.4618931929311171,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.4618931929311171,
        "precision": 0.43942934237345416,
        "recall": 0.5216234198270127
      },
      {
        "accuracy": 0.7797737857618097,
        "f1": 0.7414187498019833,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7414187498019833,
        "precision": 0.7262601780565852,
        "recall": 0.7797737857618097
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.008705516008839355,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.008705516008839355,
        "precision": 0.006548067082879809,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.8376928682317905,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.8376928682317905,
        "precision": 0.8256537430190125,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.5056553559547572,
        "f1": 0.43550417203111813,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.43550417203111813,
        "precision": 0.4090446091943098,
        "recall": 0.5056553559547572
      },
      {
        "accuracy": 0.7252162341982701,
        "f1": 0.6692408833127396,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.6692408833127396,
        "precision": 0.6455707632354339,
        "recall": 0.7252162341982701
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7875043563666319,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.7875043563666319,
        "precision": 0.7718008427589266,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.007225726886405529,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007225726886405529,
        "precision": 0.005846410770772573,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.6001330671989354,
        "f1": 0.5445156492062679,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.5445156492062679,
        "precision": 0.5231634614369145,
        "recall": 0.6001330671989354
      },
      {
        "accuracy": 0.654690618762475,
        "f1": 0.6029290625099009,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.6029290625099009,
        "precision": 0.580700503754396,
        "recall": 0.654690618762475
      },
      {
        "accuracy": 0.5449101796407185,
        "f1": 0.4823036466749042,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.4823036466749042,
        "precision": 0.45893768019516523,
        "recall": 0.5449101796407185
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}