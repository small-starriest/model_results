{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 23.375675201416016,
  "kg_co2_emissions": 0.009261076394901558,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8314620914166958,
        "cosine_spearman": 0.8121304982811004,
        "euclidean_pearson": 0.8130399360741561,
        "euclidean_spearman": 0.8121304982811004,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.8121304982811004,
        "manhattan_pearson": 0.80395208947215,
        "manhattan_spearman": 0.8064476979357564,
        "pearson": 0.8314620914166958,
        "spearman": 0.8121304982811004
      },
      {
        "cosine_pearson": 0.7765524602431892,
        "cosine_spearman": 0.7721251636420521,
        "euclidean_pearson": 0.7588346324550125,
        "euclidean_spearman": 0.7721251636420521,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7721251636420521,
        "manhattan_pearson": 0.7592012001315086,
        "manhattan_spearman": 0.7716954329830096,
        "pearson": 0.7765524602431892,
        "spearman": 0.7721251636420521
      },
      {
        "cosine_pearson": 0.6183477926438368,
        "cosine_spearman": 0.6244505707960685,
        "euclidean_pearson": 0.6105557598445693,
        "euclidean_spearman": 0.6244505707960685,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.6244505707960685,
        "manhattan_pearson": 0.59765876282942,
        "manhattan_spearman": 0.6106957158643701,
        "pearson": 0.6183477926438368,
        "spearman": 0.6244505707960685
      },
      {
        "cosine_pearson": 0.5717234154038863,
        "cosine_spearman": 0.5314609247568162,
        "euclidean_pearson": 0.5716641989646543,
        "euclidean_spearman": 0.531465601417354,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.5314609247568162,
        "manhattan_pearson": 0.5725714466498375,
        "manhattan_spearman": 0.5332226241605617,
        "pearson": 0.5717234154038863,
        "spearman": 0.5314609247568162
      },
      {
        "cosine_pearson": 0.4831425861534969,
        "cosine_spearman": 0.47149251373297796,
        "euclidean_pearson": 0.4789035572869865,
        "euclidean_spearman": 0.47149251373297796,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.47149251373297796,
        "manhattan_pearson": 0.4784861534849251,
        "manhattan_spearman": 0.4711750120299445,
        "pearson": 0.4831425861534969,
        "spearman": 0.47149251373297796
      },
      {
        "cosine_pearson": 0.8344403836973366,
        "cosine_spearman": 0.8192518420729024,
        "euclidean_pearson": 0.8294953573006402,
        "euclidean_spearman": 0.8192518420729024,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8192518420729024,
        "manhattan_pearson": 0.8238426925335395,
        "manhattan_spearman": 0.8084755085188178,
        "pearson": 0.8344403836973366,
        "spearman": 0.8192518420729024
      },
      {
        "cosine_pearson": 0.5603484051489315,
        "cosine_spearman": 0.5349230743013745,
        "euclidean_pearson": 0.5565812791764417,
        "euclidean_spearman": 0.5349230743013745,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.5349230743013745,
        "manhattan_pearson": 0.5620079217790082,
        "manhattan_spearman": 0.5428485969854357,
        "pearson": 0.5603484051489315,
        "spearman": 0.5349230743013745
      },
      {
        "cosine_pearson": 0.7792404438833314,
        "cosine_spearman": 0.7875648863111774,
        "euclidean_pearson": 0.7524253344084882,
        "euclidean_spearman": 0.7875648863111774,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7875648863111774,
        "manhattan_pearson": 0.7475733409615898,
        "manhattan_spearman": 0.7851543240896348,
        "pearson": 0.7792404438833314,
        "spearman": 0.7875648863111774
      },
      {
        "cosine_pearson": 0.5353151963185775,
        "cosine_spearman": 0.5321234834973624,
        "euclidean_pearson": 0.5460376263963593,
        "euclidean_spearman": 0.5321234834973624,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5321234834973624,
        "manhattan_pearson": 0.5406708800957383,
        "manhattan_spearman": 0.525129653894895,
        "pearson": 0.5353151963185775,
        "spearman": 0.5321234834973624
      },
      {
        "cosine_pearson": 0.5578068181366497,
        "cosine_spearman": 0.5426930277718763,
        "euclidean_pearson": 0.5617335595408547,
        "euclidean_spearman": 0.5426930277718763,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5426930277718763,
        "manhattan_pearson": 0.5706192665069538,
        "manhattan_spearman": 0.5516686439219877,
        "pearson": 0.5578068181366497,
        "spearman": 0.5426930277718763
      },
      {
        "cosine_pearson": 0.7894635502287309,
        "cosine_spearman": 0.7613362183303183,
        "euclidean_pearson": 0.7815674673917359,
        "euclidean_spearman": 0.7613362183303183,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7613362183303183,
        "manhattan_pearson": 0.7816332382344325,
        "manhattan_spearman": 0.7624210539956345,
        "pearson": 0.7894635502287309,
        "spearman": 0.7613362183303183
      },
      {
        "cosine_pearson": 0.8071524054738644,
        "cosine_spearman": 0.7753376200349847,
        "euclidean_pearson": 0.7881801248734044,
        "euclidean_spearman": 0.7753376200349847,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7753376200349847,
        "manhattan_pearson": 0.7892470258144055,
        "manhattan_spearman": 0.7777770990211205,
        "pearson": 0.8071524054738644,
        "spearman": 0.7753376200349847
      }
    ]
  },
  "task_name": "SemRel24STS"
}