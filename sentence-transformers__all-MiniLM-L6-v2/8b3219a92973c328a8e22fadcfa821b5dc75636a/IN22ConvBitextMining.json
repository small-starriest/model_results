{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 20.803040742874146,
  "kg_co2_emissions": 0.0031264883006695008,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.0530088521752253,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.0530088521752253,
        "precision": 0.04686459922693338,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0017238250771184902,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0017238250771184902,
        "precision": 0.0015841333206602665,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013398490375570698,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0013398490375570698,
        "precision": 0.00133529237820655,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006699710066086557,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0006699710066086557,
        "precision": 0.0006676575461067806,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 6.941852518990925e-05,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 6.941852518990925e-05,
        "precision": 3.5642999714856005e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0021334959158449992,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0021334959158449992,
        "precision": 0.0018986303769678195,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000949018898556716,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.000949018898556716,
        "precision": 0.0008405065935628913,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00038184239248353506,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.00038184239248353506,
        "precision": 0.0002465979972394574,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 5.350443699285478e-06,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 5.350443699285478e-06,
        "precision": 2.6809485733761275e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0012896543255433318,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0012896543255433318,
        "precision": 0.0010348416926238726,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0004657351962741184,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0004657351962741184,
        "precision": 0.0003439448786043731,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0004795214376052699,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0004795214376052699,
        "precision": 0.00035114955274635914,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0010448355889923087,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0010448355889923087,
        "precision": 0.0009111189385934014,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.0025193880451186e-05,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 1.0025193880451186e-05,
        "precision": 5.0403854751855874e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0014163394344209185,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0014163394344209185,
        "precision": 0.0011541937849936378,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0014758759330642248,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0014758759330642248,
        "precision": 0.0012371658313841815,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006858428250537313,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0006858428250537313,
        "precision": 0.0004538799519084941,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008605315205986695,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0008605315205986695,
        "precision": 0.0007707555106026218,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007363560821674716,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0007363560821674716,
        "precision": 0.0007018175024790025,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006426652867105295,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0006426652867105295,
        "precision": 0.0004419667916125137,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0010110497958331702,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0010110497958331702,
        "precision": 0.0008937021446655643,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00012344815475983308,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.00012344815475983308,
        "precision": 6.777489796526351e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.07984031936127745,
        "f1": 0.04824099250944769,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.04824099250944769,
        "precision": 0.0401880268688757,
        "recall": 0.07984031936127745
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007338579545889065,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0007338579545889065,
        "precision": 0.0007007947928432541,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0020140075769064197,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0020140075769064197,
        "precision": 0.0020051137572037856,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 1.6267383732941614e-06,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 1.6267383732941614e-06,
        "precision": 8.143647425670893e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001802834655844877,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.001802834655844877,
        "precision": 0.0016777868940672236,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013341372809935683,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0013341372809935683,
        "precision": 0.0013324091590535202,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017328796322532989,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0017328796322532989,
        "precision": 0.001563397073661734,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007002330090322823,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0007002330090322823,
        "precision": 0.0006831924386521076,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006987575408411325,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0006987575408411325,
        "precision": 0.0006821712756099207,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0001874378562179431,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0001874378562179431,
        "precision": 9.91165465821467e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000698188261756401,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.000698188261756401,
        "precision": 0.0006821318988949295,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006670777119408653,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0006670777119408653,
        "precision": 0.000666207994670336,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006676302567279234,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0006676302567279234,
        "precision": 0.0006664851069306407,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006709393166517818,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0006709393166517818,
        "precision": 0.0006681436169512297,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006805679815015047,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0006805679815015047,
        "precision": 0.0006729908165106293,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006704737243659399,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0006704737243659399,
        "precision": 0.0006679148163621078,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0014368196461456747,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.0014368196461456747,
        "precision": 0.001387427830541603,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0003032009888397896,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0003032009888397896,
        "precision": 0.000185204023280821,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0013423768339318597,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0013423768339318597,
        "precision": 0.0013365423488251836,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006869870827690422,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0006869870827690422,
        "precision": 0.0006762396418567947,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 3.080259234617185e-06,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 3.080259234617185e-06,
        "precision": 1.543703003891675e-06,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0013468385955402846,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0013468385955402846,
        "precision": 0.0013387888589365337,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.001224435356171883,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.001224435356171883,
        "precision": 0.000889449171831775,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007071835323801501,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0007071835323801501,
        "precision": 0.0006868555200462814,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.02361938245014198,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.02361938245014198,
        "precision": 0.021653542362125196,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000598915532167469,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.000598915532167469,
        "precision": 0.0003723784243894842,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.020373263899338682,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.020373263899338682,
        "precision": 0.018843097878556373,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.011089165430299147,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011089165430299147,
        "precision": 0.00985375864304448,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.03170944217272613,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.03170944217272613,
        "precision": 0.02939256621891352,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.001510381052036613,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.001510381052036613,
        "precision": 0.0014286397637342805,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.004055113560047354,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.004055113560047354,
        "precision": 0.003835186769318506,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.010882352805376987,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.010882352805376987,
        "precision": 0.009932353445327497,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.02185650756944266,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.02185650756944266,
        "precision": 0.02110244419617609,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.008683390794169236,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.008683390794169236,
        "precision": 0.00784420081310172,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002984431032916825,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002984431032916825,
        "precision": 0.0024230456406675515,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.01205137088853527,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.01205137088853527,
        "precision": 0.010730535429016962,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0023619427811044577,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0023619427811044577,
        "precision": 0.0022348465462237914,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.016067945559900324,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.016067945559900324,
        "precision": 0.01535530998709904,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.011951976960357021,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.011951976960357021,
        "precision": 0.01047063974045901,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0009966964119560832,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009966964119560832,
        "precision": 0.0006533794590874359,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.02266966137256845,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02266966137256845,
        "precision": 0.021252303840950077,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0073336473121173385,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0073336473121173385,
        "precision": 0.007104477912861147,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.024796808324137026,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.024796808324137026,
        "precision": 0.023291385571873685,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.004923445751106064,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.004923445751106064,
        "precision": 0.004680112628278796,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.001568498641616979,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.001568498641616979,
        "precision": 0.0014606876882325983,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008918413874611264,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0008918413874611264,
        "precision": 0.0007889059732740791,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.027961896798589538,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.027961896798589538,
        "precision": 0.025377314953395347,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 4.293628978572922e-06,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 4.293628978572922e-06,
        "precision": 2.150353294873984e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0658682634730539,
        "f1": 0.04963614414712219,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04963614414712219,
        "precision": 0.04524206295663381,
        "recall": 0.0658682634730539
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.011796413029035504,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011796413029035504,
        "precision": 0.010431399476673413,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.2055888223552894,
        "f1": 0.16012570988872257,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.16012570988872257,
        "precision": 0.14501433640655198,
        "recall": 0.2055888223552894
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0014878360835414279,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0014878360835414279,
        "precision": 0.0014167568043461116,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.005155871785543476,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.005155871785543476,
        "precision": 0.0047272031519250916,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.11244178310046574,
        "f1": 0.08284652436349042,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08284652436349042,
        "precision": 0.07412243564644645,
        "recall": 0.11244178310046574
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.019568177199256503,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.019568177199256503,
        "precision": 0.01764624244109718,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.059214903526280775,
        "f1": 0.04324367138738396,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04324367138738396,
        "precision": 0.038658060199188465,
        "recall": 0.059214903526280775
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014606059516239155,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0014606059516239155,
        "precision": 0.001156740568677564,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.09181636726546906,
        "f1": 0.06316278531847394,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.06316278531847394,
        "precision": 0.05499631587455937,
        "recall": 0.09181636726546906
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015800213902439368,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0015800213902439368,
        "precision": 0.0014776247002970025,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.019787189111697988,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.019787189111697988,
        "precision": 0.01882737792389078,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.02230275700002912,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.02230275700002912,
        "precision": 0.019615677284550066,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0028752022969290923,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0028752022969290923,
        "precision": 0.0023836079282863604,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.09447771124417831,
        "f1": 0.07289510039011037,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.07289510039011037,
        "precision": 0.06664286404805367,
        "recall": 0.09447771124417831
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.008705665591893137,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.008705665591893137,
        "precision": 0.007905716345087603,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.02022222057923683,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02022222057923683,
        "precision": 0.01876147056476942,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.009765965696197781,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.009765965696197781,
        "precision": 0.009579310331416473,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000501071665719115,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.000501071665719115,
        "precision": 0.00031530124505510943,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011286069835637366,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0011286069835637366,
        "precision": 0.0007243196821487049,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.005489092203491082,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.005489092203491082,
        "precision": 0.004735568551167581,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004312468349100967,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.004312468349100967,
        "precision": 0.003292428176993908,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004825694842487271,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.004825694842487271,
        "precision": 0.0034613120677806997,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.0024112672191940153,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0024112672191940153,
        "precision": 0.0013808939354113005,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.007291385460715605,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.007291385460715605,
        "precision": 0.006183544722432294,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0009570406337507762,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0009570406337507762,
        "precision": 0.0006232104493914208,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013822559862929453,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.0013822559862929453,
        "precision": 0.0008344808145207347,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011472628365671548,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0011472628365671548,
        "precision": 0.0010176076418591388,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.004468635310218746,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.004468635310218746,
        "precision": 0.0026623737087373574,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007250409446818553,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0007250409446818553,
        "precision": 0.0006955927469679377,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00018203544843610903,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.00018203544843610903,
        "precision": 9.446280778312952e-05,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0004328593154590794,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0004328593154590794,
        "precision": 0.0002747024637757309,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0003184023828157555,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0003184023828157555,
        "precision": 0.0001770771722963168,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.005965635603153438,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.005965635603153438,
        "precision": 0.004191732110102391,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0005738882984391966,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.0005738882984391966,
        "precision": 0.00036464180176755027,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001980588879627899,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0001980588879627899,
        "precision": 0.00010549954686456055,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.006123114490006437,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.006123114490006437,
        "precision": 0.00541369980364023,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.004884551151367112,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.004884551151367112,
        "precision": 0.004157755685731736,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.0054990241342170966,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.0054990241342170966,
        "precision": 0.0036169136272137413,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0022831208331636045,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.0022831208331636045,
        "precision": 0.0019169075592059205,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000997549634451097,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.000997549634451097,
        "precision": 0.0008519468998510916,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006858078714366139,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0006858078714366139,
        "precision": 0.000675731869594145,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.029905216022980494,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.029905216022980494,
        "precision": 0.027435274785238238,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.06852960745176315,
        "f1": 0.05378828756074264,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.05378828756074264,
        "precision": 0.04968282056668309,
        "recall": 0.06852960745176315
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.002443513895387596,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.002443513895387596,
        "precision": 0.0023306561480214176,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.009433943226484725,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.009433943226484725,
        "precision": 0.00824928617369214,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.05884915212925858,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.05884915212925858,
        "precision": 0.05386411548088194,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011880162327043047,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0011880162327043047,
        "precision": 0.001039350443869579,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.007195709590919171,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.007195709590919171,
        "precision": 0.006558599971773624,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.034458086627864724,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.034458086627864724,
        "precision": 0.029883506380512365,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.01982965903917105,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.01982965903917105,
        "precision": 0.01762766861237103,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.12704564416141262,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.12704564416141262,
        "precision": 0.11304508125865412,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002528359324402127,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002528359324402127,
        "precision": 0.002286364549995184,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.03392698292241311,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.03392698292241311,
        "precision": 0.030176203474445697,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.002541192852743664,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002541192852743664,
        "precision": 0.0023245074752318165,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.022510074205714405,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.022510074205714405,
        "precision": 0.02117648341279178,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.03196226594430187,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.03196226594430187,
        "precision": 0.02873983412905569,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00043152555278829267,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00043152555278829267,
        "precision": 0.00023807990153278235,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.06919494344644045,
        "f1": 0.05017056755897915,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.05017056755897915,
        "precision": 0.04547812275102792,
        "recall": 0.06919494344644045
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.010434604918521826,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.010434604918521826,
        "precision": 0.009710847036196337,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.023958756903187193,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.023958756903187193,
        "precision": 0.022555199515540292,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.007617988156910312,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.007617988156910312,
        "precision": 0.007080787919111272,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0004181220151784895,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.0004181220151784895,
        "precision": 0.00024672187825059664,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0013736004890949902,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0013736004890949902,
        "precision": 0.0013527346461478197,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.004014428739690859,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.004014428739690859,
        "precision": 0.0035759118697089383,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.008104343826282303,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.008104343826282303,
        "precision": 0.00787786687751894,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.003178544189205793,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.003178544189205793,
        "precision": 0.002980546842822292,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.006005772443593593,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.006005772443593593,
        "precision": 0.005422728911731174,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0032909489926051085,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.0032909489926051085,
        "precision": 0.003065090956321782,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.019669464910018284,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.019669464910018284,
        "precision": 0.01744682501444839,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0023589419116602202,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.0023589419116602202,
        "precision": 0.0019761013164709147,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 6.819935410850882e-05,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 6.819935410850882e-05,
        "precision": 3.543171589794394e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.027717756726406098,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.027717756726406098,
        "precision": 0.02528037128835532,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006878142167197085,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0006878142167197085,
        "precision": 0.0006767461346781969,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.030367175701507036,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.030367175701507036,
        "precision": 0.02588059075567929,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007418113963643595,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.0007418113963643595,
        "precision": 0.0007057504425870326,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.02371304055857846,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.02371304055857846,
        "precision": 0.021477520511454126,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.043912175648702596,
        "f1": 0.031473057843378505,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.031473057843378505,
        "precision": 0.02899608307066138,
        "recall": 0.043912175648702596
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007129256345801982,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0007129256345801982,
        "precision": 0.0006895621484965364,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.04790419161676647,
        "f1": 0.030643668680134444,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.030643668680134444,
        "precision": 0.02615165777800776,
        "recall": 0.04790419161676647
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00444551311607023,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.00444551311607023,
        "precision": 0.00432966862023364,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004369646662952352,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.004369646662952352,
        "precision": 0.0037697141494689363,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.037788204255270116,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.037788204255270116,
        "precision": 0.0354044861030889,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0026623835662009316,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.0026623835662009316,
        "precision": 0.0024400855139690212,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0018019516522510533,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0018019516522510533,
        "precision": 0.0016031429205081902,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0012045948440486099,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0012045948440486099,
        "precision": 0.0010008602686500747,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.03536713893319522,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03536713893319522,
        "precision": 0.031229362849102094,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.20625415834996674,
        "f1": 0.1653360094477859,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.1653360094477859,
        "precision": 0.15216678974164002,
        "recall": 0.20625415834996674
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 3.5964107820395246e-06,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 3.5964107820395246e-06,
        "precision": 1.8030785763612792e-06,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.07984031936127745,
        "f1": 0.06147802075945789,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.06147802075945789,
        "precision": 0.0566079721269342,
        "recall": 0.07984031936127745
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.010501553284408627,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.010501553284408627,
        "precision": 0.008354222475978963,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0010142316992032196,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0010142316992032196,
        "precision": 0.0008953286841953952,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.006389244960718834,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.006389244960718834,
        "precision": 0.005698761837304424,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.1430472388556221,
        "f1": 0.10491635776066913,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10491635776066913,
        "precision": 0.09319267448009963,
        "recall": 0.1430472388556221
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.0196715475294528,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0196715475294528,
        "precision": 0.017618942832475722,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.0718562874251497,
        "f1": 0.05338054050628901,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05338054050628901,
        "precision": 0.04781442406192905,
        "recall": 0.0718562874251497
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0009668957864378859,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009668957864378859,
        "precision": 0.0008275327252921102,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.11310711909514305,
        "f1": 0.0822814688084149,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.0822814688084149,
        "precision": 0.07331160190441627,
        "recall": 0.11310711909514305
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0026689046150123992,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0026689046150123992,
        "precision": 0.0024655451002756393,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.018399708519468996,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.018399708519468996,
        "precision": 0.017504673193295947,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.025669604227576002,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.025669604227576002,
        "precision": 0.023135306461877055,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001908854681996922,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001908854681996922,
        "precision": 0.001538445405225327,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.11709913506320692,
        "f1": 0.08383738798986735,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.08383738798986735,
        "precision": 0.07378864634679093,
        "recall": 0.11709913506320692
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.009636282989576403,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.009636282989576403,
        "precision": 0.00878953641704003,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.022133845139239095,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.022133845139239095,
        "precision": 0.020322467839772002,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.00805873715401195,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.00805873715401195,
        "precision": 0.007583388068686129,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 8.512375581633598e-05,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 8.512375581633598e-05,
        "precision": 4.383972831922791e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006816119029750208,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0006816119029750208,
        "precision": 0.000673524135319197,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010631194373299205,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0010631194373299205,
        "precision": 0.0009203860811046839,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006723964983915671,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0006723964983915671,
        "precision": 0.0006688760460688597,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008647042967025606,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0008647042967025606,
        "precision": 0.0007709453376091113,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010398296470324195,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0010398296470324195,
        "precision": 0.0009084751457987931,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.023174972805711326,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.023174972805711326,
        "precision": 0.0196192511561773,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010193000373161533,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0010193000373161533,
        "precision": 0.0008978606409585437,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006762319100327408,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0006762319100327408,
        "precision": 0.0006708192958664112,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.907174559274681e-05,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 2.907174559274681e-05,
        "precision": 1.4772240123220131e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.023233346087637507,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.023233346087637507,
        "precision": 0.020171470848377903,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006666444233787423,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0006666444233787423,
        "precision": 0.0006659908529397897,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.043912175648702596,
        "f1": 0.026588323179351645,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.026588323179351645,
        "precision": 0.022373100305960566,
        "recall": 0.043912175648702596
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006941599883268184,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0006941599883268184,
        "precision": 0.0006800117186751325,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.016938645547850087,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.016938645547850087,
        "precision": 0.013905991950492785,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.009480699420100975,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.009480699420100975,
        "precision": 0.008036618058370219,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0007790853135246578,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0007790853135246578,
        "precision": 0.0007242289646060843,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.012739455742338864,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.012739455742338864,
        "precision": 0.01046866910126779,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006681976548694726,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0006681976548694726,
        "precision": 0.0006667699084589442,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.003667128704151433,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.003667128704151433,
        "precision": 0.0027620144622498054,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.05256154357950765,
        "f1": 0.033231826961688846,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.033231826961688846,
        "precision": 0.02819312712027283,
        "recall": 0.05256154357950765
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0012163076454263884,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0012163076454263884,
        "precision": 0.0010123911158797909,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0004555024552979307,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0004555024552979307,
        "precision": 0.00028635840250618074,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.001320104479303323,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.001320104479303323,
        "precision": 0.001082289558771709,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.005853099493405089,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.005853099493405089,
        "precision": 0.005659201827558756,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.005892340400879868,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.005892340400879868,
        "precision": 0.005675575373022584,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 1.6889945842334336e-05,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 1.6889945842334336e-05,
        "precision": 8.50252878316665e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.005259850669032306,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.005259850669032306,
        "precision": 0.005078778018193305,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.004636629973702001,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.004636629973702001,
        "precision": 0.004214523368985529,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.00626302949656243,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.00626302949656243,
        "precision": 0.006015746285207363,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.00010235938379650955,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.00010235938379650955,
        "precision": 5.5444666223109334e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.00832302486137673,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.00832302486137673,
        "precision": 0.00784594292256893,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0019092108499631213,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0019092108499631213,
        "precision": 0.0017338392898410457,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006811773278839146,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0006811773278839146,
        "precision": 0.0006733520909987254,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017261772750794704,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0017261772750794704,
        "precision": 0.0013289539856124995,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0075646686425129535,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.0075646686425129535,
        "precision": 0.0071092383134964635,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0009763189670042631,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0009763189670042631,
        "precision": 0.0008376383360060864,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0005597693501885119,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0005597693501885119,
        "precision": 0.000395825119871004,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.007732870616902915,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.007732870616902915,
        "precision": 0.007250555250208119,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0010530051009092925,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.0010530051009092925,
        "precision": 0.0007261462737607222,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.011604627577218975,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.011604627577218975,
        "precision": 0.010944445258425993,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.03438915245998753,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.03438915245998753,
        "precision": 0.03144365665263305,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00022697660235085384,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00022697660235085384,
        "precision": 0.00013567635969890284,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011997898018959346,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0011997898018959346,
        "precision": 0.000799497496235599,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.012914603770133159,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.012914603770133159,
        "precision": 0.011198420436180615,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.09913506320691949,
        "f1": 0.07227777218762989,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.07227777218762989,
        "precision": 0.06489833384377629,
        "recall": 0.09913506320691949
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 6.25354324735224e-05,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 6.25354324735224e-05,
        "precision": 3.2709419491411065e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.03522385856139402,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.03522385856139402,
        "precision": 0.03269622345470649,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0019810854601603036,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0019810854601603036,
        "precision": 0.0015299334434091235,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.15302727877578176,
        "f1": 0.11722266422865225,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.11722266422865225,
        "precision": 0.1065918907735275,
        "recall": 0.15302727877578176
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.0877572995913153e-05,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 1.0877572995913153e-05,
        "precision": 5.46561835748169e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0005344289775427501,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0005344289775427501,
        "precision": 0.00033001423553652426,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007006595536466488,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0007006595536466488,
        "precision": 0.0006832906425293277,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.05615035515235116,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05615035515235116,
        "precision": 0.05010904117690544,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014632704892873643,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0014632704892873643,
        "precision": 0.0009578744608684729,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.11177644710578842,
        "f1": 0.0816406431118184,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.0816406431118184,
        "precision": 0.07381652039835672,
        "recall": 0.11177644710578842
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0013602693847300175,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0013602693847300175,
        "precision": 0.0013456681894000804,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00030775777177040347,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.00030775777177040347,
        "precision": 0.00018739391503386283,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.03153689734528058,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.03153689734528058,
        "precision": 0.027735430434988072,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003098772420593894,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003098772420593894,
        "precision": 0.002666239903934899,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.02906528175402192,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02906528175402192,
        "precision": 0.025785512077927248,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008205810601020182,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0008205810601020182,
        "precision": 0.0005211798624972278,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010465311105410217,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0010465311105410217,
        "precision": 0.0006946465369242457,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.0622870544828975e-05,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 1.0622870544828975e-05,
        "precision": 5.332930570100754e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 5.868319188301893e-05,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 5.868319188301893e-05,
        "precision": 2.994843826878388e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006777335597955228,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0006777335597955228,
        "precision": 0.0006715728269259303,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.00889229294277849,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.00889229294277849,
        "precision": 0.00825483786851627,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.007924248931451472,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.007924248931451472,
        "precision": 0.0075105920391715176,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.007418023170013482,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.007418023170013482,
        "precision": 0.00656281232628538,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.007109856332330533,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.007109856332330533,
        "precision": 0.006232596553867123,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.02409255562948178,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.02409255562948178,
        "precision": 0.02147193319554479,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.008281624127658278,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.008281624127658278,
        "precision": 0.007645824319575959,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.02461291942329866,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.02461291942329866,
        "precision": 0.021270511420358785,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003526860278988265,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.003526860278988265,
        "precision": 0.0030257381626072814,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.703659421952779e-05,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 2.703659421952779e-05,
        "precision": 1.3722885017630738e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007615107271847981,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0007615107271847981,
        "precision": 0.0007170795306388527,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.012158088137164466,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.012158088137164466,
        "precision": 0.01040414093014774,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006936705716282688,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0006936705716282688,
        "precision": 0.0006797307119557045,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.011886163202371364,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.011886163202371364,
        "precision": 0.009987524189146519,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.031013937250668457,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.031013937250668457,
        "precision": 0.02903433172127528,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007637657020176569,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0007637657020176569,
        "precision": 0.0007157699838261578,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.005850204353198364,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.005850204353198364,
        "precision": 0.004301867445451153,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.00922480520057119,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.00922480520057119,
        "precision": 0.008676589639417203,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.009142485517187094,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.009142485517187094,
        "precision": 0.008040052442492542,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.06453759148369927,
        "f1": 0.05035131492930181,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.05035131492930181,
        "precision": 0.04667961526960568,
        "recall": 0.06453759148369927
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.006329056574511611,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.006329056574511611,
        "precision": 0.005994380920534804,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.001454616513790049,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.001454616513790049,
        "precision": 0.0012263425345691048,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009613398355913325,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0009613398355913325,
        "precision": 0.0008334489665944403,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.010411032315531357,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.010411032315531357,
        "precision": 0.008913761821370613,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.035571004090486864,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.035571004090486864,
        "precision": 0.03125664341359885,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006671841502180824,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0006671841502180824,
        "precision": 0.0006662613576740816,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.1490352628077179,
        "f1": 0.11268949438262986,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.11268949438262986,
        "precision": 0.10009783223356078,
        "recall": 0.1490352628077179
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.001877799876740436,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.001877799876740436,
        "precision": 0.0013947181952466945,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.05315542556061517,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.05315542556061517,
        "precision": 0.0474893960921905,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008509550946416347,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0008509550946416347,
        "precision": 0.0007701683467798296,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0015537301465445175,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0015537301465445175,
        "precision": 0.001449165161740012,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.06786427145708583,
        "f1": 0.046827468384354615,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.046827468384354615,
        "precision": 0.04112215942555264,
        "recall": 0.06786427145708583
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011879972581138342,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0011879972581138342,
        "precision": 0.0010397403721967829,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001158575658093063,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001158575658093063,
        "precision": 0.0009542110729281499,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.06786427145708583,
        "f1": 0.04795733208906862,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04795733208906862,
        "precision": 0.04212338448865395,
        "recall": 0.06786427145708583
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0024910804707958373,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0024910804707958373,
        "precision": 0.0023044048861690643,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011215366420449212,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0011215366420449212,
        "precision": 0.001004369526360028,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.023386413674259032,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.023386413674259032,
        "precision": 0.020023219891028135,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014373728502375138,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0014373728502375138,
        "precision": 0.0011360331533777745,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.04790419161676647,
        "f1": 0.02870164740109062,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02870164740109062,
        "precision": 0.024635692092882973,
        "recall": 0.04790419161676647
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0016659322048543604,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0016659322048543604,
        "precision": 0.0015204159582070428,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000588544383676947,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.000588544383676947,
        "precision": 0.0003509869370072684,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011575285883409924,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0011575285883409924,
        "precision": 0.0010227544987785682,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00016957516497043845,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.00016957516497043845,
        "precision": 9.063961377583975e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009048330183045346,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0009048330183045346,
        "precision": 0.0008013435717962381,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007904653928240972,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0007904653928240972,
        "precision": 0.0007313540035831302,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006750133503652068,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0006750133503652068,
        "precision": 0.0006701885972184707,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0014880052305202007,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0014880052305202007,
        "precision": 0.0011815321395810664,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007095706140846746,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0007095706140846746,
        "precision": 0.0006881693646095876,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.0296897168276502,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0296897168276502,
        "precision": 0.02586367840145998,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006714660143352364,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0006714660143352364,
        "precision": 0.000668409355235032,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.026880864092374574,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.026880864092374574,
        "precision": 0.024114253800807707,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006825737433327998,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0006825737433327998,
        "precision": 0.0006740417875978082,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 4.454491639969396e-06,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 4.454491639969396e-06,
        "precision": 2.231327327306048e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.0157280712909182,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0157280712909182,
        "precision": 0.014165128451758338,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006854304858296874,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0006854304858296874,
        "precision": 0.0006755143707752915,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007191731420630383,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0007191731420630383,
        "precision": 0.0006932065782533512,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.02142616615728428,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.02142616615728428,
        "precision": 0.018412422818312322,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.016873444043048497,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.016873444043048497,
        "precision": 0.014785164209075007,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008923525337873159,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0008923525337873159,
        "precision": 0.0008010283926597722,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.030655538739371074,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.030655538739371074,
        "precision": 0.027294085759912726,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006705748607771333,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0006705748607771333,
        "precision": 0.0006679657812175385,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.002360117983195716,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.002360117983195716,
        "precision": 0.0016845622853004778,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.015499753287048916,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.015499753287048916,
        "precision": 0.012694782961355079,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662946920759825,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0006662946920759825,
        "precision": 0.0006658156889777282,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0010077387998907574,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0010077387998907574,
        "precision": 0.0008920000062875394,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006674481724381924,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0006674481724381924,
        "precision": 0.0006663937625543824,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.01498163623912127,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.01498163623912127,
        "precision": 0.012411158781946617,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.09913506320691949,
        "f1": 0.06943899598590217,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.06943899598590217,
        "precision": 0.060785250455909136,
        "recall": 0.09913506320691949
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00044652757976111266,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00044652757976111266,
        "precision": 0.00033415644475404154,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.04258150365934797,
        "f1": 0.02703820777086011,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.02703820777086011,
        "precision": 0.022488374739265116,
        "recall": 0.04258150365934797
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002554180886988955,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.002554180886988955,
        "precision": 0.002390282350177688,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.1164337990685296,
        "f1": 0.08387832319968049,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.08387832319968049,
        "precision": 0.07354286136721266,
        "recall": 0.1164337990685296
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0013306719893546241,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0013306719893546241,
        "precision": 0.0013306719893546241,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008398546821700514,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0008398546821700514,
        "precision": 0.0007579914237187924,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.12042581503659348,
        "f1": 0.08742308552687794,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08742308552687794,
        "precision": 0.0769611164321743,
        "recall": 0.12042581503659348
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.001180336819161089,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.001180336819161089,
        "precision": 0.0010348392288216342,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.05195851682877631,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05195851682877631,
        "precision": 0.045233078815913146,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003118246246751752,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003118246246751752,
        "precision": 0.00272450611400642,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.001034940962017502,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.001034940962017502,
        "precision": 0.0008779266863099198,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006902787583707427,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0006902787583707427,
        "precision": 0.000677944983939736,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.035298129360643714,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.035298129360643714,
        "precision": 0.0317912635527406,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011363173891725039,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011363173891725039,
        "precision": 0.0007378062832660669,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.04790419161676647,
        "f1": 0.030532288366619705,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.030532288366619705,
        "precision": 0.02629951736738164,
        "recall": 0.04790419161676647
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0018851186515857173,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0018851186515857173,
        "precision": 0.001532023671954337,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011405349700401896,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0011405349700401896,
        "precision": 0.0010139700814779892,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008224795173497261,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0008224795173497261,
        "precision": 0.0007513802799582538,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0006368045821989106,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0006368045821989106,
        "precision": 0.00043759016987299476,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006908599482129137,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0006908599482129137,
        "precision": 0.0006781754186360666,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011612047540191252,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0011612047540191252,
        "precision": 0.0009751696981887763,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006756578741991229,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0006756578741991229,
        "precision": 0.0006705145398688546,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0013699223514886307,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0013699223514886307,
        "precision": 0.0011398411091735308,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010412075007585708,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0010412075007585708,
        "precision": 0.0009092807295036363,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.024216779802513282,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.024216779802513282,
        "precision": 0.020741787148917265,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010328274128736446,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0010328274128736446,
        "precision": 0.0009048547571623171,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.021038152633162784,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.021038152633162784,
        "precision": 0.018527248937481103,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006758138886477431,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0006758138886477431,
        "precision": 0.0006705957314544063,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 4.98752978444414e-05,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 4.98752978444414e-05,
        "precision": 2.576002381816048e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.016960160612371853,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.016960160612371853,
        "precision": 0.015288491562208496,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011255198310842513,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0011255198310842513,
        "precision": 0.0010063943343047981,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.027631195097193337,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.027631195097193337,
        "precision": 0.022980908194691153,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007157979539826127,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0007157979539826127,
        "precision": 0.0006913902957348357,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.020763532664099707,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.020763532664099707,
        "precision": 0.01781551155278021,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010747352332360128,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0010747352332360128,
        "precision": 0.0009269702314098957,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.017921529633400008,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.017921529633400008,
        "precision": 0.014899205005700874,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008113034992498893,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0008113034992498893,
        "precision": 0.0007420450228864973,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0011146780857777309,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0011146780857777309,
        "precision": 0.0009158524648301091,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.015639716102914,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.015639716102914,
        "precision": 0.012969106157252266,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006663282929542356,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0006663282929542356,
        "precision": 0.0006658325140763249,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00024039486110082322,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.00024039486110082322,
        "precision": 0.00013260930346467302,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0015818021022427026,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0015818021022427026,
        "precision": 0.001478689300688895,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.0107700716266194,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.0107700716266194,
        "precision": 0.009735500723745448,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.013583093742998435,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.013583093742998435,
        "precision": 0.012524541213264859,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.00811776389941586,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.00811776389941586,
        "precision": 0.0069984655313996644,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.01301945267778761,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.01301945267778761,
        "precision": 0.011646109522162738,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04081291935274288,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.04081291935274288,
        "precision": 0.03544871722063978,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.009882320594246647,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.009882320594246647,
        "precision": 0.008524788480689738,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.013551219239841992,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.013551219239841992,
        "precision": 0.011726168091697901,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0035309077386912508,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.0035309077386912508,
        "precision": 0.002977374468689733,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0003904378846921091,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.0003904378846921091,
        "precision": 0.0002517765313848025,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.033456310240944635,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.033456310240944635,
        "precision": 0.03112397186626776,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006909137031500999,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0006909137031500999,
        "precision": 0.0006782363400547406,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.027272599936948656,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.027272599936948656,
        "precision": 0.0236704399062292,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010812428465061456,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0010812428465061456,
        "precision": 0.0009304033116872553,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.023183620607194512,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.023183620607194512,
        "precision": 0.020133352211742016,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0009542122588245766,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0009542122588245766,
        "precision": 0.0008431639915326358,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.059214903526280775,
        "f1": 0.038469605951269206,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.038469605951269206,
        "precision": 0.03291882070677421,
        "recall": 0.059214903526280775
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.006820314876545012,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.006820314876545012,
        "precision": 0.005901491047513115,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.010195211198875554,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.010195211198875554,
        "precision": 0.009218305218586012,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.05788423153692615,
        "f1": 0.043459707523736325,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.043459707523736325,
        "precision": 0.040055460738711204,
        "recall": 0.05788423153692615
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.006865489799621536,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.006865489799621536,
        "precision": 0.006361016123181933,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0005360271735297453,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0005360271735297453,
        "precision": 0.0003393372709534906,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013336689983396571,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0013336689983396571,
        "precision": 0.001332173876475792,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.00859642768816989,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.00859642768816989,
        "precision": 0.007231261476465474,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.023697017110190764,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.023697017110190764,
        "precision": 0.02163000045510886,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 2.7607302683705894e-06,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 2.7607302683705894e-06,
        "precision": 1.383234916169048e-06,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.030919462424872656,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.030919462424872656,
        "precision": 0.02749280053093479,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007669838672924403,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0007669838672924403,
        "precision": 0.0007177762375563495,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.043912175648702596,
        "f1": 0.025865094752867957,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.025865094752867957,
        "precision": 0.02250239087813938,
        "recall": 0.043912175648702596
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0011174232731118957,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0011174232731118957,
        "precision": 0.0010022964823042087,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.000679054262608803,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.000679054262608803,
        "precision": 0.0006722665779552008,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.05588822355289421,
        "f1": 0.03965102804266582,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.03965102804266582,
        "precision": 0.035702476720440794,
        "recall": 0.05588822355289421
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010941071576150083,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0010941071576150083,
        "precision": 0.0008992022855600049,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.026793022900807335,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.026793022900807335,
        "precision": 0.023865782046479475,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010884261813036895,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0010884261813036895,
        "precision": 0.0008992086631830839,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0552228875582169,
        "f1": 0.0357660820734673,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.0357660820734673,
        "precision": 0.030495708636485902,
        "recall": 0.0552228875582169
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0028178973971599245,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0028178973971599245,
        "precision": 0.0025406894045307826,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010112961152059425,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0010112961152059425,
        "precision": 0.0006625637613661566,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.015442076984509358,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.015442076984509358,
        "precision": 0.013713314112515706,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0016300419451941047,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0016300419451941047,
        "precision": 0.0014926422458726274,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00012312686154629499,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.00012312686154629499,
        "precision": 6.76136903681814e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.164531313307e-05,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 6.164531313307e-05,
        "precision": 3.21403750608394e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.866687790554342e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 6.866687790554342e-05,
        "precision": 3.578631925413386e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0004845750675519709,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0004845750675519709,
        "precision": 0.00035353270068051035,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 9.984423316896373e-06,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 9.984423316896373e-06,
        "precision": 5.007690240261819e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011895677304585516,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0011895677304585516,
        "precision": 0.0007997906814099903,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0004991411897609425,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0004991411897609425,
        "precision": 0.0003614173775479828,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.028379410286486505,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.028379410286486505,
        "precision": 0.024826110903955215,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00048048692723879835,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.00048048692723879835,
        "precision": 0.0003514101760617002,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.00805341980584182,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.00805341980584182,
        "precision": 0.0069547326647289975,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 2.210432161142384e-05,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 2.210432161142384e-05,
        "precision": 1.1196955823999975e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.22225052383678e-05,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 6.22225052383678e-05,
        "precision": 3.24299232186879e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005695866332121734,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.005695866332121734,
        "precision": 0.004944456029049372,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.8332853237756077e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 1.8332853237756077e-05,
        "precision": 9.272787908594736e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.029518740297183408,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.029518740297183408,
        "precision": 0.025142198108237857,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.503695656111164e-05,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 6.503695656111164e-05,
        "precision": 3.3962721779358826e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.013108439206243596,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.013108439206243596,
        "precision": 0.011972801144457831,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.02090486062365832,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.02090486062365832,
        "precision": 0.01807782952213017,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00010004398916926201,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.00010004398916926201,
        "precision": 5.236804164085392e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.26623004443429e-05,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 3.26623004443429e-05,
        "precision": 1.658601126332331e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0009307176834232602,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0009307176834232602,
        "precision": 0.0005187938921868175,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.013092220458701917,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.013092220458701917,
        "precision": 0.011409920860946346,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 9.769985237552306e-07,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 9.769985237552306e-07,
        "precision": 4.888581885946451e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0004508287614206923,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0004508287614206923,
        "precision": 0.00033632368961710276,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001532040383076688,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.001532040383076688,
        "precision": 0.0012521053771885442,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.019210379582318634,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.019210379582318634,
        "precision": 0.017668054801791715,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.05543696957535945,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.05543696957535945,
        "precision": 0.050449844886291687,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006697219735474202,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0006697219735474202,
        "precision": 0.00066753281938858,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.059880239520958084,
        "f1": 0.045169922880019926,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.045169922880019926,
        "precision": 0.0407475646996605,
        "recall": 0.059880239520958084
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.007949493925062936,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.007949493925062936,
        "precision": 0.006294369548094656,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.11310711909514305,
        "f1": 0.08984536938628755,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.08984536938628755,
        "precision": 0.08272709631242565,
        "recall": 0.11310711909514305
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006819693945442448,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0006819693945442448,
        "precision": 0.0006737579692934806,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.006625637613661565,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.006625637613661565,
        "precision": 0.006032379685074296,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.02882736949603217,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.02882736949603217,
        "precision": 0.02581622352127853,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.01560403129747946,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.01560403129747946,
        "precision": 0.014010439810081838,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.029870031335521404,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.029870031335521404,
        "precision": 0.026966058680889884,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011789387132817917,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0011789387132817917,
        "precision": 0.0010341893197061982,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.02492074095708931,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.02492074095708931,
        "precision": 0.022522586085460337,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0012575620634809731,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0012575620634809731,
        "precision": 0.0010797777664045129,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.01711392030753308,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.01711392030753308,
        "precision": 0.016374394069004847,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.013439077254130077,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.013439077254130077,
        "precision": 0.0117569808521239,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008626961914679956,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008626961914679956,
        "precision": 0.0007798692250482113,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.009314703925482368,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.009314703925482368,
        "precision": 0.008982035928143712,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.01655456851327466,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.01655456851327466,
        "precision": 0.014884932443585972,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.005313618753067047,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.005313618753067047,
        "precision": 0.005045750580425098,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00042962240343981156,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.00042962240343981156,
        "precision": 0.0002739129278017069,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017166833253837326,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0017166833253837326,
        "precision": 0.001579484336069579,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.008808465533477049,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.008808465533477049,
        "precision": 0.00781451548093189,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.008906243342543156,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.008906243342543156,
        "precision": 0.008406520524112102,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0023006227925921035,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.0023006227925921035,
        "precision": 0.0021821110985248463,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.01040648866193182,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.01040648866193182,
        "precision": 0.009383200846082126,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.013200127533226044,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.013200127533226044,
        "precision": 0.01177358424407104,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.009080329199725295,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.009080329199725295,
        "precision": 0.007838370877293032,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.005100571597659611,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.005100571597659611,
        "precision": 0.004550525420643714,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.004327807608570027,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.004327807608570027,
        "precision": 0.00401575933101118,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0005063905065903294,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0005063905065903294,
        "precision": 0.0003650107193021365,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.021260890361169408,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.021260890361169408,
        "precision": 0.0196614124344476,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0010483730738872629,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0010483730738872629,
        "precision": 0.0008714568259130914,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028722653087957565,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0028722653087957565,
        "precision": 0.0023880031313761106,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.002273231315147483,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.002273231315147483,
        "precision": 0.0019801666508253335,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0022223844604234728,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.0022223844604234728,
        "precision": 0.0019141556520407067,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.021942781104457753,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.021942781104457753,
        "precision": 0.020886005766245285,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001544388199712473,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.001544388199712473,
        "precision": 0.0012440502327823704,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0028238735126165085,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0028238735126165085,
        "precision": 0.002357401837852701,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.009390758999961646,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.009390758999961646,
        "precision": 0.00833128630391248,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.026463943977070935,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.026463943977070935,
        "precision": 0.025288001738226287,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003797553943603308,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.003797553943603308,
        "precision": 0.003464959681182207,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 8.227831003537469e-05,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 8.227831003537469e-05,
        "precision": 4.249242710119999e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 1.8923983344063906e-05,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 1.8923983344063906e-05,
        "precision": 9.541152859017425e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0075823809765564795,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.0075823809765564795,
        "precision": 0.006717822255227556,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.007990694413148335,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.007990694413148335,
        "precision": 0.007233324625709215,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.005067730500198896,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.005067730500198896,
        "precision": 0.004101388519304994,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.008823158483595571,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.008823158483595571,
        "precision": 0.007954393883560701,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.04790419161676647,
        "f1": 0.034180873520615086,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.034180873520615086,
        "precision": 0.03051108022990345,
        "recall": 0.04790419161676647
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.006575540380767252,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.006575540380767252,
        "precision": 0.0056102020534010396,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.056553559547571526,
        "f1": 0.037284218069329765,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.037284218069329765,
        "precision": 0.03217392097458053,
        "recall": 0.056553559547571526
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003938084791895865,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.003938084791895865,
        "precision": 0.0033734784905587656,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.5531572264421014e-05,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 2.5531572264421014e-05,
        "precision": 1.2944913738381154e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0658682634730539,
        "f1": 0.04914000262714599,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.04914000262714599,
        "precision": 0.04510371615866558,
        "recall": 0.0658682634730539
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 1.2636960962532043e-06,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 1.2636960962532043e-06,
        "precision": 6.324486641419316e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.014921375691445011,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.014921375691445011,
        "precision": 0.013261388664507458,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.7055129907527146e-05,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 2.7055129907527146e-05,
        "precision": 1.3732084172805507e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.015863301792320948,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.015863301792320948,
        "precision": 0.013382032670452303,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.04057559610245566,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.04057559610245566,
        "precision": 0.03846687636053349,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 2.216125161596507e-05,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 2.216125161596507e-05,
        "precision": 1.1140347924615466e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.013355123642096865,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.013355123642096865,
        "precision": 0.011613972813059247,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.006229739684245844,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.006229739684245844,
        "precision": 0.0055679361543432325,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.008955888613787877,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.008955888613787877,
        "precision": 0.007706710976981582,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.005084263819786786,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.005084263819786786,
        "precision": 0.004768739674209633,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0018248031455261856,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0018248031455261856,
        "precision": 0.0016331968301269136,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0021278155881160822,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0021278155881160822,
        "precision": 0.001875877873881866,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.007910105714496933,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.007910105714496933,
        "precision": 0.007313151474828122,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0057152788839381335,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.0057152788839381335,
        "precision": 0.0053696478510265565,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006859818638792337,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0006859818638792337,
        "precision": 0.0006757723501885607,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.00883034789157672,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.00883034789157672,
        "precision": 0.00853999537644905,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.008080235995650716,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.008080235995650716,
        "precision": 0.0069325495621359945,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.007886317573873156,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.007886317573873156,
        "precision": 0.007338435620133094,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006741977797869551,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0006741977797869551,
        "precision": 0.0006697870096221439,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.03384100432243934,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.03384100432243934,
        "precision": 0.02984306770848012,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007070460616975834,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0007070460616975834,
        "precision": 0.0004820223504752456,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.012406823222877115,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.012406823222877115,
        "precision": 0.011869881266516929,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0019634041220809445,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0019634041220809445,
        "precision": 0.00176230264484784,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006823958919767302,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0006823958919767302,
        "precision": 0.0006739767218809134,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0014786787378226888,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0014786787378226888,
        "precision": 0.0012386104709654331,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.008510947453751501,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.008510947453751501,
        "precision": 0.008121904923092069,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0013837936774671999,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.0013837936774671999,
        "precision": 0.0013577782706192553,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00026357541327601204,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00026357541327601204,
        "precision": 0.00015441958652312137,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.007153132134289809,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.007153132134289809,
        "precision": 0.006825650411956061,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.005544466622310933,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.005544466622310933,
        "precision": 0.0053226879574184965,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.013308542731887823,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.013308542731887823,
        "precision": 0.012420517903379339,
        "recall": 0.015968063872255488
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}