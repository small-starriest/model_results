{
  "dataset_revision": "b0f431acbf8d3865cb7c7b3effb2a9771a618ebc",
  "evaluation_time": 26.336185455322266,
  "kg_co2_emissions": 0.004891720545227746,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.623583984375,
        "ap": 0.39341719424300264,
        "ap_weighted": 0.39341719424300264,
        "f1": 0.6025480943482189,
        "f1_weighted": 0.6344861645169229,
        "hf_subset": "default",
        "languages": [
          "por-Latn"
        ],
        "main_score": 0.623583984375,
        "scores_per_experiment": [
          {
            "accuracy": 0.70166015625,
            "ap": 0.4364959723555031,
            "ap_weighted": 0.4364959723555031,
            "f1": 0.663583794204888,
            "f1_weighted": 0.7053627923269556
          },
          {
            "accuracy": 0.60400390625,
            "ap": 0.3839140000853558,
            "ap_weighted": 0.3839140000853558,
            "f1": 0.5896526720056132,
            "f1_weighted": 0.617980434639442
          },
          {
            "accuracy": 0.58740234375,
            "ap": 0.38458639051301297,
            "ap_weighted": 0.38458639051301297,
            "f1": 0.5798264443526675,
            "f1_weighted": 0.6006532805140616
          },
          {
            "accuracy": 0.666015625,
            "ap": 0.39155982310244064,
            "ap_weighted": 0.39155982310244064,
            "f1": 0.6167928857725299,
            "f1_weighted": 0.6674909659577717
          },
          {
            "accuracy": 0.65673828125,
            "ap": 0.4071474211597099,
            "ap_weighted": 0.4071474211597099,
            "f1": 0.629106221484081,
            "f1_weighted": 0.6664762343338748
          },
          {
            "accuracy": 0.63134765625,
            "ap": 0.4127472736549565,
            "ap_weighted": 0.4127472736549565,
            "f1": 0.6204516807625136,
            "f1_weighted": 0.6441904630925993
          },
          {
            "accuracy": 0.58154296875,
            "ap": 0.3561214756338259,
            "ap_weighted": 0.3561214756338259,
            "f1": 0.5590038530780025,
            "f1_weighted": 0.5958063832033375
          },
          {
            "accuracy": 0.53955078125,
            "ap": 0.3498164226742718,
            "ap_weighted": 0.3498164226742718,
            "f1": 0.531344769287404,
            "f1_weighted": 0.5542368174192214
          },
          {
            "accuracy": 0.65380859375,
            "ap": 0.41556941112320506,
            "ap_weighted": 0.41556941112320506,
            "f1": 0.6337749879377925,
            "f1_weighted": 0.6653937895954728
          },
          {
            "accuracy": 0.61376953125,
            "ap": 0.3962137521277451,
            "ap_weighted": 0.3962137521277451,
            "f1": 0.6019436345966958,
            "f1_weighted": 0.6272704840864918
          }
        ]
      }
    ]
  },
  "task_name": "HateSpeechPortugueseClassification"
}