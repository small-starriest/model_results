{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 10.12751030921936,
  "kg_co2_emissions": 0.0014976880265357823,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8285,
        "ap": 0.631884504712555,
        "ap_weighted": 0.631884504712555,
        "f1": 0.8086336998259208,
        "f1_weighted": 0.830124666986803,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8285,
        "scores_per_experiment": [
          {
            "accuracy": 0.835,
            "ap": 0.6430140246493837,
            "ap_weighted": 0.6430140246493837,
            "f1": 0.8170794573578957,
            "f1_weighted": 0.8371184028043381
          },
          {
            "accuracy": 0.829,
            "ap": 0.6280865384615384,
            "ap_weighted": 0.6280865384615384,
            "f1": 0.8043422294688063,
            "f1_weighted": 0.8286527074573072
          },
          {
            "accuracy": 0.822,
            "ap": 0.6267368421052631,
            "ap_weighted": 0.6267368421052631,
            "f1": 0.8073226069034795,
            "f1_weighted": 0.8259352430766034
          },
          {
            "accuracy": 0.852,
            "ap": 0.6709380022962113,
            "ap_weighted": 0.6709380022962113,
            "f1": 0.8326549072817729,
            "f1_weighted": 0.852568973315242
          },
          {
            "accuracy": 0.804,
            "ap": 0.6003746473575324,
            "ap_weighted": 0.6003746473575324,
            "f1": 0.7890758509067586,
            "f1_weighted": 0.8087128891873393
          },
          {
            "accuracy": 0.831,
            "ap": 0.6321925436526663,
            "ap_weighted": 0.6321925436526663,
            "f1": 0.8075607009345263,
            "f1_weighted": 0.8310671613153738
          },
          {
            "accuracy": 0.818,
            "ap": 0.6142657148945238,
            "ap_weighted": 0.6142657148945238,
            "f1": 0.7980927530829683,
            "f1_weighted": 0.8202823595191502
          },
          {
            "accuracy": 0.835,
            "ap": 0.6404151115157032,
            "ap_weighted": 0.6404151115157032,
            "f1": 0.8138603004633187,
            "f1_weighted": 0.8358154780236703
          },
          {
            "accuracy": 0.835,
            "ap": 0.6396736596736596,
            "ap_weighted": 0.6396736596736596,
            "f1": 0.8127075115638923,
            "f1_weighted": 0.8353230795425522
          },
          {
            "accuracy": 0.824,
            "ap": 0.6231479625190673,
            "ap_weighted": 0.6231479625190673,
            "f1": 0.8036406802957885,
            "f1_weighted": 0.8257703756264532
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}