{
  "dataset_revision": "557bf94ac6177cc442f42d0b09b6e4b76e8f47c9",
  "evaluation_time": 9.447261810302734,
  "kg_co2_emissions": 0.0013971265751830748,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.6009004739336492,
        "ap": 0.19326069686161768,
        "ap_weighted": 0.19326069686161768,
        "f1": 0.5089022438189875,
        "f1_weighted": 0.6475627934101391,
        "hf_subset": "default",
        "languages": [
          "ara-Arab"
        ],
        "main_score": 0.6009004739336492,
        "scores_per_experiment": [
          {
            "accuracy": 0.614691943127962,
            "ap": 0.20565279833155373,
            "ap_weighted": 0.20565279833155373,
            "f1": 0.5324370549555382,
            "f1_weighted": 0.6644166495372805
          },
          {
            "accuracy": 0.504739336492891,
            "ap": 0.20543901306932152,
            "ap_weighted": 0.20543901306932152,
            "f1": 0.4717886838520102,
            "f1_weighted": 0.5605741236054269
          },
          {
            "accuracy": 0.6279620853080569,
            "ap": 0.215013912878885,
            "ap_weighted": 0.215013912878885,
            "f1": 0.5458933277696916,
            "f1_weighted": 0.6758126540846066
          },
          {
            "accuracy": 0.6336492890995261,
            "ap": 0.19903111166013804,
            "ap_weighted": 0.19903111166013804,
            "f1": 0.5352209683012852,
            "f1_weighted": 0.6791635177693615
          },
          {
            "accuracy": 0.5364928909952607,
            "ap": 0.20027629651053375,
            "ap_weighted": 0.20027629651053375,
            "f1": 0.48789458010720665,
            "f1_weighted": 0.5940631977395707
          },
          {
            "accuracy": 0.5786729857819906,
            "ap": 0.1675014661826943,
            "ap_weighted": 0.1675014661826943,
            "f1": 0.4762719904534579,
            "f1_weighted": 0.6321234517251795
          },
          {
            "accuracy": 0.54739336492891,
            "ap": 0.17915434307356828,
            "ap_weighted": 0.17915434307356828,
            "f1": 0.4768108322136324,
            "f1_weighted": 0.6061362469951731
          },
          {
            "accuracy": 0.6924170616113744,
            "ap": 0.17143770440700176,
            "ap_weighted": 0.17143770440700176,
            "f1": 0.5172525143134934,
            "f1_weighted": 0.7129516938280417
          },
          {
            "accuracy": 0.685781990521327,
            "ap": 0.17337653213117038,
            "ap_weighted": 0.17337653213117038,
            "f1": 0.519601348754936,
            "f1_weighted": 0.7097516398977847
          },
          {
            "accuracy": 0.5872037914691943,
            "ap": 0.21572379037131012,
            "ap_weighted": 0.21572379037131012,
            "f1": 0.5258511374686243,
            "f1_weighted": 0.6406347589189659
          }
        ]
      }
    ]
  },
  "task_name": "TweetSarcasmClassification"
}