{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 24.52716827392578,
  "kg_co2_emissions": 0.0036973156556885703,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.08449767132401863,
        "f1": 0.06520032349451942,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.06520032349451942,
        "precision": 0.05980668902325589,
        "recall": 0.08449767132401863
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011384162962602836,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0011384162962602836,
        "precision": 0.0009626573742762744,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011199822577068086,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0011199822577068086,
        "precision": 0.000951059995442626,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0005558170762263092,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0005558170762263092,
        "precision": 0.0003555317772244743,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0012874374191533535,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0012874374191533535,
        "precision": 0.0010146476697788646,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.004996774482224634,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.004996774482224634,
        "precision": 0.004671958353305337,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007894740993626415,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0007894740993626415,
        "precision": 0.0004785620530307452,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008774602169148693,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0008774602169148693,
        "precision": 0.0007809708660717784,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 5.46636333395237e-06,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 5.46636333395237e-06,
        "precision": 2.739222502949443e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012498067154457263,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0012498067154457263,
        "precision": 0.0010245378038249743,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0026613439787092482,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0026613439787092482,
        "precision": 0.002239964515413617,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001162365676655034,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.001162365676655034,
        "precision": 0.001025051148563357,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0016030949946496268,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0016030949946496268,
        "precision": 0.00109922071073329,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0005950511264187318,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0005950511264187318,
        "precision": 0.0003608959388233603,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.003646339204451997,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.003646339204451997,
        "precision": 0.002775520147743328,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0036337861672699244,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0036337861672699244,
        "precision": 0.003273522537852828,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007746654676083785,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0007746654676083785,
        "precision": 0.0007218317272552402,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0002574603723183756,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0002574603723183756,
        "precision": 0.0001377276477929063,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.000864283735429228,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.000864283735429228,
        "precision": 0.000770175706202554,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00017146705764202347,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.00017146705764202347,
        "precision": 9.214653399966984e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0016182584878420044,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0016182584878420044,
        "precision": 0.0012717145910778745,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 4.1583499667332004e-05,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 4.1583499667332004e-05,
        "precision": 2.1462451441203615e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.06786427145708583,
        "f1": 0.03839850875969487,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.03839850875969487,
        "precision": 0.03252416894000779,
        "recall": 0.06786427145708583
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0012599796698092604,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0012599796698092604,
        "precision": 0.0010771434511320948,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006958728391679484,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0006958728391679484,
        "precision": 0.0006809407963495138,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0002826630895652767,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0002826630895652767,
        "precision": 0.00017465612705650342,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001472255279795714,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.001472255279795714,
        "precision": 0.001193765173159326,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006447422615087285,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0006447422615087285,
        "precision": 0.0003740222145516819,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0012467062603383023,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0012467062603383023,
        "precision": 0.001010410118988542,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0014846502649067301,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0014846502649067301,
        "precision": 0.00141203093447969,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000671041705209261,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.000671041705209261,
        "precision": 0.000668194980235535,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 6.423987183641879e-06,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 6.423987183641879e-06,
        "precision": 3.219769606524221e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0009869150587713462,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0009869150587713462,
        "precision": 0.0008605976452891319,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.001678776752730999,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.001678776752730999,
        "precision": 0.0015602403280655023,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011971378879667566,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0011971378879667566,
        "precision": 0.0010437083790377204,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007648217544079192,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0007648217544079192,
        "precision": 0.0007160713936855484,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007256270774178778,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0007256270774178778,
        "precision": 0.0004903367684725385,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.001146772218899902,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.001146772218899902,
        "precision": 0.0009663767148797087,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.003389299623453605,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.003389299623453605,
        "precision": 0.002932569560907089,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0012390447743299755,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0012390447743299755,
        "precision": 0.0008543796307718004,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007879952808444448,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0007879952808444448,
        "precision": 0.0007284949548420795,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0007228097100591556,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0007228097100591556,
        "precision": 0.0006943549658683928,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0011088933244621866,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0011088933244621866,
        "precision": 0.000998003992015968,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0015406805336490095,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0015406805336490095,
        "precision": 0.0014440478848407338,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0010423597249944556,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0010423597249944556,
        "precision": 0.0007207806609004214,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008565732212777744,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0008565732212777744,
        "precision": 0.0007767964309816227,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.07651363938789088,
        "f1": 0.0650566591684356,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0650566591684356,
        "precision": 0.06131711056567225,
        "recall": 0.07651363938789088
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0032896418743542347,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0032896418743542347,
        "precision": 0.0030543868905139053,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.06187624750499002,
        "f1": 0.05378644420560588,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.05378644420560588,
        "precision": 0.05132034781012688,
        "recall": 0.06187624750499002
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.010854664970151407,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.010854664970151407,
        "precision": 0.009173664958868745,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.09381237524950099,
        "f1": 0.07785381856651082,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.07785381856651082,
        "precision": 0.07343738364444093,
        "recall": 0.09381237524950099
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0026768151120949283,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0026768151120949283,
        "precision": 0.002669150884747184,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.014192592913015844,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.014192592913015844,
        "precision": 0.012903988067580249,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.018859224666032102,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.018859224666032102,
        "precision": 0.01733569897242552,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.021163091210133822,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.021163091210133822,
        "precision": 0.019365270996505556,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01622131826722645,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.01622131826722645,
        "precision": 0.014535246055538803,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004025112227129245,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004025112227129245,
        "precision": 0.003316934865813157,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.024242243686114565,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.024242243686114565,
        "precision": 0.021805874145930878,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0037636578593069118,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0037636578593069118,
        "precision": 0.003413418268542144,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.019376183685920374,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.019376183685920374,
        "precision": 0.018219946916917067,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.014570249001386724,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.014570249001386724,
        "precision": 0.012134436752131064,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011335977356737195,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011335977356737195,
        "precision": 0.0009348478843451164,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.06719893546240852,
        "f1": 0.05154312546077004,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.05154312546077004,
        "precision": 0.047313101255217024,
        "recall": 0.06719893546240852
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.02245236943960938,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.02245236943960938,
        "precision": 0.020877073014464897,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.02423970386668843,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02423970386668843,
        "precision": 0.02220022202691778,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.024950704651303453,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.024950704651303453,
        "precision": 0.023444659372803087,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002138666390163396,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.002138666390163396,
        "precision": 0.001613061755277324,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001495918372923005,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.001495918372923005,
        "precision": 0.0012230358429772467,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.08183632734530938,
        "f1": 0.06343273419121723,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.06343273419121723,
        "precision": 0.0591058158315285,
        "recall": 0.08183632734530938
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0028031019956414184,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0028031019956414184,
        "precision": 0.0025468977858316825,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.09514304723885562,
        "f1": 0.07680239845908508,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.07680239845908508,
        "precision": 0.07145820404009907,
        "recall": 0.09514304723885562
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.011638594993122591,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011638594993122591,
        "precision": 0.010119069965167244,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.2714570858283433,
        "f1": 0.21986541334687146,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.21986541334687146,
        "precision": 0.20208104714092737,
        "recall": 0.2714570858283433
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008943874546271686,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0008943874546271686,
        "precision": 0.0007890533962770337,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.019375090234826014,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.019375090234826014,
        "precision": 0.01729818743576855,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.14038589487691283,
        "f1": 0.10288403895601264,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10288403895601264,
        "precision": 0.09150728863802716,
        "recall": 0.14038589487691283
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.020745614640583325,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.020745614640583325,
        "precision": 0.018971685297928944,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.06986027944111776,
        "f1": 0.05215106103329656,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05215106103329656,
        "precision": 0.04694235866890558,
        "recall": 0.06986027944111776
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0014126197264123092,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0014126197264123092,
        "precision": 0.0011105530753063547,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.08478573495206894,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08478573495206894,
        "precision": 0.07522179167594219,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002508558565760244,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002508558565760244,
        "precision": 0.0022979853984511334,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.018200353948115647,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.018200353948115647,
        "precision": 0.017429023190228054,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.022770846829251762,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.022770846829251762,
        "precision": 0.019529599821647304,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002210502959005953,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002210502959005953,
        "precision": 0.0018351304806777542,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.14171656686626746,
        "f1": 0.10534044022067975,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.10534044022067975,
        "precision": 0.09560187723860376,
        "recall": 0.14171656686626746
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.024972277666888445,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.024972277666888445,
        "precision": 0.023243988214048092,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.025189547644637465,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.025189547644637465,
        "precision": 0.023019173999566156,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.027967018994641168,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.027967018994641168,
        "precision": 0.02637913538485276,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011356953210089043,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0011356953210089043,
        "precision": 0.0010115416072763925,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0002638389576278504,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0002638389576278504,
        "precision": 0.0001431034881375579,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.006670326138186295,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.006670326138186295,
        "precision": 0.004700982888451248,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.008000707745357993,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.008000707745357993,
        "precision": 0.00645514375019383,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.007639373797761301,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.007639373797761301,
        "precision": 0.005767978836050677,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.005251438422572815,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.005251438422572815,
        "precision": 0.003630477923325141,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008476095228464268,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.008476095228464268,
        "precision": 0.0067632255358069555,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.001897639959193673,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.001897639959193673,
        "precision": 0.001391070613966286,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.004872566298291977,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.004872566298291977,
        "precision": 0.0040638252115298016,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0002114690913563756,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0002114690913563756,
        "precision": 0.0001181937802056199,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.006592014929455845,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.006592014929455845,
        "precision": 0.00490967264336184,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006103333348842331,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0006103333348842331,
        "precision": 0.00042092593488328667,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0021934242936883755,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0021934242936883755,
        "precision": 0.0018914597644392956,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0012897696854628025,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0012897696854628025,
        "precision": 0.00084247165545096,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0005845463886879051,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0005845463886879051,
        "precision": 0.0003312124011514704,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.007145025857818237,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.007145025857818237,
        "precision": 0.005503333053593825,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00025301461507173326,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.00025301461507173326,
        "precision": 0.00013308237366450054,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00044304509046015357,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00044304509046015357,
        "precision": 0.0002420120699690592,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.009495695407282371,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.009495695407282371,
        "precision": 0.008105258263593484,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.005946006138304469,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.005946006138304469,
        "precision": 0.004739178037193536,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.0065885483002816585,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.0065885483002816585,
        "precision": 0.004779264456236266,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.005746268569771164,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.005746268569771164,
        "precision": 0.004515192853119683,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007920666603301335,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0007920666603301335,
        "precision": 0.0004853039019999218,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008790590531350532,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0008790590531350532,
        "precision": 0.0007780378722528334,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.04469389667816343,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.04469389667816343,
        "precision": 0.04126315947673233,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.08782435129740519,
        "f1": 0.0693925280751628,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0693925280751628,
        "precision": 0.06412754835908528,
        "recall": 0.08782435129740519
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003293253619240989,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003293253619240989,
        "precision": 0.0030177003416223106,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.015377035355805615,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015377035355805615,
        "precision": 0.01337199182341512,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.08569288634809766,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.08569288634809766,
        "precision": 0.07866854073101,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0012079016570034533,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0012079016570034533,
        "precision": 0.000998563097893848,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.017324055343104966,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.017324055343104966,
        "precision": 0.015886518918154544,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.040109928941942326,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.040109928941942326,
        "precision": 0.03471368700616088,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.019839129119913153,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.019839129119913153,
        "precision": 0.018068074827140745,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.2322022621423819,
        "f1": 0.18136852797531436,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.18136852797531436,
        "precision": 0.1638831284040865,
        "recall": 0.2322022621423819
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002606101478320742,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002606101478320742,
        "precision": 0.002367080881184729,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.04485986495930097,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04485986495930097,
        "precision": 0.038875123114976734,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00155201676427819,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00155201676427819,
        "precision": 0.0014493544862345341,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.020169306962518598,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.020169306962518598,
        "precision": 0.019039989475281682,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.024741255626941884,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.024741255626941884,
        "precision": 0.02128155613743422,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008684957924396175,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008684957924396175,
        "precision": 0.0005302010698825763,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.079197014835373,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.079197014835373,
        "precision": 0.07240882031926878,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.027547682412951875,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.027547682412951875,
        "precision": 0.025621056913311117,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.026426315380365134,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.026426315380365134,
        "precision": 0.024651271144130175,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.02690942277702091,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.02690942277702091,
        "precision": 0.025812977251192203,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00046940859264095594,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.00046940859264095594,
        "precision": 0.0002693177478646259,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008200148763432903,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0008200148763432903,
        "precision": 0.0007519289893560099,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.008580437693530759,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.008580437693530759,
        "precision": 0.008346918940178425,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.009957478532334394,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.009957478532334394,
        "precision": 0.009762832949457229,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.004248387273551756,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.004248387273551756,
        "precision": 0.0037604514016311356,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.009648303113856262,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.009648303113856262,
        "precision": 0.009536948511939706,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.011631225692570345,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.011631225692570345,
        "precision": 0.011361794691901956,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.023047921251514066,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.023047921251514066,
        "precision": 0.02056134644291664,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0029479820419679834,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.0029479820419679834,
        "precision": 0.002819590615342186,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013074288365017995,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.0013074288365017995,
        "precision": 0.000932285386511263,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.027361326729257535,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.027361326729257535,
        "precision": 0.02498706660383307,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0013532323549784635,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0013532323549784635,
        "precision": 0.0013421285472085796,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.049234863606121095,
        "f1": 0.03317571206792764,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.03317571206792764,
        "precision": 0.028775013705153424,
        "recall": 0.049234863606121095
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011797673129352287,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.0011797673129352287,
        "precision": 0.0010350360225752867,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.017073161406947784,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.017073161406947784,
        "precision": 0.014789767599654887,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.03385167572860853,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.03385167572860853,
        "precision": 0.03126413165023237,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014450771938696514,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0014450771938696514,
        "precision": 0.0013903047783742906,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.02846258447779863,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.02846258447779863,
        "precision": 0.02409901389281815,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0074899200199977645,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.0074899200199977645,
        "precision": 0.007049495135971551,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.009956355304788873,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.009956355304788873,
        "precision": 0.009284632380857406,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.03571830697579201,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.03571830697579201,
        "precision": 0.033187843194146374,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.006939182627539051,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.006939182627539051,
        "precision": 0.006829672294117069,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010928317355293586,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0010928317355293586,
        "precision": 0.0007784678750086861,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013081511081487443,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0013081511081487443,
        "precision": 0.0010269665591414344,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.07917498336660013,
        "f1": 0.063568020653849,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.063568020653849,
        "precision": 0.05886749767321956,
        "recall": 0.07917498336660013
      },
      {
        "accuracy": 0.25615435795076513,
        "f1": 0.20752254680651755,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.20752254680651755,
        "precision": 0.19024873533356568,
        "recall": 0.25615435795076513
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003363652412272765,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003363652412272765,
        "precision": 0.002913613015183766,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.1164337990685296,
        "f1": 0.08855294738528272,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08855294738528272,
        "precision": 0.08041111739964035,
        "recall": 0.1164337990685296
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.010816051629062831,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.010816051629062831,
        "precision": 0.00899838376114598,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0009561342931658356,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0009561342931658356,
        "precision": 0.0008256710074593295,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01591735039850314,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.01591735039850314,
        "precision": 0.014156594752347693,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.16699933466400532,
        "f1": 0.12608570737313252,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.12608570737313252,
        "precision": 0.11302712036244969,
        "recall": 0.16699933466400532
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.02223689991431483,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.02223689991431483,
        "precision": 0.020554535508653642,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.08316699933466401,
        "f1": 0.05826029019054732,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05826029019054732,
        "precision": 0.05095906071454974,
        "recall": 0.08316699933466401
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0020134717727329932,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0020134717727329932,
        "precision": 0.0017314063695909104,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.13439787092481703,
        "f1": 0.09938391115448764,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09938391115448764,
        "precision": 0.08880532585622407,
        "recall": 0.13439787092481703
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0019043541808956253,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0019043541808956253,
        "precision": 0.0016700693180770883,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.015620274741778515,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.015620274741778515,
        "precision": 0.014803364116958158,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.03421958618071181,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.03421958618071181,
        "precision": 0.030335337624021127,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011220153859668113,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011220153859668113,
        "precision": 0.0009204100364887296,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.17165668662674652,
        "f1": 0.1282348962488683,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1282348962488683,
        "precision": 0.11471343028229256,
        "recall": 0.17165668662674652
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.022319246663661283,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.022319246663661283,
        "precision": 0.020601118025387135,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.02236571638713622,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02236571638713622,
        "precision": 0.02053754653222384,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.028293782943902997,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.028293782943902997,
        "precision": 0.026152249163443712,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0003002751291181926,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0003002751291181926,
        "precision": 0.00016535665692303352,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008289634423026068,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0008289634423026068,
        "precision": 0.0007564407499329593,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008002445584884816,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0008002445584884816,
        "precision": 0.0007350452595381941,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012631990538863362,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0012631990538863362,
        "precision": 0.001081485444403689,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00020446828070539225,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.00020446828070539225,
        "precision": 0.00011187761319470785,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0011098782778221827,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0011098782778221827,
        "precision": 0.0009984968334935068,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.02530950352150058,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.02530950352150058,
        "precision": 0.02215333642479351,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007773572415911604,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0007773572415911604,
        "precision": 0.0007239324556460513,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006829972895165136,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0006829972895165136,
        "precision": 0.0006742698894110357,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001359113769604562,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.001359113769604562,
        "precision": 0.00113944263125574,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.02478766342007601,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.02478766342007601,
        "precision": 0.021428355410391335,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00135791869420201,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.00135791869420201,
        "precision": 0.0013445567596345102,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.028353226057816875,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.028353226057816875,
        "precision": 0.024153440381449474,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008043223303762906,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0008043223303762906,
        "precision": 0.0007372883852854556,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.018492007648997777,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.018492007648997777,
        "precision": 0.016231254226288433,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.010450127106591042,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.010450127106591042,
        "precision": 0.00899731356569137,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0013961988376300807,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0013961988376300807,
        "precision": 0.001364364267800942,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.011400424839064801,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.011400424839064801,
        "precision": 0.00915670384558695,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007642077640012804,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0007642077640012804,
        "precision": 0.0007184330813729077,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.003157278830170889,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.003157278830170889,
        "precision": 0.0021812124777247166,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.043196755389058,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.043196755389058,
        "precision": 0.03844534590177451,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006821785859646932,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0006821785859646932,
        "precision": 0.0006738530970188136,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009986562822068281,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0009986562822068281,
        "precision": 0.0008494914932040682,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009160563241318607,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0009160563241318607,
        "precision": 0.0008131291388306769,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.020321230669555757,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.020321230669555757,
        "precision": 0.01965881149427101,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.022811519817507845,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.022811519817507845,
        "precision": 0.021946583024427334,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.005370891077604632,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.005370891077604632,
        "precision": 0.005347223899391531,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.022171262051061277,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.022171262051061277,
        "precision": 0.021709587078848555,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.009403310260419571,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.009403310260419571,
        "precision": 0.008428594305179503,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.02064496207225242,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.02064496207225242,
        "precision": 0.019279647653592833,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007282054248989944,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0007282054248989944,
        "precision": 0.0006979147949032998,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000728423273333453,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.000728423273333453,
        "precision": 0.0004438811262729481,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.015528286860622189,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.015528286860622189,
        "precision": 0.014439686628642048,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027343232679330506,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0027343232679330506,
        "precision": 0.002439058740643215,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00015960262385736763,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.00015960262385736763,
        "precision": 8.453302734305946e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0030872598237867703,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0030872598237867703,
        "precision": 0.0025504546462630294,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.002022731858093117,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.002022731858093117,
        "precision": 0.0020096123181922386,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.021483146987649252,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.021483146987649252,
        "precision": 0.02055674662341925,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0018050835895642304,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0018050835895642304,
        "precision": 0.0016010222150069093,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 5.34079824073251e-05,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 5.34079824073251e-05,
        "precision": 2.701340118833802e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.022069857399198718,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.022069857399198718,
        "precision": 0.02125785642961817,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.014526502550454646,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.014526502550454646,
        "precision": 0.01366156575737414,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.01785961089093954,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.01785961089093954,
        "precision": 0.016902764051185654,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.07850964737192283,
        "f1": 0.0620076246050304,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.0620076246050304,
        "precision": 0.057798432652934176,
        "recall": 0.07850964737192283
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0016332761799275582,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0016332761799275582,
        "precision": 0.0012589820359281438,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00023664703825984414,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00023664703825984414,
        "precision": 0.00014057333238175706,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.015188142234050416,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.015188142234050416,
        "precision": 0.012678875054124556,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.08101623201668308,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.08101623201668308,
        "precision": 0.0711753048802775,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006747509146965554,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0006747509146965554,
        "precision": 0.0006700656435089765,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.04078874108814228,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04078874108814228,
        "precision": 0.037462134813265886,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.004273589342698437,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004273589342698437,
        "precision": 0.00381876623267739,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.1536926147704591,
        "f1": 0.11784239638531056,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.11784239638531056,
        "precision": 0.10801622773550949,
        "recall": 0.1536926147704591
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000980438995835899,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.000980438995835899,
        "precision": 0.0008566476202876989,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001733854228864209,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.001733854228864209,
        "precision": 0.0011173915535503546,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001587831369764482,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.001587831369764482,
        "precision": 0.0010747341108095557,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.05371622745254987,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05371622745254987,
        "precision": 0.04870325486592952,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0014478763502136583,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0014478763502136583,
        "precision": 0.001202710711658917,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.1596806387225549,
        "f1": 0.11884679414619534,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.11884679414619534,
        "precision": 0.10633747457925188,
        "recall": 0.1596806387225549
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.004241751239305426,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.004241751239305426,
        "precision": 0.0038940504819092473,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0010162253059513432,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0010162253059513432,
        "precision": 0.000876820631934061,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.04707720625297236,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.04707720625297236,
        "precision": 0.04254624007618019,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003219004824489507,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003219004824489507,
        "precision": 0.0026730358101514093,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.05322687957418496,
        "f1": 0.03845095271510733,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.03845095271510733,
        "precision": 0.034391054351134195,
        "recall": 0.05322687957418496
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0018078219335279683,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0018078219335279683,
        "precision": 0.0016081019465554742,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0019854800576099715,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0019854800576099715,
        "precision": 0.001781252106988759,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0022494693153375786,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0022494693153375786,
        "precision": 0.002133205872069608,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.793723863584143e-05,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 8.793723863584143e-05,
        "precision": 4.5405577202471674e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008341712564845247,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0008341712564845247,
        "precision": 0.0007616369807242299,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.01247155527050526,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.01247155527050526,
        "precision": 0.011570571293843196,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.016972361503187802,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.016972361503187802,
        "precision": 0.01630388619485733,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.007323976385852632,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.007323976385852632,
        "precision": 0.006514748281215347,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.013529630486367192,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.013529630486367192,
        "precision": 0.012921597312138265,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.025986247237861654,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.025986247237861654,
        "precision": 0.02304354696482206,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.016043747780274724,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.016043747780274724,
        "precision": 0.015452761266979908,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.02803125301336949,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.02803125301336949,
        "precision": 0.024262781303517278,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.009260423451725886,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.009260423451725886,
        "precision": 0.008656287070037504,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00017974457279864043,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.00017974457279864043,
        "precision": 9.930455253512469e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009990136065754177,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0009990136065754177,
        "precision": 0.0008593934746186051,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.013716766059140134,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.013716766059140134,
        "precision": 0.011518987122166728,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006971418721688674,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0006971418721688674,
        "precision": 0.0006814742294526737,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008782630937409242,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.008782630937409242,
        "precision": 0.006893211486201712,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.03199528828459629,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.03199528828459629,
        "precision": 0.030185721372952803,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007060794236442939,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0007060794236442939,
        "precision": 0.000686241138669615,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0066101147815933615,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0066101147815933615,
        "precision": 0.005253730199822718,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.013856568591510984,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.013856568591510984,
        "precision": 0.012950788435162957,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.01044003008765467,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.01044003008765467,
        "precision": 0.009411072333819536,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04596691235272501,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.04596691235272501,
        "precision": 0.04184035406003235,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.011485658914744405,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.011485658914744405,
        "precision": 0.010732983634473073,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015286074168309697,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0015286074168309697,
        "precision": 0.0011933422813973852,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007876381795210804,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0007876381795210804,
        "precision": 0.0007325362634783872,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.015804509427728104,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.015804509427728104,
        "precision": 0.013379688828568964,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.07850964737192283,
        "f1": 0.056468460939518815,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.056468460939518815,
        "precision": 0.051048322196026785,
        "recall": 0.07850964737192283
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006996899992005998,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0006996899992005998,
        "precision": 0.0006827051112116678,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.21823020625415834,
        "f1": 0.17428639594308257,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.17428639594308257,
        "precision": 0.15931681610324325,
        "recall": 0.21823020625415834
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0034029274181180376,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0034029274181180376,
        "precision": 0.003125515191273525,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.08848968729208251,
        "f1": 0.060270660071059266,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.060270660071059266,
        "precision": 0.053322372316736526,
        "recall": 0.08848968729208251
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0021856813508682187,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0021856813508682187,
        "precision": 0.002094567562354419,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0026805124591852024,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0026805124591852024,
        "precision": 0.0022074198941053466,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0718562874251497,
        "f1": 0.04713611774490019,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.04713611774490019,
        "precision": 0.0403368347480124,
        "recall": 0.0718562874251497
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008374152901557205,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0008374152901557205,
        "precision": 0.0007569972501075188,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002927311209570221,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002927311209570221,
        "precision": 0.002598649876624449,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.08316699933466401,
        "f1": 0.059413578643539765,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.059413578643539765,
        "precision": 0.053158243115387645,
        "recall": 0.08316699933466401
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.002680446762870151,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002680446762870151,
        "precision": 0.002670994807204316,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0021919447487549035,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0021919447487549035,
        "precision": 0.0018907379466620953,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.021890765661205576,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.021890765661205576,
        "precision": 0.01833279301537971,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002524271423987571,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002524271423987571,
        "precision": 0.002091562836727958,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.03402084956470465,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.03402084956470465,
        "precision": 0.029572446092530676,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0033997379404568655,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0033997379404568655,
        "precision": 0.0031505855813761738,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003892430208101155,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.003892430208101155,
        "precision": 0.003554146236512483,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002077089090172783,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.002077089090172783,
        "precision": 0.0017956188987798668,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0003921697249881261,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0003921697249881261,
        "precision": 0.0002301471599791795,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008821833531876711,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0008821833531876711,
        "precision": 0.0007897353268702075,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0010288511207493995,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0010288511207493995,
        "precision": 0.0008724317611425526,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006748026737459636,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0006748026737459636,
        "precision": 0.0006700816709757729,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001973363001307113,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.001973363001307113,
        "precision": 0.0017690630569338502,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662543328342166,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0006662543328342166,
        "precision": 0.0006657954808614814,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.04790419161676647,
        "f1": 0.0329552682846096,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0329552682846096,
        "precision": 0.029426622223381646,
        "recall": 0.04790419161676647
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007513844668481273,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0007513844668481273,
        "precision": 0.0007105567500389787,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.027564809614737725,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.027564809614737725,
        "precision": 0.024394405494483413,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006903489374136769,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0006903489374136769,
        "precision": 0.0006780021375829759,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00020054898434299453,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00020054898434299453,
        "precision": 0.00011613140620163765,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.015362563630736,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.015362563630736,
        "precision": 0.013702875695556997,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006849419741283073,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0006849419741283073,
        "precision": 0.0006752601716950719,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007367107361205151,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0007367107361205151,
        "precision": 0.0007018375013258828,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.021616854965288555,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.021616854965288555,
        "precision": 0.018772533012481978,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.021838992190971157,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.021838992190971157,
        "precision": 0.01916405284668758,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009121850187493382,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0009121850187493382,
        "precision": 0.0008016628525610561,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.032959620592509,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.032959620592509,
        "precision": 0.030121110901655073,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006703573984107257,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0006703573984107257,
        "precision": 0.0006678562067783625,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0026112212643284276,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0026112212643284276,
        "precision": 0.0020866366911596284,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.01556836649387815,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.01556836649387815,
        "precision": 0.013068531047572962,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006844975281557898,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0006844975281557898,
        "precision": 0.0006750436748335686,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0017322053250196964,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0017322053250196964,
        "precision": 0.0011828355474396725,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010845192731420276,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0010845192731420276,
        "precision": 0.0008992390619628505,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.024829113313249017,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.024829113313249017,
        "precision": 0.021586254816852446,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.11709913506320692,
        "f1": 0.08444944626992296,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.08444944626992296,
        "precision": 0.07474470442137057,
        "recall": 0.11709913506320692
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 7.90610709528854e-05,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 7.90610709528854e-05,
        "precision": 4.149677212846227e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.06121091151031271,
        "f1": 0.04540029836279441,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04540029836279441,
        "precision": 0.04085670861824437,
        "recall": 0.06121091151031271
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0022184240121779853,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0022184240121779853,
        "precision": 0.0019184426698484797,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.14238190286094476,
        "f1": 0.10281051454957511,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.10281051454957511,
        "precision": 0.09054915200124779,
        "recall": 0.14238190286094476
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0024656275285575204,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0024656275285575204,
        "precision": 0.0023419403197582687,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0020265266718732028,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0020265266718732028,
        "precision": 0.0017393717019781347,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.17165668662674652,
        "f1": 0.13293356307328363,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13293356307328363,
        "precision": 0.12020609574501791,
        "recall": 0.17165668662674652
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0033515292388463795,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0033515292388463795,
        "precision": 0.003078430182530499,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.09248170326014638,
        "f1": 0.06897106737426098,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06897106737426098,
        "precision": 0.06210597083850577,
        "recall": 0.09248170326014638
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003479382577119307,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003479382577119307,
        "precision": 0.0031617585776783303,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.002075829974577933,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002075829974577933,
        "precision": 0.0018334157572237704,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001993017275931703,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.001993017275931703,
        "precision": 0.0017076056237095858,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04092134670976986,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.04092134670976986,
        "precision": 0.0353323815732332,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001962403892753719,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001962403892753719,
        "precision": 0.0017624281033318222,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.05588822355289421,
        "f1": 0.03527296604650668,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.03527296604650668,
        "precision": 0.030244172669786556,
        "recall": 0.05588822355289421
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0016643960755737203,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0016643960755737203,
        "precision": 0.0015165746937497553,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0025925446198574284,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0025925446198574284,
        "precision": 0.002372241747423637,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0031080797931711487,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0031080797931711487,
        "precision": 0.002488145402317059,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00038265008660461644,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.00038265008660461644,
        "precision": 0.0002288949936223274,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0011287476390286276,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0011287476390286276,
        "precision": 0.0009228540834202287,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000889942982134961,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.000889942982134961,
        "precision": 0.0007874115733632695,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001641055026513153,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.001641055026513153,
        "precision": 0.00150156974194545,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0015918273142983038,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0015918273142983038,
        "precision": 0.0014726465056607188,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011924184516186919,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0011924184516186919,
        "precision": 0.0010411846742597213,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.03323490023186605,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.03323490023186605,
        "precision": 0.028565136041849282,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011423265590643388,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0011423265590643388,
        "precision": 0.001014925703273668,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.021421397576230766,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.021421397576230766,
        "precision": 0.018519851830730075,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007011783146126639,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0007011783146126639,
        "precision": 0.0006834253209922924,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 7.985408520744796e-05,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 7.985408520744796e-05,
        "precision": 4.0846622330257885e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.015331963172803232,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.015331963172803232,
        "precision": 0.013396652964575944,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0014880635728879697,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0014880635728879697,
        "precision": 0.001414732332165758,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.029281678923813417,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.029281678923813417,
        "precision": 0.024444674060148993,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007493870885406268,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0007493870885406268,
        "precision": 0.0007087965158620077,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.019307905062268368,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.019307905062268368,
        "precision": 0.016499116077283917,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.000883097090681921,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.000883097090681921,
        "precision": 0.0007805268669734459,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.022727734999977104,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.022727734999977104,
        "precision": 0.019000731026679128,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007130853650035922,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0007130853650035922,
        "precision": 0.0006894924471782932,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0028278127444898256,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0028278127444898256,
        "precision": 0.0024622607655554784,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.018783018983402528,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.018783018983402528,
        "precision": 0.014918759782603524,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000681424325415413,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.000681424325415413,
        "precision": 0.0006734674155694185,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0003365759409480153,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.0003365759409480153,
        "precision": 0.0001955091388046203,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007939933895403694,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0007939933895403694,
        "precision": 0.0007357300427395193,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.01959811175793199,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.01959811175793199,
        "precision": 0.017881818205446275,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.019538849376072046,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.019538849376072046,
        "precision": 0.01802435599656696,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.010128141560816489,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.010128141560816489,
        "precision": 0.00923952714600095,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.021049538936743925,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.021049538936743925,
        "precision": 0.019790577156258166,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.06187624750499002,
        "f1": 0.04213983062988795,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.04213983062988795,
        "precision": 0.03653926022051855,
        "recall": 0.06187624750499002
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.02076812520700863,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.02076812520700863,
        "precision": 0.019643499967184935,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.014408344841595986,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.014408344841595986,
        "precision": 0.011941231710902896,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.01106926777247518,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.01106926777247518,
        "precision": 0.010088209404882788,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000852319466703202,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.000852319466703202,
        "precision": 0.000593335583597417,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.03302971193403322,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.03302971193403322,
        "precision": 0.030336260969406444,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00101682599712855,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.00101682599712855,
        "precision": 0.0008966327396137223,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.025343923098414118,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.025343923098414118,
        "precision": 0.02149276403102085,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011784059323772986,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0011784059323772986,
        "precision": 0.0010336259168706946,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.01937453188900341,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.01937453188900341,
        "precision": 0.016483868830787896,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0013490579025203116,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0013490579025203116,
        "precision": 0.0011268802170706544,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.05788423153692615,
        "f1": 0.038562717960985426,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.038562717960985426,
        "precision": 0.03389522404382851,
        "recall": 0.05788423153692615
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.014576289597675398,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.014576289597675398,
        "precision": 0.013438817568263595,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.01630368486379249,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.01630368486379249,
        "precision": 0.014881346463534702,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.06187624750499002,
        "f1": 0.04777463409251556,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.04777463409251556,
        "precision": 0.04372511250486311,
        "recall": 0.06187624750499002
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.016239940753413805,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.016239940753413805,
        "precision": 0.01489619645415814,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0021981014512345294,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0021981014512345294,
        "precision": 0.0014550005704950717,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0016461646464798055,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0016461646464798055,
        "precision": 0.001333182691221331,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.019746693746152455,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.019746693746152455,
        "precision": 0.01707182616854146,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.02909896896922845,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.02909896896922845,
        "precision": 0.02565303646562182,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00015658040165269843,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00015658040165269843,
        "precision": 8.461227746794544e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.043912175648702596,
        "f1": 0.03142190684702483,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.03142190684702483,
        "precision": 0.028492079739584727,
        "recall": 0.043912175648702596
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0025874177570784354,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0025874177570784354,
        "precision": 0.0019904635174096247,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.05588822355289421,
        "f1": 0.040193653376964164,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.040193653376964164,
        "precision": 0.03623648104686029,
        "recall": 0.05588822355289421
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0029781122086041042,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0029781122086041042,
        "precision": 0.002662215978702272,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0027807130836366486,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0027807130836366486,
        "precision": 0.002483463777941662,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.06986027944111776,
        "f1": 0.04897131766901001,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.04897131766901001,
        "precision": 0.04312935345869478,
        "recall": 0.06986027944111776
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0012910077002268202,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0012910077002268202,
        "precision": 0.001095773066586451,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.02668853857946502,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.02668853857946502,
        "precision": 0.023705442382252848,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000784283005644303,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.000784283005644303,
        "precision": 0.0005238247302505882,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.04379600826119553,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04379600826119553,
        "precision": 0.03841183932501298,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002765063023493531,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002765063023493531,
        "precision": 0.0022239963806742376,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008013267002235677,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0008013267002235677,
        "precision": 0.0007368105965168069,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0019265867622468543,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0019265867622468543,
        "precision": 0.0012840732267846247,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.02761981723302685,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02761981723302685,
        "precision": 0.025400208888434396,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.004076794047772336,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.004076794047772336,
        "precision": 0.0036541169339899364,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0023091954229678777,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0023091954229678777,
        "precision": 0.0019986482062330367,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0022242841986636133,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0022242841986636133,
        "precision": 0.002118112134191087,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.747050687339124e-05,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 6.747050687339124e-05,
        "precision": 3.532294256736611e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00010120479770723222,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.00010120479770723222,
        "precision": 5.3820933539956875e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0004262190284881744,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0004262190284881744,
        "precision": 0.0002380082660697901,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007058250254763096,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0007058250254763096,
        "precision": 0.0006859615305594042,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015515798572253753,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0015515798572253753,
        "precision": 0.001087730293381491,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662568749467616,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0006662568749467616,
        "precision": 0.000665796753676396,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.02567347407616269,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.02567347407616269,
        "precision": 0.021557740884088187,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00011303012987271244,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.00011303012987271244,
        "precision": 5.91827674320532e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.010567084525833693,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.010567084525833693,
        "precision": 0.009099088528262772,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.1783418766585768e-05,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 2.1783418766585768e-05,
        "precision": 1.0998222666181766e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.000856469257372831,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.000856469257372831,
        "precision": 0.0005955501906197017,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.006878762812473218,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.006878762812473218,
        "precision": 0.0055424529791585145,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006838409444589488,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0006838409444589488,
        "precision": 0.0006746950622437304,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.027737118355880826,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.027737118355880826,
        "precision": 0.02317325426107861,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 9.735308823165428e-05,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 9.735308823165428e-05,
        "precision": 5.0610889364082906e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.014238718350747455,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.014238718350747455,
        "precision": 0.012637144772873315,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.024299953993106388,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.024299953993106388,
        "precision": 0.021413382491855794,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008209604061704617,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0008209604061704617,
        "precision": 0.0007475082023122949,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.476946915475891e-05,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 2.476946915475891e-05,
        "precision": 1.2515772985933889e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.002396349223025559,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.002396349223025559,
        "precision": 0.0019143463998390817,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.01589434761256752,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.01589434761256752,
        "precision": 0.014074241059155066,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.716480013750125e-05,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 1.716480013750125e-05,
        "precision": 8.682901295608697e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00063681955218032,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00063681955218032,
        "precision": 0.00039753577642194374,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011885259759259659,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0011885259759259659,
        "precision": 0.0010402670994408868,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.05854956753160346,
        "f1": 0.04742477526908664,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.04742477526908664,
        "precision": 0.04398271697007558,
        "recall": 0.05854956753160346
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.10521852342622567,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.10521852342622567,
        "precision": 0.0954489169808531,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0033114439056375214,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0033114439056375214,
        "precision": 0.002733597056080978,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.09115103127079174,
        "f1": 0.07479435557984342,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.07479435557984342,
        "precision": 0.07008825062717278,
        "recall": 0.09115103127079174
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.01072105312059174,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01072105312059174,
        "precision": 0.008865228393827255,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.1709913506320692,
        "f1": 0.14446421879830923,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.14446421879830923,
        "precision": 0.13507276730304357,
        "recall": 0.1709913506320692
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.001149605495664509,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.001149605495664509,
        "precision": 0.0010189540016142735,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.01851516356949934,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.01851516356949934,
        "precision": 0.017041003847059255,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.059214903526280775,
        "f1": 0.044542900730525484,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.044542900730525484,
        "precision": 0.04022304008394545,
        "recall": 0.059214903526280775
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.021328833767323124,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.021328833767323124,
        "precision": 0.01946823883359734,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.0499001996007984,
        "f1": 0.03746686521137619,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.03746686521137619,
        "precision": 0.03361814003950783,
        "recall": 0.0499001996007984
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0035044980154760597,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0035044980154760597,
        "precision": 0.0031724912072080887,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.05256154357950765,
        "f1": 0.036319779677182515,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.036319779677182515,
        "precision": 0.031946292599985215,
        "recall": 0.05256154357950765
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0017891577619579247,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0017891577619579247,
        "precision": 0.0016708670508879936,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.016440124714298017,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.016440124714298017,
        "precision": 0.01563678199157241,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.018445960412028277,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.018445960412028277,
        "precision": 0.01626039581376048,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0019760368704271943,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0019760368704271943,
        "precision": 0.0015535558635405456,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.019821978010772835,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.019821978010772835,
        "precision": 0.018465591995822914,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.02368225035713887,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02368225035713887,
        "precision": 0.02235906471563065,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.02495521685392365,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.02495521685392365,
        "precision": 0.02313567857696991,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00139472137975132,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.00139472137975132,
        "precision": 0.0009502520029852461,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0014413480730846,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0014413480730846,
        "precision": 0.0013903011586889114,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.020101275228896598,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.020101275228896598,
        "precision": 0.01858520807418766,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.024975181911309655,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.024975181911309655,
        "precision": 0.02387699438597642,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004927427472127822,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.004927427472127822,
        "precision": 0.004401770071376619,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.023875997630375668,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.023875997630375668,
        "precision": 0.022707987548900046,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.015682154782282697,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.015682154782282697,
        "precision": 0.013488263712814611,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.024524918417133987,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.024524918417133987,
        "precision": 0.02351552209745831,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.008116252443115958,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.008116252443115958,
        "precision": 0.007041544616394915,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.013349635505324127,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.013349635505324127,
        "precision": 0.012379633497862155,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0019136170153069125,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0019136170153069125,
        "precision": 0.001684332002832052,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.02508883592343353,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.02508883592343353,
        "precision": 0.02288821558617722,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0025815060634765755,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0025815060634765755,
        "precision": 0.0023149116916764516,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028934961617982672,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0028934961617982672,
        "precision": 0.0022021767820974824,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0013473644986738203,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.0013473644986738203,
        "precision": 0.0010967963063771447,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.005478697776860073,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.005478697776860073,
        "precision": 0.00441397905942501,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.027377568096130966,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.027377568096130966,
        "precision": 0.025571080062098028,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0012915176123851288,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0012915176123851288,
        "precision": 0.0010247412056994805,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0037986823888464354,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0037986823888464354,
        "precision": 0.002704157934872975,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.01656846423990388,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.01656846423990388,
        "precision": 0.015177110021691958,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.03023160029148053,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.03023160029148053,
        "precision": 0.027777777777777776,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.01457336649452418,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.01457336649452418,
        "precision": 0.013028277104962441,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0001248206214146716,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.0001248206214146716,
        "precision": 6.52933698966826e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.3259251317401327e-05,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 1.3259251317401327e-05,
        "precision": 6.673183566348456e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.014382891508711386,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.014382891508711386,
        "precision": 0.01321926511564163,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.01686129772813548,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.01686129772813548,
        "precision": 0.015588058283508505,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0076568178736723,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.0076568178736723,
        "precision": 0.006365641321162495,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.016836387595084334,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.016836387595084334,
        "precision": 0.016033571953836687,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.03663940119422983,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.03663940119422983,
        "precision": 0.03227764108828068,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.01881483819655349,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.01881483819655349,
        "precision": 0.0176919720241961,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.03750728353541381,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.03750728353541381,
        "precision": 0.032294654000837184,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.007486004147332653,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.007486004147332653,
        "precision": 0.00683553552445258,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011270935773762425,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.0011270935773762425,
        "precision": 0.0009415150732981364,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.046965505271507064,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.046965505271507064,
        "precision": 0.04220666609013485,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00019118137530578554,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.00019118137530578554,
        "precision": 0.00011143246387044505,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.01626575508255879,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.01626575508255879,
        "precision": 0.013997367160905622,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 4.482102235673233e-05,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 4.482102235673233e-05,
        "precision": 2.2713267340328593e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.01752020749190888,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.01752020749190888,
        "precision": 0.015242470446578999,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.04057715867833968,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.04057715867833968,
        "precision": 0.03795928694703598,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 1.6458659590870204e-05,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 1.6458659590870204e-05,
        "precision": 8.2708407631435e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.014888115418576237,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.014888115418576237,
        "precision": 0.012939015934205727,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.012741490370826997,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.012741490370826997,
        "precision": 0.011662547090643776,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.014811471224759554,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.014811471224759554,
        "precision": 0.013617993862293273,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.012137213945391715,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.012137213945391715,
        "precision": 0.011015161383184304,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010957937604644192,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0010957937604644192,
        "precision": 0.0009184360324185935,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011393878908848968,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0011393878908848968,
        "precision": 0.0009481804440274596,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.029246139060077544,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.029246139060077544,
        "precision": 0.027671527382197574,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.03106599136435687,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.03106599136435687,
        "precision": 0.029737956910011652,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0046857179892213,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0046857179892213,
        "precision": 0.004011865450116976,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.03470630596379099,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.03470630596379099,
        "precision": 0.03318438418238817,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.00968486307807665,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.00968486307807665,
        "precision": 0.007987759308646945,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.03889005276493458,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.03889005276493458,
        "precision": 0.037555146866980055,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000838248174084975,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.000838248174084975,
        "precision": 0.0007636814013955258,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.08449767132401863,
        "f1": 0.06186844524064393,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.06186844524064393,
        "precision": 0.05610232309954942,
        "recall": 0.08449767132401863
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001452491147349413,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.001452491147349413,
        "precision": 0.0011902997242116268,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.018361244338503304,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.018361244338503304,
        "precision": 0.016489306384093082,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0018881567154883535,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0018881567154883535,
        "precision": 0.0015335461799513101,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 2.9990779861596605e-05,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 2.9990779861596605e-05,
        "precision": 1.5271252513235284e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.003360610213570959,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.003360610213570959,
        "precision": 0.0031016599280072332,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006165276643712689,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0006165276643712689,
        "precision": 0.00042373544535886514,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.02596349446700469,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.02596349446700469,
        "precision": 0.024425600175499447,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.002251053448658239,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.002251053448658239,
        "precision": 0.0019140463035282093,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0002060832137135373,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0002060832137135373,
        "precision": 0.00011098335445656739,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.02518200251733186,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.02518200251733186,
        "precision": 0.024191836755745485,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.02301776033260433,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.02301776033260433,
        "precision": 0.022044205240313024,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.0234627584789646,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.0234627584789646,
        "precision": 0.021719828396239354,
        "recall": 0.02927478376580173
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}