{
  "dataset_revision": "264a18480c529d9e922483839b4b9758e690b762",
  "evaluation_time": 576.6353447437286,
  "kg_co2_emissions": 0.10092965853697923,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.0390625,
        "f1": 0.019743117314448833,
        "hf_subset": "eng_Latn-aai_Latn",
        "languages": [
          "eng-Latn",
          "aai-Latn"
        ],
        "main_score": 0.019743117314448833,
        "precision": 0.01727698023653906,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022563525883838382,
        "hf_subset": "aai_Latn-eng_Latn",
        "languages": [
          "aai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022563525883838382,
        "precision": 0.018349288438967135,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008605072463768116,
        "hf_subset": "eng_Latn-aak_Arab",
        "languages": [
          "eng-Latn",
          "aak-Arab"
        ],
        "main_score": 0.0008605072463768116,
        "precision": 0.0004565746753246753,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00411141018907563,
        "hf_subset": "aak_Arab-eng_Latn",
        "languages": [
          "aak-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00411141018907563,
        "precision": 0.004010376540832049,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010796909606866002,
        "hf_subset": "eng_Latn-aau_Latn",
        "languages": [
          "eng-Latn",
          "aau-Latn"
        ],
        "main_score": 0.010796909606866002,
        "precision": 0.009546653091060986,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02077752976190476,
        "hf_subset": "aau_Latn-eng_Latn",
        "languages": [
          "aau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02077752976190476,
        "precision": 0.01901830808080808,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023612214571563088,
        "hf_subset": "eng_Latn-aaz_Latn",
        "languages": [
          "eng-Latn",
          "aaz-Latn"
        ],
        "main_score": 0.023612214571563088,
        "precision": 0.021003493544853837,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023003897635383484,
        "hf_subset": "aaz_Latn-eng_Latn",
        "languages": [
          "aaz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023003897635383484,
        "precision": 0.02194412846268315,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01341781670205237,
        "hf_subset": "eng_Latn-abt_Latn",
        "languages": [
          "eng-Latn",
          "abt-Latn"
        ],
        "main_score": 0.01341781670205237,
        "precision": 0.012666099091880342,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013531122676343264,
        "hf_subset": "abt_Latn-eng_Latn",
        "languages": [
          "abt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013531122676343264,
        "precision": 0.012736002604166668,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023861344130970654,
        "hf_subset": "eng_Latn-abx_Latn",
        "languages": [
          "eng-Latn",
          "abx-Latn"
        ],
        "main_score": 0.023861344130970654,
        "precision": 0.021216784808727015,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03886101066353325,
        "hf_subset": "abx_Latn-eng_Latn",
        "languages": [
          "abx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03886101066353325,
        "precision": 0.036487886037714544,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-aby_Latn",
        "languages": [
          "eng-Latn",
          "aby-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00016983695652173913,
        "hf_subset": "aby_Latn-eng_Latn",
        "languages": [
          "aby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00016983695652173913,
        "precision": 8.680555555555556e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0007618417877463929,
        "hf_subset": "eng_Latn-acf_Latn",
        "languages": [
          "eng-Latn",
          "acf-Latn"
        ],
        "main_score": 0.0007618417877463929,
        "precision": 0.00039654356060606056,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013506155303030305,
        "hf_subset": "acf_Latn-eng_Latn",
        "languages": [
          "acf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013506155303030305,
        "precision": 0.011549161985138185,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01720300099206349,
        "hf_subset": "eng_Latn-acr_Latn",
        "languages": [
          "eng-Latn",
          "acr-Latn"
        ],
        "main_score": 0.01720300099206349,
        "precision": 0.012857663799574082,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.021585925039872406,
        "hf_subset": "acr_Latn-eng_Latn",
        "languages": [
          "acr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021585925039872406,
        "precision": 0.017995101686507933,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0016860268354833572,
        "hf_subset": "eng_Latn-acu_Latn",
        "languages": [
          "eng-Latn",
          "acu-Latn"
        ],
        "main_score": 0.0016860268354833572,
        "precision": 0.0009444559073629452,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006556644477317554,
        "hf_subset": "acu_Latn-eng_Latn",
        "languages": [
          "acu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006556644477317554,
        "precision": 0.005882626488095238,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.0405702906162465,
        "hf_subset": "eng_Latn-adz_Latn",
        "languages": [
          "eng-Latn",
          "adz-Latn"
        ],
        "main_score": 0.0405702906162465,
        "precision": 0.03835830510635198,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03547565202067669,
        "hf_subset": "adz_Latn-eng_Latn",
        "languages": [
          "adz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03547565202067669,
        "precision": 0.03177701939066561,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.02001953125,
        "hf_subset": "eng_Latn-aer_Latn",
        "languages": [
          "eng-Latn",
          "aer-Latn"
        ],
        "main_score": 0.02001953125,
        "precision": 0.018489583333333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015619533237913485,
        "hf_subset": "aer_Latn-eng_Latn",
        "languages": [
          "aer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015619533237913485,
        "precision": 0.01328339629120879,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003960776989483385,
        "hf_subset": "eng_Latn-aey_Latn",
        "languages": [
          "eng-Latn",
          "aey-Latn"
        ],
        "main_score": 0.003960776989483385,
        "precision": 0.002692114400584795,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0146203753591954,
        "hf_subset": "aey_Latn-eng_Latn",
        "languages": [
          "aey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0146203753591954,
        "precision": 0.013823517403882045,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000316722972972973,
        "hf_subset": "eng_Latn-agd_Latn",
        "languages": [
          "eng-Latn",
          "agd-Latn"
        ],
        "main_score": 0.000316722972972973,
        "precision": 0.00016201721841704718,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004832607794361525,
        "hf_subset": "agd_Latn-eng_Latn",
        "languages": [
          "agd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004832607794361525,
        "precision": 0.00442390155075188,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003876782061117504,
        "hf_subset": "eng_Latn-agg_Latn",
        "languages": [
          "eng-Latn",
          "agg-Latn"
        ],
        "main_score": 0.003876782061117504,
        "precision": 0.0026522987280103126,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008247592520319159,
        "hf_subset": "agg_Latn-eng_Latn",
        "languages": [
          "agg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008247592520319159,
        "precision": 0.00653901332443897,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.944620253164557e-05,
        "hf_subset": "eng_Latn-agm_Latn",
        "languages": [
          "eng-Latn",
          "agm-Latn"
        ],
        "main_score": 4.944620253164557e-05,
        "precision": 2.4880573248407645e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002850519018583043,
        "hf_subset": "agm_Latn-eng_Latn",
        "languages": [
          "agm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002850519018583043,
        "precision": 0.0020788837679856114,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016309054878944667,
        "hf_subset": "eng_Latn-agn_Latn",
        "languages": [
          "eng-Latn",
          "agn-Latn"
        ],
        "main_score": 0.016309054878944667,
        "precision": 0.014865535340103158,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0215609681372549,
        "hf_subset": "agn_Latn-eng_Latn",
        "languages": [
          "agn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0215609681372549,
        "precision": 0.020752080347837414,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00758809840425532,
        "hf_subset": "eng_Latn-agr_Latn",
        "languages": [
          "eng-Latn",
          "agr-Latn"
        ],
        "main_score": 0.00758809840425532,
        "precision": 0.006269814311594203,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009312140804597701,
        "hf_subset": "agr_Latn-eng_Latn",
        "languages": [
          "agr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009312140804597701,
        "precision": 0.007912675018422992,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019884672619047618,
        "hf_subset": "eng_Latn-agt_Latn",
        "languages": [
          "eng-Latn",
          "agt-Latn"
        ],
        "main_score": 0.019884672619047618,
        "precision": 0.01860175075301205,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02257597117794486,
        "hf_subset": "agt_Latn-eng_Latn",
        "languages": [
          "agt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02257597117794486,
        "precision": 0.021714256084070797,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011519582648026315,
        "hf_subset": "eng_Latn-agu_Latn",
        "languages": [
          "eng-Latn",
          "agu-Latn"
        ],
        "main_score": 0.011519582648026315,
        "precision": 0.010133298792902852,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015336007591442373,
        "hf_subset": "agu_Latn-eng_Latn",
        "languages": [
          "agu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015336007591442373,
        "precision": 0.014223958333333333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015692934782608695,
        "hf_subset": "eng_Latn-aia_Latn",
        "languages": [
          "eng-Latn",
          "aia-Latn"
        ],
        "main_score": 0.015692934782608695,
        "precision": 0.013706140350877194,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.515895953757225e-05,
        "hf_subset": "aia_Latn-eng_Latn",
        "languages": [
          "aia-Latn",
          "eng-Latn"
        ],
        "main_score": 4.515895953757225e-05,
        "precision": 2.2710755813953488e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.622781065088757e-05,
        "hf_subset": "eng_Latn-aii_Syrc",
        "languages": [
          "eng-Latn",
          "aii-Syrc"
        ],
        "main_score": 4.622781065088757e-05,
        "precision": 2.3251488095238094e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00013753607503607504,
        "hf_subset": "aii_Syrc-eng_Latn",
        "languages": [
          "aii-Syrc",
          "eng-Latn"
        ],
        "main_score": 0.00013753607503607504,
        "precision": 6.942149518983624e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01699067947978898,
        "hf_subset": "eng_Latn-aka_Latn",
        "languages": [
          "eng-Latn",
          "aka-Latn"
        ],
        "main_score": 0.01699067947978898,
        "precision": 0.014026510740165633,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029140559321143338,
        "hf_subset": "aka_Latn-eng_Latn",
        "languages": [
          "aka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029140559321143338,
        "precision": 0.027189852051357735,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-ake_Latn",
        "languages": [
          "eng-Latn",
          "ake-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002220869408369408,
        "hf_subset": "ake_Latn-eng_Latn",
        "languages": [
          "ake-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002220869408369408,
        "precision": 0.0012950622957516342,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029440611471861472,
        "hf_subset": "eng_Latn-alp_Latn",
        "languages": [
          "eng-Latn",
          "alp-Latn"
        ],
        "main_score": 0.029440611471861472,
        "precision": 0.027125539020327258,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024129554072343448,
        "hf_subset": "alp_Latn-eng_Latn",
        "languages": [
          "alp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024129554072343448,
        "precision": 0.021411465195432588,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012631704980842911,
        "hf_subset": "eng_Latn-alq_Latn",
        "languages": [
          "eng-Latn",
          "alq-Latn"
        ],
        "main_score": 0.012631704980842911,
        "precision": 0.012229610729768785,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016266025641025642,
        "hf_subset": "alq_Latn-eng_Latn",
        "languages": [
          "alq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016266025641025642,
        "precision": 0.012891045932112068,
        "recall": 0.03125
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.19270833333333331,
        "hf_subset": "eng_Latn-als_Latn",
        "languages": [
          "eng-Latn",
          "als-Latn"
        ],
        "main_score": 0.19270833333333331,
        "precision": 0.17708333333333334,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.17669270833333334,
        "hf_subset": "als_Latn-eng_Latn",
        "languages": [
          "als-Latn",
          "eng-Latn"
        ],
        "main_score": 0.17669270833333334,
        "precision": 0.16712239583333333,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020243092572850035,
        "hf_subset": "eng_Latn-aly_Latn",
        "languages": [
          "eng-Latn",
          "aly-Latn"
        ],
        "main_score": 0.020243092572850035,
        "precision": 0.017550505050505052,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.014549411505263465,
        "hf_subset": "aly_Latn-eng_Latn",
        "languages": [
          "aly-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014549411505263465,
        "precision": 0.010798836580086579,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011975173190745224,
        "hf_subset": "eng_Latn-ame_Latn",
        "languages": [
          "eng-Latn",
          "ame-Latn"
        ],
        "main_score": 0.011975173190745224,
        "precision": 0.011849103170189099,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010416666666666666,
        "hf_subset": "ame_Latn-eng_Latn",
        "languages": [
          "ame-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.008463541666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004135865494364389,
        "hf_subset": "eng_Latn-amf_Latn",
        "languages": [
          "eng-Latn",
          "amf-Latn"
        ],
        "main_score": 0.004135865494364389,
        "precision": 0.00285149360670194,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0004538670771539548,
        "hf_subset": "amf_Latn-eng_Latn",
        "languages": [
          "amf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004538670771539548,
        "precision": 0.00023280528780885148,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.016927083333333332,
        "hf_subset": "eng_Latn-amk_Latn",
        "languages": [
          "eng-Latn",
          "amk-Latn"
        ],
        "main_score": 0.016927083333333332,
        "precision": 0.015625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0214920881262341,
        "hf_subset": "amk_Latn-eng_Latn",
        "languages": [
          "amk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0214920881262341,
        "precision": 0.019629457980225987,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004685614440868866,
        "hf_subset": "eng_Latn-amm_Latn",
        "languages": [
          "eng-Latn",
          "amm-Latn"
        ],
        "main_score": 0.004685614440868866,
        "precision": 0.004331752232142857,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006871520748987853,
        "hf_subset": "amm_Latn-eng_Latn",
        "languages": [
          "amm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006871520748987853,
        "precision": 0.005750868055555555,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008473396418522721,
        "hf_subset": "eng_Latn-amn_Latn",
        "languages": [
          "eng-Latn",
          "amn-Latn"
        ],
        "main_score": 0.008473396418522721,
        "precision": 0.006682358440170941,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010048024891774893,
        "hf_subset": "amn_Latn-eng_Latn",
        "languages": [
          "amn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010048024891774893,
        "precision": 0.008318014705882353,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01012561274509804,
        "hf_subset": "eng_Latn-amo_Latn",
        "languages": [
          "eng-Latn",
          "amo-Latn"
        ],
        "main_score": 0.01012561274509804,
        "precision": 0.009082959651663697,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012371576739783261,
        "hf_subset": "amo_Latn-eng_Latn",
        "languages": [
          "amo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012371576739783261,
        "precision": 0.012059484538678486,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005282036163522012,
        "hf_subset": "eng_Latn-amp_Latn",
        "languages": [
          "eng-Latn",
          "amp-Latn"
        ],
        "main_score": 0.005282036163522012,
        "precision": 0.004724702380952381,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013739174338213546,
        "hf_subset": "amp_Latn-eng_Latn",
        "languages": [
          "amp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013739174338213546,
        "precision": 0.011830056002787168,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015955171130952378,
        "hf_subset": "eng_Latn-amr_Latn",
        "languages": [
          "eng-Latn",
          "amr-Latn"
        ],
        "main_score": 0.015955171130952378,
        "precision": 0.013511753941441442,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.027180716036414566,
        "hf_subset": "amr_Latn-eng_Latn",
        "languages": [
          "amr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027180716036414566,
        "precision": 0.022164220328282826,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.029338304924242425,
        "hf_subset": "eng_Latn-amu_Latn",
        "languages": [
          "eng-Latn",
          "amu-Latn"
        ],
        "main_score": 0.029338304924242425,
        "precision": 0.023993598090277776,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018840838557030483,
        "hf_subset": "amu_Latn-eng_Latn",
        "languages": [
          "amu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018840838557030483,
        "precision": 0.016315569196428573,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.06062825520833333,
        "hf_subset": "eng_Latn-amx_Latn",
        "languages": [
          "eng-Latn",
          "amx-Latn"
        ],
        "main_score": 0.06062825520833333,
        "precision": 0.057462993421052634,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07174905323971695,
        "hf_subset": "amx_Latn-eng_Latn",
        "languages": [
          "amx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07174905323971695,
        "precision": 0.06591908489646363,
        "recall": 0.09375
      },
      {
        "accuracy": 0.02702702702702703,
        "f1": 0.009997967892704735,
        "hf_subset": "eng_Latn-anh_Latn",
        "languages": [
          "eng-Latn",
          "anh-Latn"
        ],
        "main_score": 0.009997967892704735,
        "precision": 0.009517466592188372,
        "recall": 0.02702702702702703
      },
      {
        "accuracy": 0.036036036036036036,
        "f1": 0.019527463971908417,
        "hf_subset": "anh_Latn-eng_Latn",
        "languages": [
          "anh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019527463971908417,
        "precision": 0.018823631323631324,
        "recall": 0.036036036036036036
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007634775934707998,
        "hf_subset": "eng_Latn-anv_Latn",
        "languages": [
          "eng-Latn",
          "anv-Latn"
        ],
        "main_score": 0.007634775934707998,
        "precision": 0.006078533294905577,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019394066220238093,
        "hf_subset": "anv_Latn-eng_Latn",
        "languages": [
          "anv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019394066220238093,
        "precision": 0.01825373427672956,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004502467105263158,
        "hf_subset": "eng_Latn-aoi_Latn",
        "languages": [
          "eng-Latn",
          "aoi-Latn"
        ],
        "main_score": 0.004502467105263158,
        "precision": 0.004217416429587482,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0008013225655430711,
        "hf_subset": "aoi_Latn-eng_Latn",
        "languages": [
          "aoi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008013225655430711,
        "precision": 0.0004310048570381232,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.009167389100170314,
        "hf_subset": "eng_Latn-aoj_Latn",
        "languages": [
          "eng-Latn",
          "aoj-Latn"
        ],
        "main_score": 0.009167389100170314,
        "precision": 0.005529527151769798,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007821892110064095,
        "hf_subset": "aoj_Latn-eng_Latn",
        "languages": [
          "aoj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007821892110064095,
        "precision": 0.0065417024684917835,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03999789957849168,
        "hf_subset": "eng_Latn-aom_Latn",
        "languages": [
          "eng-Latn",
          "aom-Latn"
        ],
        "main_score": 0.03999789957849168,
        "precision": 0.03641493055555556,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04780061141304348,
        "hf_subset": "aom_Latn-eng_Latn",
        "languages": [
          "aom-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04780061141304348,
        "precision": 0.04390656001984127,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0001881256764069264,
        "hf_subset": "eng_Latn-aon_Latn",
        "languages": [
          "eng-Latn",
          "aon-Latn"
        ],
        "main_score": 0.0001881256764069264,
        "precision": 9.528759528759528e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011152285223682496,
        "hf_subset": "aon_Latn-eng_Latn",
        "languages": [
          "aon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011152285223682496,
        "precision": 0.010152151432606941,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006309185606060606,
        "hf_subset": "eng_Latn-apb_Latn",
        "languages": [
          "eng-Latn",
          "apb-Latn"
        ],
        "main_score": 0.006309185606060606,
        "precision": 0.005443744140886567,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006587747236063835,
        "hf_subset": "apb_Latn-eng_Latn",
        "languages": [
          "apb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006587747236063835,
        "precision": 0.0055835544384754444,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001445970985854245,
        "hf_subset": "eng_Latn-ape_Latn",
        "languages": [
          "eng-Latn",
          "ape-Latn"
        ],
        "main_score": 0.001445970985854245,
        "precision": 0.0008539272592245154,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0033601268591426075,
        "hf_subset": "ape_Latn-eng_Latn",
        "languages": [
          "ape-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0033601268591426075,
        "precision": 0.002061483609592162,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003980654761904762,
        "hf_subset": "eng_Latn-apn_Latn",
        "languages": [
          "eng-Latn",
          "apn-Latn"
        ],
        "main_score": 0.003980654761904762,
        "precision": 0.003943810096153846,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004036458333333334,
        "hf_subset": "apn_Latn-eng_Latn",
        "languages": [
          "apn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004036458333333334,
        "precision": 0.003972457627118644,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011346237970253718,
        "hf_subset": "eng_Latn-apr_Latn",
        "languages": [
          "eng-Latn",
          "apr-Latn"
        ],
        "main_score": 0.011346237970253718,
        "precision": 0.010284908234126984,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008249627976190476,
        "hf_subset": "apr_Latn-eng_Latn",
        "languages": [
          "apr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008249627976190476,
        "precision": 0.00803894927536232,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00439453125,
        "hf_subset": "eng_Latn-apu_Latn",
        "languages": [
          "eng-Latn",
          "apu-Latn"
        ],
        "main_score": 0.00439453125,
        "precision": 0.004166666666666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.519144144144144e-05,
        "hf_subset": "apu_Latn-eng_Latn",
        "languages": [
          "apu-Latn",
          "eng-Latn"
        ],
        "main_score": 3.519144144144144e-05,
        "precision": 1.767533936651584e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.033645976419413914,
        "hf_subset": "eng_Latn-apw_Latn",
        "languages": [
          "eng-Latn",
          "apw-Latn"
        ],
        "main_score": 0.033645976419413914,
        "precision": 0.03150409637266509,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019562865802675584,
        "hf_subset": "apw_Latn-eng_Latn",
        "languages": [
          "apw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019562865802675584,
        "precision": 0.017279445358187134,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008813214045698924,
        "hf_subset": "eng_Latn-apz_Latn",
        "languages": [
          "eng-Latn",
          "apz-Latn"
        ],
        "main_score": 0.008813214045698924,
        "precision": 0.008337823275862069,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009765625,
        "hf_subset": "apz_Latn-eng_Latn",
        "languages": [
          "apz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.009114583333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.13925471230158729,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ],
        "main_score": 0.13925471230158729,
        "precision": 0.12375062003968254,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07183779761904763,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.07183779761904763,
        "precision": 0.06303919604700856,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03886384882478633,
        "hf_subset": "eng_Latn-are_Latn",
        "languages": [
          "eng-Latn",
          "are-Latn"
        ],
        "main_score": 0.03886384882478633,
        "precision": 0.03538225446428571,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029055598688750857,
        "hf_subset": "are_Latn-eng_Latn",
        "languages": [
          "are-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029055598688750857,
        "precision": 0.026361109814538212,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009853405898876405,
        "hf_subset": "eng_Latn-arl_Latn",
        "languages": [
          "eng-Latn",
          "arl-Latn"
        ],
        "main_score": 0.009853405898876405,
        "precision": 0.009158972537878788,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.3103813559322034e-05,
        "hf_subset": "arl_Latn-eng_Latn",
        "languages": [
          "arl-Latn",
          "eng-Latn"
        ],
        "main_score": 3.3103813559322034e-05,
        "precision": 1.6622340425531915e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015265853937728937,
        "hf_subset": "eng_Latn-arn_Latn",
        "languages": [
          "eng-Latn",
          "arn-Latn"
        ],
        "main_score": 0.015265853937728937,
        "precision": 0.014187716709521583,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02346223766568483,
        "hf_subset": "arn_Latn-eng_Latn",
        "languages": [
          "arn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02346223766568483,
        "precision": 0.02195909288194444,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.15053763440860216,
        "f1": 0.09654035612289882,
        "hf_subset": "eng_Latn-arp_Latn",
        "languages": [
          "eng-Latn",
          "arp-Latn"
        ],
        "main_score": 0.09654035612289882,
        "precision": 0.08822431302270012,
        "recall": 0.15053763440860216
      },
      {
        "accuracy": 0.13978494623655913,
        "f1": 0.11206690561529271,
        "hf_subset": "arp_Latn-eng_Latn",
        "languages": [
          "arp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11206690561529271,
        "precision": 0.10695084485407066,
        "recall": 0.13978494623655913
      },
      {
        "accuracy": 0.43359375,
        "f1": 0.3588169642857143,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.3588169642857143,
        "precision": 0.33395816423160174,
        "recall": 0.43359375
      },
      {
        "accuracy": 0.453125,
        "f1": 0.3845470610119047,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.3845470610119047,
        "precision": 0.3610987103174603,
        "recall": 0.453125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001372466216216216,
        "hf_subset": "eng_Latn-aso_Latn",
        "languages": [
          "eng-Latn",
          "aso-Latn"
        ],
        "main_score": 0.001372466216216216,
        "precision": 0.0008167613636363637,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004359436898698358,
        "hf_subset": "aso_Latn-eng_Latn",
        "languages": [
          "aso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004359436898698358,
        "precision": 0.004144378753753754,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00489549512987013,
        "hf_subset": "eng_Latn-ata_Latn",
        "languages": [
          "eng-Latn",
          "ata-Latn"
        ],
        "main_score": 0.00489549512987013,
        "precision": 0.0029947916666666664,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012561392526964562,
        "hf_subset": "ata_Latn-eng_Latn",
        "languages": [
          "ata-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012561392526964562,
        "precision": 0.011004849137931035,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00046871181573802543,
        "hf_subset": "eng_Latn-atb_Latn",
        "languages": [
          "eng-Latn",
          "atb-Latn"
        ],
        "main_score": 0.00046871181573802543,
        "precision": 0.00024211489794225024,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0038775027056277057,
        "hf_subset": "atb_Latn-eng_Latn",
        "languages": [
          "atb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0038775027056277057,
        "precision": 0.002644142909356725,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.00699313707126207,
        "hf_subset": "eng_Latn-atd_Latn",
        "languages": [
          "eng-Latn",
          "atd-Latn"
        ],
        "main_score": 0.00699313707126207,
        "precision": 0.004562978563135781,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005461140422077922,
        "hf_subset": "atd_Latn-eng_Latn",
        "languages": [
          "atd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005461140422077922,
        "precision": 0.0047651873249299715,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333333,
        "hf_subset": "eng_Latn-atg_Latn",
        "languages": [
          "eng-Latn",
          "atg-Latn"
        ],
        "main_score": 0.007161458333333333,
        "precision": 0.005989583333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005022321428571428,
        "hf_subset": "atg_Latn-eng_Latn",
        "languages": [
          "atg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005022321428571428,
        "precision": 0.004535308441558442,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007982269238437001,
        "hf_subset": "eng_Latn-att_Latn",
        "languages": [
          "eng-Latn",
          "att-Latn"
        ],
        "main_score": 0.007982269238437001,
        "precision": 0.006666494205298013,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006379422367538564,
        "hf_subset": "att_Latn-eng_Latn",
        "languages": [
          "att-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006379422367538564,
        "precision": 0.005366245567375886,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-auc_Latn",
        "languages": [
          "eng-Latn",
          "auc-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004009046052631579,
        "hf_subset": "auc_Latn-eng_Latn",
        "languages": [
          "auc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004009046052631579,
        "precision": 0.003958333333333334,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025956176346801342,
        "hf_subset": "eng_Latn-aui_Latn",
        "languages": [
          "eng-Latn",
          "aui-Latn"
        ],
        "main_score": 0.025956176346801342,
        "precision": 0.02410584033690546,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010319002097708491,
        "hf_subset": "aui_Latn-eng_Latn",
        "languages": [
          "aui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010319002097708491,
        "precision": 0.008461345169815563,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.677350427350428e-05,
        "hf_subset": "eng_Latn-auy_Latn",
        "languages": [
          "eng-Latn",
          "auy-Latn"
        ],
        "main_score": 6.677350427350428e-05,
        "precision": 3.367456896551724e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "auy_Latn-eng_Latn",
        "languages": [
          "auy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019540550595238095,
        "hf_subset": "eng_Latn-avt_Latn",
        "languages": [
          "eng-Latn",
          "avt-Latn"
        ],
        "main_score": 0.019540550595238095,
        "precision": 0.0168102297008547,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018903882575757574,
        "hf_subset": "avt_Latn-eng_Latn",
        "languages": [
          "avt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018903882575757574,
        "precision": 0.014861350835755814,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00011837121212121212,
        "hf_subset": "eng_Latn-awb_Latn",
        "languages": [
          "eng-Latn",
          "awb-Latn"
        ],
        "main_score": 0.00011837121212121212,
        "precision": 6.009615384615385e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010198733396778617,
        "hf_subset": "awb_Latn-eng_Latn",
        "languages": [
          "awb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010198733396778617,
        "precision": 0.0005649535123966942,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.050505050505050504,
        "f1": 0.023692480359147023,
        "hf_subset": "eng_Latn-awk_Latn",
        "languages": [
          "eng-Latn",
          "awk-Latn"
        ],
        "main_score": 0.023692480359147023,
        "precision": 0.02213976499690785,
        "recall": 0.050505050505050504
      },
      {
        "accuracy": 0.030303030303030304,
        "f1": 0.01346801346801347,
        "hf_subset": "awk_Latn-eng_Latn",
        "languages": [
          "awk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01346801346801347,
        "precision": 0.011957813428401664,
        "recall": 0.030303030303030304
      },
      {
        "accuracy": 0.109375,
        "f1": 0.06612447785725387,
        "hf_subset": "eng_Latn-awx_Latn",
        "languages": [
          "eng-Latn",
          "awx-Latn"
        ],
        "main_score": 0.06612447785725387,
        "precision": 0.0609541034800329,
        "recall": 0.109375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07989149881762363,
        "hf_subset": "awx_Latn-eng_Latn",
        "languages": [
          "awx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07989149881762363,
        "precision": 0.07557821952353203,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8186197916666667,
        "hf_subset": "eng_Latn-azb_Arab",
        "languages": [
          "eng-Latn",
          "azb-Arab"
        ],
        "main_score": 0.8186197916666667,
        "precision": 0.7998046875,
        "recall": 0.859375
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.8463541666666666,
        "hf_subset": "azb_Arab-eng_Latn",
        "languages": [
          "azb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8463541666666666,
        "precision": 0.8313802083333333,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.029723515070921983,
        "hf_subset": "eng_Latn-azg_Latn",
        "languages": [
          "eng-Latn",
          "azg-Latn"
        ],
        "main_score": 0.029723515070921983,
        "precision": 0.027754189311594204,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02049104324494949,
        "hf_subset": "azg_Latn-eng_Latn",
        "languages": [
          "azg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02049104324494949,
        "precision": 0.01753103667166167,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01696004746835443,
        "hf_subset": "eng_Latn-azz_Latn",
        "languages": [
          "eng-Latn",
          "azz-Latn"
        ],
        "main_score": 0.01696004746835443,
        "precision": 0.015641551906779662,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00941465736040609,
        "hf_subset": "azz_Latn-eng_Latn",
        "languages": [
          "azz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00941465736040609,
        "precision": 0.008808992346938774,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015935819892473117,
        "hf_subset": "eng_Latn-bao_Latn",
        "languages": [
          "eng-Latn",
          "bao-Latn"
        ],
        "main_score": 0.015935819892473117,
        "precision": 0.01272067775974026,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.031487412928658906,
        "hf_subset": "bao_Latn-eng_Latn",
        "languages": [
          "bao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031487412928658906,
        "precision": 0.03014571595683728,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013671875,
        "hf_subset": "eng_Latn-bba_Latn",
        "languages": [
          "eng-Latn",
          "bba-Latn"
        ],
        "main_score": 0.013671875,
        "precision": 0.011848958333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014934421390013494,
        "hf_subset": "bba_Latn-eng_Latn",
        "languages": [
          "bba-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014934421390013494,
        "precision": 0.013991684941520467,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0006843095765437957,
        "hf_subset": "eng_Latn-bbb_Latn",
        "languages": [
          "eng-Latn",
          "bbb-Latn"
        ],
        "main_score": 0.0006843095765437957,
        "precision": 0.00035711550245098037,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006594422043010752,
        "hf_subset": "bbb_Latn-eng_Latn",
        "languages": [
          "bbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006594422043010752,
        "precision": 0.005901834239130435,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011787109375,
        "hf_subset": "eng_Latn-bbr_Latn",
        "languages": [
          "eng-Latn",
          "bbr-Latn"
        ],
        "main_score": 0.011787109375,
        "precision": 0.010527539552005012,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01814021675480537,
        "hf_subset": "bbr_Latn-eng_Latn",
        "languages": [
          "bbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01814021675480537,
        "precision": 0.016012470885093166,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011069677871148459,
        "hf_subset": "eng_Latn-bch_Latn",
        "languages": [
          "eng-Latn",
          "bch-Latn"
        ],
        "main_score": 0.011069677871148459,
        "precision": 0.008350035226430316,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02101934523809524,
        "hf_subset": "bch_Latn-eng_Latn",
        "languages": [
          "bch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02101934523809524,
        "precision": 0.01933059635994087,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004491976122835498,
        "hf_subset": "eng_Latn-bco_Latn",
        "languages": [
          "eng-Latn",
          "bco-Latn"
        ],
        "main_score": 0.004491976122835498,
        "precision": 0.002975272770398482,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0001519281601057302,
        "hf_subset": "bco_Latn-eng_Latn",
        "languages": [
          "bco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001519281601057302,
        "precision": 7.671110897189064e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-bdd_Latn",
        "languages": [
          "eng-Latn",
          "bdd-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010902255639097743,
        "hf_subset": "bdd_Latn-eng_Latn",
        "languages": [
          "bdd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010902255639097743,
        "precision": 0.008848323985042735,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03333333333333333,
        "f1": 0.01595238095238095,
        "hf_subset": "eng_Latn-bea_Latn",
        "languages": [
          "eng-Latn",
          "bea-Latn"
        ],
        "main_score": 0.01595238095238095,
        "precision": 0.014811463046757165,
        "recall": 0.03333333333333333
      },
      {
        "accuracy": 0.08666666666666667,
        "f1": 0.05161345621420715,
        "hf_subset": "bea_Latn-eng_Latn",
        "languages": [
          "bea-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05161345621420715,
        "precision": 0.045561594202898556,
        "recall": 0.08666666666666667
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010146103896103897,
        "hf_subset": "eng_Latn-bef_Latn",
        "languages": [
          "eng-Latn",
          "bef-Latn"
        ],
        "main_score": 0.00010146103896103897,
        "precision": 5.139802631578947e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002654897186147186,
        "hf_subset": "bef_Latn-eng_Latn",
        "languages": [
          "bef-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002654897186147186,
        "precision": 0.001978656045751634,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.890625,
        "f1": 0.8580729166666667,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ],
        "main_score": 0.8580729166666667,
        "precision": 0.8424479166666667,
        "recall": 0.890625
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8361979166666667,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.8361979166666667,
        "precision": 0.8207682291666667,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.75390625,
        "f1": 0.6965587797619047,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.6965587797619047,
        "precision": 0.6716579861111112,
        "recall": 0.75390625
      },
      {
        "accuracy": 0.76953125,
        "f1": 0.7207775297619047,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.7207775297619047,
        "precision": 0.7003255208333333,
        "recall": 0.76953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007076408959537572,
        "hf_subset": "eng_Latn-beo_Latn",
        "languages": [
          "eng-Latn",
          "beo-Latn"
        ],
        "main_score": 0.007076408959537572,
        "precision": 0.0061611036129568105,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008028846153846154,
        "hf_subset": "beo_Latn-eng_Latn",
        "languages": [
          "beo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008028846153846154,
        "precision": 0.00792250039550704,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029710953674948238,
        "hf_subset": "eng_Latn-beu_Latn",
        "languages": [
          "eng-Latn",
          "beu-Latn"
        ],
        "main_score": 0.029710953674948238,
        "precision": 0.026379024621212124,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.016211601997142614,
        "hf_subset": "beu_Latn-eng_Latn",
        "languages": [
          "beu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016211601997142614,
        "precision": 0.01429817716736543,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015309551103136629,
        "hf_subset": "eng_Latn-bgs_Latn",
        "languages": [
          "eng-Latn",
          "bgs-Latn"
        ],
        "main_score": 0.015309551103136629,
        "precision": 0.014203361742424243,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011782476300705468,
        "hf_subset": "bgs_Latn-eng_Latn",
        "languages": [
          "bgs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011782476300705468,
        "precision": 0.010227141650974771,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009645243888126534,
        "hf_subset": "eng_Latn-bgt_Latn",
        "languages": [
          "eng-Latn",
          "bgt-Latn"
        ],
        "main_score": 0.009645243888126534,
        "precision": 0.007503043831168831,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01481729055258467,
        "hf_subset": "bgt_Latn-eng_Latn",
        "languages": [
          "bgt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01481729055258467,
        "precision": 0.01269156265788809,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.015038487045110686,
        "hf_subset": "eng_Latn-bhg_Latn",
        "languages": [
          "eng-Latn",
          "bhg-Latn"
        ],
        "main_score": 0.015038487045110686,
        "precision": 0.011385407127594626,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03234338669007403,
        "hf_subset": "bhg_Latn-eng_Latn",
        "languages": [
          "bhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03234338669007403,
        "precision": 0.030427177950434658,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002622230924144104,
        "hf_subset": "eng_Latn-bhl_Latn",
        "languages": [
          "eng-Latn",
          "bhl-Latn"
        ],
        "main_score": 0.0002622230924144104,
        "precision": 0.00013382523148148148,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006623352465986394,
        "hf_subset": "bhl_Latn-eng_Latn",
        "languages": [
          "bhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006623352465986394,
        "precision": 0.004709694602272727,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-big_Latn",
        "languages": [
          "eng-Latn",
          "big-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "big_Latn-eng_Latn",
        "languages": [
          "big-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011921972352024923,
        "hf_subset": "eng_Latn-bjk_Latn",
        "languages": [
          "eng-Latn",
          "bjk-Latn"
        ],
        "main_score": 0.011921972352024923,
        "precision": 0.010591617829235754,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017246344150641024,
        "hf_subset": "bjk_Latn-eng_Latn",
        "languages": [
          "bjk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017246344150641024,
        "precision": 0.01657018282179768,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008929839691558441,
        "hf_subset": "eng_Latn-bjp_Latn",
        "languages": [
          "eng-Latn",
          "bjp-Latn"
        ],
        "main_score": 0.008929839691558441,
        "precision": 0.006941431561557708,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029016608061101026,
        "hf_subset": "bjp_Latn-eng_Latn",
        "languages": [
          "bjp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029016608061101026,
        "precision": 0.024109161590992984,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004507211538461538,
        "hf_subset": "eng_Latn-bjr_Latn",
        "languages": [
          "eng-Latn",
          "bjr-Latn"
        ],
        "main_score": 0.004507211538461538,
        "precision": 0.004231770833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.487723214285714e-05,
        "hf_subset": "bjr_Latn-eng_Latn",
        "languages": [
          "bjr-Latn",
          "eng-Latn"
        ],
        "main_score": 3.487723214285714e-05,
        "precision": 1.7516816143497758e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005530781680700531,
        "hf_subset": "eng_Latn-bjv_Latn",
        "languages": [
          "eng-Latn",
          "bjv-Latn"
        ],
        "main_score": 0.005530781680700531,
        "precision": 0.004786717189060939,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007105654761904761,
        "hf_subset": "bjv_Latn-eng_Latn",
        "languages": [
          "bjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007105654761904761,
        "precision": 0.006175952953296703,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.017497010717776845,
        "hf_subset": "eng_Latn-bjz_Latn",
        "languages": [
          "eng-Latn",
          "bjz-Latn"
        ],
        "main_score": 0.017497010717776845,
        "precision": 0.013820866888422035,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008841849662162162,
        "hf_subset": "bjz_Latn-eng_Latn",
        "languages": [
          "bjz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008841849662162162,
        "precision": 0.008397108843537414,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006323714951721576,
        "hf_subset": "eng_Latn-bkd_Latn",
        "languages": [
          "eng-Latn",
          "bkd-Latn"
        ],
        "main_score": 0.006323714951721576,
        "precision": 0.00427455734448952,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02546953914141414,
        "hf_subset": "bkd_Latn-eng_Latn",
        "languages": [
          "bkd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02546953914141414,
        "precision": 0.02282631802721088,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0068256268853695325,
        "hf_subset": "eng_Latn-bki_Latn",
        "languages": [
          "eng-Latn",
          "bki-Latn"
        ],
        "main_score": 0.0068256268853695325,
        "precision": 0.00602047329143755,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0036748556726907628,
        "hf_subset": "bki_Latn-eng_Latn",
        "languages": [
          "bki-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0036748556726907628,
        "precision": 0.0025587979094076653,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017976641414141414,
        "hf_subset": "eng_Latn-bkq_Latn",
        "languages": [
          "eng-Latn",
          "bkq-Latn"
        ],
        "main_score": 0.017976641414141414,
        "precision": 0.01701735381652661,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02185337449009324,
        "hf_subset": "bkq_Latn-eng_Latn",
        "languages": [
          "bkq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02185337449009324,
        "precision": 0.02090686237526155,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022746239911958913,
        "hf_subset": "eng_Latn-bkx_Latn",
        "languages": [
          "eng-Latn",
          "bkx-Latn"
        ],
        "main_score": 0.022746239911958913,
        "precision": 0.0199801048136646,
        "recall": 0.046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.017462787888695146,
        "hf_subset": "bkx_Latn-eng_Latn",
        "languages": [
          "bkx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017462787888695146,
        "precision": 0.014180307539682538,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008472862204215646,
        "hf_subset": "eng_Latn-blw_Latn",
        "languages": [
          "eng-Latn",
          "blw-Latn"
        ],
        "main_score": 0.008472862204215646,
        "precision": 0.006655523175705467,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008052248677248677,
        "hf_subset": "blw_Latn-eng_Latn",
        "languages": [
          "blw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008052248677248677,
        "precision": 0.006521883611909896,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03271780303030303,
        "hf_subset": "eng_Latn-blz_Latn",
        "languages": [
          "eng-Latn",
          "blz-Latn"
        ],
        "main_score": 0.03271780303030303,
        "precision": 0.030101943597560975,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.042440941220238095,
        "hf_subset": "blz_Latn-eng_Latn",
        "languages": [
          "blz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.042440941220238095,
        "precision": 0.038836188905920485,
        "recall": 0.0625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004603897753669095,
        "hf_subset": "eng_Latn-bmh_Latn",
        "languages": [
          "eng-Latn",
          "bmh-Latn"
        ],
        "main_score": 0.004603897753669095,
        "precision": 0.0028221970140515223,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015838055094895893,
        "hf_subset": "bmh_Latn-eng_Latn",
        "languages": [
          "bmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015838055094895893,
        "precision": 0.015733013731060605,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.06299212598425197,
        "f1": 0.03513125140225857,
        "hf_subset": "eng_Latn-bmk_Latn",
        "languages": [
          "eng-Latn",
          "bmk-Latn"
        ],
        "main_score": 0.03513125140225857,
        "precision": 0.03090295531240413,
        "recall": 0.06299212598425197
      },
      {
        "accuracy": 0.09448818897637795,
        "f1": 0.05836398357182097,
        "hf_subset": "bmk_Latn-eng_Latn",
        "languages": [
          "bmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05836398357182097,
        "precision": 0.05241248253059276,
        "recall": 0.09448818897637795
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0038520691474477065,
        "hf_subset": "eng_Latn-bmr_Latn",
        "languages": [
          "eng-Latn",
          "bmr-Latn"
        ],
        "main_score": 0.0038520691474477065,
        "precision": 0.002449343607305936,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016902767936807853,
        "hf_subset": "bmr_Latn-eng_Latn",
        "languages": [
          "bmr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016902767936807853,
        "precision": 0.016300245852651402,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010546406335698616,
        "hf_subset": "eng_Latn-bmu_Latn",
        "languages": [
          "eng-Latn",
          "bmu-Latn"
        ],
        "main_score": 0.010546406335698616,
        "precision": 0.008005175369198312,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005408653846153846,
        "hf_subset": "bmu_Latn-eng_Latn",
        "languages": [
          "bmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005408653846153846,
        "precision": 0.004009046052631578,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.043069718000413565,
        "hf_subset": "eng_Latn-bnp_Latn",
        "languages": [
          "eng-Latn",
          "bnp-Latn"
        ],
        "main_score": 0.043069718000413565,
        "precision": 0.039544894569228585,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022908363526570046,
        "hf_subset": "bnp_Latn-eng_Latn",
        "languages": [
          "bnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022908363526570046,
        "precision": 0.020771908219046047,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004728403141361256,
        "hf_subset": "eng_Latn-boa_Latn",
        "languages": [
          "eng-Latn",
          "boa-Latn"
        ],
        "main_score": 0.004728403141361256,
        "precision": 0.004360836988304094,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016260162601626016,
        "hf_subset": "boa_Latn-eng_Latn",
        "languages": [
          "boa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016260162601626016,
        "precision": 0.0010085809426229509,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014397321428571428,
        "hf_subset": "eng_Latn-boj_Latn",
        "languages": [
          "eng-Latn",
          "boj-Latn"
        ],
        "main_score": 0.014397321428571428,
        "precision": 0.013296274038461538,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006525607638888889,
        "hf_subset": "boj_Latn-eng_Latn",
        "languages": [
          "boj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006525607638888889,
        "precision": 0.005350056689342403,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0078000992063492055,
        "hf_subset": "eng_Latn-bon_Latn",
        "languages": [
          "eng-Latn",
          "bon-Latn"
        ],
        "main_score": 0.0078000992063492055,
        "precision": 0.006599195075757576,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012688253012048192,
        "hf_subset": "bon_Latn-eng_Latn",
        "languages": [
          "bon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012688253012048192,
        "precision": 0.01029492716802168,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006544091235632183,
        "hf_subset": "eng_Latn-box_Latn",
        "languages": [
          "eng-Latn",
          "box-Latn"
        ],
        "main_score": 0.006544091235632183,
        "precision": 0.005876285173160173,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0048828125,
        "hf_subset": "box_Latn-eng_Latn",
        "languages": [
          "box-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0048828125,
        "precision": 0.004464285714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004927765376984127,
        "hf_subset": "eng_Latn-bpr_Latn",
        "languages": [
          "eng-Latn",
          "bpr-Latn"
        ],
        "main_score": 0.004927765376984127,
        "precision": 0.0028669421799516906,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005557322589765338,
        "hf_subset": "bpr_Latn-eng_Latn",
        "languages": [
          "bpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005557322589765338,
        "precision": 0.004799584096459096,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005517375009810846,
        "hf_subset": "eng_Latn-bps_Latn",
        "languages": [
          "eng-Latn",
          "bps-Latn"
        ],
        "main_score": 0.005517375009810846,
        "precision": 0.004065180759803922,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012363849956540635,
        "hf_subset": "bps_Latn-eng_Latn",
        "languages": [
          "bps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012363849956540635,
        "precision": 0.01206646543560606,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0014761821161048687,
        "hf_subset": "eng_Latn-bqc_Latn",
        "languages": [
          "eng-Latn",
          "bqc-Latn"
        ],
        "main_score": 0.0014761821161048687,
        "precision": 0.0008695268361581922,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004105438758510792,
        "hf_subset": "bqc_Latn-eng_Latn",
        "languages": [
          "bqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004105438758510792,
        "precision": 0.004007273706896551,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004901960784313725,
        "hf_subset": "eng_Latn-bqp_Latn",
        "languages": [
          "eng-Latn",
          "bqp-Latn"
        ],
        "main_score": 0.0004901960784313725,
        "precision": 0.0002530694879832811,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004087673838887431,
        "hf_subset": "bqp_Latn-eng_Latn",
        "languages": [
          "bqp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004087673838887431,
        "precision": 0.003998056842600054,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.05838846483377733,
        "hf_subset": "eng_Latn-bre_Latn",
        "languages": [
          "eng-Latn",
          "bre-Latn"
        ],
        "main_score": 0.05838846483377733,
        "precision": 0.04946929498224728,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0851325489038525,
        "hf_subset": "bre_Latn-eng_Latn",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0851325489038525,
        "precision": 0.08187983419274539,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007639620092454845,
        "hf_subset": "eng_Latn-bsj_Latn",
        "languages": [
          "eng-Latn",
          "bsj-Latn"
        ],
        "main_score": 0.007639620092454845,
        "precision": 0.00608396060821434,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.024834857723577235,
        "hf_subset": "bsj_Latn-eng_Latn",
        "languages": [
          "bsj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024834857723577235,
        "precision": 0.024266975308641976,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011574792960662526,
        "hf_subset": "eng_Latn-bsn_Latn",
        "languages": [
          "eng-Latn",
          "bsn-Latn"
        ],
        "main_score": 0.011574792960662526,
        "precision": 0.00925597117003367,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010634586495888679,
        "hf_subset": "bsn_Latn-eng_Latn",
        "languages": [
          "bsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010634586495888679,
        "precision": 0.009876164861436377,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03516995284982422,
        "hf_subset": "eng_Latn-bsp_Latn",
        "languages": [
          "eng-Latn",
          "bsp-Latn"
        ],
        "main_score": 0.03516995284982422,
        "precision": 0.032671891001024064,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03244765559732665,
        "hf_subset": "bsp_Latn-eng_Latn",
        "languages": [
          "bsp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03244765559732665,
        "precision": 0.030669129570771073,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005442405523255814,
        "hf_subset": "eng_Latn-bss_Latn",
        "languages": [
          "eng-Latn",
          "bss-Latn"
        ],
        "main_score": 0.005442405523255814,
        "precision": 0.003580846401060424,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01209279567805383,
        "hf_subset": "bss_Latn-eng_Latn",
        "languages": [
          "bss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01209279567805383,
        "precision": 0.01074112601902174,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00939796586976004,
        "hf_subset": "eng_Latn-buk_Latn",
        "languages": [
          "eng-Latn",
          "buk-Latn"
        ],
        "main_score": 0.00939796586976004,
        "precision": 0.007319467358954452,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004409811916776803,
        "hf_subset": "buk_Latn-eng_Latn",
        "languages": [
          "buk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004409811916776803,
        "precision": 0.00416421746751026,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005044190395752895,
        "hf_subset": "eng_Latn-bus_Latn",
        "languages": [
          "eng-Latn",
          "bus-Latn"
        ],
        "main_score": 0.005044190395752895,
        "precision": 0.004545898506243928,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004113285363285363,
        "hf_subset": "bus_Latn-eng_Latn",
        "languages": [
          "bus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004113285363285363,
        "precision": 0.004011158300288392,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0028616240530303034,
        "hf_subset": "eng_Latn-bvd_Latn",
        "languages": [
          "eng-Latn",
          "bvd-Latn"
        ],
        "main_score": 0.0028616240530303034,
        "precision": 0.001679713884667342,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012132597201470556,
        "hf_subset": "bvd_Latn-eng_Latn",
        "languages": [
          "bvd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012132597201470556,
        "precision": 0.010508377032316338,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011118438852813852,
        "hf_subset": "eng_Latn-bvr_Latn",
        "languages": [
          "eng-Latn",
          "bvr-Latn"
        ],
        "main_score": 0.011118438852813852,
        "precision": 0.009921364379084969,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014558605268523747,
        "hf_subset": "bvr_Latn-eng_Latn",
        "languages": [
          "bvr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014558605268523747,
        "precision": 0.013481671439412314,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010215850943646996,
        "hf_subset": "eng_Latn-bxh_Latn",
        "languages": [
          "eng-Latn",
          "bxh-Latn"
        ],
        "main_score": 0.010215850943646996,
        "precision": 0.008397803525742173,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001818374515503876,
        "hf_subset": "bxh_Latn-eng_Latn",
        "languages": [
          "bxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001818374515503876,
        "precision": 0.001022581070188492,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004240369496855346,
        "hf_subset": "eng_Latn-byr_Latn",
        "languages": [
          "eng-Latn",
          "byr-Latn"
        ],
        "main_score": 0.004240369496855346,
        "precision": 0.002966889880952381,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003948941256830601,
        "hf_subset": "byr_Latn-eng_Latn",
        "languages": [
          "byr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003948941256830601,
        "precision": 0.003927712912087912,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0182041266025641,
        "hf_subset": "eng_Latn-byx_Latn",
        "languages": [
          "eng-Latn",
          "byx-Latn"
        ],
        "main_score": 0.0182041266025641,
        "precision": 0.016139596463585433,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021251921387790952,
        "hf_subset": "byx_Latn-eng_Latn",
        "languages": [
          "byx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021251921387790952,
        "precision": 0.01974866651205937,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017441553101503762,
        "hf_subset": "eng_Latn-bzd_Latn",
        "languages": [
          "eng-Latn",
          "bzd-Latn"
        ],
        "main_score": 0.017441553101503762,
        "precision": 0.014172697961760461,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012072138737097754,
        "hf_subset": "bzd_Latn-eng_Latn",
        "languages": [
          "bzd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012072138737097754,
        "precision": 0.01059919010913329,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008295298793859648,
        "hf_subset": "eng_Latn-bzh_Latn",
        "languages": [
          "eng-Latn",
          "bzh-Latn"
        ],
        "main_score": 0.008295298793859648,
        "precision": 0.006823620495495495,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03197916666666666,
        "hf_subset": "bzh_Latn-eng_Latn",
        "languages": [
          "bzh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03197916666666666,
        "precision": 0.030638415404040404,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.016813834908963585,
        "hf_subset": "eng_Latn-bzj_Latn",
        "languages": [
          "eng-Latn",
          "bzj-Latn"
        ],
        "main_score": 0.016813834908963585,
        "precision": 0.013459511408730158,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03541241744366744,
        "hf_subset": "bzj_Latn-eng_Latn",
        "languages": [
          "bzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03541241744366744,
        "precision": 0.03141854410666088,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.030013020833333334,
        "hf_subset": "eng_Latn-caa_Latn",
        "languages": [
          "eng-Latn",
          "caa-Latn"
        ],
        "main_score": 0.030013020833333334,
        "precision": 0.02497444186560566,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.036775575950232425,
        "hf_subset": "caa_Latn-eng_Latn",
        "languages": [
          "caa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.036775575950232425,
        "precision": 0.03336505074786325,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011065955629963656,
        "hf_subset": "eng_Latn-cab_Latn",
        "languages": [
          "eng-Latn",
          "cab-Latn"
        ],
        "main_score": 0.011065955629963656,
        "precision": 0.010103689713064712,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012406128875968992,
        "hf_subset": "cab_Latn-eng_Latn",
        "languages": [
          "cab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012406128875968992,
        "precision": 0.011085961838006229,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018998134540897698,
        "hf_subset": "eng_Latn-cac_Latn",
        "languages": [
          "eng-Latn",
          "cac-Latn"
        ],
        "main_score": 0.018998134540897698,
        "precision": 0.017998342803030302,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03126989432136491,
        "hf_subset": "cac_Latn-eng_Latn",
        "languages": [
          "cac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03126989432136491,
        "precision": 0.028546412211345382,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029276669682425607,
        "hf_subset": "eng_Latn-caf_Latn",
        "languages": [
          "eng-Latn",
          "caf-Latn"
        ],
        "main_score": 0.029276669682425607,
        "precision": 0.025966318837412586,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.030465411324786328,
        "hf_subset": "caf_Latn-eng_Latn",
        "languages": [
          "caf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030465411324786328,
        "precision": 0.029290364583333332,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.024636646356943386,
        "hf_subset": "eng_Latn-cak_Latn",
        "languages": [
          "eng-Latn",
          "cak-Latn"
        ],
        "main_score": 0.024636646356943386,
        "precision": 0.020630259646962232,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02445579594017094,
        "hf_subset": "cak_Latn-eng_Latn",
        "languages": [
          "cak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02445579594017094,
        "precision": 0.0240023743872549,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01609847176156256,
        "hf_subset": "eng_Latn-cao_Latn",
        "languages": [
          "eng-Latn",
          "cao-Latn"
        ],
        "main_score": 0.01609847176156256,
        "precision": 0.014756451231060607,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022835904535864978,
        "hf_subset": "cao_Latn-eng_Latn",
        "languages": [
          "cao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022835904535864978,
        "precision": 0.02163946390658174,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010588653074866311,
        "hf_subset": "eng_Latn-cap_Latn",
        "languages": [
          "eng-Latn",
          "cap-Latn"
        ],
        "main_score": 0.010588653074866311,
        "precision": 0.009569612455197132,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018441621440242764,
        "hf_subset": "cap_Latn-eng_Latn",
        "languages": [
          "cap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018441621440242764,
        "precision": 0.016209235430283225,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009395926339285715,
        "hf_subset": "eng_Latn-car_Latn",
        "languages": [
          "eng-Latn",
          "car-Latn"
        ],
        "main_score": 0.009395926339285715,
        "precision": 0.0065343189158350735,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010649181547619048,
        "hf_subset": "car_Latn-eng_Latn",
        "languages": [
          "car-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010649181547619048,
        "precision": 0.009883646637891867,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009961948794669384,
        "hf_subset": "eng_Latn-cav_Latn",
        "languages": [
          "eng-Latn",
          "cav-Latn"
        ],
        "main_score": 0.009961948794669384,
        "precision": 0.00899215919384058,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009765625,
        "hf_subset": "cav_Latn-eng_Latn",
        "languages": [
          "cav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0005580357142857143,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01735258556547619,
        "hf_subset": "eng_Latn-cax_Latn",
        "languages": [
          "eng-Latn",
          "cax-Latn"
        ],
        "main_score": 0.01735258556547619,
        "precision": 0.01444894042725461,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021849553193739425,
        "hf_subset": "cax_Latn-eng_Latn",
        "languages": [
          "cax-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021849553193739425,
        "precision": 0.01981328753092146,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017401413690476188,
        "hf_subset": "eng_Latn-cbc_Latn",
        "languages": [
          "eng-Latn",
          "cbc-Latn"
        ],
        "main_score": 0.017401413690476188,
        "precision": 0.01437458664021164,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012021150544857442,
        "hf_subset": "cbc_Latn-eng_Latn",
        "languages": [
          "cbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012021150544857442,
        "precision": 0.010371719916556874,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019577752976190476,
        "hf_subset": "eng_Latn-cbi_Latn",
        "languages": [
          "eng-Latn",
          "cbi-Latn"
        ],
        "main_score": 0.019577752976190476,
        "precision": 0.017601515718562874,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008262552369730294,
        "hf_subset": "cbi_Latn-eng_Latn",
        "languages": [
          "cbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008262552369730294,
        "precision": 0.008049045138888888,
        "recall": 0.015625
      },
      {
        "accuracy": 0.671875,
        "f1": 0.6044921875,
        "hf_subset": "eng_Latn-cbk_Latn",
        "languages": [
          "eng-Latn",
          "cbk-Latn"
        ],
        "main_score": 0.6044921875,
        "precision": 0.574906994047619,
        "recall": 0.671875
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.5799138144841269,
        "hf_subset": "cbk_Latn-eng_Latn",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5799138144841269,
        "precision": 0.5542364211309523,
        "recall": 0.64453125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012701596685971686,
        "hf_subset": "eng_Latn-cbr_Latn",
        "languages": [
          "eng-Latn",
          "cbr-Latn"
        ],
        "main_score": 0.012701596685971686,
        "precision": 0.01106924139848247,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024613204656862744,
        "hf_subset": "cbr_Latn-eng_Latn",
        "languages": [
          "cbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024613204656862744,
        "precision": 0.0217613412552521,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012679362050551075,
        "hf_subset": "eng_Latn-cbs_Latn",
        "languages": [
          "eng-Latn",
          "cbs-Latn"
        ],
        "main_score": 0.012679362050551075,
        "precision": 0.009723772321428572,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020837162990196074,
        "hf_subset": "cbs_Latn-eng_Latn",
        "languages": [
          "cbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020837162990196074,
        "precision": 0.01877335258152174,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001974826388888889,
        "hf_subset": "eng_Latn-cbt_Latn",
        "languages": [
          "eng-Latn",
          "cbt-Latn"
        ],
        "main_score": 0.001974826388888889,
        "precision": 0.001103670634920635,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.979885057471264e-05,
        "hf_subset": "cbt_Latn-eng_Latn",
        "languages": [
          "cbt-Latn",
          "eng-Latn"
        ],
        "main_score": 8.979885057471264e-05,
        "precision": 4.5421511627906976e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.5511363636363635e-05,
        "hf_subset": "eng_Latn-cbu_Latn",
        "languages": [
          "eng-Latn",
          "cbu-Latn"
        ],
        "main_score": 3.5511363636363635e-05,
        "precision": 1.783675799086758e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.228305785123967e-05,
        "hf_subset": "cbu_Latn-eng_Latn",
        "languages": [
          "cbu-Latn",
          "eng-Latn"
        ],
        "main_score": 3.228305785123967e-05,
        "precision": 1.620850622406639e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017544022817460318,
        "hf_subset": "eng_Latn-cbv_Latn",
        "languages": [
          "eng-Latn",
          "cbv-Latn"
        ],
        "main_score": 0.017544022817460318,
        "precision": 0.015562855113636363,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01982485702614379,
        "hf_subset": "cbv_Latn-eng_Latn",
        "languages": [
          "cbv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01982485702614379,
        "precision": 0.01823529032590759,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014317735963748895,
        "hf_subset": "eng_Latn-cco_Latn",
        "languages": [
          "eng-Latn",
          "cco-Latn"
        ],
        "main_score": 0.014317735963748895,
        "precision": 0.013368933646435453,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008573130498533723,
        "hf_subset": "cco_Latn-eng_Latn",
        "languages": [
          "cco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008573130498533723,
        "precision": 0.007056615259740259,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022637898176806615,
        "hf_subset": "eng_Latn-ceb_Latn",
        "languages": [
          "eng-Latn",
          "ceb-Latn"
        ],
        "main_score": 0.022637898176806615,
        "precision": 0.02050335088090322,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04717665204909398,
        "hf_subset": "ceb_Latn-eng_Latn",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04717665204909398,
        "precision": 0.04451318538232601,
        "recall": 0.0625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00753968253968254,
        "hf_subset": "eng_Latn-cek_Latn",
        "languages": [
          "eng-Latn",
          "cek-Latn"
        ],
        "main_score": 0.00753968253968254,
        "precision": 0.006429106795592048,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016669173351158646,
        "hf_subset": "cek_Latn-eng_Latn",
        "languages": [
          "cek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016669173351158646,
        "precision": 0.014884700040950043,
        "recall": 0.03125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9739583333333333,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ],
        "main_score": 0.9739583333333333,
        "precision": 0.970703125,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9583333333333333,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9583333333333333,
        "precision": 0.953125,
        "recall": 0.96875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01676413509145272,
        "hf_subset": "eng_Latn-cgc_Latn",
        "languages": [
          "eng-Latn",
          "cgc-Latn"
        ],
        "main_score": 0.01676413509145272,
        "precision": 0.015044893957928683,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014663027944277943,
        "hf_subset": "cgc_Latn-eng_Latn",
        "languages": [
          "cgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014663027944277943,
        "precision": 0.013382680230953257,
        "recall": 0.03125
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.07650808621203357,
        "hf_subset": "eng_Latn-cha_Latn",
        "languages": [
          "eng-Latn",
          "cha-Latn"
        ],
        "main_score": 0.07650808621203357,
        "precision": 0.06945203458538587,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07624921211740768,
        "hf_subset": "cha_Latn-eng_Latn",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07624921211740768,
        "precision": 0.0703182246006281,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015846641390931372,
        "hf_subset": "eng_Latn-chd_Latn",
        "languages": [
          "eng-Latn",
          "chd-Latn"
        ],
        "main_score": 0.015846641390931372,
        "precision": 0.013201208513708514,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009047343474426808,
        "hf_subset": "chd_Latn-eng_Latn",
        "languages": [
          "chd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009047343474426808,
        "precision": 0.007032729640151515,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015873681589602926,
        "hf_subset": "eng_Latn-chf_Latn",
        "languages": [
          "eng-Latn",
          "chf-Latn"
        ],
        "main_score": 0.015873681589602926,
        "precision": 0.013373168163464216,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028413081650570677,
        "hf_subset": "chf_Latn-eng_Latn",
        "languages": [
          "chf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028413081650570677,
        "precision": 0.02651492901287309,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005597891051912568,
        "hf_subset": "eng_Latn-chk_Latn",
        "languages": [
          "eng-Latn",
          "chk-Latn"
        ],
        "main_score": 0.005597891051912568,
        "precision": 0.004889620014372978,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020018635783933876,
        "hf_subset": "chk_Latn-eng_Latn",
        "languages": [
          "chk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020018635783933876,
        "precision": 0.018551164547258296,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018023252966254448,
        "hf_subset": "eng_Latn-chq_Latn",
        "languages": [
          "eng-Latn",
          "chq-Latn"
        ],
        "main_score": 0.018023252966254448,
        "precision": 0.015921917756156888,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016755756578947366,
        "hf_subset": "chq_Latn-eng_Latn",
        "languages": [
          "chq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016755756578947366,
        "precision": 0.014020373774509804,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02055544969512195,
        "hf_subset": "eng_Latn-chz_Latn",
        "languages": [
          "eng-Latn",
          "chz-Latn"
        ],
        "main_score": 0.02055544969512195,
        "precision": 0.01763929210487876,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02400272253787879,
        "hf_subset": "chz_Latn-eng_Latn",
        "languages": [
          "chz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02400272253787879,
        "precision": 0.022287946428571428,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-cjo_Latn",
        "languages": [
          "eng-Latn",
          "cjo-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.70260663507109e-05,
        "hf_subset": "cjo_Latn-eng_Latn",
        "languages": [
          "cjo-Latn",
          "eng-Latn"
        ],
        "main_score": 3.70260663507109e-05,
        "precision": 1.8601190476190478e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006696523864412569,
        "hf_subset": "eng_Latn-cjv_Latn",
        "languages": [
          "eng-Latn",
          "cjv-Latn"
        ],
        "main_score": 0.006696523864412569,
        "precision": 0.005953662026105208,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012369791666666666,
        "hf_subset": "cjv_Latn-eng_Latn",
        "languages": [
          "cjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012369791666666666,
        "precision": 0.011067708333333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.66015625,
        "f1": 0.6073567708333334,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ],
        "main_score": 0.6073567708333334,
        "precision": 0.5871465773809523,
        "recall": 0.66015625
      },
      {
        "accuracy": 0.69140625,
        "f1": 0.6234375,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.6234375,
        "precision": 0.5950520833333333,
        "recall": 0.69140625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004897121108058608,
        "hf_subset": "eng_Latn-cle_Latn",
        "languages": [
          "eng-Latn",
          "cle-Latn"
        ],
        "main_score": 0.004897121108058608,
        "precision": 0.0034290271132376396,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0032672821283685886,
        "hf_subset": "cle_Latn-eng_Latn",
        "languages": [
          "cle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0032672821283685886,
        "precision": 0.002053829479768786,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022163193725297292,
        "hf_subset": "eng_Latn-clu_Latn",
        "languages": [
          "eng-Latn",
          "clu-Latn"
        ],
        "main_score": 0.022163193725297292,
        "precision": 0.01976988442312469,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024695845713441758,
        "hf_subset": "clu_Latn-eng_Latn",
        "languages": [
          "clu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024695845713441758,
        "precision": 0.022801863195213483,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006998697916666666,
        "hf_subset": "eng_Latn-cme_Latn",
        "languages": [
          "eng-Latn",
          "cme-Latn"
        ],
        "main_score": 0.006998697916666666,
        "precision": 0.006119791666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012175444802237834,
        "hf_subset": "cme_Latn-eng_Latn",
        "languages": [
          "cme-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012175444802237834,
        "precision": 0.011952073628364389,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9694010416666666,
        "hf_subset": "eng_Latn-cmn_Hans",
        "languages": [
          "eng-Latn",
          "cmn-Hans"
        ],
        "main_score": 0.9694010416666666,
        "precision": 0.9661458333333334,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9583333333333333,
        "hf_subset": "cmn_Hans-eng_Latn",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.9583333333333333,
        "precision": 0.953125,
        "recall": 0.96875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004111842105263158,
        "hf_subset": "eng_Latn-cni_Latn",
        "languages": [
          "eng-Latn",
          "cni-Latn"
        ],
        "main_score": 0.004111842105263158,
        "precision": 0.004011824324324324,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008207070707070708,
        "hf_subset": "cni_Latn-eng_Latn",
        "languages": [
          "cni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008207070707070708,
        "precision": 0.00045385645798082344,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010109747023809524,
        "hf_subset": "eng_Latn-cnl_Latn",
        "languages": [
          "eng-Latn",
          "cnl-Latn"
        ],
        "main_score": 0.010109747023809524,
        "precision": 0.007969577655741557,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026998546511627905,
        "hf_subset": "cnl_Latn-eng_Latn",
        "languages": [
          "cnl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026998546511627905,
        "precision": 0.024567114400584796,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004355996142500568,
        "hf_subset": "eng_Latn-cnt_Latn",
        "languages": [
          "eng-Latn",
          "cnt-Latn"
        ],
        "main_score": 0.004355996142500568,
        "precision": 0.003025599888392857,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021384114583333336,
        "hf_subset": "cnt_Latn-eng_Latn",
        "languages": [
          "cnt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021384114583333336,
        "precision": 0.0206044186827957,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007899305555555555,
        "hf_subset": "eng_Latn-cof_Latn",
        "languages": [
          "eng-Latn",
          "cof-Latn"
        ],
        "main_score": 0.007899305555555555,
        "precision": 0.007856390449438201,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010462622549019607,
        "hf_subset": "cof_Latn-eng_Latn",
        "languages": [
          "cof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010462622549019607,
        "precision": 0.009788738905325445,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009616760334321477,
        "hf_subset": "eng_Latn-con_Latn",
        "languages": [
          "eng-Latn",
          "con-Latn"
        ],
        "main_score": 0.009616760334321477,
        "precision": 0.007613610347985348,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013069224500795647,
        "hf_subset": "con_Latn-eng_Latn",
        "languages": [
          "con-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013069224500795647,
        "precision": 0.011187065972222222,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.489942528735632e-05,
        "hf_subset": "eng_Latn-cop_Copt",
        "languages": [
          "eng-Latn",
          "cop-Copt"
        ],
        "main_score": 4.489942528735632e-05,
        "precision": 2.2579479768786126e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.0398832684824903e-05,
        "hf_subset": "cop_Copt-eng_Latn",
        "languages": [
          "cop-Copt",
          "eng-Latn"
        ],
        "main_score": 3.0398832684824903e-05,
        "precision": 1.52587890625e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005900710978835979,
        "hf_subset": "eng_Latn-cot_Latn",
        "languages": [
          "eng-Latn",
          "cot-Latn"
        ],
        "main_score": 0.005900710978835979,
        "precision": 0.005229111258865248,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003939636752136752,
        "hf_subset": "cot_Latn-eng_Latn",
        "languages": [
          "cot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003939636752136752,
        "precision": 0.003923015021459228,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0050570436507936505,
        "hf_subset": "eng_Latn-cpa_Latn",
        "languages": [
          "eng-Latn",
          "cpa-Latn"
        ],
        "main_score": 0.0050570436507936505,
        "precision": 0.004574730282738096,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017156862745098037,
        "hf_subset": "cpa_Latn-eng_Latn",
        "languages": [
          "cpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017156862745098037,
        "precision": 0.014441287878787878,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.021661931818181816,
        "hf_subset": "eng_Latn-cpb_Latn",
        "languages": [
          "eng-Latn",
          "cpb-Latn"
        ],
        "main_score": 0.021661931818181816,
        "precision": 0.020924176356589146,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02765590507726269,
        "hf_subset": "cpb_Latn-eng_Latn",
        "languages": [
          "cpb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02765590507726269,
        "precision": 0.026393229166666667,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013421604437229437,
        "hf_subset": "eng_Latn-cpc_Latn",
        "languages": [
          "eng-Latn",
          "cpc-Latn"
        ],
        "main_score": 0.013421604437229437,
        "precision": 0.011924482729138167,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020879289215686273,
        "hf_subset": "cpc_Latn-eng_Latn",
        "languages": [
          "cpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020879289215686273,
        "precision": 0.019554363905325445,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.022174092409240922,
        "hf_subset": "eng_Latn-cpu_Latn",
        "languages": [
          "eng-Latn",
          "cpu-Latn"
        ],
        "main_score": 0.022174092409240922,
        "precision": 0.02150380907960199,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027606451023391813,
        "hf_subset": "cpu_Latn-eng_Latn",
        "languages": [
          "cpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027606451023391813,
        "precision": 0.025250842524509803,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010449354951185496,
        "hf_subset": "eng_Latn-cpy_Latn",
        "languages": [
          "eng-Latn",
          "cpy-Latn"
        ],
        "main_score": 0.010449354951185496,
        "precision": 0.00978203781512605,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015342881944444444,
        "hf_subset": "cpy_Latn-eng_Latn",
        "languages": [
          "cpy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015342881944444444,
        "precision": 0.014251733339984038,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022068339646464645,
        "hf_subset": "eng_Latn-crn_Latn",
        "languages": [
          "eng-Latn",
          "crn-Latn"
        ],
        "main_score": 0.022068339646464645,
        "precision": 0.01875271267361111,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011067708333333332,
        "hf_subset": "crn_Latn-eng_Latn",
        "languages": [
          "crn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.009114583333333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.029236507461743312,
        "hf_subset": "eng_Latn-crx_Latn",
        "languages": [
          "eng-Latn",
          "crx-Latn"
        ],
        "main_score": 0.029236507461743312,
        "precision": 0.0269500248015873,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02623644111570248,
        "hf_subset": "crx_Latn-eng_Latn",
        "languages": [
          "crx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02623644111570248,
        "precision": 0.024034288194444444,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006541666666666666,
        "hf_subset": "eng_Latn-cso_Latn",
        "languages": [
          "eng-Latn",
          "cso-Latn"
        ],
        "main_score": 0.006541666666666666,
        "precision": 0.005875062751004016,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015051309818481847,
        "hf_subset": "cso_Latn-eng_Latn",
        "languages": [
          "cso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015051309818481847,
        "precision": 0.013059895833333331,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0121263903298804,
        "hf_subset": "eng_Latn-csy_Latn",
        "languages": [
          "eng-Latn",
          "csy-Latn"
        ],
        "main_score": 0.0121263903298804,
        "precision": 0.009266447143545905,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.037803410953082005,
        "hf_subset": "csy_Latn-eng_Latn",
        "languages": [
          "csy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.037803410953082005,
        "precision": 0.03339976005417182,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025885214793281652,
        "hf_subset": "eng_Latn-cta_Latn",
        "languages": [
          "eng-Latn",
          "cta-Latn"
        ],
        "main_score": 0.025885214793281652,
        "precision": 0.02388231682054924,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025128658234126983,
        "hf_subset": "cta_Latn-eng_Latn",
        "languages": [
          "cta-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025128658234126983,
        "precision": 0.022998664952531646,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.008047153520499109,
        "hf_subset": "eng_Latn-cth_Latn",
        "languages": [
          "eng-Latn",
          "cth-Latn"
        ],
        "main_score": 0.008047153520499109,
        "precision": 0.0062647592867956315,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00578125,
        "hf_subset": "cth_Latn-eng_Latn",
        "languages": [
          "cth-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00578125,
        "precision": 0.004992734300095877,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01927548363095238,
        "hf_subset": "eng_Latn-ctp_Latn",
        "languages": [
          "eng-Latn",
          "ctp-Latn"
        ],
        "main_score": 0.01927548363095238,
        "precision": 0.016999477155727156,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0168774162371134,
        "hf_subset": "ctp_Latn-eng_Latn",
        "languages": [
          "ctp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0168774162371134,
        "precision": 0.014067678740530304,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.0178644638076114,
        "hf_subset": "eng_Latn-ctu_Latn",
        "languages": [
          "eng-Latn",
          "ctu-Latn"
        ],
        "main_score": 0.0178644638076114,
        "precision": 0.01562597696249025,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013199869791666666,
        "hf_subset": "ctu_Latn-eng_Latn",
        "languages": [
          "ctu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013199869791666666,
        "precision": 0.011426231278801843,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.021623883928571428,
        "hf_subset": "eng_Latn-cub_Latn",
        "languages": [
          "eng-Latn",
          "cub-Latn"
        ],
        "main_score": 0.021623883928571428,
        "precision": 0.02074032738095238,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023509368235930736,
        "hf_subset": "cub_Latn-eng_Latn",
        "languages": [
          "cub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023509368235930736,
        "precision": 0.02194725847069597,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01175037955465587,
        "hf_subset": "eng_Latn-cuc_Latn",
        "languages": [
          "eng-Latn",
          "cuc-Latn"
        ],
        "main_score": 0.01175037955465587,
        "precision": 0.01173462906504065,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01641310307017544,
        "hf_subset": "cuc_Latn-eng_Latn",
        "languages": [
          "cuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01641310307017544,
        "precision": 0.015043712797619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003714767156862745,
        "hf_subset": "eng_Latn-cui_Latn",
        "languages": [
          "eng-Latn",
          "cui-Latn"
        ],
        "main_score": 0.003714767156862745,
        "precision": 0.0023274739583333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003945508793969849,
        "hf_subset": "cui_Latn-eng_Latn",
        "languages": [
          "cui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003945508793969849,
        "precision": 0.003925978535353535,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01138599537037037,
        "hf_subset": "eng_Latn-cuk_Latn",
        "languages": [
          "eng-Latn",
          "cuk-Latn"
        ],
        "main_score": 0.01138599537037037,
        "precision": 0.010120296952736318,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007064027311423145,
        "hf_subset": "cuk_Latn-eng_Latn",
        "languages": [
          "cuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007064027311423145,
        "precision": 0.005761581976540616,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.011841047482211273,
        "hf_subset": "eng_Latn-cut_Latn",
        "languages": [
          "eng-Latn",
          "cut-Latn"
        ],
        "main_score": 0.011841047482211273,
        "precision": 0.007862774803522574,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01165922619047619,
        "hf_subset": "cut_Latn-eng_Latn",
        "languages": [
          "cut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01165922619047619,
        "precision": 0.00927734375,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014187875203500202,
        "hf_subset": "eng_Latn-cux_Latn",
        "languages": [
          "eng-Latn",
          "cux-Latn"
        ],
        "main_score": 0.014187875203500202,
        "precision": 0.011913031438536954,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010660807291666666,
        "hf_subset": "cux_Latn-eng_Latn",
        "languages": [
          "cux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010660807291666666,
        "precision": 0.00871975806451613,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009399694683908045,
        "hf_subset": "eng_Latn-cwe_Latn",
        "languages": [
          "eng-Latn",
          "cwe-Latn"
        ],
        "main_score": 0.009399694683908045,
        "precision": 0.00640221800177569,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00012807377049180329,
        "hf_subset": "cwe_Latn-eng_Latn",
        "languages": [
          "cwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00012807377049180329,
        "precision": 6.510416666666667e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021063061167227833,
        "hf_subset": "eng_Latn-cya_Latn",
        "languages": [
          "eng-Latn",
          "cya-Latn"
        ],
        "main_score": 0.021063061167227833,
        "precision": 0.019253243077122152,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011502223782771536,
        "hf_subset": "cya_Latn-eng_Latn",
        "languages": [
          "cya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011502223782771536,
        "precision": 0.009342244647636038,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008068347953216374,
        "hf_subset": "eng_Latn-daa_Latn",
        "languages": [
          "eng-Latn",
          "daa-Latn"
        ],
        "main_score": 0.008068347953216374,
        "precision": 0.007942834260154737,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005106026785714286,
        "hf_subset": "daa_Latn-eng_Latn",
        "languages": [
          "daa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005106026785714286,
        "precision": 0.004579175420168067,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009374948459559308,
        "hf_subset": "eng_Latn-dad_Latn",
        "languages": [
          "eng-Latn",
          "dad-Latn"
        ],
        "main_score": 0.009374948459559308,
        "precision": 0.007646251860119047,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018594744435866534,
        "hf_subset": "dad_Latn-eng_Latn",
        "languages": [
          "dad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018594744435866534,
        "precision": 0.017459542410714284,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011343355802493463,
        "hf_subset": "eng_Latn-dah_Latn",
        "languages": [
          "eng-Latn",
          "dah-Latn"
        ],
        "main_score": 0.011343355802493463,
        "precision": 0.009986887069600044,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0036641550559617783,
        "hf_subset": "dah_Latn-eng_Latn",
        "languages": [
          "dah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0036641550559617783,
        "precision": 0.0025047261447192514,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9609375,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ],
        "main_score": 0.9609375,
        "precision": 0.95703125,
        "recall": 0.96875
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9388020833333333,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9388020833333333,
        "precision": 0.931640625,
        "recall": 0.953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004351128472222222,
        "hf_subset": "eng_Latn-ded_Latn",
        "languages": [
          "eng-Latn",
          "ded-Latn"
        ],
        "main_score": 0.004351128472222222,
        "precision": 0.0030230241519698478,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012940395752895753,
        "hf_subset": "ded_Latn-eng_Latn",
        "languages": [
          "ded-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012940395752895753,
        "precision": 0.011121218607305935,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96875,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.96875,
        "precision": 0.96484375,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9739583333333333,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9739583333333333,
        "precision": 0.970703125,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017721688034188034,
        "hf_subset": "eng_Latn-dgc_Latn",
        "languages": [
          "eng-Latn",
          "dgc-Latn"
        ],
        "main_score": 0.017721688034188034,
        "precision": 0.015579989097911893,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028538532664746256,
        "hf_subset": "dgc_Latn-eng_Latn",
        "languages": [
          "dgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028538532664746256,
        "precision": 0.02425804817119155,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04644670490261982,
        "hf_subset": "eng_Latn-dgr_Latn",
        "languages": [
          "eng-Latn",
          "dgr-Latn"
        ],
        "main_score": 0.04644670490261982,
        "precision": 0.043135198583743845,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.030122799749136096,
        "hf_subset": "dgr_Latn-eng_Latn",
        "languages": [
          "dgr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030122799749136096,
        "precision": 0.025619973011606074,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002637987012987013,
        "hf_subset": "eng_Latn-dgz_Latn",
        "languages": [
          "eng-Latn",
          "dgz-Latn"
        ],
        "main_score": 0.002637987012987013,
        "precision": 0.001970108695652174,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005142629523026316,
        "hf_subset": "dgz_Latn-eng_Latn",
        "languages": [
          "dgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005142629523026316,
        "precision": 0.004553620379072682,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.382034632034632e-05,
        "hf_subset": "eng_Latn-dhg_Latn",
        "languages": [
          "eng-Latn",
          "dhg-Latn"
        ],
        "main_score": 3.382034632034632e-05,
        "precision": 1.6983695652173913e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006092168341887653,
        "hf_subset": "dhg_Latn-eng_Latn",
        "languages": [
          "dhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006092168341887653,
        "precision": 0.004125094126506024,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012321820175438597,
        "hf_subset": "eng_Latn-dif_Latn",
        "languages": [
          "eng-Latn",
          "dif-Latn"
        ],
        "main_score": 0.012321820175438597,
        "precision": 0.009616358293592565,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015922268081761004,
        "hf_subset": "dif_Latn-eng_Latn",
        "languages": [
          "dif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015922268081761004,
        "precision": 0.014666950533175356,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022778707837301584,
        "hf_subset": "eng_Latn-dik_Latn",
        "languages": [
          "eng-Latn",
          "dik-Latn"
        ],
        "main_score": 0.022778707837301584,
        "precision": 0.01901984351432881,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013598424145299146,
        "hf_subset": "dik_Latn-eng_Latn",
        "languages": [
          "dik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013598424145299146,
        "precision": 0.011295150162337661,
        "recall": 0.03125
      },
      {
        "accuracy": 0.06842105263157895,
        "f1": 0.03461083263714842,
        "hf_subset": "eng_Latn-dji_Latn",
        "languages": [
          "eng-Latn",
          "dji-Latn"
        ],
        "main_score": 0.03461083263714842,
        "precision": 0.029829463908411277,
        "recall": 0.06842105263157895
      },
      {
        "accuracy": 0.02631578947368421,
        "f1": 0.013574287732517069,
        "hf_subset": "dji_Latn-eng_Latn",
        "languages": [
          "dji-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013574287732517069,
        "precision": 0.012494840041279669,
        "recall": 0.02631578947368421
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015830686240842492,
        "hf_subset": "eng_Latn-djk_Latn",
        "languages": [
          "eng-Latn",
          "djk-Latn"
        ],
        "main_score": 0.015830686240842492,
        "precision": 0.015729693193840367,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019563802083333335,
        "hf_subset": "djk_Latn-eng_Latn",
        "languages": [
          "djk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019563802083333335,
        "precision": 0.01831943267282363,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005263350938967136,
        "hf_subset": "eng_Latn-djr_Latn",
        "languages": [
          "eng-Latn",
          "djr-Latn"
        ],
        "main_score": 0.005263350938967136,
        "precision": 0.0039339539007092195,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004617947722567288,
        "hf_subset": "djr_Latn-eng_Latn",
        "languages": [
          "djr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004617947722567288,
        "precision": 0.004279119318181818,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008989640163671373,
        "hf_subset": "eng_Latn-dob_Latn",
        "languages": [
          "eng-Latn",
          "dob-Latn"
        ],
        "main_score": 0.008989640163671373,
        "precision": 0.008472308621194378,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014548399390243903,
        "hf_subset": "dob_Latn-eng_Latn",
        "languages": [
          "dob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014548399390243903,
        "precision": 0.013503086419753087,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-dop_Latn",
        "languages": [
          "eng-Latn",
          "dop-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006254836309523809,
        "hf_subset": "dop_Latn-eng_Latn",
        "languages": [
          "dop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006254836309523809,
        "precision": 0.0052048473959476265,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007366395867940199,
        "hf_subset": "eng_Latn-dov_Latn",
        "languages": [
          "eng-Latn",
          "dov-Latn"
        ],
        "main_score": 0.007366395867940199,
        "precision": 0.006308072009291521,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00396165780141844,
        "hf_subset": "dov_Latn-eng_Latn",
        "languages": [
          "dov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00396165780141844,
        "precision": 0.003934151785714286,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0009221747803478573,
        "hf_subset": "eng_Latn-dwr_Latn",
        "languages": [
          "eng-Latn",
          "dwr-Latn"
        ],
        "main_score": 0.0009221747803478573,
        "precision": 0.00048828125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0034803806390977443,
        "hf_subset": "dwr_Latn-eng_Latn",
        "languages": [
          "dwr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0034803806390977443,
        "precision": 0.0021701388888888886,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009765625,
        "hf_subset": "eng_Latn-dww_Latn",
        "languages": [
          "eng-Latn",
          "dww-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0005580357142857143,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010604319852941177,
        "hf_subset": "dww_Latn-eng_Latn",
        "languages": [
          "dww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010604319852941177,
        "precision": 0.009577546296296296,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.045112781954887216,
        "f1": 0.017942371456591787,
        "hf_subset": "eng_Latn-dwy_Latn",
        "languages": [
          "eng-Latn",
          "dwy-Latn"
        ],
        "main_score": 0.017942371456591787,
        "precision": 0.014362830152303836,
        "recall": 0.045112781954887216
      },
      {
        "accuracy": 0.07518796992481203,
        "f1": 0.04347962297046965,
        "hf_subset": "dwy_Latn-eng_Latn",
        "languages": [
          "dwy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04347962297046965,
        "precision": 0.0389659737949818,
        "recall": 0.07518796992481203
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012724905303030304,
        "hf_subset": "eng_Latn-ebk_Latn",
        "languages": [
          "eng-Latn",
          "ebk-Latn"
        ],
        "main_score": 0.012724905303030304,
        "precision": 0.011253720238095238,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02727949134199134,
        "hf_subset": "ebk_Latn-eng_Latn",
        "languages": [
          "ebk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02727949134199134,
        "precision": 0.02573996443089431,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008412050189393939,
        "hf_subset": "eng_Latn-eko_Latn",
        "languages": [
          "eng-Latn",
          "eko-Latn"
        ],
        "main_score": 0.008412050189393939,
        "precision": 0.006590861470306513,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028441466792902726,
        "hf_subset": "eko_Latn-eng_Latn",
        "languages": [
          "eko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028441466792902726,
        "precision": 0.0020751953125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014528751718726661,
        "hf_subset": "eng_Latn-emi_Latn",
        "languages": [
          "eng-Latn",
          "emi-Latn"
        ],
        "main_score": 0.014528751718726661,
        "precision": 0.012291201636904763,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011247519841269843,
        "hf_subset": "emi_Latn-eng_Latn",
        "languages": [
          "emi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011247519841269843,
        "precision": 0.010211692338813888,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01682017140328024,
        "hf_subset": "eng_Latn-emp_Latn",
        "languages": [
          "eng-Latn",
          "emp-Latn"
        ],
        "main_score": 0.01682017140328024,
        "precision": 0.013744951105442176,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009817708333333335,
        "hf_subset": "emp_Latn-eng_Latn",
        "languages": [
          "emp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009817708333333335,
        "precision": 0.009140799776286354,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0005401499542124542,
        "hf_subset": "eng_Latn-enq_Latn",
        "languages": [
          "eng-Latn",
          "enq-Latn"
        ],
        "main_score": 0.0005401499542124542,
        "precision": 0.0002778750734513817,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00018484120046620046,
        "hf_subset": "enq_Latn-eng_Latn",
        "languages": [
          "enq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00018484120046620046,
        "precision": 9.371642993554548e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.515625,
        "f1": 0.43505394345238096,
        "hf_subset": "eng_Latn-epo_Latn",
        "languages": [
          "eng-Latn",
          "epo-Latn"
        ],
        "main_score": 0.43505394345238096,
        "precision": 0.408986066017316,
        "recall": 0.515625
      },
      {
        "accuracy": 0.58984375,
        "f1": 0.5228298611111112,
        "hf_subset": "epo_Latn-eng_Latn",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5228298611111112,
        "precision": 0.49916190197669974,
        "recall": 0.58984375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009587070671603677,
        "hf_subset": "eng_Latn-eri_Latn",
        "languages": [
          "eng-Latn",
          "eri-Latn"
        ],
        "main_score": 0.009587070671603677,
        "precision": 0.008805549918831168,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020324843830278612,
        "hf_subset": "eri_Latn-eng_Latn",
        "languages": [
          "eri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020324843830278612,
        "precision": 0.01853664658634538,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.316298342541436e-05,
        "hf_subset": "eng_Latn-ese_Latn",
        "languages": [
          "eng-Latn",
          "ese-Latn"
        ],
        "main_score": 4.316298342541436e-05,
        "precision": 2.170138888888889e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026778694968553458,
        "hf_subset": "ese_Latn-eng_Latn",
        "languages": [
          "ese-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026778694968553458,
        "precision": 0.001990327380952381,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.043229166666666666,
        "hf_subset": "eng_Latn-esk_Latn",
        "languages": [
          "eng-Latn",
          "esk-Latn"
        ],
        "main_score": 0.043229166666666666,
        "precision": 0.0400390625,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03033559922171302,
        "hf_subset": "esk_Latn-eng_Latn",
        "languages": [
          "esk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03033559922171302,
        "precision": 0.02665828112999232,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009054756189032218,
        "hf_subset": "eng_Latn-etr_Latn",
        "languages": [
          "eng-Latn",
          "etr-Latn"
        ],
        "main_score": 0.009054756189032218,
        "precision": 0.008470517113095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006988014800514799,
        "hf_subset": "etr_Latn-eng_Latn",
        "languages": [
          "etr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006988014800514799,
        "precision": 0.006108197773972603,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02689772885918275,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ],
        "main_score": 0.02689772885918275,
        "precision": 0.024217685697434876,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03023325358851675,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03023325358851675,
        "precision": 0.02659846077814828,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0022174873737373737,
        "hf_subset": "eng_Latn-faa_Latn",
        "languages": [
          "eng-Latn",
          "faa-Latn"
        ],
        "main_score": 0.0022174873737373737,
        "precision": 0.0014375090737514518,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003941283632286996,
        "hf_subset": "faa_Latn-eng_Latn",
        "languages": [
          "faa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003941283632286996,
        "precision": 0.0039238457207207205,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002999559250748934,
        "hf_subset": "eng_Latn-fai_Latn",
        "languages": [
          "eng-Latn",
          "fai-Latn"
        ],
        "main_score": 0.002999559250748934,
        "precision": 0.002154339800824176,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "fai_Latn-eng_Latn",
        "languages": [
          "fai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021495220728451562,
        "hf_subset": "eng_Latn-far_Latn",
        "languages": [
          "eng-Latn",
          "far-Latn"
        ],
        "main_score": 0.021495220728451562,
        "precision": 0.019586335378746093,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022593292124542124,
        "hf_subset": "far_Latn-eng_Latn",
        "languages": [
          "far-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022593292124542124,
        "precision": 0.020482772435897433,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006660354980667481,
        "hf_subset": "eng_Latn-ffm_Latn",
        "languages": [
          "eng-Latn",
          "ffm-Latn"
        ],
        "main_score": 0.006660354980667481,
        "precision": 0.005622262924155002,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014787060657596371,
        "hf_subset": "ffm_Latn-eng_Latn",
        "languages": [
          "ffm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014787060657596371,
        "precision": 0.01352434513778747,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003428342490842491,
        "hf_subset": "eng_Latn-for_Latn",
        "languages": [
          "eng-Latn",
          "for-Latn"
        ],
        "main_score": 0.003428342490842491,
        "precision": 0.0023935355392156864,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004921875,
        "hf_subset": "for_Latn-eng_Latn",
        "languages": [
          "for-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004921875,
        "precision": 0.004483915111270638,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9739583333333334,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ],
        "main_score": 0.9739583333333334,
        "precision": 0.970703125,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96875,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.96875,
        "precision": 0.96484375,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015787423438578328,
        "hf_subset": "eng_Latn-fue_Latn",
        "languages": [
          "eng-Latn",
          "fue-Latn"
        ],
        "main_score": 0.015787423438578328,
        "precision": 0.011701221955128205,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019287274171133614,
        "hf_subset": "fue_Latn-eng_Latn",
        "languages": [
          "fue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019287274171133614,
        "precision": 0.01815321180555556,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006307418587966341,
        "hf_subset": "eng_Latn-fuf_Latn",
        "languages": [
          "eng-Latn",
          "fuf-Latn"
        ],
        "main_score": 0.006307418587966341,
        "precision": 0.005327432790770317,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006264153079710145,
        "hf_subset": "fuf_Latn-eng_Latn",
        "languages": [
          "fuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006264153079710145,
        "precision": 0.005202548274094327,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01610353334845735,
        "hf_subset": "eng_Latn-fuh_Latn",
        "languages": [
          "eng-Latn",
          "fuh-Latn"
        ],
        "main_score": 0.01610353334845735,
        "precision": 0.015875981280193234,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013795488931358495,
        "hf_subset": "fuh_Latn-eng_Latn",
        "languages": [
          "fuh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013795488931358495,
        "precision": 0.012877096861471862,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0003252992901164549,
        "hf_subset": "eng_Latn-gah_Latn",
        "languages": [
          "eng-Latn",
          "gah-Latn"
        ],
        "main_score": 0.0003252992901164549,
        "precision": 0.00016510325407915067,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003959396258503401,
        "hf_subset": "gah_Latn-eng_Latn",
        "languages": [
          "gah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003959396258503401,
        "precision": 0.0039330051369863015,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019300235215053765,
        "hf_subset": "eng_Latn-gai_Latn",
        "languages": [
          "eng-Latn",
          "gai-Latn"
        ],
        "main_score": 0.0019300235215053765,
        "precision": 0.001167514321386604,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013985437925170067,
        "hf_subset": "gai_Latn-eng_Latn",
        "languages": [
          "gai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013985437925170067,
        "precision": 0.0107689426369863,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018329326923076924,
        "hf_subset": "eng_Latn-gam_Latn",
        "languages": [
          "eng-Latn",
          "gam-Latn"
        ],
        "main_score": 0.018329326923076924,
        "precision": 0.01762885551948052,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.028180803571428572,
        "hf_subset": "gam_Latn-eng_Latn",
        "languages": [
          "gam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028180803571428572,
        "precision": 0.026592092803030303,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010416666666666666,
        "hf_subset": "eng_Latn-gaw_Latn",
        "languages": [
          "eng-Latn",
          "gaw-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.00859375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013882211538461538,
        "hf_subset": "gaw_Latn-eng_Latn",
        "languages": [
          "gaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013882211538461538,
        "precision": 0.011848958333333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "eng_Latn-gdn_Latn",
        "languages": [
          "eng-Latn",
          "gdn-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00015626562656265627,
        "hf_subset": "gdn_Latn-eng_Latn",
        "languages": [
          "gdn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015626562656265627,
        "precision": 7.892219387755102e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004853219696969697,
        "hf_subset": "eng_Latn-gdr_Latn",
        "languages": [
          "eng-Latn",
          "gdr-Latn"
        ],
        "main_score": 0.004853219696969697,
        "precision": 0.0044189453125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023393843927061616,
        "hf_subset": "gdr_Latn-eng_Latn",
        "languages": [
          "gdr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023393843927061616,
        "precision": 0.02103319857226107,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002807194213444213,
        "hf_subset": "eng_Latn-geb_Latn",
        "languages": [
          "eng-Latn",
          "geb-Latn"
        ],
        "main_score": 0.002807194213444213,
        "precision": 0.0016656662665066027,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011963823646496815,
        "hf_subset": "geb_Latn-eng_Latn",
        "languages": [
          "geb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011963823646496815,
        "precision": 0.01184395032051282,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005329241071428572,
        "hf_subset": "eng_Latn-gfk_Latn",
        "languages": [
          "eng-Latn",
          "gfk-Latn"
        ],
        "main_score": 0.005329241071428572,
        "precision": 0.0031213498772568894,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009207589285714286,
        "hf_subset": "gfk_Latn-eng_Latn",
        "languages": [
          "gfk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009207589285714286,
        "precision": 0.007436342592592592,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006897399475524476,
        "hf_subset": "eng_Latn-ghs_Latn",
        "languages": [
          "eng-Latn",
          "ghs-Latn"
        ],
        "main_score": 0.0006897399475524476,
        "precision": 0.00037042025862068964,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ghs_Latn-eng_Latn",
        "languages": [
          "ghs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.8064516129032258,
        "f1": 0.7598566308243728,
        "hf_subset": "eng_Latn-glk_Arab",
        "languages": [
          "eng-Latn",
          "glk-Arab"
        ],
        "main_score": 0.7598566308243728,
        "precision": 0.7401433691756272,
        "recall": 0.8064516129032258
      },
      {
        "accuracy": 0.7419354838709677,
        "f1": 0.6792114695340502,
        "hf_subset": "glk_Arab-eng_Latn",
        "languages": [
          "glk-Arab",
          "eng-Latn"
        ],
        "main_score": 0.6792114695340502,
        "precision": 0.6523297491039426,
        "recall": 0.7419354838709677
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008735301346037507,
        "hf_subset": "eng_Latn-gmv_Latn",
        "languages": [
          "eng-Latn",
          "gmv-Latn"
        ],
        "main_score": 0.008735301346037507,
        "precision": 0.007299743499373434,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004151348039215686,
        "hf_subset": "gmv_Latn-eng_Latn",
        "languages": [
          "gmv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004151348039215686,
        "precision": 0.0026159659292821604,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007587061658902691,
        "hf_subset": "eng_Latn-gng_Latn",
        "languages": [
          "eng-Latn",
          "gng-Latn"
        ],
        "main_score": 0.007587061658902691,
        "precision": 0.006423199820708425,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016136400250983583,
        "hf_subset": "gng_Latn-eng_Latn",
        "languages": [
          "gng-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016136400250983583,
        "precision": 0.014697265625,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0022135416666666666,
        "hf_subset": "eng_Latn-gnn_Latn",
        "languages": [
          "eng-Latn",
          "gnn-Latn"
        ],
        "main_score": 0.0022135416666666666,
        "precision": 0.0014367816091954023,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003948479729729729,
        "hf_subset": "gnn_Latn-eng_Latn",
        "languages": [
          "gnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003948479729729729,
        "precision": 0.003927479619565217,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014968885281385281,
        "hf_subset": "eng_Latn-gnw_Latn",
        "languages": [
          "eng-Latn",
          "gnw-Latn"
        ],
        "main_score": 0.014968885281385281,
        "precision": 0.013575629340277777,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021298416907746705,
        "hf_subset": "gnw_Latn-eng_Latn",
        "languages": [
          "gnw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021298416907746705,
        "precision": 0.019439717409240925,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009454744816586922,
        "hf_subset": "eng_Latn-gof_Latn",
        "languages": [
          "eng-Latn",
          "gof-Latn"
        ],
        "main_score": 0.009454744816586922,
        "precision": 0.0073970734126984124,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005409564393939394,
        "hf_subset": "gof_Latn-eng_Latn",
        "languages": [
          "gof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005409564393939394,
        "precision": 0.0035524515993265995,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.6796875,
        "f1": 0.5992931547619047,
        "hf_subset": "eng_Latn-grc_Grek",
        "languages": [
          "eng-Latn",
          "grc-Grek"
        ],
        "main_score": 0.5992931547619047,
        "precision": 0.5666666666666667,
        "recall": 0.6796875
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.4626860119047619,
        "hf_subset": "grc_Grek-eng_Latn",
        "languages": [
          "grc-Grek",
          "eng-Latn"
        ],
        "main_score": 0.4626860119047619,
        "precision": 0.4373435808982684,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-gub_Latn",
        "languages": [
          "eng-Latn",
          "gub-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007504480286738351,
        "hf_subset": "gub_Latn-eng_Latn",
        "languages": [
          "gub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007504480286738351,
        "precision": 0.006411693135245902,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0058951088659147865,
        "hf_subset": "eng_Latn-guh_Latn",
        "languages": [
          "eng-Latn",
          "guh-Latn"
        ],
        "main_score": 0.0058951088659147865,
        "precision": 0.005043568733511495,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003942928403755868,
        "hf_subset": "guh_Latn-eng_Latn",
        "languages": [
          "guh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003942928403755868,
        "precision": 0.00392467570754717,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013912519771894772,
        "hf_subset": "eng_Latn-gui_Latn",
        "languages": [
          "eng-Latn",
          "gui-Latn"
        ],
        "main_score": 0.013912519771894772,
        "precision": 0.013143616526394137,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02264608358358358,
        "hf_subset": "gui_Latn-eng_Latn",
        "languages": [
          "gui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02264608358358358,
        "precision": 0.019463150604161285,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.48046875,
        "f1": 0.383490966498779,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.383490966498779,
        "precision": 0.34965408940018317,
        "recall": 0.48046875
      },
      {
        "accuracy": 0.54296875,
        "f1": 0.48973927331349204,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.48973927331349204,
        "precision": 0.4761827256944444,
        "recall": 0.54296875
      },
      {
        "accuracy": 0.26171875,
        "f1": 0.20736593986200677,
        "hf_subset": "eng_Latn-gul_Latn",
        "languages": [
          "eng-Latn",
          "gul-Latn"
        ],
        "main_score": 0.20736593986200677,
        "precision": 0.19491962031024532,
        "recall": 0.26171875
      },
      {
        "accuracy": 0.37109375,
        "f1": 0.2910714285714286,
        "hf_subset": "gul_Latn-eng_Latn",
        "languages": [
          "gul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2910714285714286,
        "precision": 0.26795351617847024,
        "recall": 0.37109375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007850985221674878,
        "hf_subset": "eng_Latn-gum_Latn",
        "languages": [
          "eng-Latn",
          "gum-Latn"
        ],
        "main_score": 0.007850985221674878,
        "precision": 0.007831837871287129,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020651041666666668,
        "hf_subset": "gum_Latn-eng_Latn",
        "languages": [
          "gum-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020651041666666668,
        "precision": 0.019028172348484848,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015039388836675022,
        "hf_subset": "eng_Latn-gun_Latn",
        "languages": [
          "eng-Latn",
          "gun-Latn"
        ],
        "main_score": 0.015039388836675022,
        "precision": 0.013681724889774895,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013856229600388143,
        "hf_subset": "gun_Latn-eng_Latn",
        "languages": [
          "gun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013856229600388143,
        "precision": 0.011772926516942474,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009128692434865747,
        "hf_subset": "eng_Latn-guo_Latn",
        "languages": [
          "eng-Latn",
          "guo-Latn"
        ],
        "main_score": 0.009128692434865747,
        "precision": 0.007355843423551757,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028435664724827128,
        "hf_subset": "guo_Latn-eng_Latn",
        "languages": [
          "guo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028435664724827128,
        "precision": 0.024658738741344437,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03887469951923077,
        "hf_subset": "eng_Latn-gup_Latn",
        "languages": [
          "eng-Latn",
          "gup-Latn"
        ],
        "main_score": 0.03887469951923077,
        "precision": 0.036261160714285715,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02740673120471014,
        "hf_subset": "gup_Latn-eng_Latn",
        "languages": [
          "gup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02740673120471014,
        "precision": 0.022643874595629943,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015085565476190475,
        "hf_subset": "eng_Latn-gux_Latn",
        "languages": [
          "eng-Latn",
          "gux-Latn"
        ],
        "main_score": 0.015085565476190475,
        "precision": 0.012686820652173912,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018973214285714288,
        "hf_subset": "gux_Latn-eng_Latn",
        "languages": [
          "gux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018973214285714288,
        "precision": 0.01755708122895623,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007903343023255814,
        "hf_subset": "eng_Latn-gvc_Latn",
        "languages": [
          "eng-Latn",
          "gvc-Latn"
        ],
        "main_score": 0.007903343023255814,
        "precision": 0.007858455882352941,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01208309070910973,
        "hf_subset": "gvc_Latn-eng_Latn",
        "languages": [
          "gvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01208309070910973,
        "precision": 0.010700560794970162,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004734492481203008,
        "hf_subset": "eng_Latn-gvf_Latn",
        "languages": [
          "eng-Latn",
          "gvf-Latn"
        ],
        "main_score": 0.004734492481203008,
        "precision": 0.002981770833333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005601165254237288,
        "hf_subset": "gvf_Latn-eng_Latn",
        "languages": [
          "gvf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005601165254237288,
        "precision": 0.004950161637931034,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023472794533124564,
        "hf_subset": "eng_Latn-gvn_Latn",
        "languages": [
          "eng-Latn",
          "gvn-Latn"
        ],
        "main_score": 0.023472794533124564,
        "precision": 0.021899167455808083,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019853670634920634,
        "hf_subset": "gvn_Latn-eng_Latn",
        "languages": [
          "gvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019853670634920634,
        "precision": 0.0185859375,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003939607757996816,
        "hf_subset": "eng_Latn-gvs_Latn",
        "languages": [
          "eng-Latn",
          "gvs-Latn"
        ],
        "main_score": 0.003939607757996816,
        "precision": 0.0027158402819138375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007546164772727272,
        "hf_subset": "gvs_Latn-eng_Latn",
        "languages": [
          "gvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007546164772727272,
        "precision": 0.00644722941657579,
        "recall": 0.015625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04383477850274725,
        "hf_subset": "eng_Latn-gwi_Latn",
        "languages": [
          "eng-Latn",
          "gwi-Latn"
        ],
        "main_score": 0.04383477850274725,
        "precision": 0.037406755570818066,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04420665045204402,
        "hf_subset": "gwi_Latn-eng_Latn",
        "languages": [
          "gwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04420665045204402,
        "precision": 0.04139374451737486,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015981867283950617,
        "hf_subset": "eng_Latn-gym_Latn",
        "languages": [
          "eng-Latn",
          "gym-Latn"
        ],
        "main_score": 0.015981867283950617,
        "precision": 0.014697265625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014404174041051671,
        "hf_subset": "gym_Latn-eng_Latn",
        "languages": [
          "gym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014404174041051671,
        "precision": 0.013281575321074778,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007267456248020273,
        "hf_subset": "eng_Latn-gyr_Latn",
        "languages": [
          "eng-Latn",
          "gyr-Latn"
        ],
        "main_score": 0.007267456248020273,
        "precision": 0.006008429276315789,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01786013585038814,
        "hf_subset": "gyr_Latn-eng_Latn",
        "languages": [
          "gyr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01786013585038814,
        "precision": 0.016963252314814815,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022143326518691588,
        "hf_subset": "eng_Latn-hat_Latn",
        "languages": [
          "eng-Latn",
          "hat-Latn"
        ],
        "main_score": 0.022143326518691588,
        "precision": 0.020059919365944305,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.039431423611111106,
        "hf_subset": "hat_Latn-eng_Latn",
        "languages": [
          "hat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.039431423611111106,
        "precision": 0.034709512201619774,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009283358412653975,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ],
        "main_score": 0.009283358412653975,
        "precision": 0.006380499261043615,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006182493580681746,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006182493580681746,
        "precision": 0.00441256653659768,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0032727417021025276,
        "hf_subset": "eng_Latn-haw_Latn",
        "languages": [
          "eng-Latn",
          "haw-Latn"
        ],
        "main_score": 0.0032727417021025276,
        "precision": 0.0023032050589279216,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020312499999999997,
        "hf_subset": "haw_Latn-eng_Latn",
        "languages": [
          "haw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020312499999999997,
        "precision": 0.017621527777777778,
        "recall": 0.03125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04020224567099567,
        "hf_subset": "eng_Latn-hbo_Hebr",
        "languages": [
          "eng-Latn",
          "hbo-Hebr"
        ],
        "main_score": 0.04020224567099567,
        "precision": 0.03371465773809524,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007660308441558442,
        "hf_subset": "hbo_Hebr-eng_Latn",
        "languages": [
          "hbo-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0007660308441558442,
        "precision": 0.0004187275179856115,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-hch_Latn",
        "languages": [
          "eng-Latn",
          "hch-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00264209142394822,
        "hf_subset": "hch_Latn-eng_Latn",
        "languages": [
          "hch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00264209142394822,
        "precision": 0.0019721798780487805,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.890625,
        "f1": 0.8606770833333334,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ],
        "main_score": 0.8606770833333334,
        "precision": 0.8463541666666667,
        "recall": 0.890625
      },
      {
        "accuracy": 0.84375,
        "f1": 0.8044270833333332,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.8044270833333332,
        "precision": 0.7884114583333333,
        "recall": 0.84375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014960937499999999,
        "hf_subset": "eng_Latn-heg_Latn",
        "languages": [
          "eng-Latn",
          "heg-Latn"
        ],
        "main_score": 0.014960937499999999,
        "precision": 0.011788504464285714,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02318138450950951,
        "hf_subset": "heg_Latn-eng_Latn",
        "languages": [
          "heg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02318138450950951,
        "precision": 0.021698405263851146,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9251302083333333,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9251302083333333,
        "precision": 0.9173177083333334,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9453125,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9453125,
        "precision": 0.939453125,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00025862275162648297,
        "hf_subset": "eng_Latn-hix_Latn",
        "languages": [
          "eng-Latn",
          "hix-Latn"
        ],
        "main_score": 0.00025862275162648297,
        "precision": 0.00013216635338345864,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.0080128205128203e-05,
        "hf_subset": "hix_Latn-eng_Latn",
        "languages": [
          "hix-Latn",
          "eng-Latn"
        ],
        "main_score": 5.0080128205128203e-05,
        "precision": 2.5201612903225806e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013651094136620714,
        "hf_subset": "eng_Latn-hla_Latn",
        "languages": [
          "eng-Latn",
          "hla-Latn"
        ],
        "main_score": 0.013651094136620714,
        "precision": 0.01174876435293102,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009429281223358907,
        "hf_subset": "hla_Latn-eng_Latn",
        "languages": [
          "hla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009429281223358907,
        "precision": 0.007973797036297036,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008607903079710145,
        "hf_subset": "eng_Latn-hlt_Latn",
        "languages": [
          "eng-Latn",
          "hlt-Latn"
        ],
        "main_score": 0.008607903079710145,
        "precision": 0.00702899531024531,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022507994632808438,
        "hf_subset": "hlt_Latn-eng_Latn",
        "languages": [
          "hlt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022507994632808438,
        "precision": 0.01888669398949004,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.016333462732919253,
        "hf_subset": "eng_Latn-hmo_Latn",
        "languages": [
          "eng-Latn",
          "hmo-Latn"
        ],
        "main_score": 0.016333462732919253,
        "precision": 0.011940928123143197,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01466022472113574,
        "hf_subset": "hmo_Latn-eng_Latn",
        "languages": [
          "hmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01466022472113574,
        "precision": 0.012097892664298913,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0030980341379931546,
        "hf_subset": "eng_Latn-hns_Latn",
        "languages": [
          "eng-Latn",
          "hns-Latn"
        ],
        "main_score": 0.0030980341379931546,
        "precision": 0.0017976075770820088,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012099780701754386,
        "hf_subset": "hns_Latn-eng_Latn",
        "languages": [
          "hns-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012099780701754386,
        "precision": 0.011916079000737463,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04220501803291881,
        "hf_subset": "eng_Latn-hop_Latn",
        "languages": [
          "eng-Latn",
          "hop-Latn"
        ],
        "main_score": 0.04220501803291881,
        "precision": 0.039746191483527676,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04360586564171123,
        "hf_subset": "hop_Latn-eng_Latn",
        "languages": [
          "hop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04360586564171123,
        "precision": 0.04106657033367209,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004090063280553077,
        "hf_subset": "eng_Latn-hot_Latn",
        "languages": [
          "eng-Latn",
          "hot-Latn"
        ],
        "main_score": 0.004090063280553077,
        "precision": 0.0039994683432290476,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003949652777777778,
        "hf_subset": "hot_Latn-eng_Latn",
        "languages": [
          "hot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003949652777777778,
        "precision": 0.003928072625698324,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9212239583333334,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ],
        "main_score": 0.9212239583333334,
        "precision": 0.9134114583333333,
        "recall": 0.9375
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9420572916666667,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9420572916666667,
        "precision": 0.9368489583333334,
        "recall": 0.953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025430253623188404,
        "hf_subset": "eng_Latn-hto_Latn",
        "languages": [
          "eng-Latn",
          "hto-Latn"
        ],
        "main_score": 0.025430253623188404,
        "precision": 0.023524305555555555,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02163100495676804,
        "hf_subset": "hto_Latn-eng_Latn",
        "languages": [
          "hto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02163100495676804,
        "precision": 0.019216008771929822,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002111343265503876,
        "hf_subset": "eng_Latn-hub_Latn",
        "languages": [
          "eng-Latn",
          "hub-Latn"
        ],
        "main_score": 0.002111343265503876,
        "precision": 0.0012674967447916666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008186246141975308,
        "hf_subset": "hub_Latn-eng_Latn",
        "languages": [
          "hub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008186246141975308,
        "precision": 0.008006599378881988,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00859375,
        "hf_subset": "eng_Latn-hui_Latn",
        "languages": [
          "eng-Latn",
          "hui-Latn"
        ],
        "main_score": 0.00859375,
        "precision": 0.008246527777777778,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005518511146496815,
        "hf_subset": "hui_Latn-eng_Latn",
        "languages": [
          "hui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005518511146496815,
        "precision": 0.004907852564102564,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9596354166666666,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ],
        "main_score": 0.9596354166666666,
        "precision": 0.955078125,
        "recall": 0.96875
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9479166666666667,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9479166666666667,
        "precision": 0.94140625,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01060617965756705,
        "hf_subset": "eng_Latn-hus_Latn",
        "languages": [
          "eng-Latn",
          "hus-Latn"
        ],
        "main_score": 0.01060617965756705,
        "precision": 0.00819519040127659,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004831722928897587,
        "hf_subset": "hus_Latn-eng_Latn",
        "languages": [
          "hus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004831722928897587,
        "precision": 0.003284421741452991,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.027157738095238096,
        "hf_subset": "eng_Latn-huu_Latn",
        "languages": [
          "eng-Latn",
          "huu-Latn"
        ],
        "main_score": 0.027157738095238096,
        "precision": 0.026041666666666668,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022866594753930276,
        "hf_subset": "huu_Latn-eng_Latn",
        "languages": [
          "huu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022866594753930276,
        "precision": 0.020677787162162165,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020218379327366538,
        "hf_subset": "eng_Latn-huv_Latn",
        "languages": [
          "eng-Latn",
          "huv-Latn"
        ],
        "main_score": 0.020218379327366538,
        "precision": 0.016334626782161805,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018153202177610173,
        "hf_subset": "huv_Latn-eng_Latn",
        "languages": [
          "huv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018153202177610173,
        "precision": 0.017223996463967328,
        "recall": 0.03125
      },
      {
        "accuracy": 0.06349206349206349,
        "f1": 0.04127671270528413,
        "hf_subset": "eng_Latn-hvn_Latn",
        "languages": [
          "eng-Latn",
          "hvn-Latn"
        ],
        "main_score": 0.04127671270528413,
        "precision": 0.03584656084656085,
        "recall": 0.06349206349206349
      },
      {
        "accuracy": 0.03968253968253968,
        "f1": 0.025531200134374737,
        "hf_subset": "hvn_Latn-eng_Latn",
        "languages": [
          "hvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025531200134374737,
        "precision": 0.02472527472527472,
        "recall": 0.03968253968253968
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005234400256069964,
        "hf_subset": "eng_Latn-ian_Latn",
        "languages": [
          "eng-Latn",
          "ian-Latn"
        ],
        "main_score": 0.005234400256069964,
        "precision": 0.003505284926470588,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012834821428571428,
        "hf_subset": "ian_Latn-eng_Latn",
        "languages": [
          "ian-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012834821428571428,
        "precision": 0.012369791666666668,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008274695536509561,
        "hf_subset": "eng_Latn-ign_Latn",
        "languages": [
          "eng-Latn",
          "ign-Latn"
        ],
        "main_score": 0.008274695536509561,
        "precision": 0.006877397195674043,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.019566127232142856,
        "hf_subset": "ign_Latn-eng_Latn",
        "languages": [
          "ign-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019566127232142856,
        "precision": 0.0195487668161435,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013165656887755103,
        "hf_subset": "eng_Latn-ikk_Latn",
        "languages": [
          "eng-Latn",
          "ikk-Latn"
        ],
        "main_score": 0.013165656887755103,
        "precision": 0.012498800758007893,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.006636104024367106,
        "hf_subset": "ikk_Latn-eng_Latn",
        "languages": [
          "ikk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006636104024367106,
        "precision": 0.00439495181955211,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00213858981092437,
        "hf_subset": "eng_Latn-ikw_Latn",
        "languages": [
          "eng-Latn",
          "ikw-Latn"
        ],
        "main_score": 0.00213858981092437,
        "precision": 0.0012321912862778247,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001481782616892911,
        "hf_subset": "ikw_Latn-eng_Latn",
        "languages": [
          "ikw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001481782616892911,
        "precision": 0.0007874204142488717,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020527844551282055,
        "hf_subset": "eng_Latn-ilo_Latn",
        "languages": [
          "eng-Latn",
          "ilo-Latn"
        ],
        "main_score": 0.020527844551282055,
        "precision": 0.01885237373458155,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02213944966814159,
        "hf_subset": "ilo_Latn-eng_Latn",
        "languages": [
          "ilo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02213944966814159,
        "precision": 0.019147600446428572,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007944915254237288,
        "hf_subset": "eng_Latn-imo_Latn",
        "languages": [
          "eng-Latn",
          "imo-Latn"
        ],
        "main_score": 0.007944915254237288,
        "precision": 0.007879849137931034,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010457785087719298,
        "hf_subset": "imo_Latn-eng_Latn",
        "languages": [
          "imo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010457785087719298,
        "precision": 0.00978629298941799,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006543104951185494,
        "hf_subset": "eng_Latn-inb_Latn",
        "languages": [
          "eng-Latn",
          "inb-Latn"
        ],
        "main_score": 0.006543104951185494,
        "precision": 0.00587578781512605,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01491780379604672,
        "hf_subset": "inb_Latn-eng_Latn",
        "languages": [
          "inb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01491780379604672,
        "precision": 0.013990868802406126,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.927734375,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ],
        "main_score": 0.927734375,
        "precision": 0.9192708333333334,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9322916666666666,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9322916666666666,
        "precision": 0.923828125,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0007674284257640765,
        "hf_subset": "eng_Latn-ino_Latn",
        "languages": [
          "eng-Latn",
          "ino-Latn"
        ],
        "main_score": 0.0007674284257640765,
        "precision": 0.00039885831381733023,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008720826174112257,
        "hf_subset": "ino_Latn-eng_Latn",
        "languages": [
          "ino-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008720826174112257,
        "precision": 0.0083210208873057,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016566265060240966,
        "hf_subset": "eng_Latn-iou_Latn",
        "languages": [
          "eng-Latn",
          "iou-Latn"
        ],
        "main_score": 0.0016566265060240966,
        "precision": 0.0010241996951219513,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003558250217055248,
        "hf_subset": "iou_Latn-eng_Latn",
        "languages": [
          "iou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003558250217055248,
        "precision": 0.002467698317307692,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019856770833333332,
        "hf_subset": "eng_Latn-ipi_Latn",
        "languages": [
          "eng-Latn",
          "ipi-Latn"
        ],
        "main_score": 0.0019856770833333332,
        "precision": 0.0013184274755927475,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.112549800796813e-05,
        "hf_subset": "ipi_Latn-eng_Latn",
        "languages": [
          "ipi-Latn",
          "eng-Latn"
        ],
        "main_score": 3.112549800796813e-05,
        "precision": 1.5625e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006902874253887494,
        "hf_subset": "eng_Latn-isn_Latn",
        "languages": [
          "eng-Latn",
          "isn-Latn"
        ],
        "main_score": 0.006902874253887494,
        "precision": 0.006059205971000325,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013889653022300469,
        "hf_subset": "isn_Latn-eng_Latn",
        "languages": [
          "isn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013889653022300469,
        "precision": 0.01313164893617021,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96875,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ],
        "main_score": 0.96875,
        "precision": 0.96484375,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9583333333333333,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9583333333333333,
        "precision": 0.953125,
        "recall": 0.96875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004120633417508418,
        "hf_subset": "eng_Latn-iws_Latn",
        "languages": [
          "eng-Latn",
          "iws-Latn"
        ],
        "main_score": 0.004120633417508418,
        "precision": 0.004015094972308757,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009309357782369146,
        "hf_subset": "iws_Latn-eng_Latn",
        "languages": [
          "iws-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009309357782369146,
        "precision": 0.007628038194444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01648065476190476,
        "hf_subset": "eng_Latn-ixl_Latn",
        "languages": [
          "eng-Latn",
          "ixl-Latn"
        ],
        "main_score": 0.01648065476190476,
        "precision": 0.012292286706349204,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01606373681521972,
        "hf_subset": "ixl_Latn-eng_Latn",
        "languages": [
          "ixl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01606373681521972,
        "precision": 0.01242491883116883,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014675597933919943,
        "hf_subset": "eng_Latn-jac_Latn",
        "languages": [
          "eng-Latn",
          "jac-Latn"
        ],
        "main_score": 0.014675597933919943,
        "precision": 0.012040231523722626,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01656005685856432,
        "hf_subset": "jac_Latn-eng_Latn",
        "languages": [
          "jac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01656005685856432,
        "precision": 0.014899596930846932,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015172132554945055,
        "hf_subset": "eng_Latn-jae_Latn",
        "languages": [
          "eng-Latn",
          "jae-Latn"
        ],
        "main_score": 0.015172132554945055,
        "precision": 0.012940976662404092,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01731485109717868,
        "hf_subset": "jae_Latn-eng_Latn",
        "languages": [
          "jae-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01731485109717868,
        "precision": 0.01452252174908425,
        "recall": 0.03125
      },
      {
        "accuracy": 0.007874015748031496,
        "f1": 0.00021572645885017797,
        "hf_subset": "eng_Latn-jao_Latn",
        "languages": [
          "eng-Latn",
          "jao-Latn"
        ],
        "main_score": 0.00021572645885017797,
        "precision": 0.00010936132983377077,
        "recall": 0.007874015748031496
      },
      {
        "accuracy": 0.007874015748031496,
        "f1": 0.000124000248000496,
        "hf_subset": "jao_Latn-eng_Latn",
        "languages": [
          "jao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000124000248000496,
        "precision": 6.249218847644044e-05,
        "recall": 0.007874015748031496
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01896359298029557,
        "hf_subset": "eng_Latn-jic_Latn",
        "languages": [
          "eng-Latn",
          "jic-Latn"
        ],
        "main_score": 0.01896359298029557,
        "precision": 0.015243675595238093,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013349454365079366,
        "hf_subset": "jic_Latn-eng_Latn",
        "languages": [
          "jic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013349454365079366,
        "precision": 0.011306911282771535,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010351920215201465,
        "hf_subset": "eng_Latn-jid_Latn",
        "languages": [
          "eng-Latn",
          "jid-Latn"
        ],
        "main_score": 0.010351920215201465,
        "precision": 0.008460439381702338,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012507891414141414,
        "hf_subset": "jid_Latn-eng_Latn",
        "languages": [
          "jid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012507891414141414,
        "precision": 0.01213454131652661,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002611011549183592,
        "hf_subset": "eng_Latn-jiv_Latn",
        "languages": [
          "eng-Latn",
          "jiv-Latn"
        ],
        "main_score": 0.002611011549183592,
        "precision": 0.0015561311141304348,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002565414186507936,
        "hf_subset": "jiv_Latn-eng_Latn",
        "languages": [
          "jiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002565414186507936,
        "precision": 0.001629880536130536,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008017113095238095,
        "hf_subset": "eng_Latn-jni_Latn",
        "languages": [
          "eng-Latn",
          "jni-Latn"
        ],
        "main_score": 0.008017113095238095,
        "precision": 0.006716008771929825,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011990613553113552,
        "hf_subset": "jni_Latn-eng_Latn",
        "languages": [
          "jni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011990613553113552,
        "precision": 0.01185742716802168,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9505208333333333,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ],
        "main_score": 0.9505208333333333,
        "precision": 0.9453125,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.93125,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.93125,
        "precision": 0.9248046875,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.06460978706398965,
        "hf_subset": "eng_Latn-jvn_Latn",
        "languages": [
          "eng-Latn",
          "jvn-Latn"
        ],
        "main_score": 0.06460978706398965,
        "precision": 0.05466941550925926,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08812008304195804,
        "hf_subset": "jvn_Latn-eng_Latn",
        "languages": [
          "jvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08812008304195804,
        "precision": 0.08494047619047619,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.4375,
        "f1": 0.3447699652777778,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.3447699652777778,
        "precision": 0.31346142623716156,
        "recall": 0.4375
      },
      {
        "accuracy": 0.44140625,
        "f1": 0.4024305555555555,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.4024305555555555,
        "precision": 0.3895053817342615,
        "recall": 0.44140625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009071787587412587,
        "hf_subset": "eng_Latn-kaq_Latn",
        "languages": [
          "eng-Latn",
          "kaq-Latn"
        ],
        "main_score": 0.009071787587412587,
        "precision": 0.008493620801033592,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026358695652173914,
        "hf_subset": "kaq_Latn-eng_Latn",
        "languages": [
          "kaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026358695652173914,
        "precision": 0.02444257527372263,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013678233368719036,
        "hf_subset": "eng_Latn-kbc_Latn",
        "languages": [
          "eng-Latn",
          "kbc-Latn"
        ],
        "main_score": 0.013678233368719036,
        "precision": 0.012842239312222864,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023403397817460318,
        "hf_subset": "kbc_Latn-eng_Latn",
        "languages": [
          "kbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023403397817460318,
        "precision": 0.0195825686690102,
        "recall": 0.046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020954605800653597,
        "hf_subset": "eng_Latn-kbh_Latn",
        "languages": [
          "eng-Latn",
          "kbh-Latn"
        ],
        "main_score": 0.020954605800653597,
        "precision": 0.017668000771391728,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0203529792746114,
        "hf_subset": "kbh_Latn-eng_Latn",
        "languages": [
          "kbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0203529792746114,
        "precision": 0.01998562282986111,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00440119395711501,
        "hf_subset": "eng_Latn-kbm_Latn",
        "languages": [
          "eng-Latn",
          "kbm-Latn"
        ],
        "main_score": 0.00440119395711501,
        "precision": 0.004162064708939709,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006201171875,
        "hf_subset": "kbm_Latn-eng_Latn",
        "languages": [
          "kbm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006201171875,
        "precision": 0.005383787600381108,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0224609375,
        "hf_subset": "eng_Latn-kbq_Latn",
        "languages": [
          "eng-Latn",
          "kbq-Latn"
        ],
        "main_score": 0.0224609375,
        "precision": 0.020352128623188404,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00823997641509434,
        "hf_subset": "kbq_Latn-eng_Latn",
        "languages": [
          "kbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00823997641509434,
        "precision": 0.008036605138438515,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014907786885245902,
        "hf_subset": "eng_Latn-kdc_Latn",
        "languages": [
          "eng-Latn",
          "kdc-Latn"
        ],
        "main_score": 0.014907786885245902,
        "precision": 0.013983175914994097,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010277549342105263,
        "hf_subset": "kdc_Latn-eng_Latn",
        "languages": [
          "kdc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010277549342105263,
        "precision": 0.009246128727511706,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013738596661490682,
        "hf_subset": "eng_Latn-kde_Latn",
        "languages": [
          "eng-Latn",
          "kde-Latn"
        ],
        "main_score": 0.013738596661490682,
        "precision": 0.011683188900560224,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019143725198412698,
        "hf_subset": "kde_Latn-eng_Latn",
        "languages": [
          "kde-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019143725198412698,
        "precision": 0.0011090472027972028,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.006884133531859092,
        "hf_subset": "eng_Latn-kdl_Latn",
        "languages": [
          "eng-Latn",
          "kdl-Latn"
        ],
        "main_score": 0.006884133531859092,
        "precision": 0.00552423538846636,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005296989007296467,
        "hf_subset": "kdl_Latn-eng_Latn",
        "languages": [
          "kdl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005296989007296467,
        "precision": 0.00464430495088994,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020491888753607503,
        "hf_subset": "eng_Latn-kek_Latn",
        "languages": [
          "eng-Latn",
          "kek-Latn"
        ],
        "main_score": 0.020491888753607503,
        "precision": 0.01643910137071176,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018177838918450703,
        "hf_subset": "kek_Latn-eng_Latn",
        "languages": [
          "kek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018177838918450703,
        "precision": 0.015924239529543225,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00809233369883041,
        "hf_subset": "eng_Latn-ken_Latn",
        "languages": [
          "eng-Latn",
          "ken-Latn"
        ],
        "main_score": 0.00809233369883041,
        "precision": 0.005258301237161532,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009521044481981981,
        "hf_subset": "ken_Latn-eng_Latn",
        "languages": [
          "ken-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009521044481981981,
        "precision": 0.008758060515873016,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012539701048329778,
        "hf_subset": "eng_Latn-kew_Latn",
        "languages": [
          "eng-Latn",
          "kew-Latn"
        ],
        "main_score": 0.012539701048329778,
        "precision": 0.009200565952925793,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016485645036781398,
        "hf_subset": "kew_Latn-eng_Latn",
        "languages": [
          "kew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016485645036781398,
        "precision": 0.016091579861111108,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008472028548723254,
        "hf_subset": "eng_Latn-kgf_Latn",
        "languages": [
          "eng-Latn",
          "kgf-Latn"
        ],
        "main_score": 0.008472028548723254,
        "precision": 0.007039149823576774,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004537118544600939,
        "hf_subset": "kgf_Latn-eng_Latn",
        "languages": [
          "kgf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004537118544600939,
        "precision": 0.004241071428571428,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010640851449275363,
        "hf_subset": "eng_Latn-kgk_Latn",
        "languages": [
          "eng-Latn",
          "kgk-Latn"
        ],
        "main_score": 0.010640851449275363,
        "precision": 0.009879609738632295,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0072730654761904755,
        "hf_subset": "kgk_Latn-eng_Latn",
        "languages": [
          "kgk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0072730654761904755,
        "precision": 0.006271100955204216,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030533854166666666,
        "hf_subset": "eng_Latn-kgp_Latn",
        "languages": [
          "eng-Latn",
          "kgp-Latn"
        ],
        "main_score": 0.030533854166666666,
        "precision": 0.02810014230050995,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03173160173160173,
        "hf_subset": "kgp_Latn-eng_Latn",
        "languages": [
          "kgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03173160173160173,
        "precision": 0.03029668898809524,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.976114649681529e-05,
        "hf_subset": "eng_Latn-khs_Latn",
        "languages": [
          "eng-Latn",
          "khs-Latn"
        ],
        "main_score": 4.976114649681529e-05,
        "precision": 2.5040064102564102e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0039544753086419755,
        "hf_subset": "khs_Latn-eng_Latn",
        "languages": [
          "khs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0039544753086419755,
        "precision": 0.003930512422360248,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00853988252086078,
        "hf_subset": "eng_Latn-khz_Latn",
        "languages": [
          "eng-Latn",
          "khz-Latn"
        ],
        "main_score": 0.00853988252086078,
        "precision": 0.007020987497987334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009804300742574257,
        "hf_subset": "khz_Latn-eng_Latn",
        "languages": [
          "khz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009804300742574257,
        "precision": 0.006884964382632293,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017980802945301542,
        "hf_subset": "eng_Latn-kik_Latn",
        "languages": [
          "eng-Latn",
          "kik-Latn"
        ],
        "main_score": 0.017980802945301542,
        "precision": 0.01713639828159645,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0106704840805718,
        "hf_subset": "kik_Latn-eng_Latn",
        "languages": [
          "kik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0106704840805718,
        "precision": 0.009895461746684573,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.024096385542168676,
        "f1": 0.0026208731028008136,
        "hf_subset": "eng_Latn-kiw_Latn",
        "languages": [
          "eng-Latn",
          "kiw-Latn"
        ],
        "main_score": 0.0026208731028008136,
        "precision": 0.0014238773274917855,
        "recall": 0.024096385542168676
      },
      {
        "accuracy": 0.060240963855421686,
        "f1": 0.026064698353854977,
        "hf_subset": "kiw_Latn-eng_Latn",
        "languages": [
          "kiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026064698353854977,
        "precision": 0.02134177736587375,
        "recall": 0.060240963855421686
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01916268049080549,
        "hf_subset": "eng_Latn-kiz_Latn",
        "languages": [
          "eng-Latn",
          "kiz-Latn"
        ],
        "main_score": 0.01916268049080549,
        "precision": 0.01582344572752721,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018305016181229775,
        "hf_subset": "kiz_Latn-eng_Latn",
        "languages": [
          "kiz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018305016181229775,
        "precision": 0.01761642156862745,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01852791305916306,
        "hf_subset": "eng_Latn-kje_Latn",
        "languages": [
          "eng-Latn",
          "kje-Latn"
        ],
        "main_score": 0.01852791305916306,
        "precision": 0.015976849724264705,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018399959415584415,
        "hf_subset": "kje_Latn-eng_Latn",
        "languages": [
          "kje-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018399959415584415,
        "precision": 0.01602590460526316,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002772484756097561,
        "hf_subset": "eng_Latn-kjs_Latn",
        "languages": [
          "eng-Latn",
          "kjs-Latn"
        ],
        "main_score": 0.002772484756097561,
        "precision": 0.0017552593954248364,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011962890625,
        "hf_subset": "kjs_Latn-eng_Latn",
        "languages": [
          "kjs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011962890625,
        "precision": 0.011844758064516129,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006274126040943789,
        "hf_subset": "eng_Latn-kkc_Latn",
        "languages": [
          "eng-Latn",
          "kkc-Latn"
        ],
        "main_score": 0.006274126040943789,
        "precision": 0.005424393315018315,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005380097259731793,
        "hf_subset": "kkc_Latn-eng_Latn",
        "languages": [
          "kkc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005380097259731793,
        "precision": 0.004739066309648206,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009895833333333333,
        "hf_subset": "eng_Latn-kkl_Latn",
        "languages": [
          "eng-Latn",
          "kkl-Latn"
        ],
        "main_score": 0.009895833333333333,
        "precision": 0.00775943023989899,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017988494008714596,
        "hf_subset": "kkl_Latn-eng_Latn",
        "languages": [
          "kkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017988494008714596,
        "precision": 0.016182141426282052,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010555313158587987,
        "hf_subset": "eng_Latn-klt_Latn",
        "languages": [
          "eng-Latn",
          "klt-Latn"
        ],
        "main_score": 0.010555313158587987,
        "precision": 0.00827875600671303,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01684285609217674,
        "hf_subset": "klt_Latn-eng_Latn",
        "languages": [
          "klt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01684285609217674,
        "precision": 0.014823091947115384,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0041416105723969115,
        "hf_subset": "eng_Latn-klv_Latn",
        "languages": [
          "eng-Latn",
          "klv-Latn"
        ],
        "main_score": 0.0041416105723969115,
        "precision": 0.002854170710403727,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003011924342105263,
        "hf_subset": "klv_Latn-eng_Latn",
        "languages": [
          "klv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003011924342105263,
        "precision": 0.0021645178075855686,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016572627314814813,
        "hf_subset": "eng_Latn-kmg_Latn",
        "languages": [
          "eng-Latn",
          "kmg-Latn"
        ],
        "main_score": 0.016572627314814813,
        "precision": 0.014015564437984497,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021467285156249998,
        "hf_subset": "kmg_Latn-eng_Latn",
        "languages": [
          "kmg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021467285156249998,
        "precision": 0.018748205790682416,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006550276360544217,
        "hf_subset": "eng_Latn-kmh_Latn",
        "languages": [
          "eng-Latn",
          "kmh-Latn"
        ],
        "main_score": 0.006550276360544217,
        "precision": 0.005879407051282051,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.8740601503759395e-05,
        "hf_subset": "kmh_Latn-eng_Latn",
        "languages": [
          "kmh-Latn",
          "eng-Latn"
        ],
        "main_score": 5.8740601503759395e-05,
        "precision": 2.959280303030303e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021042921165559246,
        "hf_subset": "eng_Latn-kmk_Latn",
        "languages": [
          "eng-Latn",
          "kmk-Latn"
        ],
        "main_score": 0.021042921165559246,
        "precision": 0.017752393728956227,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.040669800362750946,
        "hf_subset": "kmk_Latn-eng_Latn",
        "languages": [
          "kmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.040669800362750946,
        "precision": 0.036845709800068356,
        "recall": 0.0625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016787574404761904,
        "hf_subset": "eng_Latn-kmo_Latn",
        "languages": [
          "eng-Latn",
          "kmo-Latn"
        ],
        "main_score": 0.016787574404761904,
        "precision": 0.01382547405189621,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008816189236111112,
        "hf_subset": "kmo_Latn-eng_Latn",
        "languages": [
          "kmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008816189236111112,
        "precision": 0.007046555973180234,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0058760862299465245,
        "hf_subset": "eng_Latn-kms_Latn",
        "languages": [
          "eng-Latn",
          "kms-Latn"
        ],
        "main_score": 0.0058760862299465245,
        "precision": 0.005092026735377026,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021490141802641805,
        "hf_subset": "kms_Latn-eng_Latn",
        "languages": [
          "kms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021490141802641805,
        "precision": 0.018192545572916666,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0039459073604060915,
        "hf_subset": "eng_Latn-kmu_Latn",
        "languages": [
          "eng-Latn",
          "kmu-Latn"
        ],
        "main_score": 0.0039459073604060915,
        "precision": 0.002754304846938775,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003939075630252101,
        "hf_subset": "kmu_Latn-eng_Latn",
        "languages": [
          "kmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003939075630252101,
        "precision": 0.003922732067510548,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01584832499354558,
        "hf_subset": "eng_Latn-kne_Latn",
        "languages": [
          "eng-Latn",
          "kne-Latn"
        ],
        "main_score": 0.01584832499354558,
        "precision": 0.012226383605653998,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025583178258380065,
        "hf_subset": "kne_Latn-eng_Latn",
        "languages": [
          "kne-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025583178258380065,
        "precision": 0.02343871312111801,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008816248855311355,
        "hf_subset": "eng_Latn-knf_Latn",
        "languages": [
          "eng-Latn",
          "knf-Latn"
        ],
        "main_score": 0.008816248855311355,
        "precision": 0.006909134973099817,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021077575051759834,
        "hf_subset": "knf_Latn-eng_Latn",
        "languages": [
          "knf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021077575051759834,
        "precision": 0.02040379549808429,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013058213716108451,
        "hf_subset": "eng_Latn-knj_Latn",
        "languages": [
          "eng-Latn",
          "knj-Latn"
        ],
        "main_score": 0.013058213716108451,
        "precision": 0.011737530048076924,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011455098564473565,
        "hf_subset": "knj_Latn-eng_Latn",
        "languages": [
          "knj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011455098564473565,
        "precision": 0.010033491397180763,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.0690104166666664e-05,
        "hf_subset": "eng_Latn-knv_Latn",
        "languages": [
          "eng-Latn",
          "knv-Latn"
        ],
        "main_score": 4.0690104166666664e-05,
        "precision": 2.0451570680628273e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001537602282515073,
        "hf_subset": "knv_Latn-eng_Latn",
        "languages": [
          "knv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001537602282515073,
        "precision": 0.0009009087125416205,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02738231134176764,
        "hf_subset": "eng_Latn-kos_Latn",
        "languages": [
          "eng-Latn",
          "kos-Latn"
        ],
        "main_score": 0.02738231134176764,
        "precision": 0.022766038018168698,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.041765480895915676,
        "hf_subset": "kos_Latn-eng_Latn",
        "languages": [
          "kos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.041765480895915676,
        "precision": 0.036693948412698414,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012794041895604395,
        "hf_subset": "eng_Latn-kpf_Latn",
        "languages": [
          "eng-Latn",
          "kpf-Latn"
        ],
        "main_score": 0.012794041895604395,
        "precision": 0.01107287533068783,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008795705782312925,
        "hf_subset": "kpf_Latn-eng_Latn",
        "languages": [
          "kpf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008795705782312925,
        "precision": 0.00833504840621707,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025516633064516125,
        "hf_subset": "eng_Latn-kpg_Latn",
        "languages": [
          "eng-Latn",
          "kpg-Latn"
        ],
        "main_score": 0.025516633064516125,
        "precision": 0.023284522996357013,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04160870612596359,
        "hf_subset": "kpg_Latn-eng_Latn",
        "languages": [
          "kpg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04160870612596359,
        "precision": 0.03810172032828282,
        "recall": 0.0625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009689670138888887,
        "hf_subset": "eng_Latn-kpj_Latn",
        "languages": [
          "eng-Latn",
          "kpj-Latn"
        ],
        "main_score": 0.009689670138888887,
        "precision": 0.007839816433566434,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016847130847953216,
        "hf_subset": "kpj_Latn-eng_Latn",
        "languages": [
          "kpj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016847130847953216,
        "precision": 0.015273492209383753,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03081939384588841,
        "hf_subset": "eng_Latn-kpr_Latn",
        "languages": [
          "eng-Latn",
          "kpr-Latn"
        ],
        "main_score": 0.03081939384588841,
        "precision": 0.029508106387147334,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022473958333333335,
        "hf_subset": "kpr_Latn-eng_Latn",
        "languages": [
          "kpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022473958333333335,
        "precision": 0.02165853034656914,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009351325757575756,
        "hf_subset": "eng_Latn-kpw_Latn",
        "languages": [
          "eng-Latn",
          "kpw-Latn"
        ],
        "main_score": 0.009351325757575756,
        "precision": 0.0079345703125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013582835477941176,
        "hf_subset": "kpw_Latn-eng_Latn",
        "languages": [
          "kpw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013582835477941176,
        "precision": 0.012850255749701315,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00420217803030303,
        "hf_subset": "eng_Latn-kpx_Latn",
        "languages": [
          "eng-Latn",
          "kpx-Latn"
        ],
        "main_score": 0.00420217803030303,
        "precision": 0.0028862640147900766,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0021116578733766235,
        "hf_subset": "kpx_Latn-eng_Latn",
        "languages": [
          "kpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0021116578733766235,
        "precision": 0.001382174200062131,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.06349206349206349,
        "f1": 0.043003489812000445,
        "hf_subset": "eng_Latn-kqa_Latn",
        "languages": [
          "eng-Latn",
          "kqa-Latn"
        ],
        "main_score": 0.043003489812000445,
        "precision": 0.04002760524499655,
        "recall": 0.06349206349206349
      },
      {
        "accuracy": 0.031746031746031744,
        "f1": 0.031746031746031744,
        "hf_subset": "kqa_Latn-eng_Latn",
        "languages": [
          "kqa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031746031746031744,
        "precision": 0.031746031746031744,
        "recall": 0.031746031746031744
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02689838882598729,
        "hf_subset": "eng_Latn-kqc_Latn",
        "languages": [
          "eng-Latn",
          "kqc-Latn"
        ],
        "main_score": 0.02689838882598729,
        "precision": 0.024599505312395936,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03308733481430849,
        "hf_subset": "kqc_Latn-eng_Latn",
        "languages": [
          "kqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03308733481430849,
        "precision": 0.03022510947433995,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0132352301716141,
        "hf_subset": "eng_Latn-kqf_Latn",
        "languages": [
          "eng-Latn",
          "kqf-Latn"
        ],
        "main_score": 0.0132352301716141,
        "precision": 0.010583010402851457,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013552865235806446,
        "hf_subset": "kqf_Latn-eng_Latn",
        "languages": [
          "kqf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013552865235806446,
        "precision": 0.011992335885565052,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.08571428571428572,
        "f1": 0.0550937950937951,
        "hf_subset": "eng_Latn-kql_Latn",
        "languages": [
          "eng-Latn",
          "kql-Latn"
        ],
        "main_score": 0.0550937950937951,
        "precision": 0.04706632653061224,
        "recall": 0.08571428571428572
      },
      {
        "accuracy": 0.07857142857142857,
        "f1": 0.0446969696969697,
        "hf_subset": "kql_Latn-eng_Latn",
        "languages": [
          "kql-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0446969696969697,
        "precision": 0.037142857142857144,
        "recall": 0.07857142857142857
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01305755876068376,
        "hf_subset": "eng_Latn-kqw_Latn",
        "languages": [
          "eng-Latn",
          "kqw-Latn"
        ],
        "main_score": 0.01305755876068376,
        "precision": 0.011263020833333333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010596055856553146,
        "hf_subset": "kqw_Latn-eng_Latn",
        "languages": [
          "kqw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010596055856553146,
        "precision": 0.00985638407590759,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023737745905714654,
        "hf_subset": "eng_Latn-ksd_Latn",
        "languages": [
          "eng-Latn",
          "ksd-Latn"
        ],
        "main_score": 0.023737745905714654,
        "precision": 0.021921073717948717,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.031190103882462072,
        "hf_subset": "ksd_Latn-eng_Latn",
        "languages": [
          "ksd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031190103882462072,
        "precision": 0.028951901189002826,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021884672226133897,
        "hf_subset": "eng_Latn-ksj_Latn",
        "languages": [
          "eng-Latn",
          "ksj-Latn"
        ],
        "main_score": 0.021884672226133897,
        "precision": 0.018614267676767677,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006111391129032258,
        "hf_subset": "ksj_Latn-eng_Latn",
        "languages": [
          "ksj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006111391129032258,
        "precision": 0.005338541666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.010717474026141434,
        "hf_subset": "eng_Latn-ksr_Latn",
        "languages": [
          "eng-Latn",
          "ksr-Latn"
        ],
        "main_score": 0.010717474026141434,
        "precision": 0.008374886831918081,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006618923611111111,
        "hf_subset": "ksr_Latn-eng_Latn",
        "languages": [
          "ksr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006618923611111111,
        "precision": 0.005914392605633803,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.05596161018755328,
        "hf_subset": "eng_Latn-ktm_Latn",
        "languages": [
          "eng-Latn",
          "ktm-Latn"
        ],
        "main_score": 0.05596161018755328,
        "precision": 0.04850872001262626,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.046705985336907715,
        "hf_subset": "ktm_Latn-eng_Latn",
        "languages": [
          "ktm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.046705985336907715,
        "precision": 0.042763898427960925,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01119171626984127,
        "hf_subset": "eng_Latn-kto_Latn",
        "languages": [
          "eng-Latn",
          "kto-Latn"
        ],
        "main_score": 0.01119171626984127,
        "precision": 0.007950220352564102,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01065142077267637,
        "hf_subset": "kto_Latn-eng_Latn",
        "languages": [
          "kto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01065142077267637,
        "precision": 0.008583028728998332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0026452850877192982,
        "hf_subset": "eng_Latn-kud_Latn",
        "languages": [
          "eng-Latn",
          "kud-Latn"
        ],
        "main_score": 0.0026452850877192982,
        "precision": 0.0015831679894179895,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kud_Latn-eng_Latn",
        "languages": [
          "kud-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007421808243612748,
        "hf_subset": "eng_Latn-kue_Latn",
        "languages": [
          "eng-Latn",
          "kue-Latn"
        ],
        "main_score": 0.007421808243612748,
        "precision": 0.006122139006716154,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014490609217171716,
        "hf_subset": "kue_Latn-eng_Latn",
        "languages": [
          "kue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014490609217171716,
        "precision": 0.013466475938967137,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003942928403755868,
        "hf_subset": "eng_Latn-kup_Latn",
        "languages": [
          "eng-Latn",
          "kup-Latn"
        ],
        "main_score": 0.003942928403755868,
        "precision": 0.00392467570754717,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0027588244097338233,
        "hf_subset": "kup_Latn-eng_Latn",
        "languages": [
          "kup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027588244097338233,
        "precision": 0.0020313431961486023,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0087109375,
        "hf_subset": "eng_Latn-kvg_Latn",
        "languages": [
          "eng-Latn",
          "kvg-Latn"
        ],
        "main_score": 0.0087109375,
        "precision": 0.006905691964285714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004529698377354627,
        "hf_subset": "kvg_Latn-eng_Latn",
        "languages": [
          "kvg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004529698377354627,
        "precision": 0.004228883880862167,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-kvn_Latn",
        "languages": [
          "eng-Latn",
          "kvn-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015371839525283799,
        "hf_subset": "kvn_Latn-eng_Latn",
        "languages": [
          "kvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015371839525283799,
        "precision": 0.012648500875737463,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010745614035087719,
        "hf_subset": "eng_Latn-kwd_Latn",
        "languages": [
          "eng-Latn",
          "kwd-Latn"
        ],
        "main_score": 0.0010745614035087719,
        "precision": 0.000583501629818594,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004557291666666666,
        "hf_subset": "kwd_Latn-eng_Latn",
        "languages": [
          "kwd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004557291666666666,
        "precision": 0.003255208333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021777398459383753,
        "hf_subset": "eng_Latn-kwf_Latn",
        "languages": [
          "eng-Latn",
          "kwf-Latn"
        ],
        "main_score": 0.021777398459383753,
        "precision": 0.02002982136910708,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015877278645833333,
        "hf_subset": "kwf_Latn-eng_Latn",
        "languages": [
          "kwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015877278645833333,
        "precision": 0.014523020382395382,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007893880208333332,
        "hf_subset": "eng_Latn-kwi_Latn",
        "languages": [
          "eng-Latn",
          "kwi-Latn"
        ],
        "main_score": 0.007893880208333332,
        "precision": 0.007853618421052632,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016368890646976088,
        "hf_subset": "kwi_Latn-eng_Latn",
        "languages": [
          "kwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016368890646976088,
        "precision": 0.01360101415167978,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005300715321729958,
        "hf_subset": "eng_Latn-kwj_Latn",
        "languages": [
          "eng-Latn",
          "kwj-Latn"
        ],
        "main_score": 0.005300715321729958,
        "precision": 0.00364542451596023,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013405444570526092,
        "hf_subset": "kwj_Latn-eng_Latn",
        "languages": [
          "kwj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013405444570526092,
        "precision": 0.01266650319383652,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016017587939698493,
        "hf_subset": "eng_Latn-kyc_Latn",
        "languages": [
          "eng-Latn",
          "kyc-Latn"
        ],
        "main_score": 0.0016017587939698493,
        "precision": 0.0009962910353535353,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005656514190821256,
        "hf_subset": "kyc_Latn-eng_Latn",
        "languages": [
          "kyc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005656514190821256,
        "precision": 0.004138824423815621,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.003369016325950488,
        "hf_subset": "eng_Latn-kyf_Latn",
        "languages": [
          "eng-Latn",
          "kyf-Latn"
        ],
        "main_score": 0.003369016325950488,
        "precision": 0.0019441891339869281,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005079339063714064,
        "hf_subset": "kyf_Latn-eng_Latn",
        "languages": [
          "kyf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005079339063714064,
        "precision": 0.0045293898809523805,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007862261146496815,
        "hf_subset": "eng_Latn-kyg_Latn",
        "languages": [
          "eng-Latn",
          "kyg-Latn"
        ],
        "main_score": 0.007862261146496815,
        "precision": 0.007837540064102564,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0001311174140708915,
        "hf_subset": "kyg_Latn-eng_Latn",
        "languages": [
          "kyg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001311174140708915,
        "precision": 6.613982385471428e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011923363095238095,
        "hf_subset": "eng_Latn-kyq_Latn",
        "languages": [
          "eng-Latn",
          "kyq-Latn"
        ],
        "main_score": 0.011923363095238095,
        "precision": 0.010287561793785312,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01276865118577075,
        "hf_subset": "kyq_Latn-eng_Latn",
        "languages": [
          "kyq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01276865118577075,
        "precision": 0.012286931818181818,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004129464285714286,
        "hf_subset": "eng_Latn-kyz_Latn",
        "languages": [
          "eng-Latn",
          "kyz-Latn"
        ],
        "main_score": 0.004129464285714286,
        "precision": 0.0040211397058823525,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007493179563492064,
        "hf_subset": "kyz_Latn-eng_Latn",
        "languages": [
          "kyz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007493179563492064,
        "precision": 0.004579241071428571,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00427827380952381,
        "hf_subset": "eng_Latn-kze_Latn",
        "languages": [
          "eng-Latn",
          "kze-Latn"
        ],
        "main_score": 0.00427827380952381,
        "precision": 0.0041015625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.763719512195122e-05,
        "hf_subset": "kze_Latn-eng_Latn",
        "languages": [
          "kze-Latn",
          "eng-Latn"
        ],
        "main_score": 4.763719512195122e-05,
        "precision": 2.396472392638037e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020015859962406013,
        "hf_subset": "eng_Latn-lac_Latn",
        "languages": [
          "eng-Latn",
          "lac-Latn"
        ],
        "main_score": 0.020015859962406013,
        "precision": 0.01978150025025025,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011858819205392999,
        "hf_subset": "lac_Latn-eng_Latn",
        "languages": [
          "lac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011858819205392999,
        "precision": 0.0092829335016835,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.3046875,
        "f1": 0.21796283143939393,
        "hf_subset": "eng_Latn-lat_Latn",
        "languages": [
          "eng-Latn",
          "lat-Latn"
        ],
        "main_score": 0.21796283143939393,
        "precision": 0.19384105702128332,
        "recall": 0.3046875
      },
      {
        "accuracy": 0.328125,
        "f1": 0.2843180135579494,
        "hf_subset": "lat_Latn-eng_Latn",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2843180135579494,
        "precision": 0.27291511656746037,
        "recall": 0.328125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021783825983044732,
        "hf_subset": "eng_Latn-lbb_Latn",
        "languages": [
          "eng-Latn",
          "lbb-Latn"
        ],
        "main_score": 0.021783825983044732,
        "precision": 0.018391927083333336,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011278018945930399,
        "hf_subset": "lbb_Latn-eng_Latn",
        "languages": [
          "lbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011278018945930399,
        "precision": 0.009101314622993654,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010736177689142597,
        "hf_subset": "eng_Latn-lbk_Latn",
        "languages": [
          "eng-Latn",
          "lbk-Latn"
        ],
        "main_score": 0.010736177689142597,
        "precision": 0.00942422144285527,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03147728982744783,
        "hf_subset": "lbk_Latn-eng_Latn",
        "languages": [
          "lbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03147728982744783,
        "precision": 0.027946174918831168,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007300967261904762,
        "hf_subset": "eng_Latn-lcm_Latn",
        "languages": [
          "eng-Latn",
          "lcm-Latn"
        ],
        "main_score": 0.007300967261904762,
        "precision": 0.004526289682539682,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018354301948051946,
        "hf_subset": "lcm_Latn-eng_Latn",
        "languages": [
          "lcm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018354301948051946,
        "precision": 0.0153250102124183,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006306825614861329,
        "hf_subset": "eng_Latn-leu_Latn",
        "languages": [
          "eng-Latn",
          "leu-Latn"
        ],
        "main_score": 0.006306825614861329,
        "precision": 0.005326359940419049,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00719551282051282,
        "hf_subset": "leu_Latn-eng_Latn",
        "languages": [
          "leu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00719551282051282,
        "precision": 0.006215176841085272,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014836453843390805,
        "hf_subset": "eng_Latn-lex_Latn",
        "languages": [
          "eng-Latn",
          "lex-Latn"
        ],
        "main_score": 0.014836453843390805,
        "precision": 0.012515379931684048,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03323447145061728,
        "hf_subset": "lex_Latn-eng_Latn",
        "languages": [
          "lex-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03323447145061728,
        "precision": 0.031210163243286446,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019269245426829267,
        "hf_subset": "eng_Latn-lgl_Latn",
        "languages": [
          "eng-Latn",
          "lgl-Latn"
        ],
        "main_score": 0.019269245426829267,
        "precision": 0.018168179156908666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02337622549019608,
        "hf_subset": "lgl_Latn-eng_Latn",
        "languages": [
          "lgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02337622549019608,
        "precision": 0.020735042951839824,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008132102272727272,
        "hf_subset": "eng_Latn-lid_Latn",
        "languages": [
          "eng-Latn",
          "lid-Latn"
        ],
        "main_score": 0.008132102272727272,
        "precision": 0.006402231522242816,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006004050925925926,
        "hf_subset": "lid_Latn-eng_Latn",
        "languages": [
          "lid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006004050925925926,
        "precision": 0.005282036163522012,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005168876262626262,
        "hf_subset": "eng_Latn-lif_Deva",
        "languages": [
          "eng-Latn",
          "lif-Deva"
        ],
        "main_score": 0.005168876262626262,
        "precision": 0.003575830768353853,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00023623591499072886,
        "hf_subset": "lif_Deva-eng_Latn",
        "languages": [
          "lif-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00023623591499072886,
        "precision": 0.0001206341911764706,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007895611702127658,
        "hf_subset": "eng_Latn-lin_Latn",
        "languages": [
          "eng-Latn",
          "lin-Latn"
        ],
        "main_score": 0.007895611702127658,
        "precision": 0.007854502688172043,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003947153141361256,
        "hf_subset": "lin_Latn-eng_Latn",
        "languages": [
          "lin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003947153141361256,
        "precision": 0.003926809210526316,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96875,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ],
        "main_score": 0.96875,
        "precision": 0.96484375,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9739583333333334,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9739583333333334,
        "precision": 0.970703125,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020629783661355827,
        "hf_subset": "eng_Latn-llg_Latn",
        "languages": [
          "eng-Latn",
          "llg-Latn"
        ],
        "main_score": 0.020629783661355827,
        "precision": 0.017043340773809524,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015079532657657657,
        "hf_subset": "llg_Latn-eng_Latn",
        "languages": [
          "llg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015079532657657657,
        "precision": 0.014080498910336239,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00415146993810787,
        "hf_subset": "eng_Latn-lug_Latn",
        "languages": [
          "eng-Latn",
          "lug-Latn"
        ],
        "main_score": 0.00415146993810787,
        "precision": 0.004031625532400366,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "lug_Latn-eng_Latn",
        "languages": [
          "lug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01607736592111592,
        "hf_subset": "eng_Latn-luo_Latn",
        "languages": [
          "eng-Latn",
          "luo-Latn"
        ],
        "main_score": 0.01607736592111592,
        "precision": 0.014625815097259062,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019975142045454544,
        "hf_subset": "luo_Latn-eng_Latn",
        "languages": [
          "luo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019975142045454544,
        "precision": 0.018551370504495505,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003332559818481848,
        "hf_subset": "eng_Latn-lww_Latn",
        "languages": [
          "eng-Latn",
          "lww-Latn"
        ],
        "main_score": 0.003332559818481848,
        "precision": 0.0021223958333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0065163238940442875,
        "hf_subset": "lww_Latn-eng_Latn",
        "languages": [
          "lww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0065163238940442875,
        "precision": 0.0054620702904183156,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021544355528730526,
        "hf_subset": "eng_Latn-maa_Latn",
        "languages": [
          "eng-Latn",
          "maa-Latn"
        ],
        "main_score": 0.021544355528730526,
        "precision": 0.01960857371794872,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028193204365079362,
        "hf_subset": "maa_Latn-eng_Latn",
        "languages": [
          "maa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028193204365079362,
        "precision": 0.02518084129412254,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007886904761904762,
        "hf_subset": "eng_Latn-maj_Latn",
        "languages": [
          "eng-Latn",
          "maj-Latn"
        ],
        "main_score": 0.007886904761904762,
        "precision": 0.006315104166666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016611842105263154,
        "hf_subset": "maj_Latn-eng_Latn",
        "languages": [
          "maj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016611842105263154,
        "precision": 0.012518768768768767,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.72265625,
        "f1": 0.6584635416666667,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.6584635416666667,
        "precision": 0.6330729166666667,
        "recall": 0.72265625
      },
      {
        "accuracy": 0.734375,
        "f1": 0.6857014079670329,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.6857014079670329,
        "precision": 0.667751736111111,
        "recall": 0.734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017029303497714875,
        "hf_subset": "eng_Latn-mam_Latn",
        "languages": [
          "eng-Latn",
          "mam-Latn"
        ],
        "main_score": 0.017029303497714875,
        "precision": 0.013871670067656654,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016536458333333334,
        "hf_subset": "mam_Latn-eng_Latn",
        "languages": [
          "mam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016536458333333334,
        "precision": 0.013831676136363637,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02160218253968254,
        "hf_subset": "eng_Latn-maq_Latn",
        "languages": [
          "eng-Latn",
          "maq-Latn"
        ],
        "main_score": 0.02160218253968254,
        "precision": 0.018361600783475783,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018988715277777776,
        "hf_subset": "maq_Latn-eng_Latn",
        "languages": [
          "maq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018988715277777776,
        "precision": 0.016982100938967137,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.46875,
        "f1": 0.36881725045787545,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.36881725045787545,
        "precision": 0.3361328125,
        "recall": 0.46875
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.5243248350075795,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5243248350075795,
        "precision": 0.518155368936619,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020584921690307328,
        "hf_subset": "eng_Latn-mau_Latn",
        "languages": [
          "eng-Latn",
          "mau-Latn"
        ],
        "main_score": 0.020584921690307328,
        "precision": 0.017877294146825394,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020537405303030304,
        "hf_subset": "mau_Latn-eng_Latn",
        "languages": [
          "mau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020537405303030304,
        "precision": 0.019066220238095236,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-mav_Latn",
        "languages": [
          "eng-Latn",
          "mav-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "mav_Latn-eng_Latn",
        "languages": [
          "mav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027396149857087358,
        "hf_subset": "eng_Latn-maz_Latn",
        "languages": [
          "eng-Latn",
          "maz-Latn"
        ],
        "main_score": 0.027396149857087358,
        "precision": 0.024739644337987258,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.036319742022017834,
        "hf_subset": "maz_Latn-eng_Latn",
        "languages": [
          "maz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.036319742022017834,
        "precision": 0.03240653271182701,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.056863839285714285,
        "hf_subset": "eng_Latn-mbb_Latn",
        "languages": [
          "eng-Latn",
          "mbb-Latn"
        ],
        "main_score": 0.056863839285714285,
        "precision": 0.048569623161764705,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03411965638528139,
        "hf_subset": "mbb_Latn-eng_Latn",
        "languages": [
          "mbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03411965638528139,
        "precision": 0.030502852182539685,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011368189102564102,
        "hf_subset": "eng_Latn-mbc_Latn",
        "languages": [
          "eng-Latn",
          "mbc-Latn"
        ],
        "main_score": 0.011368189102564102,
        "precision": 0.010052083333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005480755023640663,
        "hf_subset": "mbc_Latn-eng_Latn",
        "languages": [
          "mbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005480755023640663,
        "precision": 0.0037713913690476187,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01774175579322638,
        "hf_subset": "eng_Latn-mbh_Latn",
        "languages": [
          "eng-Latn",
          "mbh-Latn"
        ],
        "main_score": 0.01774175579322638,
        "precision": 0.016051307091346154,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02709517045454545,
        "hf_subset": "mbh_Latn-eng_Latn",
        "languages": [
          "mbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02709517045454545,
        "precision": 0.025788483796296297,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008277529761904762,
        "hf_subset": "eng_Latn-mbj_Latn",
        "languages": [
          "eng-Latn",
          "mbj-Latn"
        ],
        "main_score": 0.008277529761904762,
        "precision": 0.008055652201417003,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008953373015873015,
        "hf_subset": "mbj_Latn-eng_Latn",
        "languages": [
          "mbj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008953373015873015,
        "precision": 0.00741934026308365,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005543154761904761,
        "hf_subset": "eng_Latn-mbl_Latn",
        "languages": [
          "eng-Latn",
          "mbl-Latn"
        ],
        "main_score": 0.005543154761904761,
        "precision": 0.004920372596153846,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004940941220238095,
        "hf_subset": "mbl_Latn-eng_Latn",
        "languages": [
          "mbl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004940941220238095,
        "precision": 0.00025731646825396826,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016102430555555554,
        "hf_subset": "eng_Latn-mbs_Latn",
        "languages": [
          "eng-Latn",
          "mbs-Latn"
        ],
        "main_score": 0.016102430555555554,
        "precision": 0.012532552083333332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.025780968163780664,
        "hf_subset": "mbs_Latn-eng_Latn",
        "languages": [
          "mbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025780968163780664,
        "precision": 0.02231999077494503,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022387432795698926,
        "hf_subset": "eng_Latn-mbt_Latn",
        "languages": [
          "eng-Latn",
          "mbt-Latn"
        ],
        "main_score": 0.022387432795698926,
        "precision": 0.020126488095238093,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021667286706349206,
        "hf_subset": "mbt_Latn-eng_Latn",
        "languages": [
          "mbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021667286706349206,
        "precision": 0.01961586040866411,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02758471665181224,
        "hf_subset": "eng_Latn-mca_Latn",
        "languages": [
          "eng-Latn",
          "mca-Latn"
        ],
        "main_score": 0.02758471665181224,
        "precision": 0.02623258496504518,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02192221317874976,
        "hf_subset": "mca_Latn-eng_Latn",
        "languages": [
          "mca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02192221317874976,
        "precision": 0.01868574134199134,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.1629554655870446e-05,
        "hf_subset": "eng_Latn-mcb_Latn",
        "languages": [
          "eng-Latn",
          "mcb-Latn"
        ],
        "main_score": 3.1629554655870446e-05,
        "precision": 1.5879065040650408e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003947153141361256,
        "hf_subset": "mcb_Latn-eng_Latn",
        "languages": [
          "mcb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003947153141361256,
        "precision": 0.003926809210526316,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004792476574960128,
        "hf_subset": "eng_Latn-mcd_Latn",
        "languages": [
          "eng-Latn",
          "mcd-Latn"
        ],
        "main_score": 0.004792476574960128,
        "precision": 0.004367673185607968,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333332,
        "hf_subset": "mcd_Latn-eng_Latn",
        "languages": [
          "mcd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.0078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003055756262042389,
        "hf_subset": "eng_Latn-mcf_Latn",
        "languages": [
          "eng-Latn",
          "mcf-Latn"
        ],
        "main_score": 0.0003055756262042389,
        "precision": 0.00015740903167602244,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006758410300095647,
        "hf_subset": "mcf_Latn-eng_Latn",
        "languages": [
          "mcf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006758410300095647,
        "precision": 0.0059859664351851844,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015236849087350159,
        "hf_subset": "eng_Latn-mco_Latn",
        "languages": [
          "eng-Latn",
          "mco-Latn"
        ],
        "main_score": 0.015236849087350159,
        "precision": 0.012945944165426588,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02448846726190476,
        "hf_subset": "mco_Latn-eng_Latn",
        "languages": [
          "mco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02448846726190476,
        "precision": 0.02171688988095238,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013112745098039214,
        "hf_subset": "eng_Latn-mcp_Latn",
        "languages": [
          "eng-Latn",
          "mcp-Latn"
        ],
        "main_score": 0.013112745098039214,
        "precision": 0.011765252976190476,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "mcp_Latn-eng_Latn",
        "languages": [
          "mcp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009672619047619048,
        "hf_subset": "eng_Latn-mcq_Latn",
        "languages": [
          "eng-Latn",
          "mcq-Latn"
        ],
        "main_score": 0.009672619047619048,
        "precision": 0.00747221870782726,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004203250297000296,
        "hf_subset": "mcq_Latn-eng_Latn",
        "languages": [
          "mcq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004203250297000296,
        "precision": 0.004058159722222222,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008504444808027922,
        "hf_subset": "eng_Latn-mcr_Latn",
        "languages": [
          "eng-Latn",
          "mcr-Latn"
        ],
        "main_score": 0.008504444808027922,
        "precision": 0.007182017543859649,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0008399803321678321,
        "hf_subset": "mcr_Latn-eng_Latn",
        "languages": [
          "mcr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008399803321678321,
        "precision": 0.0004507435811315122,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-mdy_Latn",
        "languages": [
          "eng-Latn",
          "mdy-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010416666666666667,
        "hf_subset": "mdy_Latn-eng_Latn",
        "languages": [
          "mdy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010416666666666667,
        "precision": 0.0005687260536398468,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-med_Latn",
        "languages": [
          "eng-Latn",
          "med-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "med_Latn-eng_Latn",
        "languages": [
          "med-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00239704880874939,
        "hf_subset": "eng_Latn-mee_Latn",
        "languages": [
          "eng-Latn",
          "mee-Latn"
        ],
        "main_score": 0.00239704880874939,
        "precision": 0.0015284624049272486,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0042216050664451825,
        "hf_subset": "mee_Latn-eng_Latn",
        "languages": [
          "mee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0042216050664451825,
        "precision": 0.004069179430598823,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013924064217032966,
        "hf_subset": "eng_Latn-mek_Latn",
        "languages": [
          "eng-Latn",
          "mek-Latn"
        ],
        "main_score": 0.013924064217032966,
        "precision": 0.012955729166666667,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01997767857142857,
        "hf_subset": "mek_Latn-eng_Latn",
        "languages": [
          "mek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01997767857142857,
        "precision": 0.01856720753205128,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.003925751248079877,
        "hf_subset": "eng_Latn-meq_Latn",
        "languages": [
          "eng-Latn",
          "meq-Latn"
        ],
        "main_score": 0.003925751248079877,
        "precision": 0.002430441876200454,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013151041666666665,
        "hf_subset": "meq_Latn-eng_Latn",
        "languages": [
          "meq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013151041666666665,
        "precision": 0.011381807383040937,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01036850136689291,
        "hf_subset": "eng_Latn-met_Latn",
        "languages": [
          "eng-Latn",
          "met-Latn"
        ],
        "main_score": 0.01036850136689291,
        "precision": 0.008144191247582205,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01709571602363573,
        "hf_subset": "met_Latn-eng_Latn",
        "languages": [
          "met-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01709571602363573,
        "precision": 0.01571033474531117,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027487909226190474,
        "hf_subset": "eng_Latn-meu_Latn",
        "languages": [
          "eng-Latn",
          "meu-Latn"
        ],
        "main_score": 0.027487909226190474,
        "precision": 0.023798212274774775,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010295007365319865,
        "hf_subset": "meu_Latn-eng_Latn",
        "languages": [
          "meu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010295007365319865,
        "precision": 0.00847405724676447,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.025747906607281608,
        "hf_subset": "eng_Latn-mgc_Latn",
        "languages": [
          "eng-Latn",
          "mgc-Latn"
        ],
        "main_score": 0.025747906607281608,
        "precision": 0.022055938852813855,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018044151572112095,
        "hf_subset": "mgc_Latn-eng_Latn",
        "languages": [
          "mgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018044151572112095,
        "precision": 0.0159619140625,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004231770833333333,
        "hf_subset": "eng_Latn-mgh_Latn",
        "languages": [
          "eng-Latn",
          "mgh-Latn"
        ],
        "main_score": 0.004231770833333333,
        "precision": 0.004076086956521739,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0025564202953908834,
        "hf_subset": "mgh_Latn-eng_Latn",
        "languages": [
          "mgh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0025564202953908834,
        "precision": 0.0014368127893518519,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03349282296650718,
        "f1": 0.016719600573894572,
        "hf_subset": "eng_Latn-mgw_Latn",
        "languages": [
          "eng-Latn",
          "mgw-Latn"
        ],
        "main_score": 0.016719600573894572,
        "precision": 0.014417728814013644,
        "recall": 0.03349282296650718
      },
      {
        "accuracy": 0.019138755980861243,
        "f1": 0.012546517809675705,
        "hf_subset": "mgw_Latn-eng_Latn",
        "languages": [
          "mgw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012546517809675705,
        "precision": 0.011363636363636364,
        "recall": 0.019138755980861243
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001337534406029737,
        "hf_subset": "eng_Latn-mhl_Latn",
        "languages": [
          "eng-Latn",
          "mhl-Latn"
        ],
        "main_score": 0.001337534406029737,
        "precision": 0.0007074089105339105,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004533422882427307,
        "hf_subset": "mhl_Latn-eng_Latn",
        "languages": [
          "mhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004533422882427307,
        "precision": 0.004241608001373626,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020984914932365886,
        "hf_subset": "eng_Latn-mib_Latn",
        "languages": [
          "eng-Latn",
          "mib-Latn"
        ],
        "main_score": 0.020984914932365886,
        "precision": 0.017632013742997197,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03018663194444444,
        "hf_subset": "mib_Latn-eng_Latn",
        "languages": [
          "mib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03018663194444444,
        "precision": 0.02653140747120527,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "eng_Latn-mic_Latn",
        "languages": [
          "eng-Latn",
          "mic-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mic_Latn-eng_Latn",
        "languages": [
          "mic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.010422324678852212,
        "hf_subset": "eng_Latn-mie_Latn",
        "languages": [
          "eng-Latn",
          "mie-Latn"
        ],
        "main_score": 0.010422324678852212,
        "precision": 0.009237737592017483,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.026314748415646308,
        "hf_subset": "mie_Latn-eng_Latn",
        "languages": [
          "mie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026314748415646308,
        "precision": 0.022862033799533797,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.029207857445781724,
        "hf_subset": "eng_Latn-mig_Latn",
        "languages": [
          "eng-Latn",
          "mig-Latn"
        ],
        "main_score": 0.029207857445781724,
        "precision": 0.025704580829850224,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017357847744360902,
        "hf_subset": "mig_Latn-eng_Latn",
        "languages": [
          "mig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017357847744360902,
        "precision": 0.016631155303030304,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03025018601190476,
        "hf_subset": "eng_Latn-mih_Latn",
        "languages": [
          "eng-Latn",
          "mih-Latn"
        ],
        "main_score": 0.03025018601190476,
        "precision": 0.029036458333333334,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022782762580556698,
        "hf_subset": "mih_Latn-eng_Latn",
        "languages": [
          "mih-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022782762580556698,
        "precision": 0.020517602600250626,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007855902777777778,
        "hf_subset": "eng_Latn-mil_Latn",
        "languages": [
          "eng-Latn",
          "mil-Latn"
        ],
        "main_score": 0.007855902777777778,
        "precision": 0.007834322625698324,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00585063085063085,
        "hf_subset": "mil_Latn-eng_Latn",
        "languages": [
          "mil-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00585063085063085,
        "precision": 0.0042525487588652485,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013386081990146246,
        "hf_subset": "eng_Latn-mio_Latn",
        "languages": [
          "eng-Latn",
          "mio-Latn"
        ],
        "main_score": 0.013386081990146246,
        "precision": 0.012626726827094474,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014009292497408694,
        "hf_subset": "mio_Latn-eng_Latn",
        "languages": [
          "mio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014009292497408694,
        "precision": 0.012251968606591572,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01762121383363472,
        "hf_subset": "eng_Latn-mir_Latn",
        "languages": [
          "eng-Latn",
          "mir-Latn"
        ],
        "main_score": 0.01762121383363472,
        "precision": 0.016760149572649572,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016481775315547904,
        "hf_subset": "mir_Latn-eng_Latn",
        "languages": [
          "mir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016481775315547904,
        "precision": 0.01490166680038511,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01638902094440359,
        "hf_subset": "eng_Latn-mit_Latn",
        "languages": [
          "eng-Latn",
          "mit-Latn"
        ],
        "main_score": 0.01638902094440359,
        "precision": 0.014463068453311788,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01446933033052219,
        "hf_subset": "mit_Latn-eng_Latn",
        "languages": [
          "mit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01446933033052219,
        "precision": 0.013745795355902778,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00754318420263789,
        "hf_subset": "eng_Latn-miz_Latn",
        "languages": [
          "eng-Latn",
          "miz-Latn"
        ],
        "main_score": 0.00754318420263789,
        "precision": 0.006149788843402974,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023859471450617283,
        "hf_subset": "miz_Latn-eng_Latn",
        "languages": [
          "miz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023859471450617283,
        "precision": 0.02222144717261905,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01435875382262997,
        "hf_subset": "eng_Latn-mjc_Latn",
        "languages": [
          "eng-Latn",
          "mjc-Latn"
        ],
        "main_score": 0.01435875382262997,
        "precision": 0.013689876152073732,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013368055555555555,
        "hf_subset": "mjc_Latn-eng_Latn",
        "languages": [
          "mjc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013368055555555555,
        "precision": 0.011622197210451978,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.057418156347684,
        "hf_subset": "eng_Latn-mkj_Latn",
        "languages": [
          "eng-Latn",
          "mkj-Latn"
        ],
        "main_score": 0.057418156347684,
        "precision": 0.0495119301271645,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.125,
        "f1": 0.08143139374636084,
        "hf_subset": "mkj_Latn-eng_Latn",
        "languages": [
          "mkj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08143139374636084,
        "precision": 0.07221749416042894,
        "recall": 0.125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333334,
        "hf_subset": "eng_Latn-mkl_Latn",
        "languages": [
          "eng-Latn",
          "mkl-Latn"
        ],
        "main_score": 0.009114583333333334,
        "precision": 0.00859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012775031887755101,
        "hf_subset": "mkl_Latn-eng_Latn",
        "languages": [
          "mkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012775031887755101,
        "precision": 0.012317056332842415,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.26953125,
        "f1": 0.20932802007020757,
        "hf_subset": "eng_Latn-mkn_Latn",
        "languages": [
          "eng-Latn",
          "mkn-Latn"
        ],
        "main_score": 0.20932802007020757,
        "precision": 0.19232691136988012,
        "recall": 0.26953125
      },
      {
        "accuracy": 0.203125,
        "f1": 0.14495866706057423,
        "hf_subset": "mkn_Latn-eng_Latn",
        "languages": [
          "mkn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.14495866706057423,
        "precision": 0.1292715370147326,
        "recall": 0.203125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03999207130358705,
        "hf_subset": "eng_Latn-mks_Latn",
        "languages": [
          "eng-Latn",
          "mks-Latn"
        ],
        "main_score": 0.03999207130358705,
        "precision": 0.037238033234126985,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02495659722222222,
        "hf_subset": "mks_Latn-eng_Latn",
        "languages": [
          "mks-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02495659722222222,
        "precision": 0.023274739583333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.8675742574257426e-05,
        "hf_subset": "eng_Latn-mle_Latn",
        "languages": [
          "eng-Latn",
          "mle-Latn"
        ],
        "main_score": 3.8675742574257426e-05,
        "precision": 1.943407960199005e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015625,
        "hf_subset": "mle_Latn-eng_Latn",
        "languages": [
          "mle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015625,
        "precision": 7.971938775510203e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001337534406029737,
        "hf_subset": "eng_Latn-mlh_Latn",
        "languages": [
          "eng-Latn",
          "mlh-Latn"
        ],
        "main_score": 0.001337534406029737,
        "precision": 0.0007074089105339105,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004533422882427307,
        "hf_subset": "mlh_Latn-eng_Latn",
        "languages": [
          "mlh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004533422882427307,
        "precision": 0.004241608001373626,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005050505050505051,
        "hf_subset": "eng_Latn-mlp_Latn",
        "languages": [
          "eng-Latn",
          "mlp-Latn"
        ],
        "main_score": 0.005050505050505051,
        "precision": 0.0033203125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004697248217468805,
        "hf_subset": "mlp_Latn-eng_Latn",
        "languages": [
          "mlp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004697248217468805,
        "precision": 0.0032096652809633025,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010546875,
        "hf_subset": "eng_Latn-mmo_Latn",
        "languages": [
          "eng-Latn",
          "mmo-Latn"
        ],
        "main_score": 0.010546875,
        "precision": 0.009548611111111112,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "mmo_Latn-eng_Latn",
        "languages": [
          "mmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011775238576067158,
        "hf_subset": "eng_Latn-mmx_Latn",
        "languages": [
          "eng-Latn",
          "mmx-Latn"
        ],
        "main_score": 0.011775238576067158,
        "precision": 0.01048426214494062,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008026679164650862,
        "hf_subset": "mmx_Latn-eng_Latn",
        "languages": [
          "mmx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008026679164650862,
        "precision": 0.006749419761273209,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010466427813163481,
        "hf_subset": "eng_Latn-mna_Latn",
        "languages": [
          "eng-Latn",
          "mna-Latn"
        ],
        "main_score": 0.010466427813163481,
        "precision": 0.00848858173076923,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015276075708061002,
        "hf_subset": "mna_Latn-eng_Latn",
        "languages": [
          "mna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015276075708061002,
        "precision": 0.013956961554800338,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013723958333333331,
        "hf_subset": "eng_Latn-mop_Latn",
        "languages": [
          "eng-Latn",
          "mop-Latn"
        ],
        "main_score": 0.013723958333333331,
        "precision": 0.012100080079316657,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015244708994708993,
        "hf_subset": "mop_Latn-eng_Latn",
        "languages": [
          "mop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015244708994708993,
        "precision": 0.012494991987179488,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008413461538461538,
        "hf_subset": "eng_Latn-mox_Latn",
        "languages": [
          "eng-Latn",
          "mox-Latn"
        ],
        "main_score": 0.008413461538461538,
        "precision": 0.008138020833333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010977564102564102,
        "hf_subset": "mox_Latn-eng_Latn",
        "languages": [
          "mox-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010977564102564102,
        "precision": 0.010056573275862069,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.060240963855421686,
        "f1": 0.03231106243154436,
        "hf_subset": "eng_Latn-mph_Latn",
        "languages": [
          "eng-Latn",
          "mph-Latn"
        ],
        "main_score": 0.03231106243154436,
        "precision": 0.02530120481927711,
        "recall": 0.060240963855421686
      },
      {
        "accuracy": 0.04819277108433735,
        "f1": 0.013493711580175082,
        "hf_subset": "mph_Latn-eng_Latn",
        "languages": [
          "mph-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013493711580175082,
        "precision": 0.008985943775100402,
        "recall": 0.04819277108433735
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002232142857142857,
        "hf_subset": "eng_Latn-mpj_Latn",
        "languages": [
          "eng-Latn",
          "mpj-Latn"
        ],
        "main_score": 0.0002232142857142857,
        "precision": 0.00011488970588235294,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.515895953757225e-05,
        "hf_subset": "mpj_Latn-eng_Latn",
        "languages": [
          "mpj-Latn",
          "eng-Latn"
        ],
        "main_score": 4.515895953757225e-05,
        "precision": 2.2710755813953488e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013126969537815125,
        "hf_subset": "eng_Latn-mpm_Latn",
        "languages": [
          "eng-Latn",
          "mpm-Latn"
        ],
        "main_score": 0.013126969537815125,
        "precision": 0.009929201940496098,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021623558732933732,
        "hf_subset": "mpm_Latn-eng_Latn",
        "languages": [
          "mpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021623558732933732,
        "precision": 0.019950082595303485,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007980555704195206,
        "hf_subset": "eng_Latn-mpp_Latn",
        "languages": [
          "eng-Latn",
          "mpp-Latn"
        ],
        "main_score": 0.007980555704195206,
        "precision": 0.00789751134623797,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013028154283801874,
        "hf_subset": "mpp_Latn-eng_Latn",
        "languages": [
          "mpp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013028154283801874,
        "precision": 0.012430194384664434,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009105463882877566,
        "hf_subset": "eng_Latn-mps_Latn",
        "languages": [
          "eng-Latn",
          "mps-Latn"
        ],
        "main_score": 0.009105463882877566,
        "precision": 0.007385518127705627,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "mps_Latn-eng_Latn",
        "languages": [
          "mps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00486200319840604,
        "hf_subset": "eng_Latn-mpt_Latn",
        "languages": [
          "eng-Latn",
          "mpt-Latn"
        ],
        "main_score": 0.00486200319840604,
        "precision": 0.0031265919937794938,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "mpt_Latn-eng_Latn",
        "languages": [
          "mpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011443856388709329,
        "hf_subset": "eng_Latn-mpx_Latn",
        "languages": [
          "eng-Latn",
          "mpx-Latn"
        ],
        "main_score": 0.011443856388709329,
        "precision": 0.009979667666373173,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007904411764705882,
        "hf_subset": "mpx_Latn-eng_Latn",
        "languages": [
          "mpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007904411764705882,
        "precision": 0.007859002976190476,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01922636625299043,
        "hf_subset": "eng_Latn-mqb_Latn",
        "languages": [
          "eng-Latn",
          "mqb-Latn"
        ],
        "main_score": 0.01922636625299043,
        "precision": 0.018115442745376957,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021186179321955184,
        "hf_subset": "mqb_Latn-eng_Latn",
        "languages": [
          "mqb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021186179321955184,
        "precision": 0.020431624341816588,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022963419848025378,
        "hf_subset": "eng_Latn-mqj_Latn",
        "languages": [
          "eng-Latn",
          "mqj-Latn"
        ],
        "main_score": 0.022963419848025378,
        "precision": 0.019471797733516483,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02341373375100509,
        "hf_subset": "mqj_Latn-eng_Latn",
        "languages": [
          "mqj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02341373375100509,
        "precision": 0.020763227592949747,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.016544637261297214,
        "hf_subset": "eng_Latn-msb_Latn",
        "languages": [
          "eng-Latn",
          "msb-Latn"
        ],
        "main_score": 0.016544637261297214,
        "precision": 0.01319543087121212,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06444636793257455,
        "hf_subset": "msb_Latn-eng_Latn",
        "languages": [
          "msb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06444636793257455,
        "precision": 0.06161297084460551,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02093245208479583,
        "hf_subset": "eng_Latn-msc_Latn",
        "languages": [
          "eng-Latn",
          "msc-Latn"
        ],
        "main_score": 0.02093245208479583,
        "precision": 0.015159011624112364,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03343503834991708,
        "hf_subset": "msc_Latn-eng_Latn",
        "languages": [
          "msc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03343503834991708,
        "precision": 0.03267023204317612,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00975378787878788,
        "hf_subset": "eng_Latn-msk_Latn",
        "languages": [
          "eng-Latn",
          "msk-Latn"
        ],
        "main_score": 0.00975378787878788,
        "precision": 0.00893286401098901,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02046475418871252,
        "hf_subset": "msk_Latn-eng_Latn",
        "languages": [
          "msk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02046475418871252,
        "precision": 0.019024310848577235,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01910914606227106,
        "hf_subset": "eng_Latn-msm_Latn",
        "languages": [
          "eng-Latn",
          "msm-Latn"
        ],
        "main_score": 0.01910914606227106,
        "precision": 0.01804832175925926,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0161033980125777,
        "hf_subset": "msm_Latn-eng_Latn",
        "languages": [
          "msm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0161033980125777,
        "precision": 0.01420045882936508,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009481072282865035,
        "hf_subset": "eng_Latn-msy_Latn",
        "languages": [
          "eng-Latn",
          "msy-Latn"
        ],
        "main_score": 0.009481072282865035,
        "precision": 0.007609049479166666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008292712784900284,
        "hf_subset": "msy_Latn-eng_Latn",
        "languages": [
          "msy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008292712784900284,
        "precision": 0.006947565087470233,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0011632489383170946,
        "hf_subset": "eng_Latn-mti_Latn",
        "languages": [
          "eng-Latn",
          "mti-Latn"
        ],
        "main_score": 0.0011632489383170946,
        "precision": 0.0006226673908199644,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013786764705882353,
        "hf_subset": "mti_Latn-eng_Latn",
        "languages": [
          "mti-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013786764705882353,
        "precision": 0.013079135572139303,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014071800595238094,
        "hf_subset": "eng_Latn-mto_Latn",
        "languages": [
          "eng-Latn",
          "mto-Latn"
        ],
        "main_score": 0.014071800595238094,
        "precision": 0.01195126488095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014832845853858783,
        "hf_subset": "mto_Latn-eng_Latn",
        "languages": [
          "mto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014832845853858783,
        "precision": 0.012522579479768786,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0048828125,
        "hf_subset": "eng_Latn-mux_Latn",
        "languages": [
          "eng-Latn",
          "mux-Latn"
        ],
        "main_score": 0.0048828125,
        "precision": 0.004464285714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004258207070707071,
        "hf_subset": "mux_Latn-eng_Latn",
        "languages": [
          "mux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004258207070707071,
        "precision": 0.004088839096869712,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007230002347189847,
        "hf_subset": "eng_Latn-muy_Latn",
        "languages": [
          "eng-Latn",
          "muy-Latn"
        ],
        "main_score": 0.007230002347189847,
        "precision": 0.005061677046658843,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01591445111492281,
        "hf_subset": "muy_Latn-eng_Latn",
        "languages": [
          "muy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01591445111492281,
        "precision": 0.015772458155270654,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008413874570446735,
        "hf_subset": "eng_Latn-mva_Latn",
        "languages": [
          "eng-Latn",
          "mva-Latn"
        ],
        "main_score": 0.008413874570446735,
        "precision": 0.008132207961309524,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021205635603792412,
        "hf_subset": "mva_Latn-eng_Latn",
        "languages": [
          "mva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021205635603792412,
        "precision": 0.019724618583027764,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00859375,
        "hf_subset": "eng_Latn-mvn_Latn",
        "languages": [
          "eng-Latn",
          "mvn-Latn"
        ],
        "main_score": 0.00859375,
        "precision": 0.008246527777777778,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0065312725468975475,
        "hf_subset": "mvn_Latn-eng_Latn",
        "languages": [
          "mvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0065312725468975475,
        "precision": 0.0054530673165666815,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.140625,
        "f1": 0.0904883791510025,
        "hf_subset": "eng_Latn-mwc_Latn",
        "languages": [
          "eng-Latn",
          "mwc-Latn"
        ],
        "main_score": 0.0904883791510025,
        "precision": 0.0821373033114761,
        "recall": 0.140625
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.08460201109183667,
        "hf_subset": "mwc_Latn-eng_Latn",
        "languages": [
          "mwc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08460201109183667,
        "precision": 0.07523922328882357,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004466906062238767,
        "hf_subset": "eng_Latn-mwe_Latn",
        "languages": [
          "eng-Latn",
          "mwe-Latn"
        ],
        "main_score": 0.004466906062238767,
        "precision": 0.0029909164186507934,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009181932471264366,
        "hf_subset": "mwe_Latn-eng_Latn",
        "languages": [
          "mwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009181932471264366,
        "precision": 0.008627717391304348,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03937590187590187,
        "hf_subset": "eng_Latn-mwf_Latn",
        "languages": [
          "eng-Latn",
          "mwf-Latn"
        ],
        "main_score": 0.03937590187590187,
        "precision": 0.0316385248655914,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04623423793859649,
        "hf_subset": "mwf_Latn-eng_Latn",
        "languages": [
          "mwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04623423793859649,
        "precision": 0.044151047080734585,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004739341285756727,
        "hf_subset": "eng_Latn-mwp_Latn",
        "languages": [
          "eng-Latn",
          "mwp-Latn"
        ],
        "main_score": 0.004739341285756727,
        "precision": 0.0028465338730831314,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006903248587570621,
        "hf_subset": "mwp_Latn-eng_Latn",
        "languages": [
          "mwp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006903248587570621,
        "precision": 0.004950161637931034,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027248207521645022,
        "hf_subset": "eng_Latn-mxb_Latn",
        "languages": [
          "eng-Latn",
          "mxb-Latn"
        ],
        "main_score": 0.027248207521645022,
        "precision": 0.02379415760869565,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017021942455375673,
        "hf_subset": "mxb_Latn-eng_Latn",
        "languages": [
          "mxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017021942455375673,
        "precision": 0.015382501911314985,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02386423319327731,
        "hf_subset": "eng_Latn-mxp_Latn",
        "languages": [
          "eng-Latn",
          "mxp-Latn"
        ],
        "main_score": 0.02386423319327731,
        "precision": 0.0224609375,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020964839596624135,
        "hf_subset": "mxp_Latn-eng_Latn",
        "languages": [
          "mxp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020964839596624135,
        "precision": 0.019076797385620913,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029570421918767506,
        "hf_subset": "eng_Latn-mxq_Latn",
        "languages": [
          "eng-Latn",
          "mxq-Latn"
        ],
        "main_score": 0.029570421918767506,
        "precision": 0.025634765625,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01831597222222222,
        "hf_subset": "mxq_Latn-eng_Latn",
        "languages": [
          "mxq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01831597222222222,
        "precision": 0.017622015449438203,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.030859375,
        "hf_subset": "eng_Latn-mxt_Latn",
        "languages": [
          "eng-Latn",
          "mxt-Latn"
        ],
        "main_score": 0.030859375,
        "precision": 0.029622395833333332,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.026947206439393943,
        "hf_subset": "mxt_Latn-eng_Latn",
        "languages": [
          "mxt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026947206439393943,
        "precision": 0.02465555726600985,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.35546875,
        "f1": 0.28880546536796536,
        "hf_subset": "eng_Latn-mya_Latn",
        "languages": [
          "eng-Latn",
          "mya-Latn"
        ],
        "main_score": 0.28880546536796536,
        "precision": 0.2640625,
        "recall": 0.35546875
      },
      {
        "accuracy": 0.3671875,
        "f1": 0.3254202178030303,
        "hf_subset": "mya_Latn-eng_Latn",
        "languages": [
          "mya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3254202178030303,
        "precision": 0.31077008928571426,
        "recall": 0.3671875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008638908959537572,
        "hf_subset": "eng_Latn-myk_Latn",
        "languages": [
          "eng-Latn",
          "myk-Latn"
        ],
        "main_score": 0.008638908959537572,
        "precision": 0.008269238533591731,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0032359052111410602,
        "hf_subset": "myk_Latn-eng_Latn",
        "languages": [
          "myk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0032359052111410602,
        "precision": 0.00229080815018315,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01000384706439394,
        "hf_subset": "eng_Latn-myu_Latn",
        "languages": [
          "eng-Latn",
          "myu-Latn"
        ],
        "main_score": 0.01000384706439394,
        "precision": 0.007885261603569386,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.020182291666666668,
        "hf_subset": "myu_Latn-eng_Latn",
        "languages": [
          "myu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020182291666666668,
        "precision": 0.019886363636363636,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001053155637254902,
        "hf_subset": "eng_Latn-myw_Latn",
        "languages": [
          "eng-Latn",
          "myw-Latn"
        ],
        "main_score": 0.001053155637254902,
        "precision": 0.0005967114568599717,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004244117777383907,
        "hf_subset": "myw_Latn-eng_Latn",
        "languages": [
          "myw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004244117777383907,
        "precision": 0.004079861111111111,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016682650428839454,
        "hf_subset": "eng_Latn-myy_Latn",
        "languages": [
          "eng-Latn",
          "myy-Latn"
        ],
        "main_score": 0.016682650428839454,
        "precision": 0.015028211805555556,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016538646708683474,
        "hf_subset": "myy_Latn-eng_Latn",
        "languages": [
          "myy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016538646708683474,
        "precision": 0.015107908466151492,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.032,
        "f1": 0.02419047619047619,
        "hf_subset": "eng_Latn-mzz_Latn",
        "languages": [
          "eng-Latn",
          "mzz-Latn"
        ],
        "main_score": 0.02419047619047619,
        "precision": 0.024096385542168676,
        "recall": 0.032
      },
      {
        "accuracy": 0.08,
        "f1": 0.03574025974025974,
        "hf_subset": "mzz_Latn-eng_Latn",
        "languages": [
          "mzz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03574025974025974,
        "precision": 0.02664848484848485,
        "recall": 0.08
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010016025641025641,
        "hf_subset": "eng_Latn-nab_Latn",
        "languages": [
          "eng-Latn",
          "nab-Latn"
        ],
        "main_score": 0.00010016025641025641,
        "precision": 5.0730519480519484e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.370283018867924e-05,
        "hf_subset": "nab_Latn-eng_Latn",
        "languages": [
          "nab-Latn",
          "eng-Latn"
        ],
        "main_score": 7.370283018867924e-05,
        "precision": 3.7202380952380956e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00408110960730446,
        "hf_subset": "eng_Latn-naf_Latn",
        "languages": [
          "eng-Latn",
          "naf-Latn"
        ],
        "main_score": 0.00408110960730446,
        "precision": 0.002528916396103896,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004835821303587052,
        "hf_subset": "naf_Latn-eng_Latn",
        "languages": [
          "naf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004835821303587052,
        "precision": 0.004425533234126984,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004615593905472637,
        "hf_subset": "eng_Latn-nak_Latn",
        "languages": [
          "eng-Latn",
          "nak-Latn"
        ],
        "main_score": 0.004615593905472637,
        "precision": 0.003284578634085213,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.852484472049689e-05,
        "hf_subset": "nak_Latn-eng_Latn",
        "languages": [
          "nak-Latn",
          "eng-Latn"
        ],
        "main_score": 4.852484472049689e-05,
        "precision": 2.44140625e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005208333333333333,
        "hf_subset": "eng_Latn-nas_Latn",
        "languages": [
          "eng-Latn",
          "nas-Latn"
        ],
        "main_score": 0.0005208333333333333,
        "precision": 0.00027901785714285713,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002533122016092522,
        "hf_subset": "nas_Latn-eng_Latn",
        "languages": [
          "nas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002533122016092522,
        "precision": 0.0016028201941287877,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017230561232577362,
        "hf_subset": "eng_Latn-nbq_Latn",
        "languages": [
          "eng-Latn",
          "nbq-Latn"
        ],
        "main_score": 0.017230561232577362,
        "precision": 0.01534817878792991,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010469022420180888,
        "hf_subset": "nbq_Latn-eng_Latn",
        "languages": [
          "nbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010469022420180888,
        "precision": 0.008584915806293017,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0126171875,
        "hf_subset": "eng_Latn-nca_Latn",
        "languages": [
          "eng-Latn",
          "nca-Latn"
        ],
        "main_score": 0.0126171875,
        "precision": 0.00875186579360237,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014182500613421665,
        "hf_subset": "nca_Latn-eng_Latn",
        "languages": [
          "nca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014182500613421665,
        "precision": 0.012335857062419561,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015537880500301386,
        "hf_subset": "eng_Latn-nch_Latn",
        "languages": [
          "eng-Latn",
          "nch-Latn"
        ],
        "main_score": 0.015537880500301386,
        "precision": 0.014372996794871794,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01175820707070707,
        "hf_subset": "nch_Latn-eng_Latn",
        "languages": [
          "nch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01175820707070707,
        "precision": 0.010436495346869712,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025432627688172043,
        "hf_subset": "eng_Latn-ncj_Latn",
        "languages": [
          "eng-Latn",
          "ncj-Latn"
        ],
        "main_score": 0.025432627688172043,
        "precision": 0.023588823198198196,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01268408764367816,
        "hf_subset": "ncj_Latn-eng_Latn",
        "languages": [
          "ncj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01268408764367816,
        "precision": 0.010118272569444444,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011466931996855346,
        "hf_subset": "eng_Latn-ncl_Latn",
        "languages": [
          "eng-Latn",
          "ncl-Latn"
        ],
        "main_score": 0.011466931996855346,
        "precision": 0.010161173844537814,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.026075487012987012,
        "hf_subset": "ncl_Latn-eng_Latn",
        "languages": [
          "ncl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026075487012987012,
        "precision": 0.025407608695652173,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001558250777000777,
        "hf_subset": "eng_Latn-ncu_Latn",
        "languages": [
          "eng-Latn",
          "ncu-Latn"
        ],
        "main_score": 0.001558250777000777,
        "precision": 0.000858327346743295,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003655849358974359,
        "hf_subset": "ncu_Latn-eng_Latn",
        "languages": [
          "ncu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003655849358974359,
        "precision": 0.0025490854715672674,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.014830802985069627,
        "hf_subset": "eng_Latn-ndg_Latn",
        "languages": [
          "eng-Latn",
          "ndg-Latn"
        ],
        "main_score": 0.014830802985069627,
        "precision": 0.012059269862824042,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01569801401869159,
        "hf_subset": "ndg_Latn-eng_Latn",
        "languages": [
          "ndg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01569801401869159,
        "precision": 0.013187893081761007,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004190427627927628,
        "hf_subset": "eng_Latn-ndj_Latn",
        "languages": [
          "eng-Latn",
          "ndj-Latn"
        ],
        "main_score": 0.004190427627927628,
        "precision": 0.0028162615740740743,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0050702508764241885,
        "hf_subset": "ndj_Latn-eng_Latn",
        "languages": [
          "ndj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0050702508764241885,
        "precision": 0.004581404320987655,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02666564375340971,
        "hf_subset": "eng_Latn-nfa_Latn",
        "languages": [
          "eng-Latn",
          "nfa-Latn"
        ],
        "main_score": 0.02666564375340971,
        "precision": 0.023184072015903133,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014237008147853737,
        "hf_subset": "nfa_Latn-eng_Latn",
        "languages": [
          "nfa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014237008147853737,
        "precision": 0.012146609232305938,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.269125683060109e-05,
        "hf_subset": "eng_Latn-ngp_Latn",
        "languages": [
          "eng-Latn",
          "ngp-Latn"
        ],
        "main_score": 4.269125683060109e-05,
        "precision": 2.146291208791209e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003720238095238095,
        "hf_subset": "ngp_Latn-eng_Latn",
        "languages": [
          "ngp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003720238095238095,
        "precision": 0.0026041666666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029576109654234652,
        "hf_subset": "eng_Latn-ngu_Latn",
        "languages": [
          "eng-Latn",
          "ngu-Latn"
        ],
        "main_score": 0.029576109654234652,
        "precision": 0.026835364079842463,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022465742500183593,
        "hf_subset": "ngu_Latn-eng_Latn",
        "languages": [
          "ngu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022465742500183593,
        "precision": 0.02004955924131016,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015269886363636364,
        "hf_subset": "eng_Latn-nhe_Latn",
        "languages": [
          "eng-Latn",
          "nhe-Latn"
        ],
        "main_score": 0.015269886363636364,
        "precision": 0.012843357591324201,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012616144018583042,
        "hf_subset": "nhe_Latn-eng_Latn",
        "languages": [
          "nhe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012616144018583042,
        "precision": 0.010021592101318944,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02470407196969697,
        "hf_subset": "eng_Latn-nhg_Latn",
        "languages": [
          "eng-Latn",
          "nhg-Latn"
        ],
        "main_score": 0.02470407196969697,
        "precision": 0.021699979707792205,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029555622329059828,
        "hf_subset": "nhg_Latn-eng_Latn",
        "languages": [
          "nhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029555622329059828,
        "precision": 0.027475360742888706,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021539051226551226,
        "hf_subset": "eng_Latn-nhi_Latn",
        "languages": [
          "eng-Latn",
          "nhi-Latn"
        ],
        "main_score": 0.021539051226551226,
        "precision": 0.01953024964527962,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017624906437125748,
        "hf_subset": "nhi_Latn-eng_Latn",
        "languages": [
          "nhi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017624906437125748,
        "precision": 0.01561302026286966,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.0325107672275641,
        "hf_subset": "eng_Latn-nho_Latn",
        "languages": [
          "eng-Latn",
          "nho-Latn"
        ],
        "main_score": 0.0325107672275641,
        "precision": 0.02933664363214898,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03072360539449614,
        "hf_subset": "nho_Latn-eng_Latn",
        "languages": [
          "nho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03072360539449614,
        "precision": 0.028310624379960316,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009248173701298702,
        "hf_subset": "eng_Latn-nhr_Latn",
        "languages": [
          "eng-Latn",
          "nhr-Latn"
        ],
        "main_score": 0.009248173701298702,
        "precision": 0.0070405505952380945,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003972457627118644,
        "hf_subset": "nhr_Latn-eng_Latn",
        "languages": [
          "nhr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003972457627118644,
        "precision": 0.003939636752136752,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.489942528735632e-05,
        "hf_subset": "eng_Latn-nhu_Latn",
        "languages": [
          "eng-Latn",
          "nhu-Latn"
        ],
        "main_score": 4.489942528735632e-05,
        "precision": 2.2579479768786126e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010639870699554453,
        "hf_subset": "nhu_Latn-eng_Latn",
        "languages": [
          "nhu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010639870699554453,
        "precision": 0.0005876488305539853,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01441375968992248,
        "hf_subset": "eng_Latn-nhw_Latn",
        "languages": [
          "eng-Latn",
          "nhw-Latn"
        ],
        "main_score": 0.01441375968992248,
        "precision": 0.013717830882352941,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014623603951890034,
        "hf_subset": "nhw_Latn-eng_Latn",
        "languages": [
          "nhw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014623603951890034,
        "precision": 0.0127155521373057,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020324586849507734,
        "hf_subset": "eng_Latn-nhy_Latn",
        "languages": [
          "eng-Latn",
          "nhy-Latn"
        ],
        "main_score": 0.020324586849507734,
        "precision": 0.018834547039969833,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012137944472531175,
        "hf_subset": "nhy_Latn-eng_Latn",
        "languages": [
          "nhy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012137944472531175,
        "precision": 0.010822408733230135,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005497030542986425,
        "hf_subset": "eng_Latn-nif_Latn",
        "languages": [
          "eng-Latn",
          "nif-Latn"
        ],
        "main_score": 0.005497030542986425,
        "precision": 0.00359194977114899,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019218411796536796,
        "hf_subset": "nif_Latn-eng_Latn",
        "languages": [
          "nif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019218411796536796,
        "precision": 0.01811342592592593,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003993113176236309,
        "hf_subset": "eng_Latn-nii_Latn",
        "languages": [
          "eng-Latn",
          "nii-Latn"
        ],
        "main_score": 0.0003993113176236309,
        "precision": 0.0002076048951048951,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.440476190476191e-05,
        "hf_subset": "nii_Latn-eng_Latn",
        "languages": [
          "nii-Latn",
          "eng-Latn"
        ],
        "main_score": 7.440476190476191e-05,
        "precision": 3.7560096153846156e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005266462053571428,
        "hf_subset": "eng_Latn-nin_Latn",
        "languages": [
          "eng-Latn",
          "nin-Latn"
        ],
        "main_score": 0.005266462053571428,
        "precision": 0.004683299731182796,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011678598474528415,
        "hf_subset": "nin_Latn-eng_Latn",
        "languages": [
          "nin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011678598474528415,
        "precision": 0.010157182846587428,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01942903331320451,
        "hf_subset": "eng_Latn-nko_Latn",
        "languages": [
          "eng-Latn",
          "nko-Latn"
        ],
        "main_score": 0.01942903331320451,
        "precision": 0.018237992263030686,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020496385576057603,
        "hf_subset": "nko_Latn-eng_Latn",
        "languages": [
          "nko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020496385576057603,
        "precision": 0.0177392578125,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9446614583333333,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ],
        "main_score": 0.9446614583333333,
        "precision": 0.9388020833333333,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9635416666666667,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9635416666666667,
        "precision": 0.958984375,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04352926587301587,
        "hf_subset": "eng_Latn-nlg_Latn",
        "languages": [
          "eng-Latn",
          "nlg-Latn"
        ],
        "main_score": 0.04352926587301587,
        "precision": 0.03830196496212121,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.039504652053320086,
        "hf_subset": "nlg_Latn-eng_Latn",
        "languages": [
          "nlg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.039504652053320086,
        "precision": 0.03440472868835034,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.09408284857503607,
        "hf_subset": "eng_Latn-nna_Latn",
        "languages": [
          "eng-Latn",
          "nna-Latn"
        ],
        "main_score": 0.09408284857503607,
        "precision": 0.08752421894511739,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.07569872058018609,
        "hf_subset": "nna_Latn-eng_Latn",
        "languages": [
          "nna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07569872058018609,
        "precision": 0.07300679743503584,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008214829928682,
        "hf_subset": "eng_Latn-nnq_Latn",
        "languages": [
          "eng-Latn",
          "nnq-Latn"
        ],
        "main_score": 0.008214829928682,
        "precision": 0.008018145986895988,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013469153724573942,
        "hf_subset": "nnq_Latn-eng_Latn",
        "languages": [
          "nnq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013469153724573942,
        "precision": 0.012790466153900311,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006682317323481117,
        "hf_subset": "eng_Latn-noa_Latn",
        "languages": [
          "eng-Latn",
          "noa-Latn"
        ],
        "main_score": 0.006682317323481117,
        "precision": 0.005530841828128012,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004833279465632406,
        "hf_subset": "noa_Latn-eng_Latn",
        "languages": [
          "noa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004833279465632406,
        "precision": 0.004399572922754724,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00715895854153517,
        "hf_subset": "eng_Latn-nop_Latn",
        "languages": [
          "eng-Latn",
          "nop-Latn"
        ],
        "main_score": 0.00715895854153517,
        "precision": 0.0062007523893900345,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009253472222222222,
        "hf_subset": "nop_Latn-eng_Latn",
        "languages": [
          "nop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009253472222222222,
        "precision": 0.007486979166666667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006009615384615385,
        "hf_subset": "eng_Latn-not_Latn",
        "languages": [
          "eng-Latn",
          "not-Latn"
        ],
        "main_score": 0.0006009615384615385,
        "precision": 0.0003255208333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.622781065088757e-05,
        "hf_subset": "not_Latn-eng_Latn",
        "languages": [
          "not-Latn",
          "eng-Latn"
        ],
        "main_score": 4.622781065088757e-05,
        "precision": 2.3251488095238094e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.027384303886696958,
        "hf_subset": "eng_Latn-nou_Latn",
        "languages": [
          "eng-Latn",
          "nou-Latn"
        ],
        "main_score": 0.027384303886696958,
        "precision": 0.024404140207219246,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.037129103535353536,
        "hf_subset": "nou_Latn-eng_Latn",
        "languages": [
          "nou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.037129103535353536,
        "precision": 0.032999674479166664,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.66015625,
        "f1": 0.5843098958333334,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.5843098958333334,
        "precision": 0.5550285218253969,
        "recall": 0.66015625
      },
      {
        "accuracy": 0.68359375,
        "f1": 0.6347945601851852,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6347945601851852,
        "precision": 0.6169471153846153,
        "recall": 0.68359375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.016312015373666187,
        "hf_subset": "eng_Latn-npl_Latn",
        "languages": [
          "eng-Latn",
          "npl-Latn"
        ],
        "main_score": 0.016312015373666187,
        "precision": 0.013298732430083914,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015154330884639303,
        "hf_subset": "npl_Latn-eng_Latn",
        "languages": [
          "npl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015154330884639303,
        "precision": 0.012946487905369484,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009215080262874379,
        "hf_subset": "eng_Latn-nsn_Latn",
        "languages": [
          "eng-Latn",
          "nsn-Latn"
        ],
        "main_score": 0.009215080262874379,
        "precision": 0.006101611408302544,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015440336722664311,
        "hf_subset": "nsn_Latn-eng_Latn",
        "languages": [
          "nsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015440336722664311,
        "precision": 0.014279086275314722,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005244840342679127,
        "hf_subset": "eng_Latn-nss_Latn",
        "languages": [
          "eng-Latn",
          "nss-Latn"
        ],
        "main_score": 0.005244840342679127,
        "precision": 0.004705839201877934,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01096726852277839,
        "hf_subset": "nss_Latn-eng_Latn",
        "languages": [
          "nss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01096726852277839,
        "precision": 0.009750888141348089,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0012269270081770082,
        "hf_subset": "eng_Latn-ntj_Latn",
        "languages": [
          "eng-Latn",
          "ntj-Latn"
        ],
        "main_score": 0.0012269270081770082,
        "precision": 0.0006596403301886793,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0008572484381972334,
        "hf_subset": "ntj_Latn-eng_Latn",
        "languages": [
          "ntj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008572484381972334,
        "precision": 0.00045293248418248417,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01056733630952381,
        "hf_subset": "eng_Latn-ntp_Latn",
        "languages": [
          "eng-Latn",
          "ntp-Latn"
        ],
        "main_score": 0.01056733630952381,
        "precision": 0.009438032174762702,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004184554256485203,
        "hf_subset": "ntp_Latn-eng_Latn",
        "languages": [
          "ntp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004184554256485203,
        "precision": 0.004049035274621212,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012373590848806366,
        "hf_subset": "eng_Latn-ntu_Latn",
        "languages": [
          "eng-Latn",
          "ntu-Latn"
        ],
        "main_score": 0.012373590848806366,
        "precision": 0.012071397569444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01117078081232493,
        "hf_subset": "ntu_Latn-eng_Latn",
        "languages": [
          "ntu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01117078081232493,
        "precision": 0.008993520907583409,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006294356684981684,
        "hf_subset": "eng_Latn-nuy_Latn",
        "languages": [
          "eng-Latn",
          "nuy-Latn"
        ],
        "main_score": 0.006294356684981684,
        "precision": 0.004235998376623376,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009796626984126984,
        "hf_subset": "nuy_Latn-eng_Latn",
        "languages": [
          "nuy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009796626984126984,
        "precision": 0.008951822916666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010974225427350427,
        "hf_subset": "eng_Latn-nvm_Latn",
        "languages": [
          "eng-Latn",
          "nvm-Latn"
        ],
        "main_score": 0.010974225427350427,
        "precision": 0.00883189418859649,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014592313218390805,
        "hf_subset": "nvm_Latn-eng_Latn",
        "languages": [
          "nvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014592313218390805,
        "precision": 0.013811383928571428,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-nwi_Latn",
        "languages": [
          "eng-Latn",
          "nwi-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.006510416666666666,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005511441256830601,
        "hf_subset": "nwi_Latn-eng_Latn",
        "languages": [
          "nwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005511441256830601,
        "precision": 0.004904275412087912,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019863911784908254,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ],
        "main_score": 0.019863911784908254,
        "precision": 0.01810402947236587,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008989133444075304,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008989133444075304,
        "precision": 0.008494059244791666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.09836065573770492,
        "f1": 0.05362281128496381,
        "hf_subset": "eng_Latn-nys_Latn",
        "languages": [
          "eng-Latn",
          "nys-Latn"
        ],
        "main_score": 0.05362281128496381,
        "precision": 0.04667354503420077,
        "recall": 0.09836065573770492
      },
      {
        "accuracy": 0.07377049180327869,
        "f1": 0.0402155736696339,
        "hf_subset": "nys_Latn-eng_Latn",
        "languages": [
          "nys-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0402155736696339,
        "precision": 0.033297303789107065,
        "recall": 0.07377049180327869
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004492005956849707,
        "hf_subset": "eng_Latn-nyu_Latn",
        "languages": [
          "eng-Latn",
          "nyu-Latn"
        ],
        "main_score": 0.004492005956849707,
        "precision": 0.003009597287123572,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016199865362811792,
        "hf_subset": "nyu_Latn-eng_Latn",
        "languages": [
          "nyu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016199865362811792,
        "precision": 0.014503867953431372,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.011672083204750825,
        "hf_subset": "eng_Latn-obo_Latn",
        "languages": [
          "eng-Latn",
          "obo-Latn"
        ],
        "main_score": 0.011672083204750825,
        "precision": 0.00858723094882847,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01882292205831608,
        "hf_subset": "obo_Latn-eng_Latn",
        "languages": [
          "obo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01882292205831608,
        "precision": 0.01788589995857498,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023186383928571426,
        "hf_subset": "eng_Latn-okv_Latn",
        "languages": [
          "eng-Latn",
          "okv-Latn"
        ],
        "main_score": 0.023186383928571426,
        "precision": 0.020511929759552044,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03622379139957265,
        "hf_subset": "okv_Latn-eng_Latn",
        "languages": [
          "okv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03622379139957265,
        "precision": 0.03136467735869332,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002232142857142857,
        "hf_subset": "eng_Latn-omw_Latn",
        "languages": [
          "eng-Latn",
          "omw-Latn"
        ],
        "main_score": 0.0002232142857142857,
        "precision": 0.00011322463768115942,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003314393939393939,
        "hf_subset": "omw_Latn-eng_Latn",
        "languages": [
          "omw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003314393939393939,
        "precision": 0.00234375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016491381828805142,
        "hf_subset": "eng_Latn-ong_Latn",
        "languages": [
          "eng-Latn",
          "ong-Latn"
        ],
        "main_score": 0.016491381828805142,
        "precision": 0.013019905923551758,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018741158376102116,
        "hf_subset": "ong_Latn-eng_Latn",
        "languages": [
          "ong-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018741158376102116,
        "precision": 0.015374700872747747,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020361328125,
        "hf_subset": "eng_Latn-ons_Latn",
        "languages": [
          "eng-Latn",
          "ons-Latn"
        ],
        "main_score": 0.020361328125,
        "precision": 0.018817970387840673,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018948445332080198,
        "hf_subset": "ons_Latn-eng_Latn",
        "languages": [
          "ons-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018948445332080198,
        "precision": 0.01554749503968254,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010728697368861794,
        "hf_subset": "eng_Latn-ood_Latn",
        "languages": [
          "eng-Latn",
          "ood-Latn"
        ],
        "main_score": 0.010728697368861794,
        "precision": 0.008217293811313208,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013717830882352941,
        "hf_subset": "ood_Latn-eng_Latn",
        "languages": [
          "ood-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013717830882352941,
        "precision": 0.013043947238658777,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008514021399680827,
        "hf_subset": "eng_Latn-opm_Latn",
        "languages": [
          "eng-Latn",
          "opm-Latn"
        ],
        "main_score": 0.008514021399680827,
        "precision": 0.006979039840367966,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "opm_Latn-eng_Latn",
        "languages": [
          "opm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.5,
        "f1": 0.4107548701298701,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.4107548701298701,
        "precision": 0.37669270833333335,
        "recall": 0.5
      },
      {
        "accuracy": 0.44140625,
        "f1": 0.3844637784090909,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.3844637784090909,
        "precision": 0.3667260760838426,
        "recall": 0.44140625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02829674030172414,
        "hf_subset": "eng_Latn-ote_Latn",
        "languages": [
          "eng-Latn",
          "ote-Latn"
        ],
        "main_score": 0.02829674030172414,
        "precision": 0.025613245630699086,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03153618605302465,
        "hf_subset": "ote_Latn-eng_Latn",
        "languages": [
          "ote-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03153618605302465,
        "precision": 0.02982049353832442,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01707175925925926,
        "hf_subset": "eng_Latn-otm_Latn",
        "languages": [
          "eng-Latn",
          "otm-Latn"
        ],
        "main_score": 0.01707175925925926,
        "precision": 0.01569870283018868,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016253551136363637,
        "hf_subset": "otm_Latn-eng_Latn",
        "languages": [
          "otm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016253551136363637,
        "precision": 0.013153296356421356,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02776730125843398,
        "hf_subset": "eng_Latn-otn_Latn",
        "languages": [
          "eng-Latn",
          "otn-Latn"
        ],
        "main_score": 0.02776730125843398,
        "precision": 0.025185448232323233,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.031106165213178293,
        "hf_subset": "otn_Latn-eng_Latn",
        "languages": [
          "otn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031106165213178293,
        "precision": 0.02877604166666667,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01900869963369963,
        "hf_subset": "eng_Latn-otq_Latn",
        "languages": [
          "eng-Latn",
          "otq-Latn"
        ],
        "main_score": 0.01900869963369963,
        "precision": 0.017630912162162164,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03328993055555556,
        "hf_subset": "otq_Latn-eng_Latn",
        "languages": [
          "otq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03328993055555556,
        "precision": 0.03237241274350649,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023149439102564104,
        "hf_subset": "eng_Latn-ots_Latn",
        "languages": [
          "eng-Latn",
          "ots-Latn"
        ],
        "main_score": 0.023149439102564104,
        "precision": 0.019458585349462366,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02901427999084249,
        "hf_subset": "ots_Latn-eng_Latn",
        "languages": [
          "ots-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02901427999084249,
        "precision": 0.027102494800631094,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004315299875874521,
        "hf_subset": "eng_Latn-pab_Latn",
        "languages": [
          "eng-Latn",
          "pab-Latn"
        ],
        "main_score": 0.004315299875874521,
        "precision": 0.004120163690476191,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026483050847457626,
        "hf_subset": "pab_Latn-eng_Latn",
        "languages": [
          "pab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026483050847457626,
        "precision": 0.0019753196022727275,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004814995659722222,
        "hf_subset": "eng_Latn-pad_Latn",
        "languages": [
          "eng-Latn",
          "pad-Latn"
        ],
        "main_score": 0.004814995659722222,
        "precision": 0.004414982820680628,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006554555084745763,
        "hf_subset": "pad_Latn-eng_Latn",
        "languages": [
          "pad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006554555084745763,
        "precision": 0.005881569602272728,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.030468749999999996,
        "hf_subset": "eng_Latn-pah_Latn",
        "languages": [
          "eng-Latn",
          "pah-Latn"
        ],
        "main_score": 0.030468749999999996,
        "precision": 0.02734375,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01802909044715447,
        "hf_subset": "pah_Latn-eng_Latn",
        "languages": [
          "pah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01802909044715447,
        "precision": 0.016048177083333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.8125,
        "f1": 0.7545572916666667,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.7545572916666667,
        "precision": 0.7259114583333334,
        "recall": 0.8125
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.747860863095238,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.747860863095238,
        "precision": 0.7286458333333333,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015236659356725146,
        "hf_subset": "eng_Latn-pao_Latn",
        "languages": [
          "eng-Latn",
          "pao-Latn"
        ],
        "main_score": 0.015236659356725146,
        "precision": 0.01388720616087344,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01765252976190476,
        "hf_subset": "pao_Latn-eng_Latn",
        "languages": [
          "pao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01765252976190476,
        "precision": 0.016964643429487176,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9108072916666666,
        "hf_subset": "eng_Latn-pes_Arab",
        "languages": [
          "eng-Latn",
          "pes-Arab"
        ],
        "main_score": 0.9108072916666666,
        "precision": 0.9016927083333333,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9342447916666666,
        "hf_subset": "pes_Arab-eng_Latn",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9342447916666666,
        "precision": 0.9270833333333334,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00020682001614205005,
        "hf_subset": "eng_Latn-pib_Latn",
        "languages": [
          "eng-Latn",
          "pib-Latn"
        ],
        "main_score": 0.00020682001614205005,
        "precision": 0.00010490923408488064,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.456611570247934e-05,
        "hf_subset": "pib_Latn-eng_Latn",
        "languages": [
          "pib-Latn",
          "eng-Latn"
        ],
        "main_score": 6.456611570247934e-05,
        "precision": 3.255208333333333e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009569128787878786,
        "hf_subset": "eng_Latn-pio_Latn",
        "languages": [
          "eng-Latn",
          "pio-Latn"
        ],
        "main_score": 0.009569128787878786,
        "precision": 0.007593784041394335,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012025394477317554,
        "hf_subset": "pio_Latn-eng_Latn",
        "languages": [
          "pio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012025394477317554,
        "precision": 0.010374813988095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009878211152882205,
        "hf_subset": "eng_Latn-pir_Latn",
        "languages": [
          "eng-Latn",
          "pir-Latn"
        ],
        "main_score": 0.009878211152882205,
        "precision": 0.008218555093555093,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014802827380952382,
        "hf_subset": "pir_Latn-eng_Latn",
        "languages": [
          "pir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014802827380952382,
        "precision": 0.013556177836345381,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.1335978835978834e-05,
        "hf_subset": "eng_Latn-piu_Latn",
        "languages": [
          "eng-Latn",
          "piu-Latn"
        ],
        "main_score": 4.1335978835978834e-05,
        "precision": 2.0777925531914893e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020572916666666665,
        "hf_subset": "piu_Latn-eng_Latn",
        "languages": [
          "piu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0020572916666666665,
        "precision": 0.0013548704954954955,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007495325854700855,
        "hf_subset": "eng_Latn-pjt_Latn",
        "languages": [
          "eng-Latn",
          "pjt-Latn"
        ],
        "main_score": 0.007495325854700855,
        "precision": 0.006127632339933319,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011411904236540158,
        "hf_subset": "pjt_Latn-eng_Latn",
        "languages": [
          "pjt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011411904236540158,
        "precision": 0.0006149334733893557,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.0674000219605386,
        "hf_subset": "eng_Latn-pls_Latn",
        "languages": [
          "eng-Latn",
          "pls-Latn"
        ],
        "main_score": 0.0674000219605386,
        "precision": 0.0626243794752224,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.056027793660567676,
        "hf_subset": "pls_Latn-eng_Latn",
        "languages": [
          "pls-Latn",
          "eng-Latn"
        ],
        "main_score": 0.056027793660567676,
        "precision": 0.05110856294407585,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00777344555246341,
        "hf_subset": "eng_Latn-plu_Latn",
        "languages": [
          "eng-Latn",
          "plu-Latn"
        ],
        "main_score": 0.00777344555246341,
        "precision": 0.006553700206043956,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004963467394533571,
        "hf_subset": "plu_Latn-eng_Latn",
        "languages": [
          "plu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004963467394533571,
        "precision": 0.004473074554283436,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010633680555555556,
        "hf_subset": "eng_Latn-pma_Latn",
        "languages": [
          "eng-Latn",
          "pma-Latn"
        ],
        "main_score": 0.010633680555555556,
        "precision": 0.009602864583333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017384770520050122,
        "hf_subset": "pma_Latn-eng_Latn",
        "languages": [
          "pma-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017384770520050122,
        "precision": 0.016646654607451763,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018371958158263303,
        "hf_subset": "eng_Latn-poe_Latn",
        "languages": [
          "eng-Latn",
          "poe-Latn"
        ],
        "main_score": 0.018371958158263303,
        "precision": 0.016060493045684278,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022490845296451914,
        "hf_subset": "poe_Latn-eng_Latn",
        "languages": [
          "poe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022490845296451914,
        "precision": 0.020168340773809523,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019430085630743525,
        "hf_subset": "eng_Latn-poh_Latn",
        "languages": [
          "eng-Latn",
          "poh-Latn"
        ],
        "main_score": 0.0019430085630743525,
        "precision": 0.001108047385620915,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.314625850340136e-05,
        "hf_subset": "poh_Latn-eng_Latn",
        "languages": [
          "poh-Latn",
          "eng-Latn"
        ],
        "main_score": 5.314625850340136e-05,
        "precision": 2.675513698630137e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.037511511120136315,
        "hf_subset": "eng_Latn-poi_Latn",
        "languages": [
          "eng-Latn",
          "poi-Latn"
        ],
        "main_score": 0.037511511120136315,
        "precision": 0.03101931867629298,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.04894934738819561,
        "hf_subset": "poi_Latn-eng_Latn",
        "languages": [
          "poi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04894934738819561,
        "precision": 0.04481718368437118,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.953125,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ],
        "main_score": 0.953125,
        "precision": 0.947265625,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9427083333333333,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9427083333333333,
        "precision": 0.935546875,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005175667828106852,
        "hf_subset": "eng_Latn-pon_Latn",
        "languages": [
          "eng-Latn",
          "pon-Latn"
        ],
        "main_score": 0.005175667828106852,
        "precision": 0.004583404876373626,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010416666666666667,
        "hf_subset": "pon_Latn-eng_Latn",
        "languages": [
          "pon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010416666666666667,
        "precision": 0.0005580357142857143,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9537760416666666,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ],
        "main_score": 0.9537760416666666,
        "precision": 0.9485677083333333,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9635416666666666,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9635416666666666,
        "precision": 0.958984375,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004348352713178294,
        "hf_subset": "eng_Latn-poy_Latn",
        "languages": [
          "eng-Latn",
          "poy-Latn"
        ],
        "main_score": 0.004348352713178294,
        "precision": 0.0026320684523809526,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009400716675709892,
        "hf_subset": "poy_Latn-eng_Latn",
        "languages": [
          "poy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009400716675709892,
        "precision": 0.007958764428490991,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008500393081761006,
        "hf_subset": "eng_Latn-ppo_Latn",
        "languages": [
          "eng-Latn",
          "ppo-Latn"
        ],
        "main_score": 0.008500393081761006,
        "precision": 0.007179971366508688,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00017152687648712956,
        "hf_subset": "ppo_Latn-eng_Latn",
        "languages": [
          "ppo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00017152687648712956,
        "precision": 8.681515369305617e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023824350845410628,
        "hf_subset": "eng_Latn-prf_Latn",
        "languages": [
          "eng-Latn",
          "prf-Latn"
        ],
        "main_score": 0.023824350845410628,
        "precision": 0.022189670138888888,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03983668926103136,
        "hf_subset": "prf_Latn-eng_Latn",
        "languages": [
          "prf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03983668926103136,
        "precision": 0.03707731058832709,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008409288194444444,
        "hf_subset": "eng_Latn-pri_Latn",
        "languages": [
          "eng-Latn",
          "pri-Latn"
        ],
        "main_score": 0.008409288194444444,
        "precision": 0.008127934272300468,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004548355800653594,
        "hf_subset": "pri_Latn-eng_Latn",
        "languages": [
          "pri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004548355800653594,
        "precision": 0.004238348618081153,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010573682598039216,
        "hf_subset": "eng_Latn-ptp_Latn",
        "languages": [
          "eng-Latn",
          "ptp-Latn"
        ],
        "main_score": 0.010573682598039216,
        "precision": 0.008234432037975373,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021713475738396625,
        "hf_subset": "ptp_Latn-eng_Latn",
        "languages": [
          "ptp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021713475738396625,
        "precision": 0.019665035485347985,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027683886054421767,
        "hf_subset": "eng_Latn-ptu_Latn",
        "languages": [
          "eng-Latn",
          "ptu-Latn"
        ],
        "main_score": 0.027683886054421767,
        "precision": 0.024263510561085434,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028560003121098625,
        "hf_subset": "ptu_Latn-eng_Latn",
        "languages": [
          "ptu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028560003121098625,
        "precision": 0.024632062815656563,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011830357142857142,
        "hf_subset": "eng_Latn-pwg_Latn",
        "languages": [
          "eng-Latn",
          "pwg-Latn"
        ],
        "main_score": 0.011830357142857142,
        "precision": 0.01177536231884058,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008452897054775668,
        "hf_subset": "pwg_Latn-eng_Latn",
        "languages": [
          "pwg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008452897054775668,
        "precision": 0.0069671552002583985,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005139691380439736,
        "hf_subset": "eng_Latn-qub_Latn",
        "languages": [
          "eng-Latn",
          "qub-Latn"
        ],
        "main_score": 0.005139691380439736,
        "precision": 0.004564966993009756,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02868217054263566,
        "hf_subset": "qub_Latn-eng_Latn",
        "languages": [
          "qub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02868217054263566,
        "precision": 0.026190128504672897,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017616800742574254,
        "hf_subset": "eng_Latn-quc_Latn",
        "languages": [
          "eng-Latn",
          "quc-Latn"
        ],
        "main_score": 0.017616800742574254,
        "precision": 0.014827672715965627,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012271518120522545,
        "hf_subset": "quc_Latn-eng_Latn",
        "languages": [
          "quc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012271518120522545,
        "precision": 0.010891954438025209,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004239004629629629,
        "hf_subset": "eng_Latn-quf_Latn",
        "languages": [
          "eng-Latn",
          "quf-Latn"
        ],
        "main_score": 0.004239004629629629,
        "precision": 0.004078313010313709,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007522170608108107,
        "hf_subset": "quf_Latn-eng_Latn",
        "languages": [
          "quf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007522170608108107,
        "precision": 0.00643508605365223,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023346044146825395,
        "hf_subset": "eng_Latn-quh_Latn",
        "languages": [
          "eng-Latn",
          "quh-Latn"
        ],
        "main_score": 0.023346044146825395,
        "precision": 0.02112011315043425,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009452624198717948,
        "hf_subset": "quh_Latn-eng_Latn",
        "languages": [
          "quh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009452624198717948,
        "precision": 0.00798762077294686,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022748685086111158,
        "hf_subset": "eng_Latn-qul_Latn",
        "languages": [
          "eng-Latn",
          "qul-Latn"
        ],
        "main_score": 0.022748685086111158,
        "precision": 0.0214684602922637,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021917925824175823,
        "hf_subset": "qul_Latn-eng_Latn",
        "languages": [
          "qul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021917925824175823,
        "precision": 0.019107381930309197,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004675099206349206,
        "hf_subset": "eng_Latn-qup_Latn",
        "languages": [
          "eng-Latn",
          "qup-Latn"
        ],
        "main_score": 0.004675099206349206,
        "precision": 0.004313625250927036,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005058323732718894,
        "hf_subset": "qup_Latn-eng_Latn",
        "languages": [
          "qup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005058323732718894,
        "precision": 0.004575376157407407,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007963814637697183,
        "hf_subset": "eng_Latn-qvc_Latn",
        "languages": [
          "eng-Latn",
          "qvc-Latn"
        ],
        "main_score": 0.007963814637697183,
        "precision": 0.006667528416733925,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.228305785123967e-05,
        "hf_subset": "qvc_Latn-eng_Latn",
        "languages": [
          "qvc-Latn",
          "eng-Latn"
        ],
        "main_score": 3.228305785123967e-05,
        "precision": 1.620850622406639e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.022431414931822602,
        "hf_subset": "eng_Latn-qve_Latn",
        "languages": [
          "eng-Latn",
          "qve-Latn"
        ],
        "main_score": 0.022431414931822602,
        "precision": 0.018747153454184706,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01687127976190476,
        "hf_subset": "qve_Latn-eng_Latn",
        "languages": [
          "qve-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01687127976190476,
        "precision": 0.01483302054236499,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015054086538461537,
        "hf_subset": "eng_Latn-qvh_Latn",
        "languages": [
          "eng-Latn",
          "qvh-Latn"
        ],
        "main_score": 0.015054086538461537,
        "precision": 0.012891728460451977,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010925834846650525,
        "hf_subset": "qvh_Latn-eng_Latn",
        "languages": [
          "qvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010925834846650525,
        "precision": 0.009787819602272728,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009325086805555556,
        "hf_subset": "eng_Latn-qvm_Latn",
        "languages": [
          "eng-Latn",
          "qvm-Latn"
        ],
        "main_score": 0.009325086805555556,
        "precision": 0.007338833971088435,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011767885220125786,
        "hf_subset": "qvm_Latn-eng_Latn",
        "languages": [
          "qvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011767885220125786,
        "precision": 0.010571598101265824,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017264851485148513,
        "hf_subset": "eng_Latn-qvn_Latn",
        "languages": [
          "eng-Latn",
          "qvn-Latn"
        ],
        "main_score": 0.017264851485148513,
        "precision": 0.014228670634920636,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00785079656862745,
        "hf_subset": "qvn_Latn-eng_Latn",
        "languages": [
          "qvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00785079656862745,
        "precision": 0.007831742610837439,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005729166666666666,
        "hf_subset": "eng_Latn-qvs_Latn",
        "languages": [
          "eng-Latn",
          "qvs-Latn"
        ],
        "main_score": 0.005729166666666666,
        "precision": 0.004185267857142857,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.7741545893719805e-05,
        "hf_subset": "qvs_Latn-eng_Latn",
        "languages": [
          "qvs-Latn",
          "eng-Latn"
        ],
        "main_score": 3.7741545893719805e-05,
        "precision": 1.8962378640776697e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01239716538789429,
        "hf_subset": "eng_Latn-qvw_Latn",
        "languages": [
          "eng-Latn",
          "qvw-Latn"
        ],
        "main_score": 0.01239716538789429,
        "precision": 0.010593471215240482,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013541909140285536,
        "hf_subset": "qvw_Latn-eng_Latn",
        "languages": [
          "qvw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013541909140285536,
        "precision": 0.012828864867576244,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013932291666666666,
        "hf_subset": "eng_Latn-qvz_Latn",
        "languages": [
          "eng-Latn",
          "qvz-Latn"
        ],
        "main_score": 0.013932291666666666,
        "precision": 0.011838228875698324,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014362776360544217,
        "hf_subset": "qvz_Latn-eng_Latn",
        "languages": [
          "qvz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014362776360544217,
        "precision": 0.013691907051282051,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02787466627875137,
        "hf_subset": "eng_Latn-qwh_Latn",
        "languages": [
          "eng-Latn",
          "qwh-Latn"
        ],
        "main_score": 0.02787466627875137,
        "precision": 0.024054023603852108,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02565498737373737,
        "hf_subset": "qwh_Latn-eng_Latn",
        "languages": [
          "qwh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02565498737373737,
        "precision": 0.020824599847560975,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003940515350877193,
        "hf_subset": "eng_Latn-qxh_Latn",
        "languages": [
          "eng-Latn",
          "qxh-Latn"
        ],
        "main_score": 0.003940515350877193,
        "precision": 0.0027515831497797356,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01156269629396985,
        "hf_subset": "qxh_Latn-eng_Latn",
        "languages": [
          "qxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01156269629396985,
        "precision": 0.01012637536075036,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.014022741198752228,
        "hf_subset": "eng_Latn-qxn_Latn",
        "languages": [
          "eng-Latn",
          "qxn-Latn"
        ],
        "main_score": 0.014022741198752228,
        "precision": 0.01066978304165946,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017254849137931034,
        "hf_subset": "qxn_Latn-eng_Latn",
        "languages": [
          "qxn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017254849137931034,
        "precision": 0.015463654891304348,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004605940934065934,
        "hf_subset": "eng_Latn-qxo_Latn",
        "languages": [
          "eng-Latn",
          "qxo-Latn"
        ],
        "main_score": 0.004605940934065934,
        "precision": 0.004270134588923289,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011780753968253968,
        "hf_subset": "qxo_Latn-eng_Latn",
        "languages": [
          "qxo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011780753968253968,
        "precision": 0.01175,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003982099514563107,
        "hf_subset": "eng_Latn-rai_Latn",
        "languages": [
          "eng-Latn",
          "rai-Latn"
        ],
        "main_score": 0.003982099514563107,
        "precision": 0.0027726715686274507,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01658252308166281,
        "hf_subset": "rai_Latn-eng_Latn",
        "languages": [
          "rai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01658252308166281,
        "precision": 0.014951422275641026,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022468712863933454,
        "hf_subset": "eng_Latn-reg_Latn",
        "languages": [
          "eng-Latn",
          "reg-Latn"
        ],
        "main_score": 0.022468712863933454,
        "precision": 0.021132094247924997,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021258327518607123,
        "hf_subset": "reg_Latn-eng_Latn",
        "languages": [
          "reg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021258327518607123,
        "precision": 0.018197721797052157,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02981770833333333,
        "hf_subset": "eng_Latn-rgu_Latn",
        "languages": [
          "eng-Latn",
          "rgu-Latn"
        ],
        "main_score": 0.02981770833333333,
        "precision": 0.02697172619047619,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01927564495349422,
        "hf_subset": "rgu_Latn-eng_Latn",
        "languages": [
          "rgu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01927564495349422,
        "precision": 0.01580044920195801,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005365769496204279,
        "hf_subset": "eng_Latn-rkb_Latn",
        "languages": [
          "eng-Latn",
          "rkb-Latn"
        ],
        "main_score": 0.005365769496204279,
        "precision": 0.004732875631313131,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0025658700980392157,
        "hf_subset": "rkb_Latn-eng_Latn",
        "languages": [
          "rkb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0025658700980392157,
        "precision": 0.0016276041666666665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.07527591765873015,
        "hf_subset": "eng_Latn-rmc_Latn",
        "languages": [
          "eng-Latn",
          "rmc-Latn"
        ],
        "main_score": 0.07527591765873015,
        "precision": 0.06501768439383329,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07551465993388164,
        "hf_subset": "rmc_Latn-eng_Latn",
        "languages": [
          "rmc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07551465993388164,
        "precision": 0.07038515827003877,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.1875,
        "f1": 0.1234918727106227,
        "hf_subset": "eng_Latn-rmy_Latn",
        "languages": [
          "eng-Latn",
          "rmy-Latn"
        ],
        "main_score": 0.1234918727106227,
        "precision": 0.10421006944444444,
        "recall": 0.1875
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10054648042929293,
        "hf_subset": "rmy_Latn-eng_Latn",
        "languages": [
          "rmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10054648042929293,
        "precision": 0.08958834981105865,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011193716397849461,
        "hf_subset": "eng_Latn-roo_Latn",
        "languages": [
          "eng-Latn",
          "roo-Latn"
        ],
        "main_score": 0.011193716397849461,
        "precision": 0.009959870218579235,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0040211397058823525,
        "hf_subset": "roo_Latn-eng_Latn",
        "languages": [
          "roo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0040211397058823525,
        "precision": 0.00396455223880597,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008378493471144952,
        "hf_subset": "eng_Latn-rop_Latn",
        "languages": [
          "eng-Latn",
          "rop-Latn"
        ],
        "main_score": 0.008378493471144952,
        "precision": 0.008105256304194626,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007031249999999999,
        "hf_subset": "rop_Latn-eng_Latn",
        "languages": [
          "rop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007031249999999999,
        "precision": 0.005859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020419517238713665,
        "hf_subset": "eng_Latn-row_Latn",
        "languages": [
          "eng-Latn",
          "row-Latn"
        ],
        "main_score": 0.020419517238713665,
        "precision": 0.015000513980263159,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025254542606516293,
        "hf_subset": "row_Latn-eng_Latn",
        "languages": [
          "row-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025254542606516293,
        "precision": 0.023045932220434433,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.007754159902597402,
        "hf_subset": "eng_Latn-rro_Latn",
        "languages": [
          "eng-Latn",
          "rro-Latn"
        ],
        "main_score": 0.007754159902597402,
        "precision": 0.004933727297008547,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011422211021505375,
        "hf_subset": "rro_Latn-eng_Latn",
        "languages": [
          "rro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011422211021505375,
        "precision": 0.009298458614864865,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012549446202531645,
        "hf_subset": "eng_Latn-ruf_Latn",
        "languages": [
          "eng-Latn",
          "ruf-Latn"
        ],
        "main_score": 0.012549446202531645,
        "precision": 0.011005783351026185,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015503058862433862,
        "hf_subset": "ruf_Latn-eng_Latn",
        "languages": [
          "ruf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015503058862433862,
        "precision": 0.014134102695780075,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012118506493506494,
        "hf_subset": "eng_Latn-rug_Latn",
        "languages": [
          "eng-Latn",
          "rug-Latn"
        ],
        "main_score": 0.012118506493506494,
        "precision": 0.011927211617405582,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008135907061688314,
        "hf_subset": "rug_Latn-eng_Latn",
        "languages": [
          "rug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008135907061688314,
        "precision": 0.007979497354497355,
        "recall": 0.015625
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9635416666666666,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9635416666666666,
        "precision": 0.958984375,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9485677083333333,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.9485677083333333,
        "precision": 0.9427083333333334,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002032537774725275,
        "hf_subset": "eng_Latn-rwo_Latn",
        "languages": [
          "eng-Latn",
          "rwo-Latn"
        ],
        "main_score": 0.002032537774725275,
        "precision": 0.0012170789051956816,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0024582188644688644,
        "hf_subset": "rwo_Latn-eng_Latn",
        "languages": [
          "rwo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0024582188644688644,
        "precision": 0.0014524269759450172,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011067708333333332,
        "hf_subset": "eng_Latn-sab_Latn",
        "languages": [
          "eng-Latn",
          "sab-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.010120738636363636,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.020833333333333332,
        "hf_subset": "sab_Latn-eng_Latn",
        "languages": [
          "sab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020833333333333332,
        "precision": 0.01953125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006770833333333333,
        "hf_subset": "eng_Latn-san_Latn",
        "languages": [
          "eng-Latn",
          "san-Latn"
        ],
        "main_score": 0.006770833333333333,
        "precision": 0.005994073275862069,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0015668402777777777,
        "hf_subset": "san_Latn-eng_Latn",
        "languages": [
          "san-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015668402777777777,
        "precision": 0.0008675345138055221,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0023432119490358126,
        "hf_subset": "eng_Latn-sbe_Latn",
        "languages": [
          "eng-Latn",
          "sbe-Latn"
        ],
        "main_score": 0.0023432119490358126,
        "precision": 0.0013718377976190475,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0012420794930875574,
        "hf_subset": "sbe_Latn-eng_Latn",
        "languages": [
          "sbe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0012420794930875574,
        "precision": 0.0007150785519125682,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01086039650422519,
        "hf_subset": "eng_Latn-sbk_Latn",
        "languages": [
          "eng-Latn",
          "sbk-Latn"
        ],
        "main_score": 0.01086039650422519,
        "precision": 0.008391617034284862,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01450013452180423,
        "hf_subset": "sbk_Latn-eng_Latn",
        "languages": [
          "sbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01450013452180423,
        "precision": 0.013761632582720588,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01723988266283525,
        "hf_subset": "eng_Latn-sbs_Latn",
        "languages": [
          "eng-Latn",
          "sbs-Latn"
        ],
        "main_score": 0.01723988266283525,
        "precision": 0.015786331554269752,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013940972222222223,
        "hf_subset": "sbs_Latn-eng_Latn",
        "languages": [
          "sbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013940972222222223,
        "precision": 0.01223324769295302,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010870321498048457,
        "hf_subset": "eng_Latn-seh_Latn",
        "languages": [
          "eng-Latn",
          "seh-Latn"
        ],
        "main_score": 0.010870321498048457,
        "precision": 0.009601547162866203,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011551339285714285,
        "hf_subset": "seh_Latn-eng_Latn",
        "languages": [
          "seh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011551339285714285,
        "precision": 0.009034160539215685,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023046875,
        "hf_subset": "eng_Latn-sey_Latn",
        "languages": [
          "eng-Latn",
          "sey-Latn"
        ],
        "main_score": 0.023046875,
        "precision": 0.020638020833333333,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012048117614180773,
        "hf_subset": "sey_Latn-eng_Latn",
        "languages": [
          "sey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012048117614180773,
        "precision": 0.010716145833333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.024874096800494825,
        "hf_subset": "eng_Latn-sgb_Latn",
        "languages": [
          "eng-Latn",
          "sgb-Latn"
        ],
        "main_score": 0.024874096800494825,
        "precision": 0.021875243254756302,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024898323659099518,
        "hf_subset": "sgb_Latn-eng_Latn",
        "languages": [
          "sgb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024898323659099518,
        "precision": 0.023017891749723143,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006076388888888888,
        "hf_subset": "eng_Latn-sgz_Latn",
        "languages": [
          "eng-Latn",
          "sgz-Latn"
        ],
        "main_score": 0.006076388888888888,
        "precision": 0.004148065476190476,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01157081996510188,
        "hf_subset": "sgz_Latn-eng_Latn",
        "languages": [
          "sgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01157081996510188,
        "precision": 0.010154578856923113,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01098901098901099,
        "f1": 0.000385579332947754,
        "hf_subset": "eng_Latn-shj_Latn",
        "languages": [
          "eng-Latn",
          "shj-Latn"
        ],
        "main_score": 0.000385579332947754,
        "precision": 0.00019623233908948193,
        "recall": 0.01098901098901099
      },
      {
        "accuracy": 0.04395604395604396,
        "f1": 0.024765089982481284,
        "hf_subset": "shj_Latn-eng_Latn",
        "languages": [
          "shj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024765089982481284,
        "precision": 0.020646020646020644,
        "recall": 0.04395604395604396
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004310498856489422,
        "hf_subset": "eng_Latn-shp_Latn",
        "languages": [
          "eng-Latn",
          "shp-Latn"
        ],
        "main_score": 0.004310498856489422,
        "precision": 0.004116985006027728,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008506704650092081,
        "hf_subset": "shp_Latn-eng_Latn",
        "languages": [
          "shp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008506704650092081,
        "precision": 0.008189315025252525,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004427083333333333,
        "hf_subset": "eng_Latn-sim_Latn",
        "languages": [
          "eng-Latn",
          "sim-Latn"
        ],
        "main_score": 0.004427083333333333,
        "precision": 0.004185267857142857,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011092748397435896,
        "hf_subset": "sim_Latn-eng_Latn",
        "languages": [
          "sim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011092748397435896,
        "precision": 0.010129070590614887,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010477120535714285,
        "hf_subset": "eng_Latn-sja_Latn",
        "languages": [
          "eng-Latn",
          "sja-Latn"
        ],
        "main_score": 0.010477120535714285,
        "precision": 0.008310546697865085,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01528115643712575,
        "hf_subset": "sja_Latn-eng_Latn",
        "languages": [
          "sja-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01528115643712575,
        "precision": 0.012849052459839357,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01484375,
        "hf_subset": "eng_Latn-sll_Latn",
        "languages": [
          "eng-Latn",
          "sll-Latn"
        ],
        "main_score": 0.01484375,
        "precision": 0.013950892857142856,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013057002314814815,
        "hf_subset": "sll_Latn-eng_Latn",
        "languages": [
          "sll-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013057002314814815,
        "precision": 0.012463533108246893,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00955966982752697,
        "hf_subset": "eng_Latn-smk_Latn",
        "languages": [
          "eng-Latn",
          "smk-Latn"
        ],
        "main_score": 0.00955966982752697,
        "precision": 0.007633337433366392,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027993992498712157,
        "hf_subset": "smk_Latn-eng_Latn",
        "languages": [
          "smk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027993992498712157,
        "precision": 0.02618083861714976,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010437122958737333,
        "hf_subset": "eng_Latn-snc_Latn",
        "languages": [
          "eng-Latn",
          "snc-Latn"
        ],
        "main_score": 0.010437122958737333,
        "precision": 0.009296412195260879,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012459697420634921,
        "hf_subset": "snc_Latn-eng_Latn",
        "languages": [
          "snc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012459697420634921,
        "precision": 0.010886850685883135,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022977705672500785,
        "hf_subset": "eng_Latn-snn_Latn",
        "languages": [
          "eng-Latn",
          "snn-Latn"
        ],
        "main_score": 0.022977705672500785,
        "precision": 0.020766369047619044,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0195717292746114,
        "hf_subset": "snn_Latn-eng_Latn",
        "languages": [
          "snn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0195717292746114,
        "precision": 0.019551595052083332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00915798611111111,
        "hf_subset": "eng_Latn-snp_Latn",
        "languages": [
          "eng-Latn",
          "snp-Latn"
        ],
        "main_score": 0.00915798611111111,
        "precision": 0.007834322625698324,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006334305919139034,
        "hf_subset": "snp_Latn-eng_Latn",
        "languages": [
          "snp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006334305919139034,
        "precision": 0.005458671955624355,
        "recall": 0.015625
      },
      {
        "accuracy": 0.11428571428571428,
        "f1": 0.06359410430839,
        "hf_subset": "eng_Latn-snx_Latn",
        "languages": [
          "eng-Latn",
          "snx-Latn"
        ],
        "main_score": 0.06359410430839,
        "precision": 0.053936638758067326,
        "recall": 0.11428571428571428
      },
      {
        "accuracy": 0.06428571428571428,
        "f1": 0.03582972582972583,
        "hf_subset": "snx_Latn-eng_Latn",
        "languages": [
          "snx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03582972582972583,
        "precision": 0.029330357142857144,
        "recall": 0.06428571428571428
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008336846891534392,
        "hf_subset": "eng_Latn-sny_Latn",
        "languages": [
          "eng-Latn",
          "sny-Latn"
        ],
        "main_score": 0.008336846891534392,
        "precision": 0.006616678140298175,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014142628205128203,
        "hf_subset": "sny_Latn-eng_Latn",
        "languages": [
          "sny-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014142628205128203,
        "precision": 0.012044270833333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03364114632972391,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ],
        "main_score": 0.03364114632972391,
        "precision": 0.030119427643369178,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04854818591700588,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04854818591700588,
        "precision": 0.046563852813852814,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0053419237012987016,
        "hf_subset": "eng_Latn-soq_Latn",
        "languages": [
          "eng-Latn",
          "soq-Latn"
        ],
        "main_score": 0.0053419237012987016,
        "precision": 0.0033203125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00919932208994709,
        "hf_subset": "soq_Latn-eng_Latn",
        "languages": [
          "soq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00919932208994709,
        "precision": 0.007436565911222923,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0035807291666666665,
        "hf_subset": "eng_Latn-soy_Latn",
        "languages": [
          "eng-Latn",
          "soy-Latn"
        ],
        "main_score": 0.0035807291666666665,
        "precision": 0.002511160714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003064230388925511,
        "hf_subset": "soy_Latn-eng_Latn",
        "languages": [
          "soy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003064230388925511,
        "precision": 0.00015673225308641974,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666667,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9791666666666667,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005238266283524904,
        "hf_subset": "eng_Latn-spl_Latn",
        "languages": [
          "eng-Latn",
          "spl-Latn"
        ],
        "main_score": 0.0005238266283524904,
        "precision": 0.0002752009233926129,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005440848214285714,
        "hf_subset": "spl_Latn-eng_Latn",
        "languages": [
          "spl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005440848214285714,
        "precision": 0.004764766483516484,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.030913360898969452,
        "hf_subset": "eng_Latn-spm_Latn",
        "languages": [
          "eng-Latn",
          "spm-Latn"
        ],
        "main_score": 0.030913360898969452,
        "precision": 0.02668574425475731,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.026106542397660817,
        "hf_subset": "spm_Latn-eng_Latn",
        "languages": [
          "spm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026106542397660817,
        "precision": 0.0237215356554856,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0047640931372549015,
        "hf_subset": "eng_Latn-spp_Latn",
        "languages": [
          "eng-Latn",
          "spp-Latn"
        ],
        "main_score": 0.0047640931372549015,
        "precision": 0.004378953520352035,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004709109450788973,
        "hf_subset": "spp_Latn-eng_Latn",
        "languages": [
          "spp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004709109450788973,
        "precision": 0.0043380358987603305,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007289411976911977,
        "hf_subset": "eng_Latn-sps_Latn",
        "languages": [
          "eng-Latn",
          "sps-Latn"
        ],
        "main_score": 0.007289411976911977,
        "precision": 0.004969970092737949,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016517857142857143,
        "hf_subset": "sps_Latn-eng_Latn",
        "languages": [
          "sps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016517857142857143,
        "precision": 0.016115640096618356,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.351027397260274e-05,
        "hf_subset": "eng_Latn-spy_Latn",
        "languages": [
          "eng-Latn",
          "spy-Latn"
        ],
        "main_score": 5.351027397260274e-05,
        "precision": 2.6939655172413793e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0024147124363327675,
        "hf_subset": "spy_Latn-eng_Latn",
        "languages": [
          "spy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0024147124363327675,
        "precision": 0.001544462481962482,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015557359307359306,
        "hf_subset": "eng_Latn-sri_Latn",
        "languages": [
          "eng-Latn",
          "sri-Latn"
        ],
        "main_score": 0.015557359307359306,
        "precision": 0.01438301282051282,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01767472065580618,
        "hf_subset": "sri_Latn-eng_Latn",
        "languages": [
          "sri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01767472065580618,
        "precision": 0.016800355222734258,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009548784168438773,
        "hf_subset": "eng_Latn-srm_Latn",
        "languages": [
          "eng-Latn",
          "srm-Latn"
        ],
        "main_score": 0.009548784168438773,
        "precision": 0.007728368265649422,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014779993587093629,
        "hf_subset": "srm_Latn-eng_Latn",
        "languages": [
          "srm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014779993587093629,
        "precision": 0.013905714054768332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03907459095678405,
        "hf_subset": "eng_Latn-srn_Latn",
        "languages": [
          "eng-Latn",
          "srn-Latn"
        ],
        "main_score": 0.03907459095678405,
        "precision": 0.031922348484848484,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04864002419149478,
        "hf_subset": "srn_Latn-eng_Latn",
        "languages": [
          "srn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04864002419149478,
        "precision": 0.04492714982759304,
        "recall": 0.078125
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.91015625,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ],
        "main_score": 0.91015625,
        "precision": 0.900390625,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9453125,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9453125,
        "precision": 0.939453125,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03399429258804258,
        "hf_subset": "eng_Latn-srq_Latn",
        "languages": [
          "eng-Latn",
          "srq-Latn"
        ],
        "main_score": 0.03399429258804258,
        "precision": 0.02960518438697318,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.039574142156862745,
        "hf_subset": "srq_Latn-eng_Latn",
        "languages": [
          "srq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.039574142156862745,
        "precision": 0.03526722301136363,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.023502066115702477,
        "hf_subset": "eng_Latn-ssd_Latn",
        "languages": [
          "eng-Latn",
          "ssd-Latn"
        ],
        "main_score": 0.023502066115702477,
        "precision": 0.02347005208333333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03135557432432433,
        "hf_subset": "ssd_Latn-eng_Latn",
        "languages": [
          "ssd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03135557432432433,
        "precision": 0.028048301940639266,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009033821202531645,
        "hf_subset": "eng_Latn-ssg_Latn",
        "languages": [
          "eng-Latn",
          "ssg-Latn"
        ],
        "main_score": 0.009033821202531645,
        "precision": 0.007465356763724598,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016320684523809526,
        "hf_subset": "ssg_Latn-eng_Latn",
        "languages": [
          "ssg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016320684523809526,
        "precision": 0.014996408045977011,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006401909722222222,
        "hf_subset": "eng_Latn-ssx_Latn",
        "languages": [
          "eng-Latn",
          "ssx-Latn"
        ],
        "main_score": 0.006401909722222222,
        "precision": 0.004564368206521739,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00785472972972973,
        "hf_subset": "ssx_Latn-eng_Latn",
        "languages": [
          "ssx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00785472972972973,
        "precision": 0.007833729619565216,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005729693292888439,
        "hf_subset": "eng_Latn-stp_Latn",
        "languages": [
          "eng-Latn",
          "stp-Latn"
        ],
        "main_score": 0.005729693292888439,
        "precision": 0.00417681277056277,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008381858178053831,
        "hf_subset": "stp_Latn-eng_Latn",
        "languages": [
          "stp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008381858178053831,
        "precision": 0.008115931919642856,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009975090579710145,
        "hf_subset": "eng_Latn-sua_Latn",
        "languages": [
          "eng-Latn",
          "sua-Latn"
        ],
        "main_score": 0.009975090579710145,
        "precision": 0.008269074675324676,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007076527316352897,
        "hf_subset": "sua_Latn-eng_Latn",
        "languages": [
          "sua-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007076527316352897,
        "precision": 0.005820072484639016,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009657078119249173,
        "hf_subset": "eng_Latn-sue_Latn",
        "languages": [
          "eng-Latn",
          "sue-Latn"
        ],
        "main_score": 0.009657078119249173,
        "precision": 0.00678879182297151,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008277778440921821,
        "hf_subset": "sue_Latn-eng_Latn",
        "languages": [
          "sue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008277778440921821,
        "precision": 0.006831320577722715,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008527930402930402,
        "hf_subset": "eng_Latn-sus_Arab",
        "languages": [
          "eng-Latn",
          "sus-Arab"
        ],
        "main_score": 0.008527930402930402,
        "precision": 0.005690104166666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001999627976190476,
        "hf_subset": "sus_Arab-eng_Latn",
        "languages": [
          "sus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.001999627976190476,
        "precision": 0.0012030117753623188,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014973958333333332,
        "hf_subset": "eng_Latn-suz_Latn",
        "languages": [
          "eng-Latn",
          "suz-Latn"
        ],
        "main_score": 0.014973958333333332,
        "precision": 0.013802083333333335,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008068875718390805,
        "hf_subset": "suz_Latn-eng_Latn",
        "languages": [
          "suz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008068875718390805,
        "precision": 0.006719680059523809,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.7906249999999999,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ],
        "main_score": 0.7906249999999999,
        "precision": 0.7705078125,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.8498697916666667,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.8498697916666667,
        "precision": 0.8376953125,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028190191010819623,
        "hf_subset": "eng_Latn-swh_Latn",
        "languages": [
          "eng-Latn",
          "swh-Latn"
        ],
        "main_score": 0.028190191010819623,
        "precision": 0.02483888722640219,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.023586452283425402,
        "hf_subset": "swh_Latn-eng_Latn",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023586452283425402,
        "precision": 0.020989301646629235,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010091145833333332,
        "hf_subset": "eng_Latn-swp_Latn",
        "languages": [
          "eng-Latn",
          "swp-Latn"
        ],
        "main_score": 0.010091145833333332,
        "precision": 0.007979910714285714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013523032200357782,
        "hf_subset": "swp_Latn-eng_Latn",
        "languages": [
          "swp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013523032200357782,
        "precision": 0.01281859946013289,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008452417425303452,
        "hf_subset": "eng_Latn-sxb_Latn",
        "languages": [
          "eng-Latn",
          "sxb-Latn"
        ],
        "main_score": 0.008452417425303452,
        "precision": 0.0065690189667542195,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021637524801587302,
        "hf_subset": "sxb_Latn-eng_Latn",
        "languages": [
          "sxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021637524801587302,
        "precision": 0.019690473172027434,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009731511304787166,
        "hf_subset": "eng_Latn-tac_Latn",
        "languages": [
          "eng-Latn",
          "tac-Latn"
        ],
        "main_score": 0.009731511304787166,
        "precision": 0.008879485308764533,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0011626825512181618,
        "hf_subset": "tac_Latn-eng_Latn",
        "languages": [
          "tac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011626825512181618,
        "precision": 0.0006114160559371775,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.028883280348124096,
        "hf_subset": "eng_Latn-taj_Deva",
        "languages": [
          "eng-Latn",
          "taj-Deva"
        ],
        "main_score": 0.028883280348124096,
        "precision": 0.024120855273199023,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.029795318613677988,
        "hf_subset": "taj_Deva-eng_Latn",
        "languages": [
          "taj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.029795318613677988,
        "precision": 0.02379888466708023,
        "recall": 0.0625
      },
      {
        "accuracy": 0.625,
        "f1": 0.5694010416666666,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.5694010416666666,
        "precision": 0.5472439236111111,
        "recall": 0.625
      },
      {
        "accuracy": 0.6484375,
        "f1": 0.6042534722222221,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.6042534722222221,
        "precision": 0.5865559895833333,
        "recall": 0.6484375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009130803780724665,
        "hf_subset": "eng_Latn-tav_Latn",
        "languages": [
          "eng-Latn",
          "tav-Latn"
        ],
        "main_score": 0.009130803780724665,
        "precision": 0.007506454772079772,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013473016275067947,
        "hf_subset": "tav_Latn-eng_Latn",
        "languages": [
          "tav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013473016275067947,
        "precision": 0.011951263691344128,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008928571428571428,
        "hf_subset": "eng_Latn-taw_Latn",
        "languages": [
          "eng-Latn",
          "taw-Latn"
        ],
        "main_score": 0.008928571428571428,
        "precision": 0.007291666666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010499778368794326,
        "hf_subset": "taw_Latn-eng_Latn",
        "languages": [
          "taw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010499778368794326,
        "precision": 0.009807627688172043,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01879504533456739,
        "hf_subset": "eng_Latn-tbc_Latn",
        "languages": [
          "eng-Latn",
          "tbc-Latn"
        ],
        "main_score": 0.01879504533456739,
        "precision": 0.016467055791290354,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010794270833333333,
        "hf_subset": "tbc_Latn-eng_Latn",
        "languages": [
          "tbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010794270833333333,
        "precision": 0.0094870531148152,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020800523999493413,
        "hf_subset": "eng_Latn-tbf_Latn",
        "languages": [
          "eng-Latn",
          "tbf-Latn"
        ],
        "main_score": 0.020800523999493413,
        "precision": 0.017863006275879917,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007018849206349207,
        "hf_subset": "tbf_Latn-eng_Latn",
        "languages": [
          "tbf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007018849206349207,
        "precision": 0.005699311633973884,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007657490079365078,
        "hf_subset": "eng_Latn-tbg_Latn",
        "languages": [
          "eng-Latn",
          "tbg-Latn"
        ],
        "main_score": 0.007657490079365078,
        "precision": 0.006492332175925926,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010228207236842105,
        "hf_subset": "tbg_Latn-eng_Latn",
        "languages": [
          "tbg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010228207236842105,
        "precision": 0.008440290178571428,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007389162561576354,
        "hf_subset": "eng_Latn-tbo_Latn",
        "languages": [
          "eng-Latn",
          "tbo-Latn"
        ],
        "main_score": 0.007389162561576354,
        "precision": 0.004756030701754386,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016589506172839507,
        "hf_subset": "tbo_Latn-eng_Latn",
        "languages": [
          "tbo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016589506172839507,
        "precision": 0.016162109375,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010586277876236892,
        "hf_subset": "eng_Latn-tbz_Latn",
        "languages": [
          "eng-Latn",
          "tbz-Latn"
        ],
        "main_score": 0.010586277876236892,
        "precision": 0.009851418331823843,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005326704545454545,
        "hf_subset": "tbz_Latn-eng_Latn",
        "languages": [
          "tbz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005326704545454545,
        "precision": 0.0002768549280177187,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008043014171511629,
        "hf_subset": "eng_Latn-tca_Latn",
        "languages": [
          "eng-Latn",
          "tca-Latn"
        ],
        "main_score": 0.008043014171511629,
        "precision": 0.007930073562443846,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004474431818181818,
        "hf_subset": "tca_Latn-eng_Latn",
        "languages": [
          "tca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004474431818181818,
        "precision": 0.004202685128518972,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.026860737269003395,
        "hf_subset": "eng_Latn-tcs_Latn",
        "languages": [
          "eng-Latn",
          "tcs-Latn"
        ],
        "main_score": 0.026860737269003395,
        "precision": 0.02314485704232694,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023259903785357416,
        "hf_subset": "tcs_Latn-eng_Latn",
        "languages": [
          "tcs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023259903785357416,
        "precision": 0.020467390682234434,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022540741840214346,
        "hf_subset": "eng_Latn-tcz_Latn",
        "languages": [
          "eng-Latn",
          "tcz-Latn"
        ],
        "main_score": 0.022540741840214346,
        "precision": 0.02169503563174114,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0150250204248366,
        "hf_subset": "tcz_Latn-eng_Latn",
        "languages": [
          "tcz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0150250204248366,
        "precision": 0.013827782346491228,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021214657738095236,
        "hf_subset": "eng_Latn-tdt_Latn",
        "languages": [
          "eng-Latn",
          "tdt-Latn"
        ],
        "main_score": 0.021214657738095236,
        "precision": 0.018134014423076925,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.012720621871292408,
        "hf_subset": "tdt_Latn-eng_Latn",
        "languages": [
          "tdt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012720621871292408,
        "precision": 0.00957280631805588,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.02473958333333333,
        "hf_subset": "eng_Latn-tee_Latn",
        "languages": [
          "eng-Latn",
          "tee-Latn"
        ],
        "main_score": 0.02473958333333333,
        "precision": 0.0234375,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00965989013077859,
        "hf_subset": "tee_Latn-eng_Latn",
        "languages": [
          "tee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00965989013077859,
        "precision": 0.008882889093137255,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.625,
        "f1": 0.5595052083333333,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.5595052083333333,
        "precision": 0.5347656249999999,
        "recall": 0.625
      },
      {
        "accuracy": 0.62890625,
        "f1": 0.5856894452530228,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.5856894452530228,
        "precision": 0.5712983630952381,
        "recall": 0.62890625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-ter_Latn",
        "languages": [
          "eng-Latn",
          "ter-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.979885057471264e-05,
        "hf_subset": "ter_Latn-eng_Latn",
        "languages": [
          "ter-Latn",
          "eng-Latn"
        ],
        "main_score": 8.979885057471264e-05,
        "precision": 4.5421511627906976e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014371432322275913,
        "hf_subset": "eng_Latn-tet_Latn",
        "languages": [
          "eng-Latn",
          "tet-Latn"
        ],
        "main_score": 0.014371432322275913,
        "precision": 0.012160391051912568,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0087802602944808,
        "hf_subset": "tet_Latn-eng_Latn",
        "languages": [
          "tet-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0087802602944808,
        "precision": 0.0068592829335016835,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.032648415585553994,
        "hf_subset": "eng_Latn-tew_Latn",
        "languages": [
          "eng-Latn",
          "tew-Latn"
        ],
        "main_score": 0.032648415585553994,
        "precision": 0.030025112400032476,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04811580882352941,
        "hf_subset": "tew_Latn-eng_Latn",
        "languages": [
          "tew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04811580882352941,
        "precision": 0.045600043402777776,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013958643353174604,
        "hf_subset": "eng_Latn-tfr_Latn",
        "languages": [
          "eng-Latn",
          "tfr-Latn"
        ],
        "main_score": 0.013958643353174604,
        "precision": 0.013166949067719057,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021448863636363637,
        "hf_subset": "tfr_Latn-eng_Latn",
        "languages": [
          "tfr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021448863636363637,
        "precision": 0.01939174107142857,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014581360479797979,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ],
        "main_score": 0.014581360479797979,
        "precision": 0.010977415054563492,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0031318530701754384,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0031318530701754384,
        "precision": 0.002228471569548872,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.06736207674668228,
        "hf_subset": "eng_Latn-tgl_Latn",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ],
        "main_score": 0.06736207674668228,
        "precision": 0.06066400548485677,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.1394985945767196,
        "hf_subset": "tgl_Latn-eng_Latn",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1394985945767196,
        "precision": 0.1291622934473566,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009017301245210727,
        "hf_subset": "eng_Latn-tgo_Latn",
        "languages": [
          "eng-Latn",
          "tgo-Latn"
        ],
        "main_score": 0.0009017301245210727,
        "precision": 0.0005051914231601731,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008163367599883347,
        "hf_subset": "tgo_Latn-eng_Latn",
        "languages": [
          "tgo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008163367599883347,
        "precision": 0.006691659035409035,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03861009916051885,
        "hf_subset": "eng_Latn-tgp_Latn",
        "languages": [
          "eng-Latn",
          "tgp-Latn"
        ],
        "main_score": 0.03861009916051885,
        "precision": 0.034882023358585854,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04136070388128114,
        "hf_subset": "tgp_Latn-eng_Latn",
        "languages": [
          "tgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04136070388128114,
        "precision": 0.037281974467418544,
        "recall": 0.0625
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8958333333333334,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ],
        "main_score": 0.8958333333333334,
        "precision": 0.884765625,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8912760416666666,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 0.8912760416666666,
        "precision": 0.8782552083333333,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006751760263229678,
        "hf_subset": "eng_Latn-tif_Latn",
        "languages": [
          "eng-Latn",
          "tif-Latn"
        ],
        "main_score": 0.006751760263229678,
        "precision": 0.005982218235542423,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007990597627876458,
        "hf_subset": "tif_Latn-eng_Latn",
        "languages": [
          "tif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007990597627876458,
        "precision": 0.006478740726363009,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007211861559139785,
        "hf_subset": "eng_Latn-tim_Latn",
        "languages": [
          "eng-Latn",
          "tim-Latn"
        ],
        "main_score": 0.007211861559139785,
        "precision": 0.005233698593073592,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02324345454044702,
        "hf_subset": "tim_Latn-eng_Latn",
        "languages": [
          "tim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02324345454044702,
        "precision": 0.022069188328953958,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.037209302325581395,
        "f1": 0.01805761724118973,
        "hf_subset": "eng_Latn-tiw_Latn",
        "languages": [
          "eng-Latn",
          "tiw-Latn"
        ],
        "main_score": 0.01805761724118973,
        "precision": 0.015055549601686136,
        "recall": 0.037209302325581395
      },
      {
        "accuracy": 0.03255813953488372,
        "f1": 0.030232558139534883,
        "hf_subset": "tiw_Latn-eng_Latn",
        "languages": [
          "tiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030232558139534883,
        "precision": 0.02945736434108527,
        "recall": 0.03255813953488372
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00420337854969574,
        "hf_subset": "eng_Latn-tiy_Latn",
        "languages": [
          "eng-Latn",
          "tiy-Latn"
        ],
        "main_score": 0.00420337854969574,
        "precision": 0.00405858860342556,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01075268817204301,
        "hf_subset": "tiy_Latn-eng_Latn",
        "languages": [
          "tiy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01075268817204301,
        "precision": 0.008636209239130435,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.004947045707915273,
        "hf_subset": "eng_Latn-tke_Latn",
        "languages": [
          "eng-Latn",
          "tke-Latn"
        ],
        "main_score": 0.004947045707915273,
        "precision": 0.0027540660532987898,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.00785024154589372,
        "hf_subset": "tke_Latn-eng_Latn",
        "languages": [
          "tke-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00785024154589372,
        "precision": 0.005745341614906832,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012215377938034188,
        "hf_subset": "eng_Latn-tku_Latn",
        "languages": [
          "eng-Latn",
          "tku-Latn"
        ],
        "main_score": 0.012215377938034188,
        "precision": 0.010729557780559031,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02581155568287921,
        "hf_subset": "tku_Latn-eng_Latn",
        "languages": [
          "tku-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02581155568287921,
        "precision": 0.0227273539624183,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-tlf_Latn",
        "languages": [
          "eng-Latn",
          "tlf-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.002734375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005435631316676025,
        "hf_subset": "tlf_Latn-eng_Latn",
        "languages": [
          "tlf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005435631316676025,
        "precision": 0.004749418397166558,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007669420498084291,
        "hf_subset": "eng_Latn-tmd_Latn",
        "languages": [
          "eng-Latn",
          "tmd-Latn"
        ],
        "main_score": 0.007669420498084291,
        "precision": 0.006495906339509488,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003959396258503401,
        "hf_subset": "tmd_Latn-eng_Latn",
        "languages": [
          "tmd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003959396258503401,
        "precision": 0.0039330051369863015,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029057298791609665,
        "hf_subset": "eng_Latn-tna_Latn",
        "languages": [
          "eng-Latn",
          "tna-Latn"
        ],
        "main_score": 0.029057298791609665,
        "precision": 0.027169426009039977,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013999118165784832,
        "hf_subset": "tna_Latn-eng_Latn",
        "languages": [
          "tna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013999118165784832,
        "precision": 0.01079604272539055,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006512701023391813,
        "hf_subset": "eng_Latn-tnc_Latn",
        "languages": [
          "eng-Latn",
          "tnc-Latn"
        ],
        "main_score": 0.006512701023391813,
        "precision": 0.0055486942153839276,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006033350840336135,
        "hf_subset": "tnc_Latn-eng_Latn",
        "languages": [
          "tnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006033350840336135,
        "precision": 0.005109690656565657,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015292433261183262,
        "hf_subset": "eng_Latn-tnk_Latn",
        "languages": [
          "eng-Latn",
          "tnk-Latn"
        ],
        "main_score": 0.015292433261183262,
        "precision": 0.01391562624601276,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015470377604166669,
        "hf_subset": "tnk_Latn-eng_Latn",
        "languages": [
          "tnk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015470377604166669,
        "precision": 0.01275952097039687,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0027976778656126485,
        "hf_subset": "eng_Latn-tnn_Latn",
        "languages": [
          "eng-Latn",
          "tnn-Latn"
        ],
        "main_score": 0.0027976778656126485,
        "precision": 0.0016663031951286262,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018984858532272324,
        "hf_subset": "tnn_Latn-eng_Latn",
        "languages": [
          "tnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018984858532272324,
        "precision": 0.017976404078377764,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013726128472222222,
        "hf_subset": "eng_Latn-tnp_Latn",
        "languages": [
          "eng-Latn",
          "tnp-Latn"
        ],
        "main_score": 0.013726128472222222,
        "precision": 0.010574191433566433,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010639880952380951,
        "hf_subset": "tnp_Latn-eng_Latn",
        "languages": [
          "tnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010639880952380951,
        "precision": 0.008672606436642454,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013117185653727992,
        "hf_subset": "eng_Latn-toc_Latn",
        "languages": [
          "eng-Latn",
          "toc-Latn"
        ],
        "main_score": 0.013117185653727992,
        "precision": 0.012492856064527259,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0039519371345029235,
        "hf_subset": "toc_Latn-eng_Latn",
        "languages": [
          "toc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0039519371345029235,
        "precision": 0.0039292279411764705,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02854205827067669,
        "hf_subset": "eng_Latn-tod_Latn",
        "languages": [
          "eng-Latn",
          "tod-Latn"
        ],
        "main_score": 0.02854205827067669,
        "precision": 0.026864472517730494,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.007106807324356542,
        "hf_subset": "tod_Latn-eng_Latn",
        "languages": [
          "tod-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007106807324356542,
        "precision": 0.004434199697871573,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013257998511904762,
        "hf_subset": "eng_Latn-tof_Latn",
        "languages": [
          "eng-Latn",
          "tof-Latn"
        ],
        "main_score": 0.013257998511904762,
        "precision": 0.011432973347035847,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014107483802893823,
        "hf_subset": "tof_Latn-eng_Latn",
        "languages": [
          "tof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014107483802893823,
        "precision": 0.013243306162925695,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019586619448010576,
        "hf_subset": "eng_Latn-toj_Latn",
        "languages": [
          "eng-Latn",
          "toj-Latn"
        ],
        "main_score": 0.019586619448010576,
        "precision": 0.01728945500137806,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015041307471264366,
        "hf_subset": "toj_Latn-eng_Latn",
        "languages": [
          "toj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015041307471264366,
        "precision": 0.012664175724637681,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007852770618556701,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ],
        "main_score": 0.007852770618556701,
        "precision": 0.0078327396373057,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011369110880127067,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011369110880127067,
        "precision": 0.010279830549664193,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014973958333333332,
        "hf_subset": "eng_Latn-too_Latn",
        "languages": [
          "eng-Latn",
          "too-Latn"
        ],
        "main_score": 0.014973958333333332,
        "precision": 0.012713320035460994,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018618095808883163,
        "hf_subset": "too_Latn-eng_Latn",
        "languages": [
          "too-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018618095808883163,
        "precision": 0.01554926424860989,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.030327690972222224,
        "hf_subset": "eng_Latn-top_Latn",
        "languages": [
          "eng-Latn",
          "top-Latn"
        ],
        "main_score": 0.030327690972222224,
        "precision": 0.02826228487318841,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013291114267676768,
        "hf_subset": "top_Latn-eng_Latn",
        "languages": [
          "top-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013291114267676768,
        "precision": 0.01096864991626021,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015099966397849463,
        "hf_subset": "eng_Latn-tos_Latn",
        "languages": [
          "eng-Latn",
          "tos-Latn"
        ],
        "main_score": 0.015099966397849463,
        "precision": 0.012677033772219081,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016952517254055593,
        "hf_subset": "tos_Latn-eng_Latn",
        "languages": [
          "tos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016952517254055593,
        "precision": 0.015052597512582267,
        "recall": 0.03125
      },
      {
        "accuracy": 0.09219858156028368,
        "f1": 0.051400530123934376,
        "hf_subset": "eng_Latn-tpa_Latn",
        "languages": [
          "eng-Latn",
          "tpa-Latn"
        ],
        "main_score": 0.051400530123934376,
        "precision": 0.045673209082412444,
        "recall": 0.09219858156028368
      },
      {
        "accuracy": 0.1276595744680851,
        "f1": 0.08487204138841052,
        "hf_subset": "tpa_Latn-eng_Latn",
        "languages": [
          "tpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08487204138841052,
        "precision": 0.07810232517679326,
        "recall": 0.1276595744680851
      },
      {
        "accuracy": 0.046875,
        "f1": 0.01723286169308688,
        "hf_subset": "eng_Latn-tpi_Latn",
        "languages": [
          "eng-Latn",
          "tpi-Latn"
        ],
        "main_score": 0.01723286169308688,
        "precision": 0.014864834428615616,
        "recall": 0.046875
      },
      {
        "accuracy": 0.078125,
        "f1": 0.03561356901200651,
        "hf_subset": "tpi_Latn-eng_Latn",
        "languages": [
          "tpi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03561356901200651,
        "precision": 0.02847068138002049,
        "recall": 0.078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028915624085455074,
        "hf_subset": "eng_Latn-tpt_Latn",
        "languages": [
          "eng-Latn",
          "tpt-Latn"
        ],
        "main_score": 0.028915624085455074,
        "precision": 0.02617897727272727,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021601228632478632,
        "hf_subset": "tpt_Latn-eng_Latn",
        "languages": [
          "tpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021601228632478632,
        "precision": 0.019542100694444446,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018986742424242423,
        "hf_subset": "eng_Latn-tpz_Latn",
        "languages": [
          "eng-Latn",
          "tpz-Latn"
        ],
        "main_score": 0.018986742424242423,
        "precision": 0.017979213169642856,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008181316707717571,
        "hf_subset": "tpz_Latn-eng_Latn",
        "languages": [
          "tpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008181316707717571,
        "precision": 0.008002597437553834,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.028705018939393936,
        "hf_subset": "eng_Latn-trc_Latn",
        "languages": [
          "eng-Latn",
          "trc-Latn"
        ],
        "main_score": 0.028705018939393936,
        "precision": 0.02591145833333333,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015083874458874458,
        "hf_subset": "trc_Latn-eng_Latn",
        "languages": [
          "trc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015083874458874458,
        "precision": 0.014088031045751634,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0053751895405858814,
        "hf_subset": "eng_Latn-tsw_Latn",
        "languages": [
          "eng-Latn",
          "tsw-Latn"
        ],
        "main_score": 0.0053751895405858814,
        "precision": 0.004739550493905002,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01038214172979798,
        "hf_subset": "tsw_Latn-eng_Latn",
        "languages": [
          "tsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01038214172979798,
        "precision": 0.009233835935435112,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.006964482312233837,
        "hf_subset": "eng_Latn-ttc_Latn",
        "languages": [
          "eng-Latn",
          "ttc-Latn"
        ],
        "main_score": 0.006964482312233837,
        "precision": 0.004403734286546787,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015502232142857142,
        "hf_subset": "ttc_Latn-eng_Latn",
        "languages": [
          "ttc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015502232142857142,
        "precision": 0.014302020524118737,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002943840579710145,
        "hf_subset": "eng_Latn-tte_Latn",
        "languages": [
          "eng-Latn",
          "tte-Latn"
        ],
        "main_score": 0.002943840579710145,
        "precision": 0.002130681818181818,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009423828125,
        "hf_subset": "tte_Latn-eng_Latn",
        "languages": [
          "tte-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009423828125,
        "precision": 0.008813630110062894,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01645868288590604,
        "hf_subset": "eng_Latn-tuc_Latn",
        "languages": [
          "eng-Latn",
          "tuc-Latn"
        ],
        "main_score": 0.01645868288590604,
        "precision": 0.014893234714086007,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005768795289855072,
        "hf_subset": "tuc_Latn-eng_Latn",
        "languages": [
          "tuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005768795289855072,
        "precision": 0.004198647660818714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02086433531746032,
        "hf_subset": "eng_Latn-tue_Latn",
        "languages": [
          "eng-Latn",
          "tue-Latn"
        ],
        "main_score": 0.02086433531746032,
        "precision": 0.01884765625,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025872564935064936,
        "hf_subset": "tue_Latn-eng_Latn",
        "languages": [
          "tue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025872564935064936,
        "precision": 0.022741977782456457,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003941923515981735,
        "hf_subset": "eng_Latn-tuf_Latn",
        "languages": [
          "eng-Latn",
          "tuf-Latn"
        ],
        "main_score": 0.003941923515981735,
        "precision": 0.003924168577981652,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016240354157036615,
        "hf_subset": "tuf_Latn-eng_Latn",
        "languages": [
          "tuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016240354157036615,
        "precision": 0.013691427387716452,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.025651041666666666,
        "hf_subset": "eng_Latn-tuo_Latn",
        "languages": [
          "eng-Latn",
          "tuo-Latn"
        ],
        "main_score": 0.025651041666666666,
        "precision": 0.023763020833333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.0321113782051282,
        "hf_subset": "tuo_Latn-eng_Latn",
        "languages": [
          "tuo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0321113782051282,
        "precision": 0.0291311553030303,
        "recall": 0.046875
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.7945312499999999,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.7945312499999999,
        "precision": 0.7750651041666667,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.81640625,
        "f1": 0.767578125,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.767578125,
        "precision": 0.7449218750000001,
        "recall": 0.81640625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011217447916666666,
        "hf_subset": "eng_Latn-tvk_Latn",
        "languages": [
          "eng-Latn",
          "tvk-Latn"
        ],
        "main_score": 0.011217447916666666,
        "precision": 0.010188802083333334,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013034142354124749,
        "hf_subset": "tvk_Latn-eng_Latn",
        "languages": [
          "tvk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013034142354124749,
        "precision": 0.012427954084713597,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01699067947978898,
        "hf_subset": "eng_Latn-twi_Latn",
        "languages": [
          "eng-Latn",
          "twi-Latn"
        ],
        "main_score": 0.01699067947978898,
        "precision": 0.014026510740165633,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029140559321143338,
        "hf_subset": "twi_Latn-eng_Latn",
        "languages": [
          "twi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029140559321143338,
        "precision": 0.027189852051357735,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015330816307378807,
        "hf_subset": "eng_Latn-txq_Latn",
        "languages": [
          "eng-Latn",
          "txq-Latn"
        ],
        "main_score": 0.015330816307378807,
        "precision": 0.011965741430420129,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02058681241765481,
        "hf_subset": "txq_Latn-eng_Latn",
        "languages": [
          "txq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02058681241765481,
        "precision": 0.018692310293872794,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002663352272727273,
        "hf_subset": "eng_Latn-txu_Latn",
        "languages": [
          "eng-Latn",
          "txu-Latn"
        ],
        "main_score": 0.002663352272727273,
        "precision": 0.0016927083333333334,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013605370743727599,
        "hf_subset": "txu_Latn-eng_Latn",
        "languages": [
          "txu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013605370743727599,
        "precision": 0.012786181829150579,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023108704936100483,
        "hf_subset": "eng_Latn-tzj_Latn",
        "languages": [
          "eng-Latn",
          "tzj-Latn"
        ],
        "main_score": 0.023108704936100483,
        "precision": 0.020522654710807768,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03141834798357328,
        "hf_subset": "tzj_Latn-eng_Latn",
        "languages": [
          "tzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03141834798357328,
        "precision": 0.027459460346638657,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.023108466248341442,
        "hf_subset": "eng_Latn-tzo_Latn",
        "languages": [
          "eng-Latn",
          "tzo-Latn"
        ],
        "main_score": 0.023108466248341442,
        "precision": 0.017988763906308065,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00455442553562257,
        "hf_subset": "tzo_Latn-eng_Latn",
        "languages": [
          "tzo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00455442553562257,
        "precision": 0.0030684703763569606,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02533487232102143,
        "hf_subset": "eng_Latn-ubr_Latn",
        "languages": [
          "eng-Latn",
          "ubr-Latn"
        ],
        "main_score": 0.02533487232102143,
        "precision": 0.02263206845238095,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04272710945663532,
        "hf_subset": "ubr_Latn-eng_Latn",
        "languages": [
          "ubr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04272710945663532,
        "precision": 0.039173025678294573,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002438562776613091,
        "hf_subset": "eng_Latn-ubu_Latn",
        "languages": [
          "eng-Latn",
          "ubu-Latn"
        ],
        "main_score": 0.0002438562776613091,
        "precision": 0.0001239483173076923,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010817307692307693,
        "hf_subset": "ubu_Latn-eng_Latn",
        "languages": [
          "ubu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010817307692307693,
        "precision": 0.0005902777777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003254274270683883,
        "hf_subset": "eng_Latn-udu_Latn",
        "languages": [
          "eng-Latn",
          "udu-Latn"
        ],
        "main_score": 0.003254274270683883,
        "precision": 0.002294921875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0029733669803683467,
        "hf_subset": "udu_Latn-eng_Latn",
        "languages": [
          "udu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029733669803683467,
        "precision": 0.002140760121855346,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.04547572212098165,
        "hf_subset": "eng_Latn-uig_Latn",
        "languages": [
          "eng-Latn",
          "uig-Latn"
        ],
        "main_score": 0.04547572212098165,
        "precision": 0.03789752026888342,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.0575584508977202,
        "hf_subset": "uig_Latn-eng_Latn",
        "languages": [
          "uig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0575584508977202,
        "precision": 0.05258744636579818,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.943359375,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ],
        "main_score": 0.943359375,
        "precision": 0.9368489583333334,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.921875,
        "f1": 0.8977864583333333,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.8977864583333333,
        "precision": 0.8860677083333334,
        "recall": 0.921875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.027515430588544915,
        "hf_subset": "eng_Latn-uli_Latn",
        "languages": [
          "eng-Latn",
          "uli-Latn"
        ],
        "main_score": 0.027515430588544915,
        "precision": 0.023652733508869178,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03819768598928933,
        "hf_subset": "uli_Latn-eng_Latn",
        "languages": [
          "uli-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03819768598928933,
        "precision": 0.03467939843406895,
        "recall": 0.0625
      },
      {
        "accuracy": 0.04712041884816754,
        "f1": 0.02367717831222605,
        "hf_subset": "eng_Latn-ulk_Latn",
        "languages": [
          "eng-Latn",
          "ulk-Latn"
        ],
        "main_score": 0.02367717831222605,
        "precision": 0.020863141432760232,
        "recall": 0.04712041884816754
      },
      {
        "accuracy": 0.05759162303664921,
        "f1": 0.027232180469226864,
        "hf_subset": "ulk_Latn-eng_Latn",
        "languages": [
          "ulk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027232180469226864,
        "precision": 0.021797622328071486,
        "recall": 0.05759162303664921
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019380868544600936,
        "hf_subset": "eng_Latn-upv_Latn",
        "languages": [
          "eng-Latn",
          "upv-Latn"
        ],
        "main_score": 0.019380868544600936,
        "precision": 0.016570560515873016,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01451727525946276,
        "hf_subset": "upv_Latn-eng_Latn",
        "languages": [
          "upv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01451727525946276,
        "precision": 0.012549967903828197,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009837299311926605,
        "hf_subset": "eng_Latn-ura_Latn",
        "languages": [
          "eng-Latn",
          "ura-Latn"
        ],
        "main_score": 0.009837299311926605,
        "precision": 0.009150752314814815,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004410708248816769,
        "hf_subset": "ura_Latn-eng_Latn",
        "languages": [
          "ura-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004410708248816769,
        "precision": 0.004172970104768786,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008643830128205129,
        "hf_subset": "eng_Latn-urb_Latn",
        "languages": [
          "eng-Latn",
          "urb-Latn"
        ],
        "main_score": 0.008643830128205129,
        "precision": 0.008271729390681003,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002247643849206349,
        "hf_subset": "urb_Latn-eng_Latn",
        "languages": [
          "urb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002247643849206349,
        "precision": 0.00011436170212765957,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.013311530374483273,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.013311530374483273,
        "precision": 0.009861801609848484,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023422332095920387,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.023422332095920387,
        "precision": 0.022159032619306795,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.027777777777777776,
        "f1": 0.007254022850767878,
        "hf_subset": "eng_Latn-uri_Latn",
        "languages": [
          "eng-Latn",
          "uri-Latn"
        ],
        "main_score": 0.007254022850767878,
        "precision": 0.0058165146400440525,
        "recall": 0.027777777777777776
      },
      {
        "accuracy": 0.031746031746031744,
        "f1": 0.02314983275248176,
        "hf_subset": "uri_Latn-eng_Latn",
        "languages": [
          "uri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02314983275248176,
        "precision": 0.022182539682539682,
        "recall": 0.031746031746031744
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010999211641852772,
        "hf_subset": "eng_Latn-urt_Latn",
        "languages": [
          "eng-Latn",
          "urt-Latn"
        ],
        "main_score": 0.010999211641852772,
        "precision": 0.007828490497076023,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015606498281130633,
        "hf_subset": "urt_Latn-eng_Latn",
        "languages": [
          "urt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015606498281130633,
        "precision": 0.012862194709820248,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.1,
        "f1": 0.04754930254930254,
        "hf_subset": "eng_Latn-urw_Latn",
        "languages": [
          "eng-Latn",
          "urw-Latn"
        ],
        "main_score": 0.04754930254930254,
        "precision": 0.04145502645502645,
        "recall": 0.1
      },
      {
        "accuracy": 0.1111111111111111,
        "f1": 0.06578347578347579,
        "hf_subset": "urw_Latn-eng_Latn",
        "languages": [
          "urw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06578347578347579,
        "precision": 0.058576998050682255,
        "recall": 0.1111111111111111
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-usa_Latn",
        "languages": [
          "eng-Latn",
          "usa-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006510416666666666,
        "hf_subset": "usa_Latn-eng_Latn",
        "languages": [
          "usa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.0003551136363636364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010696663533834586,
        "hf_subset": "eng_Latn-usp_Latn",
        "languages": [
          "eng-Latn",
          "usp-Latn"
        ],
        "main_score": 0.010696663533834586,
        "precision": 0.009908759420478171,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01092176053113553,
        "hf_subset": "usp_Latn-eng_Latn",
        "languages": [
          "usp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01092176053113553,
        "precision": 0.008825383771929823,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007720865142740142,
        "hf_subset": "eng_Latn-uvh_Latn",
        "languages": [
          "eng-Latn",
          "uvh-Latn"
        ],
        "main_score": 0.007720865142740142,
        "precision": 0.006267675339366515,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "uvh_Latn-eng_Latn",
        "languages": [
          "uvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008266387836700336,
        "hf_subset": "eng_Latn-uvl_Latn",
        "languages": [
          "eng-Latn",
          "uvl-Latn"
        ],
        "main_score": 0.008266387836700336,
        "precision": 0.005519171205490246,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00682827818627451,
        "hf_subset": "uvl_Latn-eng_Latn",
        "languages": [
          "uvl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00682827818627451,
        "precision": 0.005692997685185185,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007890817943715107,
        "hf_subset": "eng_Latn-vid_Latn",
        "languages": [
          "eng-Latn",
          "vid-Latn"
        ],
        "main_score": 0.007890817943715107,
        "precision": 0.006612570353963362,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005805727481237424,
        "hf_subset": "vid_Latn-eng_Latn",
        "languages": [
          "vid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005805727481237424,
        "precision": 0.0050541066657718466,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9583333333333334,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ],
        "main_score": 0.9583333333333334,
        "precision": 0.953125,
        "recall": 0.96875
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.912109375,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.912109375,
        "precision": 0.9016927083333334,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-viv_Latn",
        "languages": [
          "eng-Latn",
          "viv-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008213141025641026,
        "hf_subset": "viv_Latn-eng_Latn",
        "languages": [
          "viv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008213141025641026,
        "precision": 0.00045416308705612825,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016666666666666666,
        "hf_subset": "eng_Latn-vmy_Latn",
        "languages": [
          "eng-Latn",
          "vmy-Latn"
        ],
        "main_score": 0.016666666666666666,
        "precision": 0.014691840277777778,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023140440854435416,
        "hf_subset": "vmy_Latn-eng_Latn",
        "languages": [
          "vmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023140440854435416,
        "precision": 0.019290769537480063,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003662109375,
        "hf_subset": "eng_Latn-waj_Latn",
        "languages": [
          "eng-Latn",
          "waj-Latn"
        ],
        "main_score": 0.0003662109375,
        "precision": 0.00018801203277009728,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005403645833333333,
        "hf_subset": "waj_Latn-eng_Latn",
        "languages": [
          "waj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005403645833333333,
        "precision": 0.004787660256410257,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00488587382445141,
        "hf_subset": "eng_Latn-wal_Ethi",
        "languages": [
          "eng-Latn",
          "wal-Ethi"
        ],
        "main_score": 0.00488587382445141,
        "precision": 0.003424535964194838,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00427827380952381,
        "hf_subset": "wal_Ethi-eng_Latn",
        "languages": [
          "wal-Ethi",
          "eng-Latn"
        ],
        "main_score": 0.00427827380952381,
        "precision": 0.0041015625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.037507181301403,
        "hf_subset": "eng_Latn-wap_Latn",
        "languages": [
          "eng-Latn",
          "wap-Latn"
        ],
        "main_score": 0.037507181301403,
        "precision": 0.03325247479300214,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03785652616695698,
        "hf_subset": "wap_Latn-eng_Latn",
        "languages": [
          "wap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03785652616695698,
        "precision": 0.034421496706830694,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011828449328449328,
        "hf_subset": "eng_Latn-wat_Latn",
        "languages": [
          "eng-Latn",
          "wat-Latn"
        ],
        "main_score": 0.0011828449328449328,
        "precision": 0.0006847162356321838,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0007573787889845764,
        "hf_subset": "wat_Latn-eng_Latn",
        "languages": [
          "wat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007573787889845764,
        "precision": 0.0003892721861471862,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014787946428571428,
        "hf_subset": "eng_Latn-wbi_Latn",
        "languages": [
          "eng-Latn",
          "wbi-Latn"
        ],
        "main_score": 0.014787946428571428,
        "precision": 0.013671875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009243241567460318,
        "hf_subset": "wbi_Latn-eng_Latn",
        "languages": [
          "wbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009243241567460318,
        "precision": 0.0075142956002331,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007352570564516129,
        "hf_subset": "eng_Latn-wbp_Latn",
        "languages": [
          "eng-Latn",
          "wbp-Latn"
        ],
        "main_score": 0.007352570564516129,
        "precision": 0.0063113511518616385,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004160402348224512,
        "hf_subset": "wbp_Latn-eng_Latn",
        "languages": [
          "wbp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004160402348224512,
        "precision": 0.002863843513257576,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04087357231888481,
        "hf_subset": "eng_Latn-wed_Latn",
        "languages": [
          "eng-Latn",
          "wed-Latn"
        ],
        "main_score": 0.04087357231888481,
        "precision": 0.03419041895604395,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.058895596590909094,
        "hf_subset": "wed_Latn-eng_Latn",
        "languages": [
          "wed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.058895596590909094,
        "precision": 0.05199726018111092,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0075233360389610395,
        "hf_subset": "eng_Latn-wer_Latn",
        "languages": [
          "eng-Latn",
          "wer-Latn"
        ],
        "main_score": 0.0075233360389610395,
        "precision": 0.006236293859649122,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0034503984570802004,
        "hf_subset": "wer_Latn-eng_Latn",
        "languages": [
          "wer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0034503984570802004,
        "precision": 0.0021488875288018434,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03371240304834055,
        "hf_subset": "eng_Latn-wim_Latn",
        "languages": [
          "eng-Latn",
          "wim-Latn"
        ],
        "main_score": 0.03371240304834055,
        "precision": 0.0304690836681053,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03639365192099567,
        "hf_subset": "wim_Latn-eng_Latn",
        "languages": [
          "wim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03639365192099567,
        "precision": 0.031901041666666664,
        "recall": 0.0625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0074148094315245475,
        "hf_subset": "eng_Latn-wiu_Latn",
        "languages": [
          "eng-Latn",
          "wiu-Latn"
        ],
        "main_score": 0.0074148094315245475,
        "precision": 0.005975284754672897,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003995028409090909,
        "hf_subset": "wiu_Latn-eng_Latn",
        "languages": [
          "wiu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003995028409090909,
        "precision": 0.003951149425287357,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.021459825917546506,
        "hf_subset": "eng_Latn-wiv_Latn",
        "languages": [
          "eng-Latn",
          "wiv-Latn"
        ],
        "main_score": 0.021459825917546506,
        "precision": 0.01585616874216792,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014391648190990296,
        "hf_subset": "wiv_Latn-eng_Latn",
        "languages": [
          "wiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014391648190990296,
        "precision": 0.012460078554472764,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007531530969030969,
        "hf_subset": "eng_Latn-wmt_Latn",
        "languages": [
          "eng-Latn",
          "wmt-Latn"
        ],
        "main_score": 0.0007531530969030969,
        "precision": 0.0004122064917127072,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.616898148148148e-05,
        "hf_subset": "wmt_Latn-eng_Latn",
        "languages": [
          "wmt-Latn",
          "eng-Latn"
        ],
        "main_score": 3.616898148148148e-05,
        "precision": 1.816860465116279e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.021423585095460097,
        "hf_subset": "eng_Latn-wmw_Latn",
        "languages": [
          "eng-Latn",
          "wmw-Latn"
        ],
        "main_score": 0.021423585095460097,
        "precision": 0.017847603785103784,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011005704365079364,
        "hf_subset": "wmw_Latn-eng_Latn",
        "languages": [
          "wmw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011005704365079364,
        "precision": 0.009828629032258064,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002636854951185495,
        "hf_subset": "eng_Latn-wnc_Latn",
        "languages": [
          "eng-Latn",
          "wnc-Latn"
        ],
        "main_score": 0.002636854951185495,
        "precision": 0.0019695378151260504,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003966812015503876,
        "hf_subset": "wnc_Latn-eng_Latn",
        "languages": [
          "wnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003966812015503876,
        "precision": 0.003936767578125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006971047079724627,
        "hf_subset": "eng_Latn-wnu_Latn",
        "languages": [
          "eng-Latn",
          "wnu-Latn"
        ],
        "main_score": 0.006971047079724627,
        "precision": 0.004799186128803963,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01143002219043427,
        "hf_subset": "wnu_Latn-eng_Latn",
        "languages": [
          "wnu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01143002219043427,
        "precision": 0.010317460317460317,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008526792134023584,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ],
        "main_score": 0.008526792134023584,
        "precision": 0.007074414300976801,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013569671563192904,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013569671563192904,
        "precision": 0.011719766458495965,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011083835832246848,
        "hf_subset": "eng_Latn-wos_Latn",
        "languages": [
          "eng-Latn",
          "wos-Latn"
        ],
        "main_score": 0.011083835832246848,
        "precision": 0.010124532585470084,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00642510775862069,
        "hf_subset": "wos_Latn-eng_Latn",
        "languages": [
          "wos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00642510775862069,
        "precision": 0.005509930670244976,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006613212719298245,
        "hf_subset": "eng_Latn-wrk_Latn",
        "languages": [
          "eng-Latn",
          "wrk-Latn"
        ],
        "main_score": 0.006613212719298245,
        "precision": 0.005911458333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019940856777493606,
        "hf_subset": "wrk_Latn-eng_Latn",
        "languages": [
          "wrk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019940856777493606,
        "precision": 0.0012006222943722945,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.036438118732616015,
        "hf_subset": "eng_Latn-wro_Latn",
        "languages": [
          "eng-Latn",
          "wro-Latn"
        ],
        "main_score": 0.036438118732616015,
        "precision": 0.03125405914740944,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06217861622073578,
        "hf_subset": "wro_Latn-eng_Latn",
        "languages": [
          "wro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06217861622073578,
        "precision": 0.05442696002998737,
        "recall": 0.09375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0059283088235294115,
        "hf_subset": "eng_Latn-wrs_Latn",
        "languages": [
          "eng-Latn",
          "wrs-Latn"
        ],
        "main_score": 0.0059283088235294115,
        "precision": 0.005066338900862069,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004162245331069609,
        "hf_subset": "wrs_Latn-eng_Latn",
        "languages": [
          "wrs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004162245331069609,
        "precision": 0.004037189584064584,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.0379306891025641,
        "hf_subset": "eng_Latn-wsk_Latn",
        "languages": [
          "eng-Latn",
          "wsk-Latn"
        ],
        "main_score": 0.0379306891025641,
        "precision": 0.0320217803030303,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04126054067460317,
        "hf_subset": "wsk_Latn-eng_Latn",
        "languages": [
          "wsk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04126054067460317,
        "precision": 0.03815120997012101,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03820361648757864,
        "hf_subset": "eng_Latn-wuv_Latn",
        "languages": [
          "eng-Latn",
          "wuv-Latn"
        ],
        "main_score": 0.03820361648757864,
        "precision": 0.03584656084656085,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03824159398607928,
        "hf_subset": "wuv_Latn-eng_Latn",
        "languages": [
          "wuv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03824159398607928,
        "precision": 0.03442400568181818,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013545162192393735,
        "hf_subset": "eng_Latn-xav_Latn",
        "languages": [
          "eng-Latn",
          "xav-Latn"
        ],
        "main_score": 0.0013545162192393735,
        "precision": 0.0008076435810810811,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0004199359668109668,
        "hf_subset": "xav_Latn-eng_Latn",
        "languages": [
          "xav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004199359668109668,
        "precision": 0.00021447086899275836,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008795098706603131,
        "hf_subset": "eng_Latn-xbi_Latn",
        "languages": [
          "eng-Latn",
          "xbi-Latn"
        ],
        "main_score": 0.008795098706603131,
        "precision": 0.008335658482142856,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013321178994304555,
        "hf_subset": "xbi_Latn-eng_Latn",
        "languages": [
          "xbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013321178994304555,
        "precision": 0.010570980890603085,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0037440219546040236,
        "hf_subset": "eng_Latn-xed_Latn",
        "languages": [
          "eng-Latn",
          "xed-Latn"
        ],
        "main_score": 0.0037440219546040236,
        "precision": 0.002580367326461076,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008395522388059701,
        "hf_subset": "xed_Latn-eng_Latn",
        "languages": [
          "xed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008395522388059701,
        "precision": 0.00046339807852965745,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "eng_Latn-xla_Latn",
        "languages": [
          "eng-Latn",
          "xla-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.316298342541436e-05,
        "hf_subset": "xla_Latn-eng_Latn",
        "languages": [
          "xla-Latn",
          "eng-Latn"
        ],
        "main_score": 4.316298342541436e-05,
        "precision": 2.170138888888889e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015864955357142857,
        "hf_subset": "eng_Latn-xnn_Latn",
        "languages": [
          "eng-Latn",
          "xnn-Latn"
        ],
        "main_score": 0.015864955357142857,
        "precision": 0.01453137828407225,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016199448529411763,
        "hf_subset": "xnn_Latn-eng_Latn",
        "languages": [
          "xnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016199448529411763,
        "precision": 0.01475556786380597,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0091890389876881,
        "hf_subset": "eng_Latn-xon_Latn",
        "languages": [
          "eng-Latn",
          "xon-Latn"
        ],
        "main_score": 0.0091890389876881,
        "precision": 0.008544336694007747,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024850124400056465,
        "hf_subset": "xon_Latn-eng_Latn",
        "languages": [
          "xon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024850124400056465,
        "precision": 0.022694059412809414,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010458002645502645,
        "hf_subset": "eng_Latn-xsi_Latn",
        "languages": [
          "eng-Latn",
          "xsi-Latn"
        ],
        "main_score": 0.010458002645502645,
        "precision": 0.009786402925531915,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01951936202112424,
        "hf_subset": "xsi_Latn-eng_Latn",
        "languages": [
          "xsi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01951936202112424,
        "precision": 0.017260046014626353,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012058423913043478,
        "hf_subset": "eng_Latn-xtd_Latn",
        "languages": [
          "eng-Latn",
          "xtd-Latn"
        ],
        "main_score": 0.012058423913043478,
        "precision": 0.010594223484848484,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02039122802315609,
        "hf_subset": "xtd_Latn-eng_Latn",
        "languages": [
          "xtd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02039122802315609,
        "precision": 0.01878092349809122,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0014672025966183575,
        "hf_subset": "eng_Latn-xtm_Latn",
        "languages": [
          "eng-Latn",
          "xtm-Latn"
        ],
        "main_score": 0.0014672025966183575,
        "precision": 0.0008163278997730479,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012236017299409454,
        "hf_subset": "xtm_Latn-eng_Latn",
        "languages": [
          "xtm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012236017299409454,
        "precision": 0.010561368255728011,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013715520251396648,
        "hf_subset": "eng_Latn-yaa_Latn",
        "languages": [
          "eng-Latn",
          "yaa-Latn"
        ],
        "main_score": 0.013715520251396648,
        "precision": 0.011870903558052434,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013814906881313132,
        "hf_subset": "yaa_Latn-eng_Latn",
        "languages": [
          "yaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013814906881313132,
        "precision": 0.011861305675287356,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003555689102564102,
        "hf_subset": "eng_Latn-yad_Latn",
        "languages": [
          "eng-Latn",
          "yad-Latn"
        ],
        "main_score": 0.003555689102564102,
        "precision": 0.002239583333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0018158559276980329,
        "hf_subset": "yad_Latn-eng_Latn",
        "languages": [
          "yad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0018158559276980329,
        "precision": 0.0009845751509508492,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007982409381663114,
        "hf_subset": "eng_Latn-yal_Latn",
        "languages": [
          "eng-Latn",
          "yal-Latn"
        ],
        "main_score": 0.007982409381663114,
        "precision": 0.007898482619592459,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01123046875,
        "hf_subset": "yal_Latn-eng_Latn",
        "languages": [
          "yal-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01123046875,
        "precision": 0.008761160714285714,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03197262806637806,
        "hf_subset": "eng_Latn-yap_Latn",
        "languages": [
          "eng-Latn",
          "yap-Latn"
        ],
        "main_score": 0.03197262806637806,
        "precision": 0.027546574519230767,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.045261324893807284,
        "hf_subset": "yap_Latn-eng_Latn",
        "languages": [
          "yap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.045261324893807284,
        "precision": 0.04207188551168331,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004464285714285714,
        "hf_subset": "eng_Latn-yaq_Latn",
        "languages": [
          "eng-Latn",
          "yaq-Latn"
        ],
        "main_score": 0.004464285714285714,
        "precision": 0.004206730769230769,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005537280701754386,
        "hf_subset": "yaq_Latn-eng_Latn",
        "languages": [
          "yaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005537280701754386,
        "precision": 0.0049173810840707965,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-yby_Latn",
        "languages": [
          "eng-Latn",
          "yby-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "yby_Latn-eng_Latn",
        "languages": [
          "yby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005323217369849495,
        "hf_subset": "eng_Latn-ycn_Latn",
        "languages": [
          "eng-Latn",
          "ycn-Latn"
        ],
        "main_score": 0.005323217369849495,
        "precision": 0.00360107421875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00015767240638955686,
        "hf_subset": "ycn_Latn-eng_Latn",
        "languages": [
          "ycn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015767240638955686,
        "precision": 7.97682953549518e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03437466928217223,
        "hf_subset": "eng_Latn-yka_Latn",
        "languages": [
          "eng-Latn",
          "yka-Latn"
        ],
        "main_score": 0.03437466928217223,
        "precision": 0.030093127727768683,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03394106578728289,
        "hf_subset": "yka_Latn-eng_Latn",
        "languages": [
          "yka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03394106578728289,
        "precision": 0.031587401313963814,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006629273504273505,
        "hf_subset": "eng_Latn-yle_Latn",
        "languages": [
          "eng-Latn",
          "yle-Latn"
        ],
        "main_score": 0.006629273504273505,
        "precision": 0.005610360424228676,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007288935023310023,
        "hf_subset": "yle_Latn-eng_Latn",
        "languages": [
          "yle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007288935023310023,
        "precision": 0.006275738856589148,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008723958333333334,
        "hf_subset": "eng_Latn-yml_Latn",
        "languages": [
          "eng-Latn",
          "yml-Latn"
        ],
        "main_score": 0.008723958333333334,
        "precision": 0.007191051136363636,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004880198492363407,
        "hf_subset": "yml_Latn-eng_Latn",
        "languages": [
          "yml-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004880198492363407,
        "precision": 0.0034216569170771754,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007744372420020639,
        "hf_subset": "eng_Latn-yon_Latn",
        "languages": [
          "eng-Latn",
          "yon-Latn"
        ],
        "main_score": 0.007744372420020639,
        "precision": 0.0061773003472222225,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0023949032738095235,
        "hf_subset": "yon_Latn-eng_Latn",
        "languages": [
          "yon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0023949032738095235,
        "precision": 0.0015298709613869187,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018869330444165968,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ],
        "main_score": 0.018869330444165968,
        "precision": 0.01670814479638009,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.031977634803921566,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031977634803921566,
        "precision": 0.03063763407590759,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00016896802325581397,
        "hf_subset": "eng_Latn-yrb_Latn",
        "languages": [
          "eng-Latn",
          "yrb-Latn"
        ],
        "main_score": 0.00016896802325581397,
        "precision": 8.541295306001189e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005116248666329739,
        "hf_subset": "yrb_Latn-eng_Latn",
        "languages": [
          "yrb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005116248666329739,
        "precision": 0.003431296526054591,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011561355311355311,
        "hf_subset": "eng_Latn-yre_Latn",
        "languages": [
          "eng-Latn",
          "yre-Latn"
        ],
        "main_score": 0.0011561355311355311,
        "precision": 0.0006711769759450172,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002699441056910569,
        "hf_subset": "yre_Latn-eng_Latn",
        "languages": [
          "yre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002699441056910569,
        "precision": 0.0020013503086419755,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005972055288461538,
        "hf_subset": "eng_Latn-yss_Latn",
        "languages": [
          "eng-Latn",
          "yss-Latn"
        ],
        "main_score": 0.005972055288461538,
        "precision": 0.005096132535460993,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0035128066378066376,
        "hf_subset": "yss_Latn-eng_Latn",
        "languages": [
          "yss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035128066378066376,
        "precision": 0.0019422743055555556,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011923363095238096,
        "hf_subset": "eng_Latn-yuj_Latn",
        "languages": [
          "eng-Latn",
          "yuj-Latn"
        ],
        "main_score": 0.0011923363095238096,
        "precision": 0.0006489696747627024,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011638846823603565,
        "hf_subset": "yuj_Latn-eng_Latn",
        "languages": [
          "yuj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011638846823603565,
        "precision": 0.010433807618760066,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0065635629251700675,
        "hf_subset": "eng_Latn-yut_Latn",
        "languages": [
          "eng-Latn",
          "yut-Latn"
        ],
        "main_score": 0.0065635629251700675,
        "precision": 0.005590202106683271,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019286052489177488,
        "hf_subset": "yut_Latn-eng_Latn",
        "languages": [
          "yut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019286052489177488,
        "precision": 0.01636698082010582,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001806640625,
        "hf_subset": "eng_Latn-yuw_Latn",
        "languages": [
          "eng-Latn",
          "yuw-Latn"
        ],
        "main_score": 0.001806640625,
        "precision": 0.001102570564516129,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008647365196078432,
        "hf_subset": "yuw_Latn-eng_Latn",
        "languages": [
          "yuw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008647365196078432,
        "precision": 0.00824964113966804,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015092872090740344,
        "hf_subset": "eng_Latn-yva_Latn",
        "languages": [
          "eng-Latn",
          "yva-Latn"
        ],
        "main_score": 0.015092872090740344,
        "precision": 0.010960743169137064,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016580636160714285,
        "hf_subset": "yva_Latn-eng_Latn",
        "languages": [
          "yva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016580636160714285,
        "precision": 0.016136121763298622,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02199910308326229,
        "hf_subset": "eng_Latn-zaa_Latn",
        "languages": [
          "eng-Latn",
          "zaa-Latn"
        ],
        "main_score": 0.02199910308326229,
        "precision": 0.020172167812998406,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03068409455128205,
        "hf_subset": "zaa_Latn-eng_Latn",
        "languages": [
          "zaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03068409455128205,
        "precision": 0.026763865207174418,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016536458333333334,
        "hf_subset": "eng_Latn-zab_Latn",
        "languages": [
          "eng-Latn",
          "zab-Latn"
        ],
        "main_score": 0.016536458333333334,
        "precision": 0.014778645833333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04083247481684982,
        "hf_subset": "zab_Latn-eng_Latn",
        "languages": [
          "zab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04083247481684982,
        "precision": 0.0365337396978022,
        "recall": 0.0625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.046987680288461536,
        "hf_subset": "eng_Latn-zac_Latn",
        "languages": [
          "eng-Latn",
          "zac-Latn"
        ],
        "main_score": 0.046987680288461536,
        "precision": 0.04311696586879433,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03656994047619047,
        "hf_subset": "zac_Latn-eng_Latn",
        "languages": [
          "zac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03656994047619047,
        "precision": 0.031756072874493925,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014808042576384968,
        "hf_subset": "eng_Latn-zad_Latn",
        "languages": [
          "eng-Latn",
          "zad-Latn"
        ],
        "main_score": 0.014808042576384968,
        "precision": 0.0126825610051713,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.008653453368526898,
        "hf_subset": "zad_Latn-eng_Latn",
        "languages": [
          "zad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008653453368526898,
        "precision": 0.006688404837570622,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03079928392012833,
        "hf_subset": "eng_Latn-zai_Latn",
        "languages": [
          "eng-Latn",
          "zai-Latn"
        ],
        "main_score": 0.03079928392012833,
        "precision": 0.02597847659838149,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.04242931547619047,
        "hf_subset": "zai_Latn-eng_Latn",
        "languages": [
          "zai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04242931547619047,
        "precision": 0.03846807065217391,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00729667467948718,
        "hf_subset": "eng_Latn-zaj_Latn",
        "languages": [
          "eng-Latn",
          "zaj-Latn"
        ],
        "main_score": 0.00729667467948718,
        "precision": 0.005848567171813715,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002338283237913486,
        "hf_subset": "zaj_Latn-eng_Latn",
        "languages": [
          "zaj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002338283237913486,
        "precision": 0.0013693337912087911,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007404894078235202,
        "hf_subset": "eng_Latn-zam_Latn",
        "languages": [
          "eng-Latn",
          "zam-Latn"
        ],
        "main_score": 0.007404894078235202,
        "precision": 0.005891363410894661,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0293603912601626,
        "hf_subset": "zam_Latn-eng_Latn",
        "languages": [
          "zam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0293603912601626,
        "precision": 0.027730882078986586,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008760274943310657,
        "hf_subset": "eng_Latn-zao_Latn",
        "languages": [
          "eng-Latn",
          "zao-Latn"
        ],
        "main_score": 0.008760274943310657,
        "precision": 0.008341051868556701,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02254489536199095,
        "hf_subset": "zao_Latn-eng_Latn",
        "languages": [
          "zao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02254489536199095,
        "precision": 0.01858181423611111,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010035006073738466,
        "hf_subset": "eng_Latn-zap_Latn",
        "languages": [
          "eng-Latn",
          "zap-Latn"
        ],
        "main_score": 0.010035006073738466,
        "precision": 0.008309659090909092,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020634012396420487,
        "hf_subset": "zap_Latn-eng_Latn",
        "languages": [
          "zap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020634012396420487,
        "precision": 0.017857075108051672,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02279959276172301,
        "hf_subset": "eng_Latn-zar_Latn",
        "languages": [
          "eng-Latn",
          "zar-Latn"
        ],
        "main_score": 0.02279959276172301,
        "precision": 0.021421417124542125,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014246961805555555,
        "hf_subset": "zar_Latn-eng_Latn",
        "languages": [
          "zar-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014246961805555555,
        "precision": 0.013327167624042624,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02946707102768091,
        "hf_subset": "eng_Latn-zas_Latn",
        "languages": [
          "eng-Latn",
          "zas-Latn"
        ],
        "main_score": 0.02946707102768091,
        "precision": 0.028608473980309423,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03002632168458781,
        "hf_subset": "zas_Latn-eng_Latn",
        "languages": [
          "zas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03002632168458781,
        "precision": 0.026401654411764706,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021063404837570618,
        "hf_subset": "eng_Latn-zat_Latn",
        "languages": [
          "eng-Latn",
          "zat-Latn"
        ],
        "main_score": 0.021063404837570618,
        "precision": 0.018231411637931034,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018919076492537313,
        "hf_subset": "zat_Latn-eng_Latn",
        "languages": [
          "zat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018919076492537313,
        "precision": 0.01642578125,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.016978997178700585,
        "hf_subset": "eng_Latn-zav_Latn",
        "languages": [
          "eng-Latn",
          "zav-Latn"
        ],
        "main_score": 0.016978997178700585,
        "precision": 0.013462923475090482,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0215679891748366,
        "hf_subset": "zav_Latn-eng_Latn",
        "languages": [
          "zav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0215679891748366,
        "precision": 0.020625449138996346,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0065760679271708675,
        "hf_subset": "eng_Latn-zaw_Latn",
        "languages": [
          "eng-Latn",
          "zaw-Latn"
        ],
        "main_score": 0.0065760679271708675,
        "precision": 0.005892478813559322,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025568065767973856,
        "hf_subset": "zaw_Latn-eng_Latn",
        "languages": [
          "zaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025568065767973856,
        "precision": 0.023302630452856028,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018288352272727272,
        "hf_subset": "eng_Latn-zca_Latn",
        "languages": [
          "eng-Latn",
          "zca-Latn"
        ],
        "main_score": 0.018288352272727272,
        "precision": 0.017607943702290078,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01737985321969697,
        "hf_subset": "zca_Latn-eng_Latn",
        "languages": [
          "zca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01737985321969697,
        "precision": 0.015449979707792206,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011301224035210338,
        "hf_subset": "eng_Latn-zga_Latn",
        "languages": [
          "eng-Latn",
          "zga-Latn"
        ],
        "main_score": 0.011301224035210338,
        "precision": 0.009895365630986589,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0215640943877551,
        "hf_subset": "zga_Latn-eng_Latn",
        "languages": [
          "zga-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0215640943877551,
        "precision": 0.020873603951890033,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007283931518151814,
        "hf_subset": "eng_Latn-zia_Latn",
        "languages": [
          "eng-Latn",
          "zia-Latn"
        ],
        "main_score": 0.0007283931518151814,
        "precision": 0.00039417613636363635,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01181640625,
        "hf_subset": "zia_Latn-eng_Latn",
        "languages": [
          "zia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01181640625,
        "precision": 0.010351562499999998,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0068481848184818485,
        "hf_subset": "eng_Latn-ziw_Latn",
        "languages": [
          "eng-Latn",
          "ziw-Latn"
        ],
        "main_score": 0.0068481848184818485,
        "precision": 0.005703125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0046875,
        "hf_subset": "ziw_Latn-eng_Latn",
        "languages": [
          "ziw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0046875,
        "precision": 0.004340277777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.916015625,
        "hf_subset": "eng_Latn-zlm_Latn",
        "languages": [
          "eng-Latn",
          "zlm-Latn"
        ],
        "main_score": 0.916015625,
        "precision": 0.9075520833333333,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9505208333333333,
        "hf_subset": "zlm_Latn-eng_Latn",
        "languages": [
          "zlm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9505208333333333,
        "precision": 0.9453125,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02215924087054344,
        "hf_subset": "eng_Latn-zos_Latn",
        "languages": [
          "eng-Latn",
          "zos-Latn"
        ],
        "main_score": 0.02215924087054344,
        "precision": 0.020236215852740026,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029776701163419912,
        "hf_subset": "zos_Latn-eng_Latn",
        "languages": [
          "zos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029776701163419912,
        "precision": 0.02754117970867209,
        "recall": 0.046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02703602333536544,
        "hf_subset": "eng_Latn-zpc_Latn",
        "languages": [
          "eng-Latn",
          "zpc-Latn"
        ],
        "main_score": 0.02703602333536544,
        "precision": 0.0236624053030303,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02887797564525322,
        "hf_subset": "zpc_Latn-eng_Latn",
        "languages": [
          "zpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02887797564525322,
        "precision": 0.025657664817821065,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04036025747508305,
        "hf_subset": "eng_Latn-zpl_Latn",
        "languages": [
          "eng-Latn",
          "zpl-Latn"
        ],
        "main_score": 0.04036025747508305,
        "precision": 0.035379464285714285,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04339117472393425,
        "hf_subset": "zpl_Latn-eng_Latn",
        "languages": [
          "zpl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04339117472393425,
        "precision": 0.03889733425697865,
        "recall": 0.0625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009758947649572648,
        "hf_subset": "eng_Latn-zpm_Latn",
        "languages": [
          "eng-Latn",
          "zpm-Latn"
        ],
        "main_score": 0.009758947649572648,
        "precision": 0.008159843459031658,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01116488212002325,
        "hf_subset": "zpm_Latn-eng_Latn",
        "languages": [
          "zpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01116488212002325,
        "precision": 0.010154935712569094,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009442318594104307,
        "hf_subset": "eng_Latn-zpo_Latn",
        "languages": [
          "eng-Latn",
          "zpo-Latn"
        ],
        "main_score": 0.009442318594104307,
        "precision": 0.008733591696988074,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02607421875,
        "hf_subset": "zpo_Latn-eng_Latn",
        "languages": [
          "zpo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02607421875,
        "precision": 0.025100160256410257,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006532294750801875,
        "hf_subset": "eng_Latn-zpq_Latn",
        "languages": [
          "eng-Latn",
          "zpq-Latn"
        ],
        "main_score": 0.006532294750801875,
        "precision": 0.004447428385416666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013924064217032966,
        "hf_subset": "zpq_Latn-eng_Latn",
        "languages": [
          "zpq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013924064217032966,
        "precision": 0.011783854166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02964547821969697,
        "hf_subset": "eng_Latn-zpu_Latn",
        "languages": [
          "eng-Latn",
          "zpu-Latn"
        ],
        "main_score": 0.02964547821969697,
        "precision": 0.027349064625850343,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0172559862012987,
        "hf_subset": "zpu_Latn-eng_Latn",
        "languages": [
          "zpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0172559862012987,
        "precision": 0.01497415906560466,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018391927083333332,
        "hf_subset": "eng_Latn-zpv_Latn",
        "languages": [
          "eng-Latn",
          "zpv-Latn"
        ],
        "main_score": 0.018391927083333332,
        "precision": 0.01766123670212766,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02266046262254902,
        "hf_subset": "zpv_Latn-eng_Latn",
        "languages": [
          "zpv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02266046262254902,
        "precision": 0.020132365183962664,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007335557116104868,
        "hf_subset": "eng_Latn-zpz_Latn",
        "languages": [
          "eng-Latn",
          "zpz-Latn"
        ],
        "main_score": 0.007335557116104868,
        "precision": 0.006315471986817325,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0185546875,
        "hf_subset": "zpz_Latn-eng_Latn",
        "languages": [
          "zpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0185546875,
        "precision": 0.017485119047619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028104663804392065,
        "hf_subset": "eng_Latn-zsr_Latn",
        "languages": [
          "eng-Latn",
          "zsr-Latn"
        ],
        "main_score": 0.028104663804392065,
        "precision": 0.026545940658338013,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021231135966614908,
        "hf_subset": "zsr_Latn-eng_Latn",
        "languages": [
          "zsr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021231135966614908,
        "precision": 0.01896675932714239,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017511976381461673,
        "hf_subset": "eng_Latn-ztq_Latn",
        "languages": [
          "eng-Latn",
          "ztq-Latn"
        ],
        "main_score": 0.017511976381461673,
        "precision": 0.014627299783549782,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03638890330841639,
        "hf_subset": "ztq_Latn-eng_Latn",
        "languages": [
          "ztq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03638890330841639,
        "precision": 0.03352864583333333,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0013814936894297949,
        "hf_subset": "eng_Latn-zty_Latn",
        "languages": [
          "eng-Latn",
          "zty-Latn"
        ],
        "main_score": 0.0013814936894297949,
        "precision": 0.0007595486111111111,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012690831646423751,
        "hf_subset": "zty_Latn-eng_Latn",
        "languages": [
          "zty-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012690831646423751,
        "precision": 0.011115451388888888,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014677372685185184,
        "hf_subset": "eng_Latn-zyp_Latn",
        "languages": [
          "eng-Latn",
          "zyp-Latn"
        ],
        "main_score": 0.014677372685185184,
        "precision": 0.012588896092112313,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004537118544600939,
        "hf_subset": "zyp_Latn-eng_Latn",
        "languages": [
          "zyp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004537118544600939,
        "precision": 0.004241071428571428,
        "recall": 0.01171875
      }
    ]
  },
  "task_name": "BibleNLPBitextMining"
}