{
  "dataset_revision": "3f756ab4572e071eb53e887ab629f19fa747d39e",
  "evaluation_time": 28.009493827819824,
  "kg_co2_emissions": 0.005420786345370012,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8821043165467627,
        "ap": 0.8342115336971128,
        "ap_weighted": 0.8342115336971128,
        "f1": 0.8816515284718587,
        "f1_weighted": 0.8816515284718587,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ],
        "main_score": 0.8821043165467627,
        "scores_per_experiment": [
          {
            "accuracy": 0.8687050359712231,
            "ap": 0.8319785577787769,
            "ap_weighted": 0.8319785577787769,
            "f1": 0.8684991511475707,
            "f1_weighted": 0.8684991511475707
          },
          {
            "accuracy": 0.8961330935251799,
            "ap": 0.8470816003047263,
            "ap_weighted": 0.8470816003047263,
            "f1": 0.8960599430068009,
            "f1_weighted": 0.8960599430068009
          },
          {
            "accuracy": 0.8880395683453237,
            "ap": 0.830704742328586,
            "ap_weighted": 0.830704742328586,
            "f1": 0.88774978427687,
            "f1_weighted": 0.88774978427687
          },
          {
            "accuracy": 0.8889388489208633,
            "ap": 0.8383668172391087,
            "ap_weighted": 0.8383668172391087,
            "f1": 0.8888658481098346,
            "f1_weighted": 0.8888658481098346
          },
          {
            "accuracy": 0.9033273381294964,
            "ap": 0.855877063055438,
            "ap_weighted": 0.855877063055438,
            "f1": 0.9032545566929795,
            "f1_weighted": 0.9032545566929796
          },
          {
            "accuracy": 0.8606115107913669,
            "ap": 0.8371443842756598,
            "ap_weighted": 0.8371443842756598,
            "f1": 0.859586694788431,
            "f1_weighted": 0.859586694788431
          },
          {
            "accuracy": 0.8844424460431655,
            "ap": 0.8219364129848449,
            "ap_weighted": 0.8219364129848449,
            "f1": 0.8838784100690937,
            "f1_weighted": 0.8838784100690938
          },
          {
            "accuracy": 0.8651079136690647,
            "ap": 0.838589549413101,
            "ap_weighted": 0.838589549413101,
            "f1": 0.8643883695953521,
            "f1_weighted": 0.864388369595352
          },
          {
            "accuracy": 0.8705035971223022,
            "ap": 0.7998520102836649,
            "ap_weighted": 0.7998520102836649,
            "f1": 0.8692239089741955,
            "f1_weighted": 0.8692239089741957
          },
          {
            "accuracy": 0.8952338129496403,
            "ap": 0.8405841993072208,
            "ap_weighted": 0.8405841993072208,
            "f1": 0.8950086180574592,
            "f1_weighted": 0.8950086180574593
          }
        ]
      }
    ]
  },
  "task_name": "DutchBookReviewSentimentClassification"
}