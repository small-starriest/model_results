{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "evaluation_time": 1080.7815420627594,
  "kg_co2_emissions": 0.2739889396517041,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.21904296875,
        "f1": 0.1927162180029112,
        "f1_weighted": 0.20632095460130548,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.21904296875,
        "scores_per_experiment": [
          {
            "accuracy": 0.2275390625,
            "f1": 0.2032234746577223,
            "f1_weighted": 0.21079289593490996
          },
          {
            "accuracy": 0.2197265625,
            "f1": 0.19936995090017065,
            "f1_weighted": 0.21121193000242322
          },
          {
            "accuracy": 0.21337890625,
            "f1": 0.1843096259506621,
            "f1_weighted": 0.19473730397160355
          },
          {
            "accuracy": 0.2392578125,
            "f1": 0.20847216191341392,
            "f1_weighted": 0.22671221660638924
          },
          {
            "accuracy": 0.205078125,
            "f1": 0.18827728517261608,
            "f1_weighted": 0.20069726798692744
          },
          {
            "accuracy": 0.22314453125,
            "f1": 0.19432130500237435,
            "f1_weighted": 0.21272265404331536
          },
          {
            "accuracy": 0.2197265625,
            "f1": 0.18897880817936202,
            "f1_weighted": 0.21333191107828808
          },
          {
            "accuracy": 0.203125,
            "f1": 0.17638905826717335,
            "f1_weighted": 0.18607946721708848
          },
          {
            "accuracy": 0.22509765625,
            "f1": 0.1952401570562003,
            "f1_weighted": 0.21159991136856376
          },
          {
            "accuracy": 0.21435546875,
            "f1": 0.18858035292941683,
            "f1_weighted": 0.1953239878035457
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.227001953125,
        "f1": 0.18717212840094707,
        "f1_weighted": 0.2113803729303238,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.227001953125,
        "scores_per_experiment": [
          {
            "accuracy": 0.24365234375,
            "f1": 0.1982661012431447,
            "f1_weighted": 0.22554172591807273
          },
          {
            "accuracy": 0.21875,
            "f1": 0.17931624250937458,
            "f1_weighted": 0.20324369809713516
          },
          {
            "accuracy": 0.212890625,
            "f1": 0.1681512657199891,
            "f1_weighted": 0.19857242597679808
          },
          {
            "accuracy": 0.228515625,
            "f1": 0.1852971559156442,
            "f1_weighted": 0.21220012063831034
          },
          {
            "accuracy": 0.2158203125,
            "f1": 0.1851515380436123,
            "f1_weighted": 0.2078155803542292
          },
          {
            "accuracy": 0.22216796875,
            "f1": 0.1844523817174134,
            "f1_weighted": 0.20725567642346915
          },
          {
            "accuracy": 0.25048828125,
            "f1": 0.19976679987929785,
            "f1_weighted": 0.23528666450242972
          },
          {
            "accuracy": 0.21875,
            "f1": 0.1835588453450373,
            "f1_weighted": 0.19522329068424463
          },
          {
            "accuracy": 0.2353515625,
            "f1": 0.1966814173117635,
            "f1_weighted": 0.22201569168403607
          },
          {
            "accuracy": 0.2236328125,
            "f1": 0.19107953632419378,
            "f1_weighted": 0.20664885502451308
          }
        ]
      }
    ]
  },
  "task_name": "GreekLegalCodeClassification"
}