{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.8353102461703523,
            "accuracy_threshold": 0.7627541422843933,
            "ap": 0.6530753664579191,
            "f1": 0.617399438727783,
            "f1_threshold": 0.6688005924224854,
            "precision": 0.5543889122217556,
            "recall": 0.6965699208443272
        },
        "dot": {
            "accuracy": 0.8038981939560113,
            "accuracy_threshold": 1232.18505859375,
            "ap": 0.5352081118421347,
            "f1": 0.5423295784461735,
            "f1_threshold": 996.4822998046875,
            "precision": 0.4843393486828459,
            "recall": 0.6160949868073878
        },
        "euclidean": {
            "accuracy": 0.822375871729153,
            "accuracy_threshold": 26.425655364990234,
            "ap": 0.6036110279277254,
            "f1": 0.5750518791791561,
            "f1_threshold": 31.053466796875,
            "precision": 0.5106470106470107,
            "recall": 0.658047493403694
        },
        "evaluation_time": 255.26,
        "manhattan": {
            "accuracy": 0.8214221851344102,
            "accuracy_threshold": 1306.606689453125,
            "ap": 0.6034193722379336,
            "f1": 0.5753803596127247,
            "f1_threshold": 1532.455810546875,
            "precision": 0.5108473188702415,
            "recall": 0.6585751978891821
        },
        "max": {
            "accuracy": 0.8353102461703523,
            "ap": 0.6530753664579191,
            "f1": 0.617399438727783
        }
    },
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}