{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "evaluation_time": 16.870494842529297,
  "kg_co2_emissions": 0.004086750261287337,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.28515625,
        "f1": 0.27687989769002586,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "lrap": 0.4152377658420061,
        "main_score": 0.28515625,
        "scores_per_experiment": [
          {
            "accuracy": 0.25,
            "f1": 0.20721102416746126,
            "lrap": 0.37175835503471466
          },
          {
            "accuracy": 0.27880859375,
            "f1": 0.28616500844654175,
            "lrap": 0.4227973090277701
          },
          {
            "accuracy": 0.2890625,
            "f1": 0.2645680775441892,
            "lrap": 0.404690212673603
          },
          {
            "accuracy": 0.30224609375,
            "f1": 0.2793207188602188,
            "lrap": 0.4257269965277702
          },
          {
            "accuracy": 0.27490234375,
            "f1": 0.27710516719184575,
            "lrap": 0.4010484483506865
          },
          {
            "accuracy": 0.29052734375,
            "f1": 0.29126555740108917,
            "lrap": 0.4232855902777702
          },
          {
            "accuracy": 0.29052734375,
            "f1": 0.25819403503975563,
            "lrap": 0.41643608940971466
          },
          {
            "accuracy": 0.28271484375,
            "f1": 0.293388723349701,
            "lrap": 0.41739908854165875
          },
          {
            "accuracy": 0.30859375,
            "f1": 0.3095153657982328,
            "lrap": 0.4410264756944367
          },
          {
            "accuracy": 0.2841796875,
            "f1": 0.3020652991012232,
            "lrap": 0.4282090928819369
          }
        ]
      }
    ]
  },
  "task_name": "SensitiveTopicsClassification"
}