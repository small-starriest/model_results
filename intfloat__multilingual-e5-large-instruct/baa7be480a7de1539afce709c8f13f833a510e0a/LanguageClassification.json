{
  "dataset_revision": "aa56583bf2bc52b0565770607d6fc3faebecf9e2",
  "evaluation_time": 34.21914577484131,
  "kg_co2_emissions": 0.006439239993829721,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.99482421875,
        "f1": 0.9948255774772623,
        "f1_weighted": 0.9948275834173046,
        "hf_subset": "default",
        "languages": [
          "ara-Arab",
          "bul-Cyrl",
          "deu-Latn",
          "ell-Grek",
          "eng-Latn",
          "spa-Latn",
          "fra-Latn",
          "hin-Deva",
          "ita-Latn",
          "jpn-Jpan",
          "nld-Latn",
          "pol-Latn",
          "por-Latn",
          "rus-Cyrl",
          "swa-Latn",
          "tha-Thai",
          "tur-Latn",
          "urd-Arab",
          "vie-Latn",
          "cmn-Hans"
        ],
        "main_score": 0.99482421875,
        "scores_per_experiment": [
          {
            "accuracy": 0.99609375,
            "f1": 0.9960805640973337,
            "f1_weighted": 0.996091133687454
          },
          {
            "accuracy": 0.990234375,
            "f1": 0.9902548524217538,
            "f1_weighted": 0.9902379757550426
          },
          {
            "accuracy": 0.998046875,
            "f1": 0.9980415368936424,
            "f1_weighted": 0.9980468282935333
          },
          {
            "accuracy": 0.99169921875,
            "f1": 0.9917533816329573,
            "f1_weighted": 0.9917563914813297
          },
          {
            "accuracy": 0.9951171875,
            "f1": 0.9951117325622008,
            "f1_weighted": 0.9951112927878994
          },
          {
            "accuracy": 0.99462890625,
            "f1": 0.9946202210432828,
            "f1_weighted": 0.9946246521573797
          },
          {
            "accuracy": 0.99609375,
            "f1": 0.996087149157486,
            "f1_weighted": 0.9960929523183405
          },
          {
            "accuracy": 0.99609375,
            "f1": 0.9960925221546164,
            "f1_weighted": 0.9960982579624971
          },
          {
            "accuracy": 0.99267578125,
            "f1": 0.9926601060092913,
            "f1_weighted": 0.9926602310222103
          },
          {
            "accuracy": 0.99755859375,
            "f1": 0.9975537088000559,
            "f1_weighted": 0.9975561187073589
          }
        ]
      }
    ]
  },
  "task_name": "LanguageClassification"
}