{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 27.132083654403687,
  "kg_co2_emissions": 0.004401516312342061,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.4337990685296075,
        "f1": 0.3787877950161226,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.3787877950161226,
        "precision": 0.3591446068084896,
        "recall": 0.4337990685296075
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.020949288923018883,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.020949288923018883,
        "precision": 0.01785791694895465,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.18762475049900199,
        "f1": 0.15182427906978804,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.15182427906978804,
        "precision": 0.13977411477411475,
        "recall": 0.18762475049900199
      },
      {
        "accuracy": 0.40652029274783763,
        "f1": 0.33855897974327775,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.33855897974327775,
        "precision": 0.315761866210968,
        "recall": 0.40652029274783763
      },
      {
        "accuracy": 0.14105123087159016,
        "f1": 0.1113239130205198,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.1113239130205198,
        "precision": 0.10243718911383581,
        "recall": 0.14105123087159016
      },
      {
        "accuracy": 0.35728542914171657,
        "f1": 0.3115751637803882,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.3115751637803882,
        "precision": 0.29650929233969037,
        "recall": 0.35728542914171657
      },
      {
        "accuracy": 0.3872255489021956,
        "f1": 0.33116679468974874,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.33116679468974874,
        "precision": 0.3116730862892951,
        "recall": 0.3872255489021956
      },
      {
        "accuracy": 0.2994011976047904,
        "f1": 0.2566824023909852,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.2566824023909852,
        "precision": 0.24132754734377576,
        "recall": 0.2994011976047904
      },
      {
        "accuracy": 0.0718562874251497,
        "f1": 0.05318098771192583,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.05318098771192583,
        "precision": 0.04744162468713367,
        "recall": 0.0718562874251497
      },
      {
        "accuracy": 0.21689953426480374,
        "f1": 0.18378639546304212,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.18378639546304212,
        "precision": 0.1729678283570499,
        "recall": 0.21689953426480374
      },
      {
        "accuracy": 0.34530938123752497,
        "f1": 0.2979930894513494,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.2979930894513494,
        "precision": 0.28141623199008425,
        "recall": 0.34530938123752497
      },
      {
        "accuracy": 0.3652694610778443,
        "f1": 0.3124794903334598,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.3124794903334598,
        "precision": 0.2948921353395015,
        "recall": 0.3652694610778443
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0010526957384550705,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0010526957384550705,
        "precision": 0.0008753292996122531,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.3812375249500998,
        "f1": 0.3301794507879615,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.3301794507879615,
        "precision": 0.3132144150548518,
        "recall": 0.3812375249500998
      },
      {
        "accuracy": 0.35662009314703924,
        "f1": 0.30108665785312494,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.30108665785312494,
        "precision": 0.2828631146466065,
        "recall": 0.35662009314703924
      },
      {
        "accuracy": 0.3253493013972056,
        "f1": 0.28064227428909827,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.28064227428909827,
        "precision": 0.26466192709064107,
        "recall": 0.3253493013972056
      },
      {
        "accuracy": 0.18163672654690619,
        "f1": 0.14355225243448796,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.14355225243448796,
        "precision": 0.13133000071948261,
        "recall": 0.18163672654690619
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011277268086025969,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0011277268086025969,
        "precision": 0.0010074701512249133,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.11976047904191617,
        "f1": 0.0931359650920529,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0931359650920529,
        "precision": 0.08520208260727223,
        "recall": 0.11976047904191617
      },
      {
        "accuracy": 0.3000665335994677,
        "f1": 0.24766464222552048,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.24766464222552048,
        "precision": 0.2299156136980488,
        "recall": 0.3000665335994677
      },
      {
        "accuracy": 0.3213572854291417,
        "f1": 0.2708645399329249,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.2708645399329249,
        "precision": 0.2539784788287782,
        "recall": 0.3213572854291417
      },
      {
        "accuracy": 0.3878908848968729,
        "f1": 0.33329540891084475,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.33329540891084475,
        "precision": 0.3152770807960429,
        "recall": 0.3878908848968729
      },
      {
        "accuracy": 0.4963406520292748,
        "f1": 0.4240730179851936,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.4240730179851936,
        "precision": 0.3953336952837951,
        "recall": 0.4963406520292748
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.026301907094117744,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.026301907094117744,
        "precision": 0.022888522049932337,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.3473053892215569,
        "f1": 0.2824937906774234,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.2824937906774234,
        "precision": 0.25951166450168445,
        "recall": 0.3473053892215569
      },
      {
        "accuracy": 0.7518296739853626,
        "f1": 0.6986408136108735,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.6986408136108735,
        "precision": 0.6762934448563191,
        "recall": 0.7518296739853626
      },
      {
        "accuracy": 0.29208250166334,
        "f1": 0.22971161553408823,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.22971161553408823,
        "precision": 0.2096237899381612,
        "recall": 0.29208250166334
      },
      {
        "accuracy": 0.699268130405855,
        "f1": 0.643937521781833,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.643937521781833,
        "precision": 0.6204332076587565,
        "recall": 0.699268130405855
      },
      {
        "accuracy": 0.7411842980705257,
        "f1": 0.694035210003274,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.694035210003274,
        "precision": 0.6739188290086494,
        "recall": 0.7411842980705257
      },
      {
        "accuracy": 0.5728542914171657,
        "f1": 0.5102948024105709,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.5102948024105709,
        "precision": 0.4843780692583088,
        "recall": 0.5728542914171657
      },
      {
        "accuracy": 0.1317365269461078,
        "f1": 0.09322958944968797,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.09322958944968797,
        "precision": 0.08216609170028419,
        "recall": 0.1317365269461078
      },
      {
        "accuracy": 0.4111776447105788,
        "f1": 0.355669349132423,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.355669349132423,
        "precision": 0.3354307258498876,
        "recall": 0.4111776447105788
      },
      {
        "accuracy": 0.6793080505655356,
        "f1": 0.6229778538161771,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.6229778538161771,
        "precision": 0.5992596816948115,
        "recall": 0.6793080505655356
      },
      {
        "accuracy": 0.7225548902195609,
        "f1": 0.6719038114247695,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.6719038114247695,
        "precision": 0.6511844036794137,
        "recall": 0.7225548902195609
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0006237921390083341,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0006237921390083341,
        "precision": 0.0003480807052863121,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.7145708582834331,
        "f1": 0.6602667680511991,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.6602667680511991,
        "precision": 0.6375914836992681,
        "recall": 0.7145708582834331
      },
      {
        "accuracy": 0.6766467065868264,
        "f1": 0.6185977251845515,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.6185977251845515,
        "precision": 0.5939787092481703,
        "recall": 0.6766467065868264
      },
      {
        "accuracy": 0.6586826347305389,
        "f1": 0.606336533282641,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.606336533282641,
        "precision": 0.5844717971464479,
        "recall": 0.6586826347305389
      },
      {
        "accuracy": 0.29607451763140386,
        "f1": 0.23624019568384708,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.23624019568384708,
        "precision": 0.21578232424040808,
        "recall": 0.29607451763140386
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0013986869804646015,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0013986869804646015,
        "precision": 0.001111365304721474,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.2268795741849634,
        "f1": 0.1716406292753598,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.1716406292753598,
        "precision": 0.1544531815489899,
        "recall": 0.2268795741849634
      },
      {
        "accuracy": 0.5768463073852296,
        "f1": 0.51533124227735,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.51533124227735,
        "precision": 0.49049836834267974,
        "recall": 0.5768463073852296
      },
      {
        "accuracy": 0.6626746506986028,
        "f1": 0.6020488124280539,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.6020488124280539,
        "precision": 0.5767853182523842,
        "recall": 0.6626746506986028
      },
      {
        "accuracy": 0.7305389221556886,
        "f1": 0.67876685301835,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.67876685301835,
        "precision": 0.6571301840762919,
        "recall": 0.7305389221556886
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.018947796082415733,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.018947796082415733,
        "precision": 0.01730983913752523,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.021092661598028573,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.021092661598028573,
        "precision": 0.019986693719338748,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.03206806684850597,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.03206806684850597,
        "precision": 0.03024483857544636,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.03357126065362529,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03357126065362529,
        "precision": 0.031007294744323056,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.028691877521315415,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.028691877521315415,
        "precision": 0.02677632602307063,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.028588903422555077,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.028588903422555077,
        "precision": 0.026933995939234272,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.03552799670781166,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.03552799670781166,
        "precision": 0.03248755238902076,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.02072673627059135,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.02072673627059135,
        "precision": 0.01959481709980712,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.01869594145043247,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.01869594145043247,
        "precision": 0.01723220226214238,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.03707435324448975,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.03707435324448975,
        "precision": 0.03430952232670569,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.02125971522220976,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.02125971522220976,
        "precision": 0.019971381424944885,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.0368946620710525,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.0368946620710525,
        "precision": 0.034502621086128366,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0025711007335011836,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0025711007335011836,
        "precision": 0.0021028668285605883,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.03578644659932573,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.03578644659932573,
        "precision": 0.03328223406528016,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.015247376544400403,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.015247376544400403,
        "precision": 0.013955636726408923,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014662967392801842,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.014662967392801842,
        "precision": 0.013310302668295542,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.026066949901825495,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.026066949901825495,
        "precision": 0.024780189040107335,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002697170728996351,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002697170728996351,
        "precision": 0.0024797916668252377,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.02985247176863943,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02985247176863943,
        "precision": 0.028273254061677213,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.016061270665970222,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.016061270665970222,
        "precision": 0.014525143768270419,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.021088083523783795,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.021088083523783795,
        "precision": 0.019889123281032445,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.02939129774939367,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.02939129774939367,
        "precision": 0.027707959781594467,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.2155688622754491,
        "f1": 0.17468559753988896,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.17468559753988896,
        "precision": 0.1602725765400416,
        "recall": 0.2155688622754491
      },
      {
        "accuracy": 0.3213572854291417,
        "f1": 0.2761518698644447,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.2761518698644447,
        "precision": 0.26079040748911536,
        "recall": 0.3213572854291417
      },
      {
        "accuracy": 0.05854956753160346,
        "f1": 0.0391907724243699,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.0391907724243699,
        "precision": 0.03459751899845397,
        "recall": 0.05854956753160346
      },
      {
        "accuracy": 0.4590818363273453,
        "f1": 0.39556083482238685,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.39556083482238685,
        "precision": 0.37236705301987777,
        "recall": 0.4590818363273453
      },
      {
        "accuracy": 0.22954091816367264,
        "f1": 0.19083834772457525,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.19083834772457525,
        "precision": 0.17743694909363572,
        "recall": 0.22954091816367264
      },
      {
        "accuracy": 0.36593479707252163,
        "f1": 0.316871456584713,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.316871456584713,
        "precision": 0.29924205233258183,
        "recall": 0.36593479707252163
      },
      {
        "accuracy": 0.4524284763805722,
        "f1": 0.4019539062735279,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4019539062735279,
        "precision": 0.38418776627153556,
        "recall": 0.4524284763805722
      },
      {
        "accuracy": 0.2714570858283433,
        "f1": 0.22611136430165038,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.22611136430165038,
        "precision": 0.21045680312147377,
        "recall": 0.2714570858283433
      },
      {
        "accuracy": 0.12508316699933467,
        "f1": 0.09294998690619213,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.09294998690619213,
        "precision": 0.08292317481439238,
        "recall": 0.12508316699933467
      },
      {
        "accuracy": 0.35528942115768464,
        "f1": 0.30611317048442793,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.30611317048442793,
        "precision": 0.28847063707343146,
        "recall": 0.35528942115768464
      },
      {
        "accuracy": 0.31869594145043245,
        "f1": 0.27177171630764446,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.27177171630764446,
        "precision": 0.2554355124546411,
        "recall": 0.31869594145043245
      },
      {
        "accuracy": 0.4018629407850965,
        "f1": 0.3500639140514189,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3500639140514189,
        "precision": 0.33224874698330586,
        "recall": 0.4018629407850965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00026169829077164953,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00026169829077164953,
        "precision": 0.0001402946600287767,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.3925482368596141,
        "f1": 0.3428116399486265,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3428116399486265,
        "precision": 0.32581778404209627,
        "recall": 0.3925482368596141
      },
      {
        "accuracy": 0.2714570858283433,
        "f1": 0.2245491995990998,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2245491995990998,
        "precision": 0.20843942964701445,
        "recall": 0.2714570858283433
      },
      {
        "accuracy": 0.3180306054557552,
        "f1": 0.2664907599479632,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2664907599479632,
        "precision": 0.24852975164851412,
        "recall": 0.3180306054557552
      },
      {
        "accuracy": 0.2102461743180306,
        "f1": 0.16872483236010052,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.16872483236010052,
        "precision": 0.15538436853307114,
        "recall": 0.2102461743180306
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001376073972858462,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0001376073972858462,
        "precision": 7.269398098503343e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.2528276779773786,
        "f1": 0.21465587343830858,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.21465587343830858,
        "precision": 0.20210161687207598,
        "recall": 0.2528276779773786
      },
      {
        "accuracy": 0.2634730538922156,
        "f1": 0.21562656867048083,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.21562656867048083,
        "precision": 0.20033086534789007,
        "recall": 0.2634730538922156
      },
      {
        "accuracy": 0.3260146373918829,
        "f1": 0.27566325626347954,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.27566325626347954,
        "precision": 0.25868340876622187,
        "recall": 0.3260146373918829
      },
      {
        "accuracy": 0.4198270126413839,
        "f1": 0.3641349570059513,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.3641349570059513,
        "precision": 0.3452596010480242,
        "recall": 0.4198270126413839
      },
      {
        "accuracy": 0.4743845642049235,
        "f1": 0.39283083664321183,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.39283083664321183,
        "precision": 0.36302027978674684,
        "recall": 0.4743845642049235
      },
      {
        "accuracy": 0.7877578176979375,
        "f1": 0.7394264381290327,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.7394264381290327,
        "precision": 0.7186523777841144,
        "recall": 0.7877578176979375
      },
      {
        "accuracy": 0.06187624750499002,
        "f1": 0.03339815906549268,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.03339815906549268,
        "precision": 0.0276543858222606,
        "recall": 0.06187624750499002
      },
      {
        "accuracy": 0.48303393213572854,
        "f1": 0.40130106826713613,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.40130106826713613,
        "precision": 0.37148903251697657,
        "recall": 0.48303393213572854
      },
      {
        "accuracy": 0.3812375249500998,
        "f1": 0.3022799518807503,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.3022799518807503,
        "precision": 0.2755666636904162,
        "recall": 0.3812375249500998
      },
      {
        "accuracy": 0.8310046573519627,
        "f1": 0.78814751449482,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.78814751449482,
        "precision": 0.7688733643823463,
        "recall": 0.8310046573519627
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8871811931692172,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.8871811931692172,
        "precision": 0.8769128409846972,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.6214238190286094,
        "f1": 0.5515096790545893,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.5515096790545893,
        "precision": 0.523049627241244,
        "recall": 0.6214238190286094
      },
      {
        "accuracy": 0.1823020625415835,
        "f1": 0.12652559410297803,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.12652559410297803,
        "precision": 0.11191348809565398,
        "recall": 0.1823020625415835
      },
      {
        "accuracy": 0.5728542914171657,
        "f1": 0.49787368928498427,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.49787368928498427,
        "precision": 0.46916867323553946,
        "recall": 0.5728542914171657
      },
      {
        "accuracy": 0.7717897538256819,
        "f1": 0.7183685538974961,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7183685538974961,
        "precision": 0.6954590818363274,
        "recall": 0.7717897538256819
      },
      {
        "accuracy": 0.8689288090485695,
        "f1": 0.8323923581408612,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.8323923581408612,
        "precision": 0.8158128188068307,
        "recall": 0.8689288090485695
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0004475289048000538,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0004475289048000538,
        "precision": 0.00024950896911822015,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.8642714570858283,
        "f1": 0.8312633991276704,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.8312633991276704,
        "precision": 0.8162840984697272,
        "recall": 0.8642714570858283
      },
      {
        "accuracy": 0.6879574184963406,
        "f1": 0.6233189705245593,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6233189705245593,
        "precision": 0.5972225102464623,
        "recall": 0.6879574184963406
      },
      {
        "accuracy": 0.7451763140385895,
        "f1": 0.6909741843873581,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.6909741843873581,
        "precision": 0.6678341729239933,
        "recall": 0.7451763140385895
      },
      {
        "accuracy": 0.36194278110445777,
        "f1": 0.28351649828695735,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.28351649828695735,
        "precision": 0.25739819063172353,
        "recall": 0.36194278110445777
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0008683543679430916,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0008683543679430916,
        "precision": 0.0007705829402566057,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.3359946773120426,
        "f1": 0.2588454114343512,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.2588454114343512,
        "precision": 0.23292947072887193,
        "recall": 0.3359946773120426
      },
      {
        "accuracy": 0.6726546906187625,
        "f1": 0.6080980895352153,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.6080980895352153,
        "precision": 0.5815480150809492,
        "recall": 0.6726546906187625
      },
      {
        "accuracy": 0.7664670658682635,
        "f1": 0.7139773363326256,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.7139773363326256,
        "precision": 0.6910456864049679,
        "recall": 0.7664670658682635
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8759591927256597,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.8759591927256597,
        "precision": 0.8642603681525838,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.17165668662674652,
        "f1": 0.13902187485021816,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.13902187485021816,
        "precision": 0.12829288512921247,
        "recall": 0.17165668662674652
      },
      {
        "accuracy": 0.2588157019294744,
        "f1": 0.21377848843084854,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.21377848843084854,
        "precision": 0.19907502405825478,
        "recall": 0.2588157019294744
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.03597355048137693,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03597355048137693,
        "precision": 0.03200217498725746,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.23353293413173654,
        "f1": 0.19898916046620635,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.19898916046620635,
        "precision": 0.18663515459922644,
        "recall": 0.23353293413173654
      },
      {
        "accuracy": 0.35196274118429804,
        "f1": 0.2952356858045481,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2952356858045481,
        "precision": 0.2764827990020086,
        "recall": 0.35196274118429804
      },
      {
        "accuracy": 0.27877578176979373,
        "f1": 0.23488897116118376,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.23488897116118376,
        "precision": 0.21982543463003593,
        "recall": 0.27877578176979373
      },
      {
        "accuracy": 0.3439787092481703,
        "f1": 0.2978677405490446,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2978677405490446,
        "precision": 0.28156616156286596,
        "recall": 0.3439787092481703
      },
      {
        "accuracy": 0.2055888223552894,
        "f1": 0.16890805530193423,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.16890805530193423,
        "precision": 0.1569568991849431,
        "recall": 0.2055888223552894
      },
      {
        "accuracy": 0.11177644710578842,
        "f1": 0.08435290590979215,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08435290590979215,
        "precision": 0.07588640871780473,
        "recall": 0.11177644710578842
      },
      {
        "accuracy": 0.2541583499667332,
        "f1": 0.21687370809127293,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21687370809127293,
        "precision": 0.20337691620126752,
        "recall": 0.2541583499667332
      },
      {
        "accuracy": 0.2368596141051231,
        "f1": 0.19854931021278385,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.19854931021278385,
        "precision": 0.1853230673739656,
        "recall": 0.2368596141051231
      },
      {
        "accuracy": 0.3499667332002661,
        "f1": 0.30590700537648746,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.30590700537648746,
        "precision": 0.29160284128174435,
        "recall": 0.3499667332002661
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00032986312762767396,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00032986312762767396,
        "precision": 0.00017923863149430067,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.3093812375249501,
        "f1": 0.2700658308941742,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2700658308941742,
        "precision": 0.25636554372716197,
        "recall": 0.3093812375249501
      },
      {
        "accuracy": 0.2042581503659348,
        "f1": 0.16638283506511337,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.16638283506511337,
        "precision": 0.15416411256936088,
        "recall": 0.2042581503659348
      },
      {
        "accuracy": 0.23486360612109114,
        "f1": 0.19708485866170494,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.19708485866170494,
        "precision": 0.18392837341190635,
        "recall": 0.23486360612109114
      },
      {
        "accuracy": 0.1709913506320692,
        "f1": 0.13838267028553122,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.13838267028553122,
        "precision": 0.12707261624133762,
        "recall": 0.1709913506320692
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 5.5570507969729625e-05,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 5.5570507969729625e-05,
        "precision": 2.811742254205642e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.1989354624085163,
        "f1": 0.1698064189082153,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1698064189082153,
        "precision": 0.15917767639324523,
        "recall": 0.1989354624085163
      },
      {
        "accuracy": 0.19294743845642048,
        "f1": 0.16054688678388646,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.16054688678388646,
        "precision": 0.14986274190104382,
        "recall": 0.19294743845642048
      },
      {
        "accuracy": 0.25948103792415167,
        "f1": 0.21940258064629234,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.21940258064629234,
        "precision": 0.2059922067012537,
        "recall": 0.25948103792415167
      },
      {
        "accuracy": 0.313373253493014,
        "f1": 0.2652849850196334,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2652849850196334,
        "precision": 0.24865799317816334,
        "recall": 0.313373253493014
      },
      {
        "accuracy": 0.4258150365934797,
        "f1": 0.35615805426184666,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.35615805426184666,
        "precision": 0.33010062865352285,
        "recall": 0.4258150365934797
      },
      {
        "accuracy": 0.7178975382568197,
        "f1": 0.6662675271927356,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.6662675271927356,
        "precision": 0.6445121541428926,
        "recall": 0.7178975382568197
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.026806328561079926,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.026806328561079926,
        "precision": 0.022835225416286204,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.3865602129075183,
        "f1": 0.3242635607905069,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.3242635607905069,
        "precision": 0.3010930830526932,
        "recall": 0.3865602129075183
      },
      {
        "accuracy": 0.8263473053892215,
        "f1": 0.7874605766821337,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.7874605766821337,
        "precision": 0.7704923486360612,
        "recall": 0.8263473053892215
      },
      {
        "accuracy": 0.3306719893546241,
        "f1": 0.27129444814075554,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.27129444814075554,
        "precision": 0.24966284362491947,
        "recall": 0.3306719893546241
      },
      {
        "accuracy": 0.7950765136393879,
        "f1": 0.7590145659216819,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.7590145659216819,
        "precision": 0.7431628805880303,
        "recall": 0.7950765136393879
      },
      {
        "accuracy": 0.5608782435129741,
        "f1": 0.5020767987833856,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.5020767987833856,
        "precision": 0.47772050895803386,
        "recall": 0.5608782435129741
      },
      {
        "accuracy": 0.15635395874916833,
        "f1": 0.11181081799844272,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.11181081799844272,
        "precision": 0.10011955030045783,
        "recall": 0.15635395874916833
      },
      {
        "accuracy": 0.4597471723220226,
        "f1": 0.3973756191321061,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.3973756191321061,
        "precision": 0.37507762991794935,
        "recall": 0.4597471723220226
      },
      {
        "accuracy": 0.6686626746506986,
        "f1": 0.6175405802152308,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.6175405802152308,
        "precision": 0.5961558604772178,
        "recall": 0.6686626746506986
      },
      {
        "accuracy": 0.7664670658682635,
        "f1": 0.7252336596647975,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.7252336596647975,
        "precision": 0.708262798781761,
        "recall": 0.7664670658682635
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0003904137496840329,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0003904137496840329,
        "precision": 0.00020921284212020927,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.7704590818363274,
        "f1": 0.7298196710028219,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.7298196710028219,
        "precision": 0.7126635617653581,
        "recall": 0.7704590818363274
      },
      {
        "accuracy": 0.6327345309381237,
        "f1": 0.5750704939327693,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.5750704939327693,
        "precision": 0.5509298456404245,
        "recall": 0.6327345309381237
      },
      {
        "accuracy": 0.6753160345974717,
        "f1": 0.6271409561828722,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.6271409561828722,
        "precision": 0.6069372459562667,
        "recall": 0.6753160345974717
      },
      {
        "accuracy": 0.33399866932801064,
        "f1": 0.2791127701307342,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.2791127701307342,
        "precision": 0.2589756993948611,
        "recall": 0.33399866932801064
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00025690654433169403,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.00025690654433169403,
        "precision": 0.0001507884150200794,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.2098406029543754,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.2098406029543754,
        "precision": 0.19101131424904932,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.582168995342648,
        "f1": 0.5229376412011143,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.5229376412011143,
        "precision": 0.4985647752114818,
        "recall": 0.582168995342648
      },
      {
        "accuracy": 0.6613439787092482,
        "f1": 0.6135079048252701,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.6135079048252701,
        "precision": 0.593486043785445,
        "recall": 0.6613439787092482
      },
      {
        "accuracy": 0.7990685296074518,
        "f1": 0.7599822001019605,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.7599822001019605,
        "precision": 0.742814371257485,
        "recall": 0.7990685296074518
      },
      {
        "accuracy": 0.45708582834331335,
        "f1": 0.38083036945312393,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.38083036945312393,
        "precision": 0.35202797867468527,
        "recall": 0.45708582834331335
      },
      {
        "accuracy": 0.7771124417831005,
        "f1": 0.7280138136425561,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7280138136425561,
        "precision": 0.7067088046129962,
        "recall": 0.7771124417831005
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.03413252411216236,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03413252411216236,
        "precision": 0.029027107659075606,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.47837658017298734,
        "f1": 0.40304955265035103,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.40304955265035103,
        "precision": 0.37524078826474033,
        "recall": 0.47837658017298734
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8638500776225326,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8638500776225326,
        "precision": 0.8516855178531826,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.3805721889554225,
        "f1": 0.3089429274060012,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3089429274060012,
        "precision": 0.283538742620579,
        "recall": 0.3805721889554225
      },
      {
        "accuracy": 0.7990685296074518,
        "f1": 0.7504768241295188,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7504768241295188,
        "precision": 0.7283987580394766,
        "recall": 0.7990685296074518
      },
      {
        "accuracy": 0.6101131071190952,
        "f1": 0.544023593025589,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.544023593025589,
        "precision": 0.5163970593611312,
        "recall": 0.6101131071190952
      },
      {
        "accuracy": 0.17498336660013306,
        "f1": 0.123454377081062,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.123454377081062,
        "precision": 0.10930280630879431,
        "recall": 0.17498336660013306
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.46565590837047927,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.46565590837047927,
        "precision": 0.43954656823918303,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.7465069860279441,
        "f1": 0.6924500205937332,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6924500205937332,
        "precision": 0.6687181193169217,
        "recall": 0.7465069860279441
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8009441434591135,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8009441434591135,
        "precision": 0.784253714792637,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00046672546777894923,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00046672546777894923,
        "precision": 0.00024822975290998857,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.825016633399867,
        "f1": 0.7850188511865159,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7850188511865159,
        "precision": 0.7678040743909006,
        "recall": 0.825016633399867
      },
      {
        "accuracy": 0.675981370592149,
        "f1": 0.6102657119623188,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6102657119623188,
        "precision": 0.5823028546082438,
        "recall": 0.675981370592149
      },
      {
        "accuracy": 0.729208250166334,
        "f1": 0.6778728257770174,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6778728257770174,
        "precision": 0.6564775211481798,
        "recall": 0.729208250166334
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.2848599578140496,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.2848599578140496,
        "precision": 0.2618363875349903,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00025685345030596654,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00025685345030596654,
        "precision": 0.00013481457453743648,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.3306719893546241,
        "f1": 0.26082438298007155,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.26082438298007155,
        "precision": 0.23787475427616195,
        "recall": 0.3306719893546241
      },
      {
        "accuracy": 0.6633399866932801,
        "f1": 0.6021639261160219,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6021639261160219,
        "precision": 0.5757928587269905,
        "recall": 0.6633399866932801
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6792098342996546,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6792098342996546,
        "precision": 0.6547571523619428,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.8735861610113107,
        "f1": 0.8425149700598802,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8425149700598802,
        "precision": 0.8282546019072966,
        "recall": 0.8735861610113107
      },
      {
        "accuracy": 0.3226879574184963,
        "f1": 0.2622757131240165,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.2622757131240165,
        "precision": 0.23992649621392137,
        "recall": 0.3226879574184963
      },
      {
        "accuracy": 0.5508982035928144,
        "f1": 0.4898824389408438,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.4898824389408438,
        "precision": 0.4662823943263065,
        "recall": 0.5508982035928144
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.01877328834378224,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.01877328834378224,
        "precision": 0.016176311839199545,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.27345309381237526,
        "f1": 0.21930847300108777,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.21930847300108777,
        "precision": 0.20093752628682768,
        "recall": 0.27345309381237526
      },
      {
        "accuracy": 0.5728542914171657,
        "f1": 0.5126445189319441,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.5126445189319441,
        "precision": 0.48911834820018457,
        "recall": 0.5728542914171657
      },
      {
        "accuracy": 0.21756487025948104,
        "f1": 0.17022573419779008,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.17022573419779008,
        "precision": 0.15494542420690127,
        "recall": 0.21756487025948104
      },
      {
        "accuracy": 0.5402528276779773,
        "f1": 0.484311718443455,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.484311718443455,
        "precision": 0.4619095143047239,
        "recall": 0.5402528276779773
      },
      {
        "accuracy": 0.5781769793745841,
        "f1": 0.5213584657637728,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.5213584657637728,
        "precision": 0.49954406836563575,
        "recall": 0.5781769793745841
      },
      {
        "accuracy": 0.10578842315369262,
        "f1": 0.07012031903502831,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.07012031903502831,
        "precision": 0.060920979109601855,
        "recall": 0.10578842315369262
      },
      {
        "accuracy": 0.3107119095143047,
        "f1": 0.263390198919141,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.263390198919141,
        "precision": 0.24648027916490992,
        "recall": 0.3107119095143047
      },
      {
        "accuracy": 0.5449101796407185,
        "f1": 0.4849348921205209,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.4849348921205209,
        "precision": 0.4610546583600476,
        "recall": 0.5449101796407185
      },
      {
        "accuracy": 0.5548902195608783,
        "f1": 0.4934144820057206,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.4934144820057206,
        "precision": 0.4691841806582912,
        "recall": 0.5548902195608783
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0007905878554719499,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0007905878554719499,
        "precision": 0.0005219259906457473,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.5395874916833001,
        "f1": 0.4835482954245429,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.4835482954245429,
        "precision": 0.46146833317492,
        "recall": 0.5395874916833001
      },
      {
        "accuracy": 0.4856952761144378,
        "f1": 0.42837077168414495,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.42837077168414495,
        "precision": 0.4049360621558331,
        "recall": 0.4856952761144378
      },
      {
        "accuracy": 0.47904191616766467,
        "f1": 0.42141959467308765,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.42141959467308765,
        "precision": 0.398471575367783,
        "recall": 0.47904191616766467
      },
      {
        "accuracy": 0.24085163007318697,
        "f1": 0.19008601363890787,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.19008601363890787,
        "precision": 0.17220213991671077,
        "recall": 0.24085163007318697
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009308924873444504,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0009308924873444504,
        "precision": 0.000687464607409394,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.16966067864271456,
        "f1": 0.12294557164229583,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.12294557164229583,
        "precision": 0.10992838295732507,
        "recall": 0.16966067864271456
      },
      {
        "accuracy": 0.4637391882900865,
        "f1": 0.40807379949096517,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.40807379949096517,
        "precision": 0.3862269435964152,
        "recall": 0.4637391882900865
      },
      {
        "accuracy": 0.5608782435129741,
        "f1": 0.5032416648185112,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.5032416648185112,
        "precision": 0.47955279916357757,
        "recall": 0.5608782435129741
      },
      {
        "accuracy": 0.5708582834331337,
        "f1": 0.5139113307775982,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.5139113307775982,
        "precision": 0.4915061651588597,
        "recall": 0.5708582834331337
      },
      {
        "accuracy": 0.08183632734530938,
        "f1": 0.06572444084262553,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.06572444084262553,
        "precision": 0.06070874863290032,
        "recall": 0.08183632734530938
      },
      {
        "accuracy": 0.1217564870259481,
        "f1": 0.09919457621068802,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.09919457621068802,
        "precision": 0.09256533140687909,
        "recall": 0.1217564870259481
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.025940447148031977,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.025940447148031977,
        "precision": 0.02363403515804596,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.10166926008894248,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.10166926008894248,
        "precision": 0.09625710099761997,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.16234198270126413,
        "f1": 0.1345669333798339,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.1345669333798339,
        "precision": 0.1263499542246699,
        "recall": 0.16234198270126413
      },
      {
        "accuracy": 0.09248170326014638,
        "f1": 0.0773933761957714,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.0773933761957714,
        "precision": 0.07249205293117468,
        "recall": 0.09248170326014638
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.10235622747657501,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.10235622747657501,
        "precision": 0.09624598602828582,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.15568862275449102,
        "f1": 0.12906149028720054,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.12906149028720054,
        "precision": 0.12184769576641452,
        "recall": 0.15568862275449102
      },
      {
        "accuracy": 0.08915502328675981,
        "f1": 0.07181456274238451,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.07181456274238451,
        "precision": 0.06690552553826007,
        "recall": 0.08915502328675981
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.10966245232089847,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.10966245232089847,
        "precision": 0.10389739324531032,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.1051230871590153,
        "f1": 0.09001432675744864,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.09001432675744864,
        "precision": 0.08537608543596567,
        "recall": 0.1051230871590153
      },
      {
        "accuracy": 0.12308715901530273,
        "f1": 0.10360412001705113,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.10360412001705113,
        "precision": 0.09808053367038337,
        "recall": 0.12308715901530273
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00033116723945592524,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.00033116723945592524,
        "precision": 0.0001790788715647749,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.1437125748502994,
        "f1": 0.11826731145447192,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.11826731145447192,
        "precision": 0.11118329983047656,
        "recall": 0.1437125748502994
      },
      {
        "accuracy": 0.07984031936127745,
        "f1": 0.06421731388219465,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.06421731388219465,
        "precision": 0.06004727315583863,
        "recall": 0.07984031936127745
      },
      {
        "accuracy": 0.12242182302062542,
        "f1": 0.10199815901869343,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.10199815901869343,
        "precision": 0.09610923085811543,
        "recall": 0.12242182302062542
      },
      {
        "accuracy": 0.09447771124417831,
        "f1": 0.0768451459575605,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0768451459575605,
        "precision": 0.07111970143407269,
        "recall": 0.09447771124417831
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000376895288744159,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.000376895288744159,
        "precision": 0.00024414059457297918,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.1051230871590153,
        "f1": 0.08863517501459009,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.08863517501459009,
        "precision": 0.08289984838065148,
        "recall": 0.1051230871590153
      },
      {
        "accuracy": 0.09248170326014638,
        "f1": 0.07307179728972368,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.07307179728972368,
        "precision": 0.06840403564216807,
        "recall": 0.09248170326014638
      },
      {
        "accuracy": 0.11510312707917499,
        "f1": 0.09107129780973874,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.09107129780973874,
        "precision": 0.08434533852895708,
        "recall": 0.11510312707917499
      },
      {
        "accuracy": 0.16367265469061876,
        "f1": 0.13830874140338453,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.13830874140338453,
        "precision": 0.13032290631725907,
        "recall": 0.16367265469061876
      },
      {
        "accuracy": 0.26746506986027946,
        "f1": 0.21704954688986625,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.21704954688986625,
        "precision": 0.19884173452037723,
        "recall": 0.26746506986027946
      },
      {
        "accuracy": 0.40718562874251496,
        "f1": 0.3526701809577235,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.3526701809577235,
        "precision": 0.3326831786163123,
        "recall": 0.40718562874251496
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.03654849724552424,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03654849724552424,
        "precision": 0.03114829579732591,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.3819028609447771,
        "f1": 0.3280866837753065,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3280866837753065,
        "precision": 0.3076832940106393,
        "recall": 0.3819028609447771
      },
      {
        "accuracy": 0.5595475715236194,
        "f1": 0.5053674572636648,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5053674572636648,
        "precision": 0.4849924083457018,
        "recall": 0.5595475715236194
      },
      {
        "accuracy": 0.28542914171656686,
        "f1": 0.23271277550718666,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.23271277550718666,
        "precision": 0.21400957104549917,
        "recall": 0.28542914171656686
      },
      {
        "accuracy": 0.4491017964071856,
        "f1": 0.400609411288054,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.400609411288054,
        "precision": 0.38251501368094265,
        "recall": 0.4491017964071856
      },
      {
        "accuracy": 0.5209580838323353,
        "f1": 0.4684388791739308,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4684388791739308,
        "precision": 0.4488926375574133,
        "recall": 0.5209580838323353
      },
      {
        "accuracy": 0.34464404524284764,
        "f1": 0.2913662456261468,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.2913662456261468,
        "precision": 0.270987539528718,
        "recall": 0.34464404524284764
      },
      {
        "accuracy": 0.1497005988023952,
        "f1": 0.10826701998769628,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.10826701998769628,
        "precision": 0.09662597604214371,
        "recall": 0.1497005988023952
      },
      {
        "accuracy": 0.3958749168330007,
        "f1": 0.3436361806562581,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3436361806562581,
        "precision": 0.32434544303013246,
        "recall": 0.3958749168330007
      },
      {
        "accuracy": 0.4916833000665336,
        "f1": 0.4368002091055983,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4368002091055983,
        "precision": 0.4170119765652485,
        "recall": 0.4916833000665336
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.000788796372432277,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.000788796372432277,
        "precision": 0.0005144777982144111,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.5262807717897539,
        "f1": 0.4747972309349555,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.4747972309349555,
        "precision": 0.4548141811614865,
        "recall": 0.5262807717897539
      },
      {
        "accuracy": 0.31137724550898205,
        "f1": 0.2548458092026128,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2548458092026128,
        "precision": 0.23554874378227672,
        "recall": 0.31137724550898205
      },
      {
        "accuracy": 0.3586161011310712,
        "f1": 0.30819793793845685,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.30819793793845685,
        "precision": 0.2900548971377902,
        "recall": 0.3586161011310712
      },
      {
        "accuracy": 0.2967398536260812,
        "f1": 0.23962547764942974,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.23962547764942974,
        "precision": 0.2190990627617374,
        "recall": 0.2967398536260812
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.000561742143475432,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.000561742143475432,
        "precision": 0.00039412856248695333,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.2827677977378576,
        "f1": 0.23304250509252267,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.23304250509252267,
        "precision": 0.21575328179619593,
        "recall": 0.2827677977378576
      },
      {
        "accuracy": 0.3206919494344644,
        "f1": 0.2654432357027167,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.2654432357027167,
        "precision": 0.24548227517289395,
        "recall": 0.3206919494344644
      },
      {
        "accuracy": 0.4038589487691284,
        "f1": 0.34915382355502117,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.34915382355502117,
        "precision": 0.3304669923373692,
        "recall": 0.4038589487691284
      },
      {
        "accuracy": 0.4856952761144378,
        "f1": 0.4318664258784019,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4318664258784019,
        "precision": 0.4113061976510518,
        "recall": 0.4856952761144378
      },
      {
        "accuracy": 0.39654025282767796,
        "f1": 0.3281336797304861,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.3281336797304861,
        "precision": 0.30261012366800794,
        "recall": 0.39654025282767796
      },
      {
        "accuracy": 0.6666666666666666,
        "f1": 0.6120304364815342,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.6120304364815342,
        "precision": 0.5891367651347691,
        "recall": 0.6666666666666666
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.021862524719311143,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.021862524719311143,
        "precision": 0.018633918927449512,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.313373253493014,
        "f1": 0.2514637489628683,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.2514637489628683,
        "precision": 0.23007727930382618,
        "recall": 0.313373253493014
      },
      {
        "accuracy": 0.7278775781769794,
        "f1": 0.6730222095491557,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.6730222095491557,
        "precision": 0.6504264198874977,
        "recall": 0.7278775781769794
      },
      {
        "accuracy": 0.2714570858283433,
        "f1": 0.2191260816510317,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.2191260816510317,
        "precision": 0.20084199086195095,
        "recall": 0.2714570858283433
      },
      {
        "accuracy": 0.6553559547571524,
        "f1": 0.5967325090079582,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.5967325090079582,
        "precision": 0.5721525203561132,
        "recall": 0.6553559547571524
      },
      {
        "accuracy": 0.6986027944111777,
        "f1": 0.6504193152895748,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.6504193152895748,
        "precision": 0.6307345626207902,
        "recall": 0.6986027944111777
      },
      {
        "accuracy": 0.5808383233532934,
        "f1": 0.5198048347748947,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.5198048347748947,
        "precision": 0.49446451013317283,
        "recall": 0.5808383233532934
      },
      {
        "accuracy": 0.11909514304723885,
        "f1": 0.08368192014408353,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.08368192014408353,
        "precision": 0.07424378681863712,
        "recall": 0.11909514304723885
      },
      {
        "accuracy": 0.38389886892880903,
        "f1": 0.32628069055214765,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.32628069055214765,
        "precision": 0.3050058852953064,
        "recall": 0.38389886892880903
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6393662890668879,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.6393662890668879,
        "precision": 0.6171746454181584,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001772143497344861,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.0001772143497344861,
        "precision": 9.621451323760989e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.6866267465069861,
        "f1": 0.6285349935050533,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.6285349935050533,
        "precision": 0.6050628900928302,
        "recall": 0.6866267465069861
      },
      {
        "accuracy": 0.6087824351297405,
        "f1": 0.5429205081899693,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.5429205081899693,
        "precision": 0.5157241073408737,
        "recall": 0.6087824351297405
      },
      {
        "accuracy": 0.5974717232202262,
        "f1": 0.5408368448288607,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.5408368448288607,
        "precision": 0.5180987231885436,
        "recall": 0.5974717232202262
      },
      {
        "accuracy": 0.28542914171656686,
        "f1": 0.22550292909574343,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.22550292909574343,
        "precision": 0.20508937843973654,
        "recall": 0.28542914171656686
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00018393587706574634,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.00018393587706574634,
        "precision": 0.00010141213727955052,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.20758483033932135,
        "f1": 0.1603090940481377,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.1603090940481377,
        "precision": 0.14509985098807454,
        "recall": 0.20758483033932135
      },
      {
        "accuracy": 0.5881570192947438,
        "f1": 0.5304238084677206,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.5304238084677206,
        "precision": 0.5060889044421978,
        "recall": 0.5881570192947438
      },
      {
        "accuracy": 0.6660013306719893,
        "f1": 0.6108117099135063,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.6108117099135063,
        "precision": 0.5871431739695213,
        "recall": 0.6660013306719893
      },
      {
        "accuracy": 0.7072521623419827,
        "f1": 0.6538959598839839,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.6538959598839839,
        "precision": 0.632144705298398,
        "recall": 0.7072521623419827
      },
      {
        "accuracy": 0.4424484364604125,
        "f1": 0.3692440515793809,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.3692440515793809,
        "precision": 0.3411909706320884,
        "recall": 0.4424484364604125
      },
      {
        "accuracy": 0.7578176979374585,
        "f1": 0.7086641531751312,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7086641531751312,
        "precision": 0.6877190064315812,
        "recall": 0.7578176979374585
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.03659567264475095,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03659567264475095,
        "precision": 0.03249621807766599,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.4244843646041251,
        "f1": 0.3543994982617737,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3543994982617737,
        "precision": 0.32883098641581676,
        "recall": 0.4244843646041251
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.812776035231125,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.812776035231125,
        "precision": 0.7965244114944715,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.3852295409181637,
        "f1": 0.31956924571695033,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.31956924571695033,
        "precision": 0.2961653412751217,
        "recall": 0.3852295409181637
      },
      {
        "accuracy": 0.7631403858948769,
        "f1": 0.7180876342552989,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7180876342552989,
        "precision": 0.6985584386781992,
        "recall": 0.7631403858948769
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8250736621994108,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8250736621994108,
        "precision": 0.8101574628520737,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.5781769793745841,
        "f1": 0.5112499055612828,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5112499055612828,
        "precision": 0.48291829040332035,
        "recall": 0.5781769793745841
      },
      {
        "accuracy": 0.15169660678642716,
        "f1": 0.10729568901733344,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.10729568901733344,
        "precision": 0.0950281901192773,
        "recall": 0.15169660678642716
      },
      {
        "accuracy": 0.5043246839654025,
        "f1": 0.4384574765812291,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4384574765812291,
        "precision": 0.4131879098944967,
        "recall": 0.5043246839654025
      },
      {
        "accuracy": 0.7139055222887558,
        "f1": 0.6588093653961917,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6588093653961917,
        "precision": 0.6355732978487469,
        "recall": 0.7139055222887558
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00039950338847154806,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00039950338847154806,
        "precision": 0.00021815936151339333,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.791084497671324,
        "f1": 0.7468745049583374,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7468745049583374,
        "precision": 0.7272898647150144,
        "recall": 0.791084497671324
      },
      {
        "accuracy": 0.6380572188955422,
        "f1": 0.5734361963902882,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5734361963902882,
        "precision": 0.5467248043595349,
        "recall": 0.6380572188955422
      },
      {
        "accuracy": 0.6959414504324684,
        "f1": 0.6424500205937331,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6424500205937331,
        "precision": 0.6202066765939022,
        "recall": 0.6959414504324684
      },
      {
        "accuracy": 0.36593479707252163,
        "f1": 0.30117710706533063,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.30117710706533063,
        "precision": 0.2790003834415012,
        "recall": 0.36593479707252163
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0003664658625467267,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0003664658625467267,
        "precision": 0.00020092874489344707,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.29607451763140386,
        "f1": 0.2344897506574153,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2344897506574153,
        "precision": 0.21418744816948412,
        "recall": 0.29607451763140386
      },
      {
        "accuracy": 0.626746506986028,
        "f1": 0.5655482685422805,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5655482685422805,
        "precision": 0.5396814835936592,
        "recall": 0.626746506986028
      },
      {
        "accuracy": 0.7065868263473054,
        "f1": 0.6532379685074295,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6532379685074295,
        "precision": 0.6299464562937617,
        "recall": 0.7065868263473054
      },
      {
        "accuracy": 0.8343313373253493,
        "f1": 0.7956753160345974,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7956753160345974,
        "precision": 0.7783544023064982,
        "recall": 0.8343313373253493
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0014697433963323633,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0014697433963323633,
        "precision": 0.0011686918566081476,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008073447115288015,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0008073447115288015,
        "precision": 0.0007404278455647528,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0010324530204608119,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0010324530204608119,
        "precision": 0.00086636453043342,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007167259419549265,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0007167259419549265,
        "precision": 0.0006914496391424887,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006808500580448846,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0006808500580448846,
        "precision": 0.0006731683863741936,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001699937185100687,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.001699937185100687,
        "precision": 0.0015506843841117763,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006664971395196808,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0006664971395196808,
        "precision": 0.000665917074148646,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00011421530294272051,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.00011421530294272051,
        "precision": 6.0027271825050316e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007911794696701644,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0007911794696701644,
        "precision": 0.0007307424223591889,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009739261880131967,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0009739261880131967,
        "precision": 0.0008534950301417367,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007539710486090454,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0007539710486090454,
        "precision": 0.0007108185177508413,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007480781654297173,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0007480781654297173,
        "precision": 0.0007077340347709971,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008138278796179407,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0008138278796179407,
        "precision": 0.0007436981066426284,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000705207483960286,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.000705207483960286,
        "precision": 0.000685507429641776,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011937860375918756,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0011937860375918756,
        "precision": 0.0010421570592449635,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0010644436660084322,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0010644436660084322,
        "precision": 0.0009023407149008334,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008864958409347891,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0008864958409347891,
        "precision": 0.0007920362838522685,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.025594417934680203,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.025594417934680203,
        "precision": 0.023227661301513592,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0020988202176139255,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0020988202176139255,
        "precision": 0.0020493712713860667,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012454220481735007,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0012454220481735007,
        "precision": 0.0010714471124170998,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 7.860793718889841e-05,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 7.860793718889841e-05,
        "precision": 4.0536389331458246e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0009567099096058728,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0009567099096058728,
        "precision": 0.0008444510084992334,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.4624085163007319,
        "f1": 0.3888085929004092,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.3888085929004092,
        "precision": 0.3601374211653653,
        "recall": 0.4624085163007319
      },
      {
        "accuracy": 0.7524950099800399,
        "f1": 0.7020181858505211,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7020181858505211,
        "precision": 0.679570488652325,
        "recall": 0.7524950099800399
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.033130814529801454,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.033130814529801454,
        "precision": 0.027364079850242414,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.4357950765136394,
        "f1": 0.3672812291574767,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3672812291574767,
        "precision": 0.3413258379825245,
        "recall": 0.4357950765136394
      },
      {
        "accuracy": 0.8562874251497006,
        "f1": 0.8218800494249595,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8218800494249595,
        "precision": 0.8065979152805499,
        "recall": 0.8562874251497006
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.28983352715887645,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.28983352715887645,
        "precision": 0.26755433337269663,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.7160567753382124,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7160567753382124,
        "precision": 0.6947660235085384,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.8157019294743846,
        "f1": 0.7762622902343461,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7762622902343461,
        "precision": 0.7587990685296074,
        "recall": 0.8157019294743846
      },
      {
        "accuracy": 0.5768463073852296,
        "f1": 0.5138210831823606,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5138210831823606,
        "precision": 0.4876809872318854,
        "recall": 0.5768463073852296
      },
      {
        "accuracy": 0.16699933466400532,
        "f1": 0.11472814905948639,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.11472814905948639,
        "precision": 0.1003903623417792,
        "recall": 0.16699933466400532
      },
      {
        "accuracy": 0.543579507651364,
        "f1": 0.4821326562843528,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4821326562843528,
        "precision": 0.4587240862190961,
        "recall": 0.543579507651364
      },
      {
        "accuracy": 0.709913506320692,
        "f1": 0.6509425593257928,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6509425593257928,
        "precision": 0.6251275227323131,
        "recall": 0.709913506320692
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7506336533282641,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7506336533282641,
        "precision": 0.7297135886956245,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0005596363805980181,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0005596363805980181,
        "precision": 0.00033933547490729975,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.6593479707252162,
        "f1": 0.5963659981624052,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5963659981624052,
        "precision": 0.5703481925038811,
        "recall": 0.6593479707252162
      },
      {
        "accuracy": 0.6859614105123087,
        "f1": 0.6307511960206571,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6307511960206571,
        "precision": 0.6071967176757596,
        "recall": 0.6859614105123087
      },
      {
        "accuracy": 0.3805721889554225,
        "f1": 0.30881962902920984,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.30881962902920984,
        "precision": 0.2835564321093263,
        "recall": 0.3805721889554225
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0003190284492070547,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0003190284492070547,
        "precision": 0.00019303743860683023,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.30206254158349966,
        "f1": 0.2398214301407914,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2398214301407914,
        "precision": 0.21969848182423035,
        "recall": 0.30206254158349966
      },
      {
        "accuracy": 0.6167664670658682,
        "f1": 0.5528107805552915,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5528107805552915,
        "precision": 0.5262863162563761,
        "recall": 0.6167664670658682
      },
      {
        "accuracy": 0.7019294743845642,
        "f1": 0.6485600228115198,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6485600228115198,
        "precision": 0.6253936571301841,
        "recall": 0.7019294743845642
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7859297278458955,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7859297278458955,
        "precision": 0.7682856509203814,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.40718562874251496,
        "f1": 0.3376760188137434,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.3376760188137434,
        "precision": 0.31151981750784147,
        "recall": 0.40718562874251496
      },
      {
        "accuracy": 0.648037258815702,
        "f1": 0.5883360263599784,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.5883360263599784,
        "precision": 0.5635311387806398,
        "recall": 0.648037258815702
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.015193365516574561,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.015193365516574561,
        "precision": 0.013055696428949921,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.2101584044697817,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.2101584044697817,
        "precision": 0.1898206233036572,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.6314038589487692,
        "f1": 0.5653278099884886,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.5653278099884886,
        "precision": 0.5399003580141305,
        "recall": 0.6314038589487692
      },
      {
        "accuracy": 0.2262142381902861,
        "f1": 0.18130300246068712,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.18130300246068712,
        "precision": 0.16649982862557713,
        "recall": 0.2262142381902861
      },
      {
        "accuracy": 0.6061210911510313,
        "f1": 0.547847690861663,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.547847690861663,
        "precision": 0.5246692041602221,
        "recall": 0.6061210911510313
      },
      {
        "accuracy": 0.6500332667997338,
        "f1": 0.5916454341700623,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.5916454341700623,
        "precision": 0.568567874056896,
        "recall": 0.6500332667997338
      },
      {
        "accuracy": 0.49434464404524286,
        "f1": 0.43373939950786256,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.43373939950786256,
        "precision": 0.408749960396667,
        "recall": 0.49434464404524286
      },
      {
        "accuracy": 0.09514304723885562,
        "f1": 0.06345669428914702,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.06345669428914702,
        "precision": 0.054916537775819216,
        "recall": 0.09514304723885562
      },
      {
        "accuracy": 0.3073852295409182,
        "f1": 0.25139294799973444,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.25139294799973444,
        "precision": 0.2319416555943502,
        "recall": 0.3073852295409182
      },
      {
        "accuracy": 0.5941450432468397,
        "f1": 0.5273674872477268,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.5273674872477268,
        "precision": 0.50033583626398,
        "recall": 0.5941450432468397
      },
      {
        "accuracy": 0.6134397870924817,
        "f1": 0.5530542090422331,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.5530542090422331,
        "precision": 0.5297814017873899,
        "recall": 0.6134397870924817
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0005789735602639523,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0005789735602639523,
        "precision": 0.00035230370714706957,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.6167664670658682,
        "f1": 0.5554119274678156,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.5554119274678156,
        "precision": 0.5309579254190033,
        "recall": 0.6167664670658682
      },
      {
        "accuracy": 0.592814371257485,
        "f1": 0.5316214132581397,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.5316214132581397,
        "precision": 0.5073701802743719,
        "recall": 0.592814371257485
      },
      {
        "accuracy": 0.2435129740518962,
        "f1": 0.19056362907484192,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.19056362907484192,
        "precision": 0.17311220050741008,
        "recall": 0.2435129740518962
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011760932568188978,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0011760932568188978,
        "precision": 0.0009837945502427072,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.15635395874916833,
        "f1": 0.11238916944173097,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.11238916944173097,
        "precision": 0.09897610890624862,
        "recall": 0.15635395874916833
      },
      {
        "accuracy": 0.5256154357950765,
        "f1": 0.46616502444845753,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.46616502444845753,
        "precision": 0.4433094129201914,
        "recall": 0.5256154357950765
      },
      {
        "accuracy": 0.5974717232202262,
        "f1": 0.530899624512399,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.530899624512399,
        "precision": 0.5039642936349523,
        "recall": 0.5974717232202262
      },
      {
        "accuracy": 0.633399866932801,
        "f1": 0.5697260225768427,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.5697260225768427,
        "precision": 0.5444746869896571,
        "recall": 0.633399866932801
      },
      {
        "accuracy": 0.38855622089155023,
        "f1": 0.32083773770400514,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.32083773770400514,
        "precision": 0.29497196084022426,
        "recall": 0.38855622089155023
      },
      {
        "accuracy": 0.6719893546240852,
        "f1": 0.6122770332351171,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.6122770332351171,
        "precision": 0.5871510946361246,
        "recall": 0.6719893546240852
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.020127346077924105,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.020127346077924105,
        "precision": 0.01639122359633596,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.324018629407851,
        "f1": 0.26132757609803514,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.26132757609803514,
        "precision": 0.24042473014528903,
        "recall": 0.324018629407851
      },
      {
        "accuracy": 0.7052561543579507,
        "f1": 0.6431528477436661,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.6431528477436661,
        "precision": 0.6180771354893698,
        "recall": 0.7052561543579507
      },
      {
        "accuracy": 0.2774451097804391,
        "f1": 0.22406250510042924,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.22406250510042924,
        "precision": 0.2050986192174404,
        "recall": 0.2774451097804391
      },
      {
        "accuracy": 0.667332002661344,
        "f1": 0.6113122960428349,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.6113122960428349,
        "precision": 0.5887455248233692,
        "recall": 0.667332002661344
      },
      {
        "accuracy": 0.709913506320692,
        "f1": 0.6611320704135074,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.6611320704135074,
        "precision": 0.6409736083388777,
        "recall": 0.709913506320692
      },
      {
        "accuracy": 0.48303393213572854,
        "f1": 0.41784583790571816,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.41784583790571816,
        "precision": 0.39109083420460666,
        "recall": 0.48303393213572854
      },
      {
        "accuracy": 0.1264138389886893,
        "f1": 0.08996123267580353,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.08996123267580353,
        "precision": 0.07983687045563294,
        "recall": 0.1264138389886893
      },
      {
        "accuracy": 0.33998669328010644,
        "f1": 0.2858621529280212,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.2858621529280212,
        "precision": 0.2674342032625466,
        "recall": 0.33998669328010644
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5529169654918158,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.5529169654918158,
        "precision": 0.5283818606173896,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.6600133067198936,
        "f1": 0.6031904445078098,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.6031904445078098,
        "precision": 0.5802474896287271,
        "recall": 0.6600133067198936
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0007749204821967445,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.0007749204821967445,
        "precision": 0.00044290959678695656,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.6666666666666666,
        "f1": 0.6118361161275333,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.6118361161275333,
        "precision": 0.590484639187234,
        "recall": 0.6666666666666666
      },
      {
        "accuracy": 0.5934797072521624,
        "f1": 0.5294569590976776,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.5294569590976776,
        "precision": 0.5029116370433736,
        "recall": 0.5934797072521624
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.21168893574083195,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.21168893574083195,
        "precision": 0.19416378882446747,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0001816565364830823,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0001816565364830823,
        "precision": 9.652319167735827e-05,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.1525858003901916,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.1525858003901916,
        "precision": 0.1369673972938033,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.5116433799068529,
        "f1": 0.45080949212685734,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.45080949212685734,
        "precision": 0.42662611285365776,
        "recall": 0.5116433799068529
      },
      {
        "accuracy": 0.6094477711244178,
        "f1": 0.5522199468307253,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.5522199468307253,
        "precision": 0.5291765674999208,
        "recall": 0.6094477711244178
      },
      {
        "accuracy": 0.7198935462408517,
        "f1": 0.6676504134587966,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.6676504134587966,
        "precision": 0.6462851667442485,
        "recall": 0.7198935462408517
      },
      {
        "accuracy": 0.17498336660013306,
        "f1": 0.13936031588726197,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.13936031588726197,
        "precision": 0.12802166021777764,
        "recall": 0.17498336660013306
      },
      {
        "accuracy": 0.24151696606786427,
        "f1": 0.20717623655003614,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.20717623655003614,
        "precision": 0.19521485305065883,
        "recall": 0.24151696606786427
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.02681210695859409,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.02681210695859409,
        "precision": 0.023666476311186888,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.18695941450432468,
        "f1": 0.15535204896292418,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15535204896292418,
        "precision": 0.14393686007097117,
        "recall": 0.18695941450432468
      },
      {
        "accuracy": 0.3333333333333333,
        "f1": 0.2839009151633331,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2839009151633331,
        "precision": 0.26806644016311687,
        "recall": 0.3333333333333333
      },
      {
        "accuracy": 0.1550232867598137,
        "f1": 0.12436946994673648,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.12436946994673648,
        "precision": 0.11534206718837457,
        "recall": 0.1550232867598137
      },
      {
        "accuracy": 0.2721224218230206,
        "f1": 0.23790630520450068,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.23790630520450068,
        "precision": 0.22737730411579626,
        "recall": 0.2721224218230206
      },
      {
        "accuracy": 0.3120425815036593,
        "f1": 0.2698172357122936,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2698172357122936,
        "precision": 0.2557531848776945,
        "recall": 0.3120425815036593
      },
      {
        "accuracy": 0.21357285429141717,
        "f1": 0.17388395668261195,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.17388395668261195,
        "precision": 0.1611346684783145,
        "recall": 0.21357285429141717
      },
      {
        "accuracy": 0.08316699933466401,
        "f1": 0.0635990128006096,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0635990128006096,
        "precision": 0.0574820284243543,
        "recall": 0.08316699933466401
      },
      {
        "accuracy": 0.25016633399866933,
        "f1": 0.21843186901071132,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21843186901071132,
        "precision": 0.20773106734889052,
        "recall": 0.25016633399866933
      },
      {
        "accuracy": 0.25083166999334666,
        "f1": 0.20904197140709624,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.20904197140709624,
        "precision": 0.1959207134447711,
        "recall": 0.25083166999334666
      },
      {
        "accuracy": 0.30538922155688625,
        "f1": 0.2658342438333827,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2658342438333827,
        "precision": 0.2526953504196387,
        "recall": 0.30538922155688625
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0009049153288322115,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009049153288322115,
        "precision": 0.0005980803576679128,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.30538922155688625,
        "f1": 0.2683399907334391,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2683399907334391,
        "precision": 0.2566497907647676,
        "recall": 0.30538922155688625
      },
      {
        "accuracy": 0.2049234863606121,
        "f1": 0.16812194058543461,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.16812194058543461,
        "precision": 0.1558774145229055,
        "recall": 0.2049234863606121
      },
      {
        "accuracy": 0.2162341982701264,
        "f1": 0.18178547432133285,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.18178547432133285,
        "precision": 0.17032198103476598,
        "recall": 0.2162341982701264
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0009616605854475582,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009616605854475582,
        "precision": 0.0006376583277327244,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.1550232867598137,
        "f1": 0.124247147595785,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.124247147595785,
        "precision": 0.11521465404423174,
        "recall": 0.1550232867598137
      },
      {
        "accuracy": 0.20292747837658018,
        "f1": 0.1687557014843618,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1687557014843618,
        "precision": 0.15789022489962715,
        "recall": 0.20292747837658018
      },
      {
        "accuracy": 0.24151696606786427,
        "f1": 0.20381838324746337,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.20381838324746337,
        "precision": 0.19202276869070217,
        "recall": 0.24151696606786427
      },
      {
        "accuracy": 0.2940785096473719,
        "f1": 0.2515569855784164,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2515569855784164,
        "precision": 0.2382036374950547,
        "recall": 0.2940785096473719
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011877559988235189,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0011877559988235189,
        "precision": 0.0009940601893238487,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 5.785530388498365e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 5.785530388498365e-05,
        "precision": 3.0242545212605094e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0003982311127037515,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0003982311127037515,
        "precision": 0.00025589034326844735,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.3923944106384495e-05,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 3.3923944106384495e-05,
        "precision": 1.7167842562899313e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006821002699618673,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0006821002699618673,
        "precision": 0.0006738043199227244,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 7.963370059833872e-05,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 7.963370059833872e-05,
        "precision": 4.088282531396304e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 1.0065597498900334e-06,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 1.0065597498900334e-06,
        "precision": 5.036608589533021e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00029536808585536146,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.00029536808585536146,
        "precision": 0.0001812589029459636,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 9.674972382862592e-05,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 9.674972382862592e-05,
        "precision": 5.0219203192326715e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.1088933244621867e-05,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 1.1088933244621867e-05,
        "precision": 5.568911017204935e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 9.482701462301195e-05,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 9.482701462301195e-05,
        "precision": 4.860758765050814e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.864853231223721e-05,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 6.864853231223721e-05,
        "precision": 3.5256240144908946e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.5547218382837006e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 2.5547218382837006e-05,
        "precision": 1.2905816996209068e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.01985728718928985,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.01985728718928985,
        "precision": 0.01740934086243467,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.850901159295441e-05,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 1.850901159295441e-05,
        "precision": 9.368766314708225e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006858254325950131,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0006858254325950131,
        "precision": 0.0006756827951489609,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0005775689375133495,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0005775689375133495,
        "precision": 0.00040706675873841545,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0004758565375213587,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0004758565375213587,
        "precision": 0.00034907766685200406,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006702281711087628,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0006702281711087628,
        "precision": 0.000667791109048815,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 3.104994307069532e-05,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 3.104994307069532e-05,
        "precision": 1.5665024735864605e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 2.5254264642286152e-05,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 2.5254264642286152e-05,
        "precision": 1.283694242604009e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00028969953103747667,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.00028969953103747667,
        "precision": 0.00017825013359138123,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.13040585495675316,
        "f1": 0.10260976787335833,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.10260976787335833,
        "precision": 0.09376526878728358,
        "recall": 0.13040585495675316
      },
      {
        "accuracy": 0.2102461743180306,
        "f1": 0.17191692105516632,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.17191692105516632,
        "precision": 0.16022950527440605,
        "recall": 0.2102461743180306
      },
      {
        "accuracy": 0.05588822355289421,
        "f1": 0.03978555635242262,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03978555635242262,
        "precision": 0.035074583876979086,
        "recall": 0.05588822355289421
      },
      {
        "accuracy": 0.249500998003992,
        "f1": 0.21419226519026915,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.21419226519026915,
        "precision": 0.20176366843033508,
        "recall": 0.249500998003992
      },
      {
        "accuracy": 0.3213572854291417,
        "f1": 0.26979902027621494,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.26979902027621494,
        "precision": 0.2528287978355921,
        "recall": 0.3213572854291417
      },
      {
        "accuracy": 0.20758483033932135,
        "f1": 0.17137026552607157,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.17137026552607157,
        "precision": 0.15900286473992006,
        "recall": 0.20758483033932135
      },
      {
        "accuracy": 0.25083166999334666,
        "f1": 0.21029802326408725,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.21029802326408725,
        "precision": 0.19735829978853175,
        "recall": 0.25083166999334666
      },
      {
        "accuracy": 0.31270791749833665,
        "f1": 0.26793181191841287,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.26793181191841287,
        "precision": 0.25413918804637364,
        "recall": 0.31270791749833665
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.1410700335351034,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.1410700335351034,
        "precision": 0.12935163823387377,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.09382039192418434,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.09382039192418434,
        "precision": 0.086173379736254,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.22752009209095037,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.22752009209095037,
        "precision": 0.21397894446796642,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.19827012641383898,
        "f1": 0.15823973293700505,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.15823973293700505,
        "precision": 0.14632385307701343,
        "recall": 0.19827012641383898
      },
      {
        "accuracy": 0.2714570858283433,
        "f1": 0.2291001326584958,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2291001326584958,
        "precision": 0.21520008726403766,
        "recall": 0.2714570858283433
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0008008670717292405,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0008008670717292405,
        "precision": 0.0005231303346922206,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.2741184298070526,
        "f1": 0.23550182686077564,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.23550182686077564,
        "precision": 0.2233055832376167,
        "recall": 0.2741184298070526
      },
      {
        "accuracy": 0.16167664670658682,
        "f1": 0.1271668155308198,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.1271668155308198,
        "precision": 0.11584955067401938,
        "recall": 0.16167664670658682
      },
      {
        "accuracy": 0.20159680638722555,
        "f1": 0.16437301763316398,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.16437301763316398,
        "precision": 0.15225253386756465,
        "recall": 0.20159680638722555
      },
      {
        "accuracy": 0.1650033266799734,
        "f1": 0.13347342389258557,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.13347342389258557,
        "precision": 0.12335413666061196,
        "recall": 0.1650033266799734
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007413248331800885,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007413248331800885,
        "precision": 0.0007038213912771478,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.16234198270126413,
        "f1": 0.1291835323289958,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1291835323289958,
        "precision": 0.1193423728861178,
        "recall": 0.16234198270126413
      },
      {
        "accuracy": 0.20093147039254824,
        "f1": 0.168665340724974,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.168665340724974,
        "precision": 0.1583126480486932,
        "recall": 0.20093147039254824
      },
      {
        "accuracy": 0.28476380572188953,
        "f1": 0.2438334273438259,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2438334273438259,
        "precision": 0.2304727813697679,
        "recall": 0.28476380572188953
      },
      {
        "accuracy": 0.3333333333333333,
        "f1": 0.270660185530445,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.270660185530445,
        "precision": 0.24769059764069745,
        "recall": 0.3333333333333333
      },
      {
        "accuracy": 0.5721889554224884,
        "f1": 0.5113962551088299,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.5113962551088299,
        "precision": 0.48716563986025063,
        "recall": 0.5721889554224884
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.016837078482209274,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.016837078482209274,
        "precision": 0.014527712756574725,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.26679973386560213,
        "f1": 0.2134577886074892,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.2134577886074892,
        "precision": 0.19553378350783543,
        "recall": 0.26679973386560213
      },
      {
        "accuracy": 0.6067864271457086,
        "f1": 0.5388381966226277,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.5388381966226277,
        "precision": 0.5131116074728849,
        "recall": 0.6067864271457086
      },
      {
        "accuracy": 0.22355289421157684,
        "f1": 0.1794844174085691,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.1794844174085691,
        "precision": 0.16503109701712493,
        "recall": 0.22355289421157684
      },
      {
        "accuracy": 0.5582168995342648,
        "f1": 0.49379170027872626,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.49379170027872626,
        "precision": 0.4686375925397882,
        "recall": 0.5582168995342648
      },
      {
        "accuracy": 0.6234198270126414,
        "f1": 0.5666528562736147,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.5666528562736147,
        "precision": 0.5444127617780312,
        "recall": 0.6234198270126414
      },
      {
        "accuracy": 0.4763805721889554,
        "f1": 0.41093320813879697,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.41093320813879697,
        "precision": 0.3847044007223648,
        "recall": 0.4763805721889554
      },
      {
        "accuracy": 0.10379241516966067,
        "f1": 0.0732634532100817,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.0732634532100817,
        "precision": 0.06500416933550666,
        "recall": 0.10379241516966067
      },
      {
        "accuracy": 0.32335329341317365,
        "f1": 0.2728637629835235,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.2728637629835235,
        "precision": 0.25476454498410583,
        "recall": 0.32335329341317365
      },
      {
        "accuracy": 0.58416500332668,
        "f1": 0.5224736193798071,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.5224736193798071,
        "precision": 0.49752426364202806,
        "recall": 0.58416500332668
      },
      {
        "accuracy": 0.6014637391882901,
        "f1": 0.5396577695978894,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.5396577695978894,
        "precision": 0.5157146025409498,
        "recall": 0.6014637391882901
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0004837488947631237,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0004837488947631237,
        "precision": 0.00027919122878899375,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.5728542914171657,
        "f1": 0.5086728659083948,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.5086728659083948,
        "precision": 0.48317811226992863,
        "recall": 0.5728542914171657
      },
      {
        "accuracy": 0.5169660678642715,
        "f1": 0.4518814703445441,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.4518814703445441,
        "precision": 0.4255164274625352,
        "recall": 0.5169660678642715
      },
      {
        "accuracy": 0.49567531603459747,
        "f1": 0.43467615034481305,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.43467615034481305,
        "precision": 0.41075151284732125,
        "recall": 0.49567531603459747
      },
      {
        "accuracy": 0.23552894211576847,
        "f1": 0.18582839131741322,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.18582839131741322,
        "precision": 0.1693893573105737,
        "recall": 0.23552894211576847
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001210499646249764,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.001210499646249764,
        "precision": 0.0009714102518121036,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.18296739853626082,
        "f1": 0.14073694842157913,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.14073694842157913,
        "precision": 0.12745857491366475,
        "recall": 0.18296739853626082
      },
      {
        "accuracy": 0.5808383233532934,
        "f1": 0.5208524749442913,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.5208524749442913,
        "precision": 0.496048379431613,
        "recall": 0.5808383233532934
      },
      {
        "accuracy": 0.5968063872255489,
        "f1": 0.5357844823912689,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.5357844823912689,
        "precision": 0.511928787926792,
        "recall": 0.5968063872255489
      },
      {
        "accuracy": 0.3592814371257485,
        "f1": 0.2954398082142593,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.2954398082142593,
        "precision": 0.27199912344622923,
        "recall": 0.3592814371257485
      },
      {
        "accuracy": 0.6520292747837658,
        "f1": 0.5970408389570067,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.5970408389570067,
        "precision": 0.5749295060672306,
        "recall": 0.6520292747837658
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.023226983207951503,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.023226983207951503,
        "precision": 0.01959724354312114,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.32335329341317365,
        "f1": 0.2629451336977461,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.2629451336977461,
        "precision": 0.2420045311013375,
        "recall": 0.32335329341317365
      },
      {
        "accuracy": 0.7192282102461743,
        "f1": 0.6653792943214101,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.6653792943214101,
        "precision": 0.6427771441244495,
        "recall": 0.7192282102461743
      },
      {
        "accuracy": 0.2834331337325349,
        "f1": 0.23262258551679707,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.23262258551679707,
        "precision": 0.21523036917248495,
        "recall": 0.2834331337325349
      },
      {
        "accuracy": 0.6447105788423154,
        "f1": 0.5877398641869699,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.5877398641869699,
        "precision": 0.5647704590818363,
        "recall": 0.6447105788423154
      },
      {
        "accuracy": 0.6939454424484365,
        "f1": 0.6420074381152225,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.6420074381152225,
        "precision": 0.6202597690621643,
        "recall": 0.6939454424484365
      },
      {
        "accuracy": 0.5555555555555556,
        "f1": 0.497176018333703,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.497176018333703,
        "precision": 0.47301508094921263,
        "recall": 0.5555555555555556
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.08543385458379,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.08543385458379,
        "precision": 0.07623529203644834,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.37059214903526283,
        "f1": 0.3112304109251391,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.3112304109251391,
        "precision": 0.2907041736632555,
        "recall": 0.37059214903526283
      },
      {
        "accuracy": 0.6713240186294078,
        "f1": 0.619709786775655,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.619709786775655,
        "precision": 0.5976225039099291,
        "recall": 0.6713240186294078
      },
      {
        "accuracy": 0.6666666666666666,
        "f1": 0.60957291765675,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.60957291765675,
        "precision": 0.5857090052698836,
        "recall": 0.6666666666666666
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0005004919206557239,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0005004919206557239,
        "precision": 0.00028601768732389616,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.6526946107784432,
        "f1": 0.6010096689737409,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.6010096689737409,
        "precision": 0.5802542655836069,
        "recall": 0.6526946107784432
      },
      {
        "accuracy": 0.590818363273453,
        "f1": 0.5279535833428048,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.5279535833428048,
        "precision": 0.502946487976428,
        "recall": 0.590818363273453
      },
      {
        "accuracy": 0.5788423153692615,
        "f1": 0.5246037026476148,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.5246037026476148,
        "precision": 0.503001404598211,
        "recall": 0.5788423153692615
      },
      {
        "accuracy": 0.281437125748503,
        "f1": 0.22256687276647355,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.22256687276647355,
        "precision": 0.20224892465411426,
        "recall": 0.281437125748503
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007091419402092174,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0007091419402092174,
        "precision": 0.0006874650490332797,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.20825016633399868,
        "f1": 0.15810699982356669,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.15810699982356669,
        "precision": 0.14314510986167672,
        "recall": 0.20825016633399868
      },
      {
        "accuracy": 0.5761809713905522,
        "f1": 0.5151062953458163,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.5151062953458163,
        "precision": 0.49062773923053354,
        "recall": 0.5761809713905522
      },
      {
        "accuracy": 0.7072521623419827,
        "f1": 0.6579945928249322,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.6579945928249322,
        "precision": 0.6374758419668599,
        "recall": 0.7072521623419827
      },
      {
        "accuracy": 0.45442448436460414,
        "f1": 0.379007080005084,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.379007080005084,
        "precision": 0.3507297574163842,
        "recall": 0.45442448436460414
      },
      {
        "accuracy": 0.759148369926813,
        "f1": 0.7085067959319457,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7085067959319457,
        "precision": 0.6863938789088491,
        "recall": 0.759148369926813
      },
      {
        "accuracy": 0.049234863606121095,
        "f1": 0.030359841540946567,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.030359841540946567,
        "precision": 0.02684062666953581,
        "recall": 0.049234863606121095
      },
      {
        "accuracy": 0.4397870924817033,
        "f1": 0.36419225041979525,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.36419225041979525,
        "precision": 0.33615648231416695,
        "recall": 0.4397870924817033
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.8436238633843425,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8436238633843425,
        "precision": 0.8298846750942559,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.35395874916833003,
        "f1": 0.2834727038319853,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.2834727038319853,
        "precision": 0.2595860781489524,
        "recall": 0.35395874916833003
      },
      {
        "accuracy": 0.7864271457085829,
        "f1": 0.7385894876912841,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.7385894876912841,
        "precision": 0.7173209137280993,
        "recall": 0.7864271457085829
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.8341871811931691,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.8341871811931691,
        "precision": 0.8199775053068465,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.5901530272787758,
        "f1": 0.5231885435478251,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.5231885435478251,
        "precision": 0.4944383959354019,
        "recall": 0.5901530272787758
      },
      {
        "accuracy": 0.19627411842980705,
        "f1": 0.14084715646591894,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.14084715646591894,
        "precision": 0.1252162935421133,
        "recall": 0.19627411842980705
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.43824793894654174,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.43824793894654174,
        "precision": 0.41361404175775435,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.6696622627760352,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.6696622627760352,
        "precision": 0.6465909450939391,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7850077622532713,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7850077622532713,
        "precision": 0.7666999334664004,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0004035064587362344,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0004035064587362344,
        "precision": 0.00021534000682229415,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.8130405854956753,
        "f1": 0.7705699711687736,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7705699711687736,
        "precision": 0.7517853182523841,
        "recall": 0.8130405854956753
      },
      {
        "accuracy": 0.6706586826347305,
        "f1": 0.6044867936085502,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.6044867936085502,
        "precision": 0.5764257199885943,
        "recall": 0.6706586826347305
      },
      {
        "accuracy": 0.7451763140385895,
        "f1": 0.6901340176789278,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.6901340176789278,
        "precision": 0.6665335994677312,
        "recall": 0.7451763140385895
      },
      {
        "accuracy": 0.3406520292747838,
        "f1": 0.272152885925341,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.272152885925341,
        "precision": 0.2486014743000771,
        "recall": 0.3406520292747838
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0002826564037475548,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0002826564037475548,
        "precision": 0.0001540329253532216,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.2940785096473719,
        "f1": 0.22779873708017423,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.22779873708017423,
        "precision": 0.2065098038650933,
        "recall": 0.2940785096473719
      },
      {
        "accuracy": 0.6433799068529608,
        "f1": 0.5809893440631964,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.5809893440631964,
        "precision": 0.554296961632291,
        "recall": 0.6433799068529608
      },
      {
        "accuracy": 0.737857618097139,
        "f1": 0.6818141494788201,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.6818141494788201,
        "precision": 0.6569416722111333,
        "recall": 0.737857618097139
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}