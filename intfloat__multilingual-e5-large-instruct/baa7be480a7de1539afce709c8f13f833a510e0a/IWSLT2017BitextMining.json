{
  "dataset_revision": "c18a4f81a47ae6fa079fe9d32db288ddde38451d",
  "evaluation_time": 82.3619441986084,
  "kg_co2_emissions": 0.0164741857698656,
  "mteb_version": "1.12.75",
  "scores": {
    "validation": [
      {
        "accuracy": 0.9831081081081081,
        "f1": 0.9801051051051052,
        "hf_subset": "ar-en",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9801051051051052,
        "precision": 0.979054054054054,
        "recall": 0.9831081081081081
      },
      {
        "accuracy": 0.9898648648648649,
        "f1": 0.988943488943489,
        "hf_subset": "de-en",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.988943488943489,
        "precision": 0.9888513513513514,
        "recall": 0.9898648648648649
      },
      {
        "accuracy": 0.9786036036036037,
        "f1": 0.9744744744744746,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.9744744744744746,
        "precision": 0.9726351351351352,
        "recall": 0.9786036036036037
      },
      {
        "accuracy": 0.9876126126126126,
        "f1": 0.986111111111111,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.986111111111111,
        "precision": 0.9855855855855856,
        "recall": 0.9876126126126126
      },
      {
        "accuracy": 0.9764044943820225,
        "f1": 0.9711610486891384,
        "hf_subset": "en-fr",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ],
        "main_score": 0.9711610486891384,
        "precision": 0.9689887640449438,
        "recall": 0.9764044943820225
      },
      {
        "accuracy": 0.9752421959095802,
        "f1": 0.9689630426982418,
        "hf_subset": "en-it",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ],
        "main_score": 0.9689630426982418,
        "precision": 0.9663437387872265,
        "recall": 0.9752421959095802
      },
      {
        "accuracy": 0.9414466130884042,
        "f1": 0.9291454813842874,
        "hf_subset": "en-ja",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ],
        "main_score": 0.9291454813842874,
        "precision": 0.9237553491284833,
        "recall": 0.9414466130884042
      },
      {
        "accuracy": 0.9021615472127418,
        "f1": 0.8842434584755404,
        "hf_subset": "en-ko",
        "languages": [
          "eng-Latn",
          "kor-Hang"
        ],
        "main_score": 0.8842434584755404,
        "precision": 0.8761958936020369,
        "recall": 0.9021615472127418
      },
      {
        "accuracy": 0.9680957128614157,
        "f1": 0.9594549684280491,
        "hf_subset": "en-nl",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ],
        "main_score": 0.9594549684280491,
        "precision": 0.9556995679627782,
        "recall": 0.9680957128614157
      },
      {
        "accuracy": 0.9835886214442013,
        "f1": 0.9799416484318015,
        "hf_subset": "en-ro",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ],
        "main_score": 0.9799416484318015,
        "precision": 0.9785557986870896,
        "recall": 0.9835886214442013
      },
      {
        "accuracy": 0.9306029579067122,
        "f1": 0.9187207685501201,
        "hf_subset": "en-zh",
        "languages": [
          "eng-Latn",
          "cmn-Hans"
        ],
        "main_score": 0.9187207685501201,
        "precision": 0.913718240424725,
        "recall": 0.9306029579067122
      },
      {
        "accuracy": 0.9775280898876404,
        "f1": 0.972605671482076,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.972605671482076,
        "precision": 0.9706367041198501,
        "recall": 0.9775280898876404
      },
      {
        "accuracy": 0.9741657696447793,
        "f1": 0.9693577323286688,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9693577323286688,
        "precision": 0.9672886018418849,
        "recall": 0.9741657696447793
      },
      {
        "accuracy": 0.9600399600399601,
        "f1": 0.9505684791399076,
        "hf_subset": "it-nl",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ],
        "main_score": 0.9505684791399076,
        "precision": 0.9464701964701966,
        "recall": 0.9600399600399601
      },
      {
        "accuracy": 0.9781181619256017,
        "f1": 0.9737583714607785,
        "hf_subset": "it-ro",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ],
        "main_score": 0.9737583714607785,
        "precision": 0.9720277169948943,
        "recall": 0.9781181619256017
      },
      {
        "accuracy": 0.9425947187141217,
        "f1": 0.9314580941446614,
        "hf_subset": "ja-en",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.9314580941446614,
        "precision": 0.9265212399540758,
        "recall": 0.9425947187141217
      },
      {
        "accuracy": 0.9032992036405005,
        "f1": 0.8845910757173555,
        "hf_subset": "ko-en",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ],
        "main_score": 0.8845910757173555,
        "precision": 0.8759480470231322,
        "recall": 0.9032992036405005
      },
      {
        "accuracy": 0.9641076769690927,
        "f1": 0.9558182595071927,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9558182595071927,
        "precision": 0.9522266533732137,
        "recall": 0.9641076769690927
      },
      {
        "accuracy": 0.957042957042957,
        "f1": 0.9468864468864469,
        "hf_subset": "nl-it",
        "languages": [
          "nld-Latn",
          "ita-Latn"
        ],
        "main_score": 0.9468864468864469,
        "precision": 0.9424575424575424,
        "recall": 0.957042957042957
      },
      {
        "accuracy": 0.9693318729463308,
        "f1": 0.9623428780055285,
        "hf_subset": "nl-ro",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ],
        "main_score": 0.9623428780055285,
        "precision": 0.9594742606790799,
        "recall": 0.9693318729463308
      },
      {
        "accuracy": 0.9835886214442013,
        "f1": 0.9803063457330415,
        "hf_subset": "ro-en",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.9803063457330415,
        "precision": 0.9791028446389497,
        "recall": 0.9835886214442013
      },
      {
        "accuracy": 0.975929978118162,
        "f1": 0.9708971553610503,
        "hf_subset": "ro-it",
        "languages": [
          "ron-Latn",
          "ita-Latn"
        ],
        "main_score": 0.9708971553610503,
        "precision": 0.9685448577680525,
        "recall": 0.975929978118162
      },
      {
        "accuracy": 0.9704271631982475,
        "f1": 0.9636546184738956,
        "hf_subset": "ro-nl",
        "languages": [
          "ron-Latn",
          "nld-Latn"
        ],
        "main_score": 0.9636546184738956,
        "precision": 0.9608172951546445,
        "recall": 0.9704271631982475
      },
      {
        "accuracy": 0.9408418657565415,
        "f1": 0.9260740018419199,
        "hf_subset": "zh-en",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.9260740018419199,
        "precision": 0.9195108077360638,
        "recall": 0.9408418657565415
      }
    ]
  },
  "task_name": "IWSLT2017BitextMining"
}