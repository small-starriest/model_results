{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 53.025612354278564,
  "kg_co2_emissions": 0.009060914379780313,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8968507429585274,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.8968507429585274,
        "precision": 0.8877799955644268,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.16102546968814432,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.16102546968814432,
        "precision": 0.1477555183044205,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.6620093147039254,
        "f1": 0.6124417284751787,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6124417284751787,
        "precision": 0.5936439530750908,
        "recall": 0.6620093147039254
      },
      {
        "accuracy": 0.8802395209580839,
        "f1": 0.8604906588938525,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.8604906588938525,
        "precision": 0.853268050423739,
        "recall": 0.8802395209580839
      },
      {
        "accuracy": 0.6067864271457086,
        "f1": 0.561205220505042,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.561205220505042,
        "precision": 0.5439929904500762,
        "recall": 0.6067864271457086
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8725712595972076,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8725712595972076,
        "precision": 0.8640108671545798,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.8695941450432468,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.8695941450432468,
        "precision": 0.8594108080136024,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.7831004657351963,
        "f1": 0.7442311144905955,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.7442311144905955,
        "precision": 0.72907861525626,
        "recall": 0.7831004657351963
      },
      {
        "accuracy": 0.6134397870924817,
        "f1": 0.5623572959900305,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.5623572959900305,
        "precision": 0.5426026875598321,
        "recall": 0.6134397870924817
      },
      {
        "accuracy": 0.8922155688622755,
        "f1": 0.8671228970630168,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8671228970630168,
        "precision": 0.8562319804834776,
        "recall": 0.8922155688622755
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8547032918290404,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8547032918290404,
        "precision": 0.843634952317587,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.891132549715384,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.891132549715384,
        "precision": 0.8838442163292463,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.005921156491483174,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.005921156491483174,
        "precision": 0.004706684424089796,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8852406298514083,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8852406298514083,
        "precision": 0.8766973988530874,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8971739061559421,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.8971739061559421,
        "precision": 0.8885562208915503,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.8815701929474384,
        "f1": 0.8577971042042898,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8577971042042898,
        "precision": 0.8477331052181352,
        "recall": 0.8815701929474384
      },
      {
        "accuracy": 0.7937458416500333,
        "f1": 0.756935863722291,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.756935863722291,
        "precision": 0.7420542512857883,
        "recall": 0.7937458416500333
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0035700775969666108,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0035700775969666108,
        "precision": 0.0021946053370632186,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.5442448436460412,
        "f1": 0.49519890417506945,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.49519890417506945,
        "precision": 0.47720866126554745,
        "recall": 0.5442448436460412
      },
      {
        "accuracy": 0.8150365934797072,
        "f1": 0.7829045612478748,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.7829045612478748,
        "precision": 0.769040490447676,
        "recall": 0.8150365934797072
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8487697044583272,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8487697044583272,
        "precision": 0.837303171434908,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.8997021829357158,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.8997021829357158,
        "precision": 0.8914393435351519,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.8738649684757469,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.8738649684757469,
        "precision": 0.8658793524062984,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.19228210246174318,
        "f1": 0.14832268135725157,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.14832268135725157,
        "precision": 0.13460566841305363,
        "recall": 0.19228210246174318
      },
      {
        "accuracy": 0.7112441783100466,
        "f1": 0.6595592365053443,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6595592365053443,
        "precision": 0.6397182066842745,
        "recall": 0.7112441783100466
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9215378766276969,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9215378766276969,
        "precision": 0.9162452872033711,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.633399866932801,
        "f1": 0.5834818189109606,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.5834818189109606,
        "precision": 0.5655516842143589,
        "recall": 0.633399866932801
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9140940341539143,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9140940341539143,
        "precision": 0.9072141431422868,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9372144599689509,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9372144599689509,
        "precision": 0.9315812818806831,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.8376580172987359,
        "f1": 0.806348726308806,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.806348726308806,
        "precision": 0.794621075309698,
        "recall": 0.8376580172987359
      },
      {
        "accuracy": 0.6393878908848969,
        "f1": 0.5867485087544968,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.5867485087544968,
        "precision": 0.5669663558885115,
        "recall": 0.6393878908848969
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8897981814149479,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8897981814149479,
        "precision": 0.8815701929474384,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.916734784399455,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.916734784399455,
        "precision": 0.9096806387225549,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9213351075626524,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9213351075626524,
        "precision": 0.9146152140164115,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005072833097959316,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.005072833097959316,
        "precision": 0.003972798775835535,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9199600798403192,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9199600798403192,
        "precision": 0.9130294965624307,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9298514082945221,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9298514082945221,
        "precision": 0.9236748724772676,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9023952095808383,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9023952095808383,
        "precision": 0.8941450432468397,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.8063872255489022,
        "f1": 0.7688089097270734,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7688089097270734,
        "precision": 0.7535291443974078,
        "recall": 0.8063872255489022
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0037162951525403095,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0037162951525403095,
        "precision": 0.002636137087073923,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.6007984031936128,
        "f1": 0.5495389204353628,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.5495389204353628,
        "precision": 0.5308958266543097,
        "recall": 0.6007984031936128
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8502392041314196,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8502392041314196,
        "precision": 0.8392838255113704,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8935684187181193,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8935684187181193,
        "precision": 0.8843313373253494,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.9334442226657795,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9334442226657795,
        "precision": 0.9275227323131514,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.1643379906852961,
        "f1": 0.13815306401172978,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.13815306401172978,
        "precision": 0.131580772654385,
        "recall": 0.1643379906852961
      },
      {
        "accuracy": 0.17498336660013306,
        "f1": 0.13989732991157566,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.13989732991157566,
        "precision": 0.13075691004056622,
        "recall": 0.17498336660013306
      },
      {
        "accuracy": 0.17298735861610112,
        "f1": 0.15007557486964773,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15007557486964773,
        "precision": 0.14430166637612798,
        "recall": 0.17298735861610112
      },
      {
        "accuracy": 0.09913506320691949,
        "f1": 0.08634445212840147,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08634445212840147,
        "precision": 0.08279386017037647,
        "recall": 0.09913506320691949
      },
      {
        "accuracy": 0.15103127079174983,
        "f1": 0.13358389042021776,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.13358389042021776,
        "precision": 0.12868435151115032,
        "recall": 0.15103127079174983
      },
      {
        "accuracy": 0.1823020625415835,
        "f1": 0.14445020336791142,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.14445020336791142,
        "precision": 0.13418159543506877,
        "recall": 0.1823020625415835
      },
      {
        "accuracy": 0.2042581503659348,
        "f1": 0.16427796232061445,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.16427796232061445,
        "precision": 0.1533923590726169,
        "recall": 0.2042581503659348
      },
      {
        "accuracy": 0.1497005988023952,
        "f1": 0.12912507087100922,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.12912507087100922,
        "precision": 0.12408596169457164,
        "recall": 0.1497005988023952
      },
      {
        "accuracy": 0.1490352628077179,
        "f1": 0.12131469269128696,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12131469269128696,
        "precision": 0.11409027314549602,
        "recall": 0.1490352628077179
      },
      {
        "accuracy": 0.1643379906852961,
        "f1": 0.13738125203636709,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13738125203636709,
        "precision": 0.12963949210671452,
        "recall": 0.1643379906852961
      },
      {
        "accuracy": 0.16300731869594146,
        "f1": 0.12997563258207137,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.12997563258207137,
        "precision": 0.12097593494285745,
        "recall": 0.16300731869594146
      },
      {
        "accuracy": 0.18296739853626082,
        "f1": 0.14592826720066518,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.14592826720066518,
        "precision": 0.13589396339114296,
        "recall": 0.18296739853626082
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0079430272544045,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0079430272544045,
        "precision": 0.006814372882237153,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.19228210246174318,
        "f1": 0.15642293330719348,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.15642293330719348,
        "precision": 0.1476146795061991,
        "recall": 0.19228210246174318
      },
      {
        "accuracy": 0.18429807052561545,
        "f1": 0.14350701476828728,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.14350701476828728,
        "precision": 0.13339624304240047,
        "recall": 0.18429807052561545
      },
      {
        "accuracy": 0.18429807052561545,
        "f1": 0.151549243237018,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.151549243237018,
        "precision": 0.14302688664504248,
        "recall": 0.18429807052561545
      },
      {
        "accuracy": 0.14770459081836326,
        "f1": 0.12382538766577335,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.12382538766577335,
        "precision": 0.11795216181462215,
        "recall": 0.14770459081836326
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.006712205945540167,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006712205945540167,
        "precision": 0.00552020189230876,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.17165668662674652,
        "f1": 0.15497407363181853,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.15497407363181853,
        "precision": 0.15051989585961237,
        "recall": 0.17165668662674652
      },
      {
        "accuracy": 0.14770459081836326,
        "f1": 0.11776552148247019,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11776552148247019,
        "precision": 0.11022538898881634,
        "recall": 0.14770459081836326
      },
      {
        "accuracy": 0.1590153027278776,
        "f1": 0.1356602328967123,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1356602328967123,
        "precision": 0.12954036866425625,
        "recall": 0.1590153027278776
      },
      {
        "accuracy": 0.16966067864271456,
        "f1": 0.13304235821755359,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.13304235821755359,
        "precision": 0.12463787558757895,
        "recall": 0.16966067864271456
      },
      {
        "accuracy": 0.6999334664005322,
        "f1": 0.6514585067479278,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6514585067479278,
        "precision": 0.6322846610770763,
        "recall": 0.6999334664005322
      },
      {
        "accuracy": 0.7518296739853626,
        "f1": 0.7060195908440594,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7060195908440594,
        "precision": 0.6874437632671166,
        "recall": 0.7518296739853626
      },
      {
        "accuracy": 0.2268795741849634,
        "f1": 0.1837738184045569,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1837738184045569,
        "precision": 0.16936951013797324,
        "recall": 0.2268795741849634
      },
      {
        "accuracy": 0.6866267465069861,
        "f1": 0.6550028448187303,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6550028448187303,
        "precision": 0.6441706127833873,
        "recall": 0.6866267465069861
      },
      {
        "accuracy": 0.5349301397205589,
        "f1": 0.49075975034058866,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.49075975034058866,
        "precision": 0.4739463113215608,
        "recall": 0.5349301397205589
      },
      {
        "accuracy": 0.7618097139055223,
        "f1": 0.7234599583900982,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7234599583900982,
        "precision": 0.707980071602826,
        "recall": 0.7618097139055223
      },
      {
        "accuracy": 0.7764471057884231,
        "f1": 0.7320043894894194,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7320043894894194,
        "precision": 0.7144948198840413,
        "recall": 0.7764471057884231
      },
      {
        "accuracy": 0.6487025948103793,
        "f1": 0.6059697146464788,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6059697146464788,
        "precision": 0.5897436608264952,
        "recall": 0.6487025948103793
      },
      {
        "accuracy": 0.49966733200266134,
        "f1": 0.44346717320182155,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.44346717320182155,
        "precision": 0.4225969044923242,
        "recall": 0.49966733200266134
      },
      {
        "accuracy": 0.7551563539587491,
        "f1": 0.7082184836675854,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7082184836675854,
        "precision": 0.6887684947565187,
        "recall": 0.7551563539587491
      },
      {
        "accuracy": 0.7238855622089155,
        "f1": 0.6728108861641796,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6728108861641796,
        "precision": 0.6523825605162931,
        "recall": 0.7238855622089155
      },
      {
        "accuracy": 0.7551563539587491,
        "f1": 0.7080836027507901,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7080836027507901,
        "precision": 0.6885428997704447,
        "recall": 0.7551563539587491
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.004695025713980471,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004695025713980471,
        "precision": 0.0030977753387652573,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.7544910179640718,
        "f1": 0.7107898440732773,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7107898440732773,
        "precision": 0.6937503300277753,
        "recall": 0.7544910179640718
      },
      {
        "accuracy": 0.7651363938789089,
        "f1": 0.7192408833127397,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7192408833127397,
        "precision": 0.7001461535176714,
        "recall": 0.7651363938789089
      },
      {
        "accuracy": 0.761144377910845,
        "f1": 0.7185882203846276,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7185882203846276,
        "precision": 0.7010344390583911,
        "recall": 0.761144377910845
      },
      {
        "accuracy": 0.612109115103127,
        "f1": 0.555435094956053,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.555435094956053,
        "precision": 0.5338349589347593,
        "recall": 0.612109115103127
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0031266231961615387,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0031266231961615387,
        "precision": 0.0019116635116093999,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.571523619427811,
        "f1": 0.5225039683687606,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5225039683687606,
        "precision": 0.503668692141746,
        "recall": 0.571523619427811
      },
      {
        "accuracy": 0.6580172987358616,
        "f1": 0.60759641408344,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.60759641408344,
        "precision": 0.5889269320906048,
        "recall": 0.6580172987358616
      },
      {
        "accuracy": 0.6806387225548902,
        "f1": 0.6275065457201185,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6275065457201185,
        "precision": 0.608202930358619,
        "recall": 0.6806387225548902
      },
      {
        "accuracy": 0.7917498336660014,
        "f1": 0.7479067506013612,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7479067506013612,
        "precision": 0.7296211809185862,
        "recall": 0.7917498336660014
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8572808687579146,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8572808687579146,
        "precision": 0.8493565739669121,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9282047017076958,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9282047017076958,
        "precision": 0.9234937532342722,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.12699997231244584,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.12699997231244584,
        "precision": 0.11441032089398256,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6794625730438316,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.6794625730438316,
        "precision": 0.6576351188068928,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.6041250831669993,
        "f1": 0.5411521642530214,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.5411521642530214,
        "precision": 0.5179088786701149,
        "recall": 0.6041250831669993
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9155736576835556,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9155736576835556,
        "precision": 0.9103717168836929,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9507651363938789,
        "f1": 0.9398662991477363,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9398662991477363,
        "precision": 0.9354476232719745,
        "recall": 0.9507651363938789
      },
      {
        "accuracy": 0.8449767132401863,
        "f1": 0.8138569422002555,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.8138569422002555,
        "precision": 0.8019802767777405,
        "recall": 0.8449767132401863
      },
      {
        "accuracy": 0.6114437791084497,
        "f1": 0.5463001739390139,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.5463001739390139,
        "precision": 0.5204901284492103,
        "recall": 0.6114437791084497
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8835319260468961,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8835319260468961,
        "precision": 0.8763120931626026,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9163688496023826,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9163688496023826,
        "precision": 0.9106105249817825,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9216478341170133,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9216478341170133,
        "precision": 0.9162536039033045,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0030357461832462495,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0030357461832462495,
        "precision": 0.0025244548701278445,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9144291127889149,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9144291127889149,
        "precision": 0.9086070283675073,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9246262140158559,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9246262140158559,
        "precision": 0.919899090707474,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.9194943446440452,
        "f1": 0.9014215436371124,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9014215436371124,
        "precision": 0.8942068244463455,
        "recall": 0.9194943446440452
      },
      {
        "accuracy": 0.8050565535595475,
        "f1": 0.7654415223277499,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7654415223277499,
        "precision": 0.7488001413613604,
        "recall": 0.8050565535595475
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0017467066173581978,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0017467066173581978,
        "precision": 0.0013816419614752027,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.5588822355289421,
        "f1": 0.4900895251818792,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.4900895251818792,
        "precision": 0.46688203522686733,
        "recall": 0.5588822355289421
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.8403591368602523,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.8403591368602523,
        "precision": 0.8298098247948548,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.8991265332582696,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8991265332582696,
        "precision": 0.8929709604360303,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.9400532268795743,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9400532268795743,
        "precision": 0.9351791366761426,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.6194278110445776,
        "f1": 0.5671819235691491,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5671819235691491,
        "precision": 0.5467849106354703,
        "recall": 0.6194278110445776
      },
      {
        "accuracy": 0.6773120425815037,
        "f1": 0.6214382484782861,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6214382484782861,
        "precision": 0.5995436664532683,
        "recall": 0.6773120425815037
      },
      {
        "accuracy": 0.2208915502328676,
        "f1": 0.17890938678774768,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.17890938678774768,
        "precision": 0.1645211140969624,
        "recall": 0.2208915502328676
      },
      {
        "accuracy": 0.5595475715236194,
        "f1": 0.5078835569538374,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5078835569538374,
        "precision": 0.48827635733823355,
        "recall": 0.5595475715236194
      },
      {
        "accuracy": 0.5588822355289421,
        "f1": 0.5172281030863866,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5172281030863866,
        "precision": 0.5028719657789105,
        "recall": 0.5588822355289421
      },
      {
        "accuracy": 0.656686626746507,
        "f1": 0.6094071190877578,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6094071190877578,
        "precision": 0.591434761734163,
        "recall": 0.656686626746507
      },
      {
        "accuracy": 0.6852960745176314,
        "f1": 0.633322472563052,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.633322472563052,
        "precision": 0.613862986093525,
        "recall": 0.6852960745176314
      },
      {
        "accuracy": 0.6047904191616766,
        "f1": 0.5570087625403822,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5570087625403822,
        "precision": 0.5390268967427344,
        "recall": 0.6047904191616766
      },
      {
        "accuracy": 0.46107784431137727,
        "f1": 0.40571776120678316,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.40571776120678316,
        "precision": 0.38521088146543114,
        "recall": 0.46107784431137727
      },
      {
        "accuracy": 0.6407185628742516,
        "f1": 0.5855595686933012,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5855595686933012,
        "precision": 0.5643164029861223,
        "recall": 0.6407185628742516
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.5922305775100186,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5922305775100186,
        "precision": 0.569464985373169,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.7092481703260146,
        "f1": 0.6598932006117635,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6598932006117635,
        "precision": 0.6399400545314599,
        "recall": 0.7092481703260146
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.009783436124532044,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009783436124532044,
        "precision": 0.008291278559600795,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.5990647012852602,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5990647012852602,
        "precision": 0.5793744207964155,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.6719893546240852,
        "f1": 0.6199977242987996,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6199977242987996,
        "precision": 0.6009431353742731,
        "recall": 0.6719893546240852
      },
      {
        "accuracy": 0.6660013306719893,
        "f1": 0.6153472903971906,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6153472903971906,
        "precision": 0.5973497449545353,
        "recall": 0.6660013306719893
      },
      {
        "accuracy": 0.5695276114437791,
        "f1": 0.5079281072295044,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.5079281072295044,
        "precision": 0.48516683964122415,
        "recall": 0.5695276114437791
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004074865045905421,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004074865045905421,
        "precision": 0.00303227239061453,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.5103127079174984,
        "f1": 0.4656697667675712,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4656697667675712,
        "precision": 0.44978165362396894,
        "recall": 0.5103127079174984
      },
      {
        "accuracy": 0.5688622754491018,
        "f1": 0.5101363890785048,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5101363890785048,
        "precision": 0.4883252469550462,
        "recall": 0.5688622754491018
      },
      {
        "accuracy": 0.6207584830339321,
        "f1": 0.5684361289891405,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5684361289891405,
        "precision": 0.5494162649905087,
        "recall": 0.6207584830339321
      },
      {
        "accuracy": 0.6766467065868264,
        "f1": 0.6230259538642772,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6230259538642772,
        "precision": 0.601403789527542,
        "recall": 0.6766467065868264
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.8746755646955248,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8746755646955248,
        "precision": 0.8662175648702592,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9238190286094478,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.9238190286094478,
        "precision": 0.9168773563983145,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.21756487025948104,
        "f1": 0.16768870527006427,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.16768870527006427,
        "precision": 0.15295501425075095,
        "recall": 0.21756487025948104
      },
      {
        "accuracy": 0.7445109780439122,
        "f1": 0.6958124130463661,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.6958124130463661,
        "precision": 0.6765167910377492,
        "recall": 0.7445109780439122
      },
      {
        "accuracy": 0.9427811044577512,
        "f1": 0.9308937680195164,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9308937680195164,
        "precision": 0.9258593923264582,
        "recall": 0.9427811044577512
      },
      {
        "accuracy": 0.6906187624750499,
        "f1": 0.6388123464470771,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.6388123464470771,
        "precision": 0.6186634501005759,
        "recall": 0.6906187624750499
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9165462725342964,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9165462725342964,
        "precision": 0.9091325285936064,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.8483033932135728,
        "f1": 0.8161264772043215,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.8161264772043215,
        "precision": 0.8027796259333188,
        "recall": 0.8483033932135728
      },
      {
        "accuracy": 0.6360612109115104,
        "f1": 0.5727084699140588,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.5727084699140588,
        "precision": 0.5478811810648138,
        "recall": 0.6360612109115104
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8984611972635925,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.8984611972635925,
        "precision": 0.8905078731426037,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9029179735766563,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.9029179735766563,
        "precision": 0.8947882013750277,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.9421157684630739,
        "f1": 0.9294300288312265,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9294300288312265,
        "precision": 0.9239520958083832,
        "recall": 0.9421157684630739
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0034367621583928517,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0034367621583928517,
        "precision": 0.0023993493404217774,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9215790640940341,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9215790640940341,
        "precision": 0.9148813484142825,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9194278110445774,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.9194278110445774,
        "precision": 0.9128077178975383,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.908826790862719,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.908826790862719,
        "precision": 0.9006875138611664,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.810379241516966,
        "f1": 0.7705910929463823,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.7705910929463823,
        "precision": 0.753543929641734,
        "recall": 0.810379241516966
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.003332878080452672,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.003332878080452672,
        "precision": 0.0023720825762130753,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.6586826347305389,
        "f1": 0.6029210100751229,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.6029210100751229,
        "precision": 0.5820258952993483,
        "recall": 0.6586826347305389
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8265965423650055,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.8265965423650055,
        "precision": 0.8126691062319804,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8770047207172954,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.8770047207172954,
        "precision": 0.8666112220004435,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.919373950511675,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.919373950511675,
        "precision": 0.9119206032379686,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8674001203941324,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8674001203941324,
        "precision": 0.8587000601970661,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9371479263694832,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9371479263694832,
        "precision": 0.9316589044133954,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.2328675981370592,
        "f1": 0.18539839654081758,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.18539839654081758,
        "precision": 0.17042339055019576,
        "recall": 0.2328675981370592
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7162126444561574,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7162126444561574,
        "precision": 0.6993703931299329,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.9342980705256154,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9342980705256154,
        "precision": 0.929203497766372,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.6912840984697272,
        "f1": 0.6471346670888763,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6471346670888763,
        "precision": 0.6304734700318533,
        "recall": 0.6912840984697272
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9150492665462725,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9150492665462725,
        "precision": 0.9086900273527021,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8193523006896261,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8193523006896261,
        "precision": 0.8085920344902381,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.6573519627411843,
        "f1": 0.6004937215516057,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6004937215516057,
        "precision": 0.5788349442511707,
        "recall": 0.6573519627411843
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8892242451124688,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8892242451124688,
        "precision": 0.8818529607451763,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9053448658239077,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9053448658239077,
        "precision": 0.8973941006875138,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9230871590153028,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9230871590153028,
        "precision": 0.916833000665336,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0029542694533844726,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029542694533844726,
        "precision": 0.002026292675967501,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9140607673541806,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9140607673541806,
        "precision": 0.9081725438012863,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9205588822355288,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9205588822355288,
        "precision": 0.914193834553116,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9179640718562875,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9179640718562875,
        "precision": 0.9112552672432913,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.8157019294743846,
        "f1": 0.7797653850548062,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.7797653850548062,
        "precision": 0.7654064479912783,
        "recall": 0.8157019294743846
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0023568584843397244,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0023568584843397244,
        "precision": 0.0014986687750835818,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.6600133067198936,
        "f1": 0.6115161765860369,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6115161765860369,
        "precision": 0.5929920054071751,
        "recall": 0.6600133067198936
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.857329784874695,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.857329784874695,
        "precision": 0.8472351593110076,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.9007888983936887,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9007888983936887,
        "precision": 0.8934797072521624,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.9560878243512974,
        "f1": 0.9454868041694389,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9454868041694389,
        "precision": 0.9407296518074961,
        "recall": 0.9560878243512974
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7936824763172069,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7936824763172069,
        "precision": 0.7804280328232422,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.8875582168995343,
        "f1": 0.8641067072204797,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.8641067072204797,
        "precision": 0.8540252827677977,
        "recall": 0.8875582168995343
      },
      {
        "accuracy": 0.20958083832335328,
        "f1": 0.16103451143371303,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.16103451143371303,
        "precision": 0.14534419155177639,
        "recall": 0.20958083832335328
      },
      {
        "accuracy": 0.6586826347305389,
        "f1": 0.6111586351107309,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.6111586351107309,
        "precision": 0.5915724107340873,
        "recall": 0.6586826347305389
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8299935002529814,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8299935002529814,
        "precision": 0.820388587903558,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.6260811709913506,
        "f1": 0.5772047683225328,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.5772047683225328,
        "precision": 0.5581913755038094,
        "recall": 0.6260811709913506
      },
      {
        "accuracy": 0.8516300731869594,
        "f1": 0.8275829293793366,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8275829293793366,
        "precision": 0.8173320026613439,
        "recall": 0.8516300731869594
      },
      {
        "accuracy": 0.8775781769793746,
        "f1": 0.851053448658239,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.851053448658239,
        "precision": 0.839532047017077,
        "recall": 0.8775781769793746
      },
      {
        "accuracy": 0.5748502994011976,
        "f1": 0.5163065403584366,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.5163065403584366,
        "precision": 0.4941600925133859,
        "recall": 0.5748502994011976
      },
      {
        "accuracy": 0.8389886892880905,
        "f1": 0.8075219930509352,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.8075219930509352,
        "precision": 0.7939462345150967,
        "recall": 0.8389886892880905
      },
      {
        "accuracy": 0.8709248170326015,
        "f1": 0.8445331559104013,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.8445331559104013,
        "precision": 0.8326790862719007,
        "recall": 0.8709248170326015
      },
      {
        "accuracy": 0.8735861610113107,
        "f1": 0.8510677058581251,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8510677058581251,
        "precision": 0.8411906346038083,
        "recall": 0.8735861610113107
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.004332280080203403,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.004332280080203403,
        "precision": 0.003455508872046284,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.83301333840256,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.83301333840256,
        "precision": 0.8204923486360611,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8527389665114214,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.8527389665114214,
        "precision": 0.8419716123308938,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.852960745176314,
        "f1": 0.8209691727655799,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.8209691727655799,
        "precision": 0.8075468111396256,
        "recall": 0.852960745176314
      },
      {
        "accuracy": 0.729208250166334,
        "f1": 0.6788903674133215,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.6788903674133215,
        "precision": 0.6577408674714064,
        "recall": 0.729208250166334
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0021356585309740693,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0021356585309740693,
        "precision": 0.0012983060019701204,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.571523619427811,
        "f1": 0.5166526734890009,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.5166526734890009,
        "precision": 0.49480562684155494,
        "recall": 0.571523619427811
      },
      {
        "accuracy": 0.8363273453093812,
        "f1": 0.8044355732978488,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.8044355732978488,
        "precision": 0.7905522288755821,
        "recall": 0.8363273453093812
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8559547571523619,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8559547571523619,
        "precision": 0.8439454424484364,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.8769128409846972,
        "f1": 0.8486930900104553,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8486930900104553,
        "precision": 0.8359946773120426,
        "recall": 0.8769128409846972
      },
      {
        "accuracy": 0.5861610113107119,
        "f1": 0.5453519712472396,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.5453519712472396,
        "precision": 0.5303158045955061,
        "recall": 0.5861610113107119
      },
      {
        "accuracy": 0.6540252827677977,
        "f1": 0.6100614944889312,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.6100614944889312,
        "precision": 0.5933659194834279,
        "recall": 0.6540252827677977
      },
      {
        "accuracy": 0.15169660678642716,
        "f1": 0.11966808746860502,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.11966808746860502,
        "precision": 0.11063722366889965,
        "recall": 0.15169660678642716
      },
      {
        "accuracy": 0.426480372588157,
        "f1": 0.38422499423303413,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.38422499423303413,
        "precision": 0.37096561585084536,
        "recall": 0.426480372588157
      },
      {
        "accuracy": 0.5116433799068529,
        "f1": 0.4800706242174183,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.4800706242174183,
        "precision": 0.4703935663559893,
        "recall": 0.5116433799068529
      },
      {
        "accuracy": 0.3819028609447771,
        "f1": 0.3474019637492692,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.3474019637492692,
        "precision": 0.33710382351227597,
        "recall": 0.3819028609447771
      },
      {
        "accuracy": 0.635395874916833,
        "f1": 0.5949398345203084,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5949398345203084,
        "precision": 0.5794735226093098,
        "recall": 0.635395874916833
      },
      {
        "accuracy": 0.6194278110445776,
        "f1": 0.5685876142778901,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.5685876142778901,
        "precision": 0.5505332162898751,
        "recall": 0.6194278110445776
      },
      {
        "accuracy": 0.5369261477045908,
        "f1": 0.49295062149353563,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.49295062149353563,
        "precision": 0.4771412442071125,
        "recall": 0.5369261477045908
      },
      {
        "accuracy": 0.6314038589487692,
        "f1": 0.5830675645046902,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.5830675645046902,
        "precision": 0.5660550748188168,
        "recall": 0.6314038589487692
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5764069153290711,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.5764069153290711,
        "precision": 0.5566544190322338,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.6487025948103793,
        "f1": 0.6002532453131255,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.6002532453131255,
        "precision": 0.5816166848601978,
        "recall": 0.6487025948103793
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.007370624250477702,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.007370624250477702,
        "precision": 0.006109334898467161,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5925949244458222,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.5925949244458222,
        "precision": 0.5793951178931219,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.6606786427145709,
        "f1": 0.6060103260643357,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.6060103260643357,
        "precision": 0.5848345177906643,
        "recall": 0.6606786427145709
      },
      {
        "accuracy": 0.6500332667997338,
        "f1": 0.5997175442285223,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5997175442285223,
        "precision": 0.5809905669029527,
        "recall": 0.6500332667997338
      },
      {
        "accuracy": 0.5109780439121756,
        "f1": 0.4584974190703907,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.4584974190703907,
        "precision": 0.44011225212662963,
        "recall": 0.5109780439121756
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.006983092708621436,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.006983092708621436,
        "precision": 0.005646135143759009,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.3912175648702595,
        "f1": 0.3515729616727621,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.3515729616727621,
        "precision": 0.3391519886362355,
        "recall": 0.3912175648702595
      },
      {
        "accuracy": 0.5542248835662009,
        "f1": 0.5036078980754847,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.5036078980754847,
        "precision": 0.48459708769090004,
        "recall": 0.5542248835662009
      },
      {
        "accuracy": 0.590818363273453,
        "f1": 0.5390091045123087,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.5390091045123087,
        "precision": 0.5206354900778747,
        "recall": 0.590818363273453
      },
      {
        "accuracy": 0.709913506320692,
        "f1": 0.6611431593467522,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.6611431593467522,
        "precision": 0.6425580296837782,
        "recall": 0.709913506320692
      },
      {
        "accuracy": 0.8682634730538922,
        "f1": 0.8413538003358363,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8413538003358363,
        "precision": 0.8301238792256758,
        "recall": 0.8682634730538922
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9040712226340968,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9040712226340968,
        "precision": 0.89604125083167,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.19028609447771125,
        "f1": 0.15235398611147113,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.15235398611147113,
        "precision": 0.14060263649989124,
        "recall": 0.19028609447771125
      },
      {
        "accuracy": 0.7032601463739189,
        "f1": 0.6520577079459315,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6520577079459315,
        "precision": 0.6329323315850262,
        "recall": 0.7032601463739189
      },
      {
        "accuracy": 0.8962075848303394,
        "f1": 0.8776045939718593,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8776045939718593,
        "precision": 0.8707099269474519,
        "recall": 0.8962075848303394
      },
      {
        "accuracy": 0.6194278110445776,
        "f1": 0.5739533721510944,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5739533721510944,
        "precision": 0.5578341827094323,
        "recall": 0.6194278110445776
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8871938662357824,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8871938662357824,
        "precision": 0.8786981592370814,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8862623958432343,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8862623958432343,
        "precision": 0.8770237303171434,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.7984031936127745,
        "f1": 0.7606078847595813,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7606078847595813,
        "precision": 0.7458928943459883,
        "recall": 0.7984031936127745
      },
      {
        "accuracy": 0.6573519627411843,
        "f1": 0.6104244133186248,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6104244133186248,
        "precision": 0.592437899573628,
        "recall": 0.6573519627411843
      },
      {
        "accuracy": 0.8862275449101796,
        "f1": 0.8635649336248139,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8635649336248139,
        "precision": 0.8538589487691284,
        "recall": 0.8862275449101796
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8945901847099451,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8945901847099451,
        "precision": 0.8862893261096854,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.005384764839179119,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005384764839179119,
        "precision": 0.0043243909542562235,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9115008079079935,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9115008079079935,
        "precision": 0.9043801286316256,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8896999651490669,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8896999651490669,
        "precision": 0.8803725881570194,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8667126065329657,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8667126065329657,
        "precision": 0.8562272280835155,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.8003992015968064,
        "f1": 0.7629113388535721,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7629113388535721,
        "precision": 0.7473802395209581,
        "recall": 0.8003992015968064
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004266953606152465,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004266953606152465,
        "precision": 0.003230148488374833,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.5721889554224884,
        "f1": 0.5221952696628731,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5221952696628731,
        "precision": 0.5040665856284618,
        "recall": 0.5721889554224884
      },
      {
        "accuracy": 0.8117099135063207,
        "f1": 0.7768368025853056,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7768368025853056,
        "precision": 0.7621830413247579,
        "recall": 0.8117099135063207
      },
      {
        "accuracy": 0.8649367930805056,
        "f1": 0.8378617612150547,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8378617612150547,
        "precision": 0.8263251275227324,
        "recall": 0.8649367930805056
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9065424706143269,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9065424706143269,
        "precision": 0.8982812153470837,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.8669328010645376,
        "f1": 0.840779734791711,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.840779734791711,
        "precision": 0.8300916685148222,
        "recall": 0.8669328010645376
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9198048347748947,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9198048347748947,
        "precision": 0.9136172100243956,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.1375160828919977,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.1375160828919977,
        "precision": 0.12547322936544494,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.6926147704590818,
        "f1": 0.6425156703541112,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.6425156703541112,
        "precision": 0.623654601508105,
        "recall": 0.6926147704590818
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.9112695244431772,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9112695244431772,
        "precision": 0.9047867228505952,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.6254158349966733,
        "f1": 0.5764341594680916,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.5764341594680916,
        "precision": 0.558848158661033,
        "recall": 0.6254158349966733
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8960871906979693,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.8960871906979693,
        "precision": 0.8892548236859615,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.9087824351297406,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.9087824351297406,
        "precision": 0.900998003992016,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.8002286432426153,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.8002286432426153,
        "precision": 0.7876588093653961,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.6180971390552229,
        "f1": 0.5591180430132959,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.5591180430132959,
        "precision": 0.5370786953122282,
        "recall": 0.6180971390552229
      },
      {
        "accuracy": 0.8822355289421158,
        "f1": 0.8572558586530642,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.8572558586530642,
        "precision": 0.8469671767575958,
        "recall": 0.8822355289421158
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9100592465861926,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9100592465861926,
        "precision": 0.903049456642271,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.00413436767011833,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.00413436767011833,
        "precision": 0.003087876919984672,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.8999556442670215,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.8999556442670215,
        "precision": 0.8918163672654691,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9033821246396097,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.9033821246396097,
        "precision": 0.8960697652314418,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8655023286759813,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.8655023286759813,
        "precision": 0.8550074454266071,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.7990685296074518,
        "f1": 0.7590200218942734,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.7590200218942734,
        "precision": 0.7431299018125366,
        "recall": 0.7990685296074518
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0037524275766968465,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0037524275766968465,
        "precision": 0.002721527148988017,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.5655355954757152,
        "f1": 0.5116682601184186,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.5116682601184186,
        "precision": 0.49144947977283304,
        "recall": 0.5655355954757152
      },
      {
        "accuracy": 0.8735861610113107,
        "f1": 0.8508665209264011,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.8508665209264011,
        "precision": 0.8408088584735289,
        "recall": 0.8735861610113107
      },
      {
        "accuracy": 0.9028609447771124,
        "f1": 0.8831353166682508,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.8831353166682508,
        "precision": 0.8741295187402971,
        "recall": 0.9028609447771124
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9194278110445776,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.9194278110445776,
        "precision": 0.9123641605677534,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.8691394987802173,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8691394987802173,
        "precision": 0.8591990621930742,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9296961632290973,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9296961632290973,
        "precision": 0.9235085384785984,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.15963076720829508,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.15963076720829508,
        "precision": 0.14653057013042925,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.7212242182302062,
        "f1": 0.6690444507809777,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6690444507809777,
        "precision": 0.6489407668549384,
        "recall": 0.7212242182302062
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.910467952982923,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.910467952982923,
        "precision": 0.9038108967250684,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.6879574184963406,
        "f1": 0.6440134974662693,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6440134974662693,
        "precision": 0.6279597130894535,
        "recall": 0.6879574184963406
      },
      {
        "accuracy": 0.93812375249501,
        "f1": 0.924018629407851,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.924018629407851,
        "precision": 0.9177201153249058,
        "recall": 0.93812375249501
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9230871590153028,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9230871590153028,
        "precision": 0.9171102239964516,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.8290086493679308,
        "f1": 0.7960475873649526,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7960475873649526,
        "precision": 0.7835429669761006,
        "recall": 0.8290086493679308
      },
      {
        "accuracy": 0.6380572188955422,
        "f1": 0.5847356857900987,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5847356857900987,
        "precision": 0.5649791806478434,
        "recall": 0.6380572188955422
      },
      {
        "accuracy": 0.9035262807717898,
        "f1": 0.8813927700155245,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8813927700155245,
        "precision": 0.8718341095586604,
        "recall": 0.9035262807717898
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9090485695276114,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9090485695276114,
        "precision": 0.9018629407850964,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.004781513563763329,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004781513563763329,
        "precision": 0.00363954935698857,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9152140164116211,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9152140164116211,
        "precision": 0.9083721445996895,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9189398979818142,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9189398979818142,
        "precision": 0.9118651585717453,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8941450432468397,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8941450432468397,
        "precision": 0.8855843867819916,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.8097139055222887,
        "f1": 0.7729619312453643,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.7729619312453643,
        "precision": 0.7583475905332193,
        "recall": 0.8097139055222887
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0037376243865226686,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0037376243865226686,
        "precision": 0.00260922276907808,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.5914836992681304,
        "f1": 0.5368836923668436,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5368836923668436,
        "precision": 0.5167174083216997,
        "recall": 0.5914836992681304
      },
      {
        "accuracy": 0.8589487691284099,
        "f1": 0.8327345309381237,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8327345309381237,
        "precision": 0.8215568862275451,
        "recall": 0.8589487691284099
      },
      {
        "accuracy": 0.9068529607451763,
        "f1": 0.8874251497005988,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8874251497005988,
        "precision": 0.8792082501663339,
        "recall": 0.9068529607451763
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9251940563317809,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9251940563317809,
        "precision": 0.9185739631847417,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0020416049682474005,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0020416049682474005,
        "precision": 0.00201941522227779,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014554510311336286,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0014554510311336286,
        "precision": 0.0013965137879787507,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0020002391280611685,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0020002391280611685,
        "precision": 0.0017387016014936087,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009072402779503003,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0009072402779503003,
        "precision": 0.0008025724886270465,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011609408030438802,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0011609408030438802,
        "precision": 0.0009686054248092961,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0017635428757091062,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0017635428757091062,
        "precision": 0.001352708716275475,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0017938211950187996,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0017938211950187996,
        "precision": 0.001673212265820153,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015768313918837233,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0015768313918837233,
        "precision": 0.0014760411580940183,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0024045386487039273,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0024045386487039273,
        "precision": 0.002219378926482654,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0027115028627523016,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0027115028627523016,
        "precision": 0.002421197669927219,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.003239135230980349,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.003239135230980349,
        "precision": 0.003028039392249624,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006829672983143231,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0006829672983143231,
        "precision": 0.0006742036398910168,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.002449371750578472,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.002449371750578472,
        "precision": 0.0023336054114765884,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003417071238207762,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.003417071238207762,
        "precision": 0.0031733498053159344,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0017242306415784277,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0017242306415784277,
        "precision": 0.0015512227503933903,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0020154647889391846,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0020154647889391846,
        "precision": 0.0020057792505660853,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002435506692990018,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.002435506692990018,
        "precision": 0.0022609183530753374,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.027149627072502222,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.027149627072502222,
        "precision": 0.02440244902692888,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0013609103788277215,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0013609103788277215,
        "precision": 0.001134510244755983,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007016445335099195,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0007016445335099195,
        "precision": 0.0006837976724344705,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006989525875911438,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0006989525875911438,
        "precision": 0.000682429134507075,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0020356128932979205,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0020356128932979205,
        "precision": 0.0020161594638027787,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.8717786648924374,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8717786648924374,
        "precision": 0.862869499097044,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.948769128409847,
        "f1": 0.9373697050343758,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9373697050343758,
        "precision": 0.9321911732091372,
        "recall": 0.948769128409847
      },
      {
        "accuracy": 0.2109115103127079,
        "f1": 0.16579489100700545,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.16579489100700545,
        "precision": 0.15157695552387912,
        "recall": 0.2109115103127079
      },
      {
        "accuracy": 0.7272122421823021,
        "f1": 0.6783428333328533,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6783428333328533,
        "precision": 0.6592127747317368,
        "recall": 0.7272122421823021
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9163535363136162,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9163535363136162,
        "precision": 0.9105843867819916,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.6520292747837658,
        "f1": 0.6053359444577009,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6053359444577009,
        "precision": 0.5889421279541039,
        "recall": 0.6520292747837658
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9083610556664449,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9083610556664449,
        "precision": 0.900909292526059,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.9106897316478153,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9106897316478153,
        "precision": 0.9023286759813707,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.823020625415835,
        "f1": 0.7891592956463215,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7891592956463215,
        "precision": 0.7758712733263631,
        "recall": 0.823020625415835
      },
      {
        "accuracy": 0.6526946107784432,
        "f1": 0.6031096204748899,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6031096204748899,
        "precision": 0.5845162008834663,
        "recall": 0.6526946107784432
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.8997782213351077,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8997782213351077,
        "precision": 0.8909625194056333,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8917181509995881,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8917181509995881,
        "precision": 0.8822355289421158,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.93812375249501,
        "f1": 0.9247948547349744,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9247948547349744,
        "precision": 0.9190729651807497,
        "recall": 0.93812375249501
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.004951134720606484,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004951134720606484,
        "precision": 0.003764025380681928,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9256376136615657,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9256376136615657,
        "precision": 0.9189066311820802,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8936698032506416,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8936698032506416,
        "precision": 0.885362608117099,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.8296739853626082,
        "f1": 0.7935135020963365,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7935135020963365,
        "precision": 0.7791984407253869,
        "recall": 0.8296739853626082
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.00260784111316158,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00260784111316158,
        "precision": 0.0016827657649307846,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.6047904191616766,
        "f1": 0.5538300023329963,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5538300023329963,
        "precision": 0.5347691335548954,
        "recall": 0.6047904191616766
      },
      {
        "accuracy": 0.854956753160346,
        "f1": 0.8258039476602351,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8258039476602351,
        "precision": 0.8137196506457984,
        "recall": 0.854956753160346
      },
      {
        "accuracy": 0.9008649367930806,
        "f1": 0.8790767671007191,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8790767671007191,
        "precision": 0.8696680712648778,
        "recall": 0.9008649367930806
      },
      {
        "accuracy": 0.9507651363938789,
        "f1": 0.9387003770237304,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9387003770237304,
        "precision": 0.9336992681304058,
        "recall": 0.9507651363938789
      },
      {
        "accuracy": 0.906187624750499,
        "f1": 0.8844438107911161,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8844438107911161,
        "precision": 0.8752605899312486,
        "recall": 0.906187624750499
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.937658017298736,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.937658017298736,
        "precision": 0.9322687957418496,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.20026613439787092,
        "f1": 0.15929869334726288,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.15929869334726288,
        "precision": 0.14668951074437972,
        "recall": 0.20026613439787092
      },
      {
        "accuracy": 0.7119095143047239,
        "f1": 0.6635354111402015,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6635354111402015,
        "precision": 0.644693567532101,
        "recall": 0.7119095143047239
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.914887684947565,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.914887684947565,
        "precision": 0.9089598580616545,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.633399866932801,
        "f1": 0.588578185744637,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.588578185744637,
        "precision": 0.5723900120357206,
        "recall": 0.633399866932801
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9176314038589487,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9176314038589487,
        "precision": 0.9117210024395652,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9254950416627064,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.9254950416627064,
        "precision": 0.9188844533155911,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.8396540252827678,
        "f1": 0.8071449693206179,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.8071449693206179,
        "precision": 0.7945339479770618,
        "recall": 0.8396540252827678
      },
      {
        "accuracy": 0.6453759148369926,
        "f1": 0.5895820296583987,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.5895820296583987,
        "precision": 0.5679153551409041,
        "recall": 0.6453759148369926
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.905921490352628,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.905921490352628,
        "precision": 0.8979818141494789,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9113107119095143,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9113107119095143,
        "precision": 0.903581725438013,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.9427811044577512,
        "f1": 0.9292747837658017,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9292747837658017,
        "precision": 0.9232091372809935,
        "recall": 0.9427811044577512
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0034653049616797243,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0034653049616797243,
        "precision": 0.0028503511900974544,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9224883566200931,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9224883566200931,
        "precision": 0.9163561765358172,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.8968840097582612,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.8968840097582612,
        "precision": 0.888917403288661,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7807717897538257,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.7807717897538257,
        "precision": 0.7663107240951552,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0036994876568618206,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0036994876568618206,
        "precision": 0.0023932278386557294,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.5815036593479708,
        "f1": 0.5284467288459304,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.5284467288459304,
        "precision": 0.5088549396932631,
        "recall": 0.5815036593479708
      },
      {
        "accuracy": 0.872255489021956,
        "f1": 0.8463517409625194,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.8463517409625194,
        "precision": 0.834719449988911,
        "recall": 0.872255489021956
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8933022843202483,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.8933022843202483,
        "precision": 0.8840319361277446,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.9427811044577512,
        "f1": 0.9300731869594144,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9300731869594144,
        "precision": 0.9243180306054558,
        "recall": 0.9427811044577512
      },
      {
        "accuracy": 0.8888888888888888,
        "f1": 0.8662262776035231,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8662262776035231,
        "precision": 0.8564981148813484,
        "recall": 0.8888888888888888
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9163118208028388,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9163118208028388,
        "precision": 0.909409751924722,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.2162341982701264,
        "f1": 0.17031687878673962,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.17031687878673962,
        "precision": 0.1560969331178912,
        "recall": 0.2162341982701264
      },
      {
        "accuracy": 0.737857618097139,
        "f1": 0.6927542369658138,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.6927542369658138,
        "precision": 0.675249765020224,
        "recall": 0.737857618097139
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9189747489148686,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9189747489148686,
        "precision": 0.9126413838988688,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.6526946107784432,
        "f1": 0.6077290485943767,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.6077290485943767,
        "precision": 0.5903006710890942,
        "recall": 0.6526946107784432
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9154056965434212,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9154056965434212,
        "precision": 0.9091103507271173,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9197066185090137,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.9197066185090137,
        "precision": 0.9126081170991351,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.8263473053892215,
        "f1": 0.7933688179197161,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.7933688179197161,
        "precision": 0.7800961402757811,
        "recall": 0.8263473053892215
      },
      {
        "accuracy": 0.6500332667997338,
        "f1": 0.5950179487105635,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.5950179487105635,
        "precision": 0.5735349000818063,
        "recall": 0.6500332667997338
      },
      {
        "accuracy": 0.9041916167664671,
        "f1": 0.8830835683131092,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.8830835683131092,
        "precision": 0.8742237746728766,
        "recall": 0.9041916167664671
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8922599245952539,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.8922599245952539,
        "precision": 0.8837264864210972,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.915302727877578,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.915302727877578,
        "precision": 0.9079285872699047,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0039771840749715974,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.0039771840749715974,
        "precision": 0.0031360558869494445,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9129106865633813,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9129106865633813,
        "precision": 0.9060434686183189,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.9110002217786649,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.9110002217786649,
        "precision": 0.9038478598358837,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.8070525615435795,
        "f1": 0.7675426111553856,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7675426111553856,
        "precision": 0.7512699708807493,
        "recall": 0.8070525615435795
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.004374298726509012,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.004374298726509012,
        "precision": 0.0030454675512474115,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.6347305389221557,
        "f1": 0.5829422444192903,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.5829422444192903,
        "precision": 0.5633165127177103,
        "recall": 0.6347305389221557
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.810367144498881,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.810367144498881,
        "precision": 0.7984747676364443,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.895542248835662,
        "f1": 0.8727560751512847,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.8727560751512847,
        "precision": 0.8626302949656243,
        "recall": 0.895542248835662
      },
      {
        "accuracy": 0.9474384564204924,
        "f1": 0.9373697050343757,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.9373697050343757,
        "precision": 0.9331004657351961,
        "recall": 0.9474384564204924
      },
      {
        "accuracy": 0.7937458416500333,
        "f1": 0.7580965054018947,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7580965054018947,
        "precision": 0.7432911953870037,
        "recall": 0.7937458416500333
      },
      {
        "accuracy": 0.8369926813040586,
        "f1": 0.807090100702875,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.807090100702875,
        "precision": 0.7946237155318991,
        "recall": 0.8369926813040586
      },
      {
        "accuracy": 0.17298735861610112,
        "f1": 0.1413243540929346,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1413243540929346,
        "precision": 0.13075845663171012,
        "recall": 0.17298735861610112
      },
      {
        "accuracy": 0.590818363273453,
        "f1": 0.5388290733284955,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5388290733284955,
        "precision": 0.5198168018996949,
        "recall": 0.590818363273453
      },
      {
        "accuracy": 0.7571523619427811,
        "f1": 0.7266770691421389,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7266770691421389,
        "precision": 0.7159830546075602,
        "recall": 0.7571523619427811
      },
      {
        "accuracy": 0.5289421157684631,
        "f1": 0.48306620562109587,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.48306620562109587,
        "precision": 0.466871547909472,
        "recall": 0.5289421157684631
      },
      {
        "accuracy": 0.8050565535595475,
        "f1": 0.7771620779604812,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7771620779604812,
        "precision": 0.7660512308715901,
        "recall": 0.8050565535595475
      },
      {
        "accuracy": 0.8057218895542249,
        "f1": 0.771279581658823,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.771279581658823,
        "precision": 0.7577506602955705,
        "recall": 0.8057218895542249
      },
      {
        "accuracy": 0.7152361942781105,
        "f1": 0.6746723484248435,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6746723484248435,
        "precision": 0.6587051006212683,
        "recall": 0.7152361942781105
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.49945697577276527,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.49945697577276527,
        "precision": 0.47983688707241595,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.8303393213572854,
        "f1": 0.7969357581134029,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7969357581134029,
        "precision": 0.7832066026676805,
        "recall": 0.8303393213572854
      },
      {
        "accuracy": 0.8097139055222887,
        "f1": 0.7771583816493995,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7771583816493995,
        "precision": 0.7634128568260304,
        "recall": 0.8097139055222887
      },
      {
        "accuracy": 0.8496340652029275,
        "f1": 0.8204188692212645,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8204188692212645,
        "precision": 0.8079312274921057,
        "recall": 0.8496340652029275
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.00581973107889018,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00581973107889018,
        "precision": 0.004721180515432419,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.8449767132401863,
        "f1": 0.817588632259291,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.817588632259291,
        "precision": 0.8065377182143648,
        "recall": 0.8449767132401863
      },
      {
        "accuracy": 0.8436460412508316,
        "f1": 0.8143728416183506,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8143728416183506,
        "precision": 0.8023144187814846,
        "recall": 0.8436460412508316
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7827392833380857,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7827392833380857,
        "precision": 0.7684704664744584,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0049233102410030285,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0049233102410030285,
        "precision": 0.0036960344551594053,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.47837658017298734,
        "f1": 0.4307746607646807,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4307746607646807,
        "precision": 0.41382139520862066,
        "recall": 0.47837658017298734
      },
      {
        "accuracy": 0.7325349301397206,
        "f1": 0.6921426987295249,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6921426987295249,
        "precision": 0.6763768758778739,
        "recall": 0.7325349301397206
      },
      {
        "accuracy": 0.7957418496340652,
        "f1": 0.7594087438398816,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7594087438398816,
        "precision": 0.7451171730612848,
        "recall": 0.7957418496340652
      },
      {
        "accuracy": 0.8496340652029275,
        "f1": 0.8182080283876689,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8182080283876689,
        "precision": 0.8049752347157538,
        "recall": 0.8496340652029275
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0010409635396948906,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0010409635396948906,
        "precision": 0.0009090289991901402,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.0300565892865365e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 3.0300565892865365e-05,
        "precision": 1.537598060969229e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0012413332354401624,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0012413332354401624,
        "precision": 0.0010193218172650652,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008052447286654927,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0008052447286654927,
        "precision": 0.0007394661933410523,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007230177957425752,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0007230177957425752,
        "precision": 0.000695096037744075,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0009370206529512903,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0009370206529512903,
        "precision": 0.0005919235449630819,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00029766679076754577,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.00029766679076754577,
        "precision": 0.00017249909765734985,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000881323767079041,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.000881323767079041,
        "precision": 0.0007893177230972229,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0009031641251855555,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0009031641251855555,
        "precision": 0.0007913595205216662,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0016669161967906632,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0016669161967906632,
        "precision": 0.001516686592506745,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000709694899167135,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.000709694899167135,
        "precision": 0.0006878054866562744,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.3201310192390274e-05,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 1.3201310192390274e-05,
        "precision": 6.656604597909954e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.0645278808530871e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 1.0645278808530871e-05,
        "precision": 5.353278118093316e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.031089408484618067,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.031089408484618067,
        "precision": 0.02775401577796787,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00012344419758479234,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.00012344419758479234,
        "precision": 6.678633661489883e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008094335745811414,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0008094335745811414,
        "precision": 0.0007403760287640671,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 7.720335621091513e-05,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 7.720335621091513e-05,
        "precision": 3.9982100336762415e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 1.816466555670098e-05,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 1.816466555670098e-05,
        "precision": 9.13846128987964e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 7.370687556328544e-05,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 7.370687556328544e-05,
        "precision": 3.767313703214895e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000750277539410066,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.000750277539410066,
        "precision": 0.0005195978357817756,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 5.4273382116427354e-05,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 5.4273382116427354e-05,
        "precision": 2.759862555530591e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 1.0921174013516357e-05,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 1.0921174013516357e-05,
        "precision": 5.486307881517462e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.5755156353958749,
        "f1": 0.5247911731943669,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5247911731943669,
        "precision": 0.5063672358208001,
        "recall": 0.5755156353958749
      },
      {
        "accuracy": 0.624750499001996,
        "f1": 0.5674326763648121,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5674326763648121,
        "precision": 0.5460591098207506,
        "recall": 0.624750499001996
      },
      {
        "accuracy": 0.2368596141051231,
        "f1": 0.19440916147502973,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.19440916147502973,
        "precision": 0.17984665589456011,
        "recall": 0.2368596141051231
      },
      {
        "accuracy": 0.582168995342648,
        "f1": 0.5373623604162526,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5373623604162526,
        "precision": 0.5204374320142784,
        "recall": 0.582168995342648
      },
      {
        "accuracy": 0.5375914836992681,
        "f1": 0.496771256812832,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.496771256812832,
        "precision": 0.4834275813395161,
        "recall": 0.5375914836992681
      },
      {
        "accuracy": 0.5036593479707252,
        "f1": 0.4523769680456307,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4523769680456307,
        "precision": 0.43443109572101585,
        "recall": 0.5036593479707252
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.6002927303451642,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6002927303451642,
        "precision": 0.5815877338082927,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.6586826347305389,
        "f1": 0.6024187155591014,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6024187155591014,
        "precision": 0.5818584849023971,
        "recall": 0.6586826347305389
      },
      {
        "accuracy": 0.541583499667332,
        "f1": 0.49515109979024247,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.49515109979024247,
        "precision": 0.4788221524091889,
        "recall": 0.541583499667332
      },
      {
        "accuracy": 0.46041250831669994,
        "f1": 0.40656839279593776,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.40656839279593776,
        "precision": 0.38652373722234,
        "recall": 0.46041250831669994
      },
      {
        "accuracy": 0.6107784431137725,
        "f1": 0.5552286960470593,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5552286960470593,
        "precision": 0.5347398037018796,
        "recall": 0.6107784431137725
      },
      {
        "accuracy": 0.5941450432468397,
        "f1": 0.5369412812211425,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5369412812211425,
        "precision": 0.5167047944775099,
        "recall": 0.5941450432468397
      },
      {
        "accuracy": 0.6400532268795742,
        "f1": 0.5870938071050451,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5870938071050451,
        "precision": 0.5677259478157681,
        "recall": 0.6400532268795742
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.004544716578623397,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004544716578623397,
        "precision": 0.0035954521932565846,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.6147704590818364,
        "f1": 0.5626548773293235,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5626548773293235,
        "precision": 0.5438138273717116,
        "recall": 0.6147704590818364
      },
      {
        "accuracy": 0.6214238190286094,
        "f1": 0.5629742106788015,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5629742106788015,
        "precision": 0.5424386256347334,
        "recall": 0.6214238190286094
      },
      {
        "accuracy": 0.6400532268795742,
        "f1": 0.5852179239404788,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5852179239404788,
        "precision": 0.5653249297460874,
        "recall": 0.6400532268795742
      },
      {
        "accuracy": 0.5049900199600799,
        "f1": 0.44811070499693256,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.44811070499693256,
        "precision": 0.42765482954810186,
        "recall": 0.5049900199600799
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0040656951410392925,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0040656951410392925,
        "precision": 0.002881036818553941,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.541583499667332,
        "f1": 0.4852610684946014,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4852610684946014,
        "precision": 0.464810207913166,
        "recall": 0.541583499667332
      },
      {
        "accuracy": 0.5555555555555556,
        "f1": 0.5043570717722414,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5043570717722414,
        "precision": 0.48670617519170417,
        "recall": 0.5555555555555556
      },
      {
        "accuracy": 0.6553559547571524,
        "f1": 0.6023833525829534,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6023833525829534,
        "precision": 0.5829617714473003,
        "recall": 0.6553559547571524
      },
      {
        "accuracy": 0.7950765136393879,
        "f1": 0.7570747874141088,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7570747874141088,
        "precision": 0.7416550736910018,
        "recall": 0.7950765136393879
      },
      {
        "accuracy": 0.8822355289421158,
        "f1": 0.8578546610482737,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8578546610482737,
        "precision": 0.8467453980927034,
        "recall": 0.8822355289421158
      },
      {
        "accuracy": 0.17964071856287425,
        "f1": 0.1398747478587798,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.1398747478587798,
        "precision": 0.12787595183577213,
        "recall": 0.17964071856287425
      },
      {
        "accuracy": 0.6314038589487692,
        "f1": 0.5747310093617478,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.5747310093617478,
        "precision": 0.5532834043313085,
        "recall": 0.6314038589487692
      },
      {
        "accuracy": 0.8589487691284099,
        "f1": 0.8326923353869462,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8326923353869462,
        "precision": 0.821809738276804,
        "recall": 0.8589487691284099
      },
      {
        "accuracy": 0.5695276114437791,
        "f1": 0.5141367139620062,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.5141367139620062,
        "precision": 0.4933462560209067,
        "recall": 0.5695276114437791
      },
      {
        "accuracy": 0.850964737192282,
        "f1": 0.8233225855980347,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.8233225855980347,
        "precision": 0.8114992237746729,
        "recall": 0.850964737192282
      },
      {
        "accuracy": 0.8775781769793746,
        "f1": 0.8518550201184932,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.8518550201184932,
        "precision": 0.840208471944999,
        "recall": 0.8775781769793746
      },
      {
        "accuracy": 0.803725881570193,
        "f1": 0.7657901128959012,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.7657901128959012,
        "precision": 0.7507163162851787,
        "recall": 0.803725881570193
      },
      {
        "accuracy": 0.5655355954757152,
        "f1": 0.5011331833687123,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5011331833687123,
        "precision": 0.47693213860878536,
        "recall": 0.5655355954757152
      },
      {
        "accuracy": 0.8203592814371258,
        "f1": 0.7862207283364968,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.7862207283364968,
        "precision": 0.7721440956470895,
        "recall": 0.8203592814371258
      },
      {
        "accuracy": 0.8702594810379242,
        "f1": 0.8438752125378872,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8438752125378872,
        "precision": 0.8323020625415836,
        "recall": 0.8702594810379242
      },
      {
        "accuracy": 0.865602129075183,
        "f1": 0.8392400384416352,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.8392400384416352,
        "precision": 0.8275559991128854,
        "recall": 0.865602129075183
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.002877018291995516,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.002877018291995516,
        "precision": 0.0020516732109519755,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.8502994011976048,
        "f1": 0.8162357824034472,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8162357824034472,
        "precision": 0.8014996462102251,
        "recall": 0.8502994011976048
      },
      {
        "accuracy": 0.8602794411177644,
        "f1": 0.8310933688179196,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.8310933688179196,
        "precision": 0.8181871946343005,
        "recall": 0.8602794411177644
      },
      {
        "accuracy": 0.8343313373253493,
        "f1": 0.8018534359851726,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.8018534359851726,
        "precision": 0.7878945812079544,
        "recall": 0.8343313373253493
      },
      {
        "accuracy": 0.7278775781769794,
        "f1": 0.675902163926116,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.675902163926116,
        "precision": 0.6543806160572627,
        "recall": 0.7278775781769794
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0028384046465500844,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0028384046465500844,
        "precision": 0.0020600340858451215,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.5449101796407185,
        "f1": 0.4908694691129821,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.4908694691129821,
        "precision": 0.47015025269975635,
        "recall": 0.5449101796407185
      },
      {
        "accuracy": 0.8689288090485695,
        "f1": 0.8416500332667998,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8416500332667998,
        "precision": 0.8294189398979819,
        "recall": 0.8689288090485695
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.849123974273675,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.849123974273675,
        "precision": 0.8374103644562726,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.8616101131071191,
        "f1": 0.8338012287114084,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8338012287114084,
        "precision": 0.8223357517768696,
        "recall": 0.8616101131071191
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9060989132845421,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9060989132845421,
        "precision": 0.899035262807718,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.18762475049900199,
        "f1": 0.14851461098966087,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.14851461098966087,
        "precision": 0.13611601274102358,
        "recall": 0.18762475049900199
      },
      {
        "accuracy": 0.6806387225548902,
        "f1": 0.6290271456938125,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.6290271456938125,
        "precision": 0.6101495661874903,
        "recall": 0.6806387225548902
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8884025599594463,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8884025599594463,
        "precision": 0.8817095966796566,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.5981370592149036,
        "f1": 0.5513400382169238,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.5513400382169238,
        "precision": 0.5349386625554877,
        "recall": 0.5981370592149036
      },
      {
        "accuracy": 0.8942115768463074,
        "f1": 0.8757063074428344,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8757063074428344,
        "precision": 0.8681747615879353,
        "recall": 0.8942115768463074
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9094160884580046,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9094160884580046,
        "precision": 0.9024728321135506,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.8021344036314096,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.8021344036314096,
        "precision": 0.7903700535437064,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.605455755156354,
        "f1": 0.5522957906874285,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.5522957906874285,
        "precision": 0.5322344802384723,
        "recall": 0.605455755156354
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.8485177792563021,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8485177792563021,
        "precision": 0.8376968285650921,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8883787979596361,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8883787979596361,
        "precision": 0.879930614960555,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8979279536165764,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8979279536165764,
        "precision": 0.8908848968729208,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.005000617032924966,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.005000617032924966,
        "precision": 0.004073829575085128,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8889237398219434,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8889237398219434,
        "precision": 0.8796850742958526,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.9188290086493679,
        "f1": 0.8999223774672876,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.8999223774672876,
        "precision": 0.8916083177560225,
        "recall": 0.9188290086493679
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.857031967810411,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.857031967810411,
        "precision": 0.8458823094551637,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.7884231536926147,
        "f1": 0.7481090728595718,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7481090728595718,
        "precision": 0.7317188854614003,
        "recall": 0.7884231536926147
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.00396420469527328,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.00396420469527328,
        "precision": 0.0027839288327972797,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.49715751277627523,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.49715751277627523,
        "precision": 0.47728509431353744,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.8802395209580839,
        "f1": 0.8558586530642418,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.8558586530642418,
        "precision": 0.8447272122421823,
        "recall": 0.8802395209580839
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9041029053005102,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9041029053005102,
        "precision": 0.8963960966954979,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8758403827266102,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8758403827266102,
        "precision": 0.866828248265374,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.9421157684630739,
        "f1": 0.9299179418939898,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9299179418939898,
        "precision": 0.9246506986027944,
        "recall": 0.9421157684630739
      },
      {
        "accuracy": 0.17964071856287425,
        "f1": 0.14201467564741016,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.14201467564741016,
        "precision": 0.13068294698270042,
        "recall": 0.17964071856287425
      },
      {
        "accuracy": 0.7218895542248835,
        "f1": 0.6752231061612299,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6752231061612299,
        "precision": 0.6571990410712965,
        "recall": 0.7218895542248835
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9285112315052434,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9285112315052434,
        "precision": 0.9241865475398411,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.6174318030605456,
        "f1": 0.5725613509985942,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5725613509985942,
        "precision": 0.5567232799488875,
        "recall": 0.6174318030605456
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9171240011559374,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9171240011559374,
        "precision": 0.9114936793080505,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.948769128409847,
        "f1": 0.9379352406298512,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9379352406298512,
        "precision": 0.9331178912017235,
        "recall": 0.948769128409847
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7867714786876463,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.7867714786876463,
        "precision": 0.773349316463089,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.6686626746506986,
        "f1": 0.6145449938804406,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.6145449938804406,
        "precision": 0.5943761947005459,
        "recall": 0.6686626746506986
      },
      {
        "accuracy": 0.9208250166333999,
        "f1": 0.9016633399866931,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9016633399866931,
        "precision": 0.8934464404524284,
        "recall": 0.9208250166333999
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9099261793872573,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9099261793872573,
        "precision": 0.9028831226436017,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9265025504546462,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9265025504546462,
        "precision": 0.921789753825682,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005550906156116639,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.005550906156116639,
        "precision": 0.00458817029302603,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9246427779361912,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9246427779361912,
        "precision": 0.9190175205145265,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.9201485917054778,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9201485917054778,
        "precision": 0.914100370687197,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9082110910454224,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9082110910454224,
        "precision": 0.9015801729873585,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.8157019294743846,
        "f1": 0.7801550818516887,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.7801550818516887,
        "precision": 0.7658500459398662,
        "recall": 0.8157019294743846
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.003733799710267826,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.003733799710267826,
        "precision": 0.0026831822600579206,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.5808383233532934,
        "f1": 0.5345423665606829,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.5345423665606829,
        "precision": 0.5181532437769962,
        "recall": 0.5808383233532934
      },
      {
        "accuracy": 0.8622754491017964,
        "f1": 0.8371938662357825,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8371938662357825,
        "precision": 0.826658083544311,
        "recall": 0.8622754491017964
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8991276705847563,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8991276705847563,
        "precision": 0.8920843498188809,
        "recall": 0.9161676646706587
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}