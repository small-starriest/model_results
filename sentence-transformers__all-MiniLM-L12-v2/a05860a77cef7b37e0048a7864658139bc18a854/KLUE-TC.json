{
  "dataset_revision": "349481ec73fff722f88e0453ca05c77a447d967c",
  "evaluation_time": 10.922750473022461,
  "kg_co2_emissions": 0.001651395986209245,
  "mteb_version": "1.12.75",
  "scores": {
    "validation": [
      {
        "accuracy": 0.217138671875,
        "f1": 0.20798582045096992,
        "f1_weighted": 0.21566299680162565,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.217138671875,
        "scores_per_experiment": [
          {
            "accuracy": 0.2333984375,
            "f1": 0.2289025489413866,
            "f1_weighted": 0.24134162627777744
          },
          {
            "accuracy": 0.23193359375,
            "f1": 0.21865348237444746,
            "f1_weighted": 0.23741627384831399
          },
          {
            "accuracy": 0.2158203125,
            "f1": 0.2062822716822182,
            "f1_weighted": 0.2121794772323626
          },
          {
            "accuracy": 0.1767578125,
            "f1": 0.16632631262477712,
            "f1_weighted": 0.16330320306398627
          },
          {
            "accuracy": 0.21533203125,
            "f1": 0.21609509378120778,
            "f1_weighted": 0.21521359553121225
          },
          {
            "accuracy": 0.23193359375,
            "f1": 0.23363288431548673,
            "f1_weighted": 0.2252603490944422
          },
          {
            "accuracy": 0.255859375,
            "f1": 0.23080151861556703,
            "f1_weighted": 0.26346366566551715
          },
          {
            "accuracy": 0.2021484375,
            "f1": 0.18417480943935213,
            "f1_weighted": 0.2095359614036054
          },
          {
            "accuracy": 0.2119140625,
            "f1": 0.21008930766357814,
            "f1_weighted": 0.19582678657222014
          },
          {
            "accuracy": 0.1962890625,
            "f1": 0.1848999750716782,
            "f1_weighted": 0.1930890293268193
          }
        ]
      }
    ]
  },
  "task_name": "KLUE-TC"
}