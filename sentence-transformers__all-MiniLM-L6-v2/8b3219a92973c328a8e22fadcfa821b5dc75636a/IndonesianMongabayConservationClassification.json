{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 15.908357858657837,
  "kg_co2_emissions": 0.0024208270752398096,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.3069600818833163,
        "f1": 0.30312952197737497,
        "f1_weighted": 0.30367085207602046,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.30312952197737497,
        "scores_per_experiment": [
          {
            "accuracy": 0.32446264073694986,
            "f1": 0.3213938349851698,
            "f1_weighted": 0.3127403581695553
          },
          {
            "accuracy": 0.28454452405322417,
            "f1": 0.280459408764235,
            "f1_weighted": 0.28342473087142744
          },
          {
            "accuracy": 0.33162743091095187,
            "f1": 0.3307129818967158,
            "f1_weighted": 0.3252175437746574
          },
          {
            "accuracy": 0.3295803480040942,
            "f1": 0.32404848334845865,
            "f1_weighted": 0.3321801462513311
          },
          {
            "accuracy": 0.2835209825997953,
            "f1": 0.2831119099173351,
            "f1_weighted": 0.2843507588430693
          },
          {
            "accuracy": 0.28249744114636643,
            "f1": 0.28248864028639903,
            "f1_weighted": 0.28389271926709525
          },
          {
            "accuracy": 0.2937563971340839,
            "f1": 0.28965725743848775,
            "f1_weighted": 0.291105483991029
          },
          {
            "accuracy": 0.2998976458546571,
            "f1": 0.2955888931979532,
            "f1_weighted": 0.29537215957616847
          },
          {
            "accuracy": 0.3428863868986694,
            "f1": 0.33673438303874215,
            "f1_weighted": 0.3450774629725818
          },
          {
            "accuracy": 0.2968270214943705,
            "f1": 0.28709942690025386,
            "f1_weighted": 0.2833471570432895
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.31300813008130085,
        "f1": 0.3065788425247215,
        "f1_weighted": 0.31120847087691605,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.3065788425247215,
        "scores_per_experiment": [
          {
            "accuracy": 0.31910569105691056,
            "f1": 0.3127168147072787,
            "f1_weighted": 0.311747601930035
          },
          {
            "accuracy": 0.3130081300813008,
            "f1": 0.306525886767121,
            "f1_weighted": 0.3130252843277165
          },
          {
            "accuracy": 0.35365853658536583,
            "f1": 0.3512932292426674,
            "f1_weighted": 0.3482677383592018
          },
          {
            "accuracy": 0.3678861788617886,
            "f1": 0.35641760891272084,
            "f1_weighted": 0.37029565606883014
          },
          {
            "accuracy": 0.2764227642276423,
            "f1": 0.27613650588307836,
            "f1_weighted": 0.2772005030103868
          },
          {
            "accuracy": 0.258130081300813,
            "f1": 0.2573587003208772,
            "f1_weighted": 0.26477424897041363
          },
          {
            "accuracy": 0.29471544715447157,
            "f1": 0.28737505819914644,
            "f1_weighted": 0.2941863185235784
          },
          {
            "accuracy": 0.2886178861788618,
            "f1": 0.28213678894689553,
            "f1_weighted": 0.28628048228709735
          },
          {
            "accuracy": 0.34959349593495936,
            "f1": 0.3449445556508754,
            "f1_weighted": 0.3527576327521925
          },
          {
            "accuracy": 0.3089430894308943,
            "f1": 0.290883276616554,
            "f1_weighted": 0.29354924253970854
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}