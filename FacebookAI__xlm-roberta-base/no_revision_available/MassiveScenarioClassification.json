{
  "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
  "mteb_dataset_name": "MassiveScenarioClassification",
  "mteb_version": "1.0.3.dev0",
  "test": {
    "da": {
      "accuracy": 0.43913920645595156,
      "accuracy_stderr": 0.02403781459559167,
      "f1": 0.4224444767774179,
      "f1_stderr": 0.019128246487203907,
      "main_score": 0.43913920645595156
    },
    "evaluation_time": 84.39,
    "nb": {
      "accuracy": 0.44828513786146607,
      "accuracy_stderr": 0.03030513291601151,
      "f1": 0.4280187540493935,
      "f1_stderr": 0.02025670836250579,
      "main_score": 0.44828513786146607
    },
    "sv": {
      "accuracy": 0.4735036987222595,
      "accuracy_stderr": 0.03037481874129291,
      "f1": 0.46097644872017873,
      "f1_stderr": 0.022149804025228082,
      "main_score": 0.4735036987222595
    },
    "fr": {
      "accuracy": 0.23214525891055815,
      "accuracy_stderr": 0.032492086366805804,
      "f1": 0.2137516225585256,
      "f1_stderr": 0.03576007230430259,
      "main_score": 0.23214525891055815
    }
  },
  "validation": {
    "da": {
      "accuracy": 0.42616822429906537,
      "accuracy_stderr": 0.021520919097098384,
      "f1": 0.41800251412406075,
      "f1_stderr": 0.01614532633675208,
      "main_score": 0.42616822429906537
    },
    "evaluation_time": 68.01,
    "nb": {
      "accuracy": 0.4348253812100344,
      "accuracy_stderr": 0.0323904717938779,
      "f1": 0.42406110008279246,
      "f1_stderr": 0.020883262391502677,
      "main_score": 0.4348253812100344
    },
    "sv": {
      "accuracy": 0.4752090506640433,
      "accuracy_stderr": 0.028408968344763218,
      "f1": 0.46614312829233057,
      "f1_stderr": 0.02109266293949793,
      "main_score": 0.4752090506640433
    }
  }
}