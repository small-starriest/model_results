{
  "dataset_revision": "349481ec73fff722f88e0453ca05c77a447d967c",
  "evaluation_time": 10.705790996551514,
  "kg_co2_emissions": 0.0016252632003261713,
  "mteb_version": "1.12.75",
  "scores": {
    "validation": [
      {
        "accuracy": 0.514013671875,
        "f1": 0.5180238424472291,
        "f1_weighted": 0.5124981046642614,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.514013671875,
        "scores_per_experiment": [
          {
            "accuracy": 0.48681640625,
            "f1": 0.4883545949150082,
            "f1_weighted": 0.49066499892387033
          },
          {
            "accuracy": 0.5341796875,
            "f1": 0.5301329321002163,
            "f1_weighted": 0.5341338921256265
          },
          {
            "accuracy": 0.49853515625,
            "f1": 0.5090600983566022,
            "f1_weighted": 0.49424673802022956
          },
          {
            "accuracy": 0.529296875,
            "f1": 0.5460947681581986,
            "f1_weighted": 0.5192691997422281
          },
          {
            "accuracy": 0.546875,
            "f1": 0.566242344080401,
            "f1_weighted": 0.5268838017915235
          },
          {
            "accuracy": 0.50244140625,
            "f1": 0.5240885029051104,
            "f1_weighted": 0.5011104576735864
          },
          {
            "accuracy": 0.54150390625,
            "f1": 0.5106478291828753,
            "f1_weighted": 0.5442642552164954
          },
          {
            "accuracy": 0.51953125,
            "f1": 0.5090302686533803,
            "f1_weighted": 0.5326709634554164
          },
          {
            "accuracy": 0.50732421875,
            "f1": 0.5084504732704754,
            "f1_weighted": 0.5041429545227003
          },
          {
            "accuracy": 0.4736328125,
            "f1": 0.48813661285002413,
            "f1_weighted": 0.4775937851709377
          }
        ]
      }
    ]
  },
  "task_name": "KLUE-TC"
}