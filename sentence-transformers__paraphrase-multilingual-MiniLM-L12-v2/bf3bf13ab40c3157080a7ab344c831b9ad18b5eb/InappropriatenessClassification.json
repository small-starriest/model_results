{
  "dataset_revision": "601651fdc45ef243751676e62dd7a19f491c0285",
  "evaluation_time": 10.694971323013306,
  "kg_co2_emissions": 0.0015815526425240597,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.5818359375,
        "ap": 0.5500393739377205,
        "ap_weighted": 0.5500393739377205,
        "f1": 0.5770142346869944,
        "f1_weighted": 0.5770142346869944,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.5818359375,
        "scores_per_experiment": [
          {
            "accuracy": 0.59912109375,
            "ap": 0.5593188310802619,
            "ap_weighted": 0.5593188310802619,
            "f1": 0.5991164104233052,
            "f1_weighted": 0.5991164104233052
          },
          {
            "accuracy": 0.59130859375,
            "ap": 0.5547076940283668,
            "ap_weighted": 0.5547076940283668,
            "f1": 0.5906682907714251,
            "f1_weighted": 0.5906682907714251
          },
          {
            "accuracy": 0.564453125,
            "ap": 0.5371161099137931,
            "ap_weighted": 0.5371161099137931,
            "f1": 0.5619763927772294,
            "f1_weighted": 0.5619763927772294
          },
          {
            "accuracy": 0.6044921875,
            "ap": 0.562579424676525,
            "ap_weighted": 0.562579424676525,
            "f1": 0.6041747197526093,
            "f1_weighted": 0.6041747197526093
          },
          {
            "accuracy": 0.6220703125,
            "ap": 0.5776932229121179,
            "ap_weighted": 0.5776932229121179,
            "f1": 0.6210163915613105,
            "f1_weighted": 0.6210163915613105
          },
          {
            "accuracy": 0.4775390625,
            "ap": 0.4894218059501263,
            "ap_weighted": 0.4894218059501263,
            "f1": 0.4707473529639076,
            "f1_weighted": 0.4707473529639076
          },
          {
            "accuracy": 0.61279296875,
            "ap": 0.5702115298581654,
            "ap_weighted": 0.5702115298581654,
            "f1": 0.6121863256651614,
            "f1_weighted": 0.6121863256651614
          },
          {
            "accuracy": 0.56494140625,
            "ap": 0.5356959484690067,
            "ap_weighted": 0.5356959484690067,
            "f1": 0.5543998052296427,
            "f1_weighted": 0.5543998052296427
          },
          {
            "accuracy": 0.56982421875,
            "ap": 0.5441062744590239,
            "ap_weighted": 0.5441062744590239,
            "f1": 0.5447100803619936,
            "f1_weighted": 0.5447100803619936
          },
          {
            "accuracy": 0.61181640625,
            "ap": 0.569542898029819,
            "ap_weighted": 0.569542898029819,
            "f1": 0.61114657736336,
            "f1_weighted": 0.61114657736336
          }
        ]
      }
    ]
  },
  "task_name": "InappropriatenessClassification"
}