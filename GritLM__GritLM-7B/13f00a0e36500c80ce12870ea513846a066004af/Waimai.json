{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 32.87251830101013,
  "kg_co2_emissions": 0.0069761017274119095,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8791,
        "ap": 0.7241736376518259,
        "ap_weighted": 0.7241736376518259,
        "f1": 0.8642600488622776,
        "f1_weighted": 0.879920977270317,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8791,
        "scores_per_experiment": [
          {
            "accuracy": 0.882,
            "ap": 0.7284601769911505,
            "ap_weighted": 0.7284601769911505,
            "f1": 0.8669829016665465,
            "f1_weighted": 0.8826257124305606
          },
          {
            "accuracy": 0.888,
            "ap": 0.7408459200374095,
            "ap_weighted": 0.7408459200374095,
            "f1": 0.8727683338558919,
            "f1_weighted": 0.8881760886259433
          },
          {
            "accuracy": 0.882,
            "ap": 0.7284601769911505,
            "ap_weighted": 0.7284601769911505,
            "f1": 0.8669829016665465,
            "f1_weighted": 0.8826257124305606
          },
          {
            "accuracy": 0.868,
            "ap": 0.7021938883034774,
            "ap_weighted": 0.7021938883034774,
            "f1": 0.8539661466976436,
            "f1_weighted": 0.8698108197809492
          },
          {
            "accuracy": 0.848,
            "ap": 0.6700276232495684,
            "ap_weighted": 0.6700276232495684,
            "f1": 0.835662173324511,
            "f1_weighted": 0.8514221709026903
          },
          {
            "accuracy": 0.886,
            "ap": 0.738322726133801,
            "ap_weighted": 0.738322726133801,
            "f1": 0.8681434599156118,
            "f1_weighted": 0.885126582278481
          },
          {
            "accuracy": 0.889,
            "ap": 0.7427228915662651,
            "ap_weighted": 0.7427228915662651,
            "f1": 0.8741997232393911,
            "f1_weighted": 0.8893020464645022
          },
          {
            "accuracy": 0.873,
            "ap": 0.7111121251629727,
            "ap_weighted": 0.7111121251629727,
            "f1": 0.8584104736113913,
            "f1_weighted": 0.8743180569011515
          },
          {
            "accuracy": 0.885,
            "ap": 0.7342743441529569,
            "ap_weighted": 0.7342743441529569,
            "f1": 0.8710413912278989,
            "f1_weighted": 0.8858909750280063
          },
          {
            "accuracy": 0.89,
            "ap": 0.745316503929507,
            "ap_weighted": 0.745316503929507,
            "f1": 0.8744429834173424,
            "f1_weighted": 0.8899116078603259
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}