{
    "mteb_version": "0.0.2",
    "test": {
        "de": {
            "accuracy": 0.5978586723768737,
            "accuracy_stderr": 0.02490852819071997,
            "ap": 0.7509654045453356,
            "ap_stderr": 0.015620234689242401,
            "f1": 0.5801774075538704,
            "f1_stderr": 0.024162643177907967,
            "main_score": 0.5978586723768737
        },
        "en": {
            "accuracy": 0.6859701492537313,
            "accuracy_stderr": 0.045059797896798606,
            "ap": 0.30665673427831475,
            "ap_stderr": 0.03453961938189895,
            "f1": 0.6222719107093839,
            "f1_stderr": 0.040614141932149954,
            "main_score": 0.6859701492537313
        },
        "en-ext": {
            "accuracy": 0.690254872563718,
            "accuracy_stderr": 0.043790945110999464,
            "ap": 0.18838761073733304,
            "ap_stderr": 0.021001449696363604,
            "f1": 0.5663347454922097,
            "f1_stderr": 0.033253659054603306,
            "main_score": 0.690254872563718
        },
        "evaluation_time": 76.26,
        "ja": {
            "accuracy": 0.5058886509635975,
            "accuracy_stderr": 0.18292080501926233,
            "ap": 0.10441180926434628,
            "ap_stderr": 0.001690777556582401,
            "f1": 0.39215691522261775,
            "f1_stderr": 0.08922754020348223,
            "main_score": 0.5058886509635975
        }
    },
    "mteb_dataset_name": "AmazonCounterfactualClassification",
    "dataset_revision": "2d8a100785abf0ae21420d2a55b0c56e3e1ea996"
}