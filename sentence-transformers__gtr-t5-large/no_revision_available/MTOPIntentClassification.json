{
    "mteb_version": "0.0.2",
    "test": {
        "de": {
            "accuracy": 0.521301775147929,
            "accuracy_stderr": 0.026385860641426444,
            "f1": 0.33683938152804044,
            "f1_stderr": 0.010468157182074101,
            "main_score": 0.521301775147929
        },
        "en": {
            "accuracy": 0.6385544915640675,
            "accuracy_stderr": 0.024024787831657828,
            "f1": 0.4603224451374964,
            "f1_stderr": 0.007279779596183846,
            "main_score": 0.6385544915640675
        },
        "es": {
            "accuracy": 0.5261507671781188,
            "accuracy_stderr": 0.026303230794297704,
            "f1": 0.3276941381331557,
            "f1_stderr": 0.010447145824133147,
            "main_score": 0.5261507671781188
        },
        "evaluation_time": 118.44,
        "fr": {
            "accuracy": 0.4638897588474789,
            "accuracy_stderr": 0.039463757449964824,
            "f1": 0.3250642178658937,
            "f1_stderr": 0.01840006739658037,
            "main_score": 0.4638897588474789
        },
        "hi": {
            "accuracy": 0.03897454284689853,
            "accuracy_stderr": 0.015291326181332552,
            "f1": 0.010984910428927849,
            "f1_stderr": 0.0027660036950762587,
            "main_score": 0.03897454284689853
        },
        "th": {
            "accuracy": 0.05381555153707053,
            "accuracy_stderr": 0.01827944132107286,
            "f1": 0.015076390320879984,
            "f1_stderr": 0.005690802011236354,
            "main_score": 0.05381555153707053
        }
    },
    "mteb_dataset_name": "MTOPIntentClassification",
    "dataset_revision": "6299947a7777084cc2d4b64235bf7190381ce755"
}