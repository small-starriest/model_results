{
  "dataset_revision": "46958b007a63fdbf239b7672c25d0bea67b5ea1a",
  "evaluation_time": 56.197465658187866,
  "kg_co2_emissions": 0.017571345767281116,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.7463666666666666,
        "f1": 0.7374687535653383,
        "f1_weighted": 0.7374687535653383,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.7463666666666666,
        "scores_per_experiment": [
          {
            "accuracy": 0.732,
            "f1": 0.7209286535218182,
            "f1_weighted": 0.7209286535218182
          },
          {
            "accuracy": 0.731,
            "f1": 0.716169907346992,
            "f1_weighted": 0.716169907346992
          },
          {
            "accuracy": 0.7536666666666667,
            "f1": 0.744057767267608,
            "f1_weighted": 0.7440577672676079
          },
          {
            "accuracy": 0.7433333333333333,
            "f1": 0.7349838668399554,
            "f1_weighted": 0.7349838668399554
          },
          {
            "accuracy": 0.756,
            "f1": 0.749848772553467,
            "f1_weighted": 0.749848772553467
          },
          {
            "accuracy": 0.739,
            "f1": 0.7301616633331429,
            "f1_weighted": 0.7301616633331429
          },
          {
            "accuracy": 0.746,
            "f1": 0.7396445114495799,
            "f1_weighted": 0.7396445114495799
          },
          {
            "accuracy": 0.7536666666666667,
            "f1": 0.7434482809164339,
            "f1_weighted": 0.7434482809164338
          },
          {
            "accuracy": 0.754,
            "f1": 0.7446779819031338,
            "f1_weighted": 0.7446779819031338
          },
          {
            "accuracy": 0.755,
            "f1": 0.7507661305212515,
            "f1_weighted": 0.7507661305212514
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7346666666666666,
        "f1": 0.7250602353020528,
        "f1_weighted": 0.7250602353020528,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.7346666666666666,
        "scores_per_experiment": [
          {
            "accuracy": 0.716,
            "f1": 0.7030300391654153,
            "f1_weighted": 0.7030300391654152
          },
          {
            "accuracy": 0.7206666666666667,
            "f1": 0.7041704172204007,
            "f1_weighted": 0.7041704172204007
          },
          {
            "accuracy": 0.7443333333333333,
            "f1": 0.7345480116056607,
            "f1_weighted": 0.7345480116056607
          },
          {
            "accuracy": 0.7353333333333333,
            "f1": 0.7265454620517997,
            "f1_weighted": 0.7265454620517997
          },
          {
            "accuracy": 0.743,
            "f1": 0.7362781259933296,
            "f1_weighted": 0.7362781259933296
          },
          {
            "accuracy": 0.726,
            "f1": 0.7164348183722581,
            "f1_weighted": 0.716434818372258
          },
          {
            "accuracy": 0.7323333333333333,
            "f1": 0.7255824293472871,
            "f1_weighted": 0.725582429347287
          },
          {
            "accuracy": 0.7396666666666667,
            "f1": 0.7285111465723131,
            "f1_weighted": 0.7285111465723132
          },
          {
            "accuracy": 0.7453333333333333,
            "f1": 0.7355949034232755,
            "f1_weighted": 0.7355949034232754
          },
          {
            "accuracy": 0.744,
            "f1": 0.739906999268788,
            "f1_weighted": 0.7399069992687879
          }
        ]
      }
    ]
  },
  "task_name": "MultilingualSentiment"
}