{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 76.15872955322266,
  "kg_co2_emissions": 0.014729541813100074,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9052894211576847,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9052894211576847,
        "precision": 0.896912524158033,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.2940785096473719,
        "f1": 0.24190565477990628,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.24190565477990628,
        "precision": 0.22390008343102152,
        "recall": 0.2940785096473719
      },
      {
        "accuracy": 0.7930805056553559,
        "f1": 0.7524649114469474,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.7524649114469474,
        "precision": 0.7356905237144759,
        "recall": 0.7930805056553559
      },
      {
        "accuracy": 0.9414504324683965,
        "f1": 0.9262712669898299,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9262712669898299,
        "precision": 0.9196606786427146,
        "recall": 0.9414504324683965
      },
      {
        "accuracy": 0.7005988023952096,
        "f1": 0.653402190328338,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.653402190328338,
        "precision": 0.6344029113490192,
        "recall": 0.7005988023952096
      },
      {
        "accuracy": 0.9068529607451763,
        "f1": 0.8886005766245288,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8886005766245288,
        "precision": 0.8808161454868042,
        "recall": 0.9068529607451763
      },
      {
        "accuracy": 0.9194943446440452,
        "f1": 0.9024395653138169,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9024395653138169,
        "precision": 0.8947327567088046,
        "recall": 0.9194943446440452
      },
      {
        "accuracy": 0.8190286094477711,
        "f1": 0.7850901371859456,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.7850901371859456,
        "precision": 0.7712463960966955,
        "recall": 0.8190286094477711
      },
      {
        "accuracy": 0.6959414504324684,
        "f1": 0.6464256671841502,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.6464256671841502,
        "precision": 0.6255378132623642,
        "recall": 0.6959414504324684
      },
      {
        "accuracy": 0.8995342648037259,
        "f1": 0.8798529924278428,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8798529924278428,
        "precision": 0.8712574850299402,
        "recall": 0.8995342648037259
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8632005829610621,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8632005829610621,
        "precision": 0.8526835218451986,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.8986027944111776,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.8986027944111776,
        "precision": 0.8901308494122866,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.010124559884729599,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.010124559884729599,
        "precision": 0.00805257427824705,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.902084719449989,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.902084719449989,
        "precision": 0.8948990907074739,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.908528973798435,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.908528973798435,
        "precision": 0.9013639387890885,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.895542248835662,
        "f1": 0.8729778538161772,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8729778538161772,
        "precision": 0.8633510756265248,
        "recall": 0.895542248835662
      },
      {
        "accuracy": 0.8356620093147039,
        "f1": 0.8048844110720359,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.8048844110720359,
        "precision": 0.7919291047534561,
        "recall": 0.8356620093147039
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.008574421118153774,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.008574421118153774,
        "precision": 0.006800518182961443,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.6613439787092482,
        "f1": 0.6109843804454583,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.6109843804454583,
        "precision": 0.5899090707473941,
        "recall": 0.6613439787092482
      },
      {
        "accuracy": 0.8263473053892215,
        "f1": 0.7935711069443604,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.7935711069443604,
        "precision": 0.7792470614326902,
        "recall": 0.8263473053892215
      },
      {
        "accuracy": 0.8922155688622755,
        "f1": 0.8711370908975699,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8711370908975699,
        "precision": 0.8616655577733423,
        "recall": 0.8922155688622755
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9083277888667111,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9083277888667111,
        "precision": 0.9006494946614708,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8934797072521624,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.8934797072521624,
        "precision": 0.8865380350410291,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.2954091816367265,
        "f1": 0.2405978129472318,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.2405978129472318,
        "precision": 0.22203840275197562,
        "recall": 0.2954091816367265
      },
      {
        "accuracy": 0.8176979374584165,
        "f1": 0.7806028155329553,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.7806028155329553,
        "precision": 0.7655041768315223,
        "recall": 0.8176979374584165
      },
      {
        "accuracy": 0.9654025282767797,
        "f1": 0.9568418718119316,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9568418718119316,
        "precision": 0.9531159902417388,
        "recall": 0.9654025282767797
      },
      {
        "accuracy": 0.7278775781769794,
        "f1": 0.6840635375565516,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.6840635375565516,
        "precision": 0.666573994867408,
        "recall": 0.7278775781769794
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9258483033932136,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9258483033932136,
        "precision": 0.9209422424991287,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.9607451763140386,
        "f1": 0.9506098913284542,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9506098913284542,
        "precision": 0.9462408516300731,
        "recall": 0.9607451763140386
      },
      {
        "accuracy": 0.8682634730538922,
        "f1": 0.8402132243449609,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.8402132243449609,
        "precision": 0.8285936064379178,
        "recall": 0.8682634730538922
      },
      {
        "accuracy": 0.7278775781769794,
        "f1": 0.6824367138738396,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.6824367138738396,
        "precision": 0.6636029528245098,
        "recall": 0.7278775781769794
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9036941989037797,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9036941989037797,
        "precision": 0.8956974939010865,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.9328010645375915,
        "f1": 0.9181858505211798,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9181858505211798,
        "precision": 0.91158793524063,
        "recall": 0.9328010645375915
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9236637835440229,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9236637835440229,
        "precision": 0.9183189177201153,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.011821073697851885,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.011821073697851885,
        "precision": 0.009076683516246808,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9281437125748503,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9281437125748503,
        "precision": 0.9226768684852517,
        "recall": 0.9407850964737192
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.9356176535817254,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9356176535817254,
        "precision": 0.9293080505655356,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9043278522320438,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9043278522320438,
        "precision": 0.8964293634952318,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.8522954091816367,
        "f1": 0.8242383438990225,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.8242383438990225,
        "precision": 0.8130635554288249,
        "recall": 0.8522954091816367
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.006539295386630842,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.006539295386630842,
        "precision": 0.004768749084225288,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.7059214903526281,
        "f1": 0.6587613133521317,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.6587613133521317,
        "precision": 0.639664058127132,
        "recall": 0.7059214903526281
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8605804264486898,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8605804264486898,
        "precision": 0.8504842167516818,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9052339764914615,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9052339764914615,
        "precision": 0.8969948990907075,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.9560878243512974,
        "f1": 0.9461964958970946,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9461964958970946,
        "precision": 0.9417831004657352,
        "recall": 0.9560878243512974
      },
      {
        "accuracy": 0.2634730538922156,
        "f1": 0.2189289960621648,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.2189289960621648,
        "precision": 0.20695686828295892,
        "recall": 0.2634730538922156
      },
      {
        "accuracy": 0.2801064537591484,
        "f1": 0.23060703550801787,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.23060703550801787,
        "precision": 0.21719511059390123,
        "recall": 0.2801064537591484
      },
      {
        "accuracy": 0.29607451763140386,
        "f1": 0.257702337767208,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.257702337767208,
        "precision": 0.24516845340681542,
        "recall": 0.29607451763140386
      },
      {
        "accuracy": 0.3100465735196274,
        "f1": 0.25982590108875353,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.25982590108875353,
        "precision": 0.2450350680881724,
        "recall": 0.3100465735196274
      },
      {
        "accuracy": 0.25681969394544246,
        "f1": 0.22186520657578543,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.22186520657578543,
        "precision": 0.2107605997297203,
        "recall": 0.25681969394544246
      },
      {
        "accuracy": 0.26813040585495673,
        "f1": 0.22418397932369982,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.22418397932369982,
        "precision": 0.2112206028483668,
        "recall": 0.26813040585495673
      },
      {
        "accuracy": 0.3147039254823686,
        "f1": 0.2651167233765053,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2651167233765053,
        "precision": 0.2506264679861859,
        "recall": 0.3147039254823686
      },
      {
        "accuracy": 0.25815036593479707,
        "f1": 0.22019541838366213,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.22019541838366213,
        "precision": 0.2087059429703928,
        "recall": 0.25815036593479707
      },
      {
        "accuracy": 0.23020625415834997,
        "f1": 0.1888934429811396,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1888934429811396,
        "precision": 0.17620131355537902,
        "recall": 0.23020625415834997
      },
      {
        "accuracy": 0.25815036593479707,
        "f1": 0.2122866568082168,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2122866568082168,
        "precision": 0.19930904457961152,
        "recall": 0.25815036593479707
      },
      {
        "accuracy": 0.26413838988689287,
        "f1": 0.21629821847668484,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.21629821847668484,
        "precision": 0.2029583691315747,
        "recall": 0.26413838988689287
      },
      {
        "accuracy": 0.2634730538922156,
        "f1": 0.22069102574056157,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.22069102574056157,
        "precision": 0.20787285228081595,
        "recall": 0.2634730538922156
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.009231473163696437,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009231473163696437,
        "precision": 0.0073930212709812535,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.2834331337325349,
        "f1": 0.2361031275328069,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2361031275328069,
        "precision": 0.22242783558494242,
        "recall": 0.2834331337325349
      },
      {
        "accuracy": 0.26147704590818366,
        "f1": 0.2170411168760818,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2170411168760818,
        "precision": 0.20451357622043687,
        "recall": 0.26147704590818366
      },
      {
        "accuracy": 0.2694610778443114,
        "f1": 0.2232093764406185,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2232093764406185,
        "precision": 0.21085817810283664,
        "recall": 0.2694610778443114
      },
      {
        "accuracy": 0.24218230206254157,
        "f1": 0.20120763991780474,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.20120763991780474,
        "precision": 0.19018128475918777,
        "recall": 0.24218230206254157
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.007413610203010481,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007413610203010481,
        "precision": 0.00616986859946233,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.2874251497005988,
        "f1": 0.24998868516539058,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.24998868516539058,
        "precision": 0.23727721561521523,
        "recall": 0.2874251497005988
      },
      {
        "accuracy": 0.25748502994011974,
        "f1": 0.2095737947547159,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.2095737947547159,
        "precision": 0.19514878154795232,
        "recall": 0.25748502994011974
      },
      {
        "accuracy": 0.26147704590818366,
        "f1": 0.21669114690132807,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.21669114690132807,
        "precision": 0.20414323247480462,
        "recall": 0.26147704590818366
      },
      {
        "accuracy": 0.2801064537591484,
        "f1": 0.23285429342638456,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.23285429342638456,
        "precision": 0.21977314952213814,
        "recall": 0.2801064537591484
      },
      {
        "accuracy": 0.7777777777777778,
        "f1": 0.7349111301207109,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7349111301207109,
        "precision": 0.7166666666666667,
        "recall": 0.7777777777777778
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8005988023952095,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8005988023952095,
        "precision": 0.7843313373253492,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.3087159015302728,
        "f1": 0.2556008861398083,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2556008861398083,
        "precision": 0.2369443652377784,
        "recall": 0.3087159015302728
      },
      {
        "accuracy": 0.8715901530272788,
        "f1": 0.8414646896682825,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8414646896682825,
        "precision": 0.8286379621708962,
        "recall": 0.8715901530272788
      },
      {
        "accuracy": 0.6387225548902196,
        "f1": 0.5862835656248829,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5862835656248829,
        "precision": 0.5648960930398056,
        "recall": 0.6387225548902196
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.8028324303773405,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8028324303773405,
        "precision": 0.7900028226375531,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.867598137059215,
        "f1": 0.8362608117099136,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8362608117099136,
        "precision": 0.8222333111554668,
        "recall": 0.867598137059215
      },
      {
        "accuracy": 0.7325349301397206,
        "f1": 0.6896365998162406,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6896365998162406,
        "precision": 0.6721852591114068,
        "recall": 0.7325349301397206
      },
      {
        "accuracy": 0.6134397870924817,
        "f1": 0.5559727106633294,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5559727106633294,
        "precision": 0.5327490521602298,
        "recall": 0.6134397870924817
      },
      {
        "accuracy": 0.8243512974051896,
        "f1": 0.7868586060202826,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7868586060202826,
        "precision": 0.7703592814371257,
        "recall": 0.8243512974051896
      },
      {
        "accuracy": 0.7897538256819694,
        "f1": 0.7442897754275,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7442897754275,
        "precision": 0.7246396096695497,
        "recall": 0.7897538256819694
      },
      {
        "accuracy": 0.8276779773785762,
        "f1": 0.7891011627538573,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7891011627538573,
        "precision": 0.7722776668884452,
        "recall": 0.8276779773785762
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.00812287005859344,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00812287005859344,
        "precision": 0.006332611347096729,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.8243512974051896,
        "f1": 0.7892659126192062,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7892659126192062,
        "precision": 0.7742182302062542,
        "recall": 0.8243512974051896
      },
      {
        "accuracy": 0.8349966733200266,
        "f1": 0.7980372588157018,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7980372588157018,
        "precision": 0.781842663878592,
        "recall": 0.8349966733200266
      },
      {
        "accuracy": 0.8263473053892215,
        "f1": 0.7908104426068497,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7908104426068497,
        "precision": 0.7753667268637329,
        "recall": 0.8263473053892215
      },
      {
        "accuracy": 0.7019294743845642,
        "f1": 0.6481529005481101,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.6481529005481101,
        "precision": 0.6259211735259639,
        "recall": 0.7019294743845642
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.00988793885639252,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00988793885639252,
        "precision": 0.007616793486680111,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.6846307385229541,
        "f1": 0.634539386834796,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.634539386834796,
        "precision": 0.6140900738206128,
        "recall": 0.6846307385229541
      },
      {
        "accuracy": 0.7238855622089155,
        "f1": 0.6744537860306323,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.6744537860306323,
        "precision": 0.6543983461648132,
        "recall": 0.7238855622089155
      },
      {
        "accuracy": 0.7771124417831005,
        "f1": 0.7331448214681748,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7331448214681748,
        "precision": 0.7144441276177803,
        "recall": 0.7771124417831005
      },
      {
        "accuracy": 0.852960745176314,
        "f1": 0.8185554816293339,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8185554816293339,
        "precision": 0.8034320248392105,
        "recall": 0.852960745176314
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9095047999239616,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9095047999239616,
        "precision": 0.9027907148665631,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.9647371922821024,
        "f1": 0.9564426702151253,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9564426702151253,
        "precision": 0.9528165890441339,
        "recall": 0.9647371922821024
      },
      {
        "accuracy": 0.3153692614770459,
        "f1": 0.25055217070598074,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.25055217070598074,
        "precision": 0.22757430803837989,
        "recall": 0.3153692614770459
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8245403853188283,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.8245403853188283,
        "precision": 0.810640623514875,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.7491683300066534,
        "f1": 0.7078056009193733,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.7078056009193733,
        "precision": 0.6919752680231721,
        "recall": 0.7491683300066534
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.941139942337547,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.941139942337547,
        "precision": 0.9371368374362387,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.9713905522288756,
        "f1": 0.9639831448214683,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9639831448214683,
        "precision": 0.9608006209802616,
        "recall": 0.9713905522288756
      },
      {
        "accuracy": 0.8922155688622755,
        "f1": 0.8676240112367856,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.8676240112367856,
        "precision": 0.8572862212083768,
        "recall": 0.8922155688622755
      },
      {
        "accuracy": 0.7544910179640718,
        "f1": 0.7075531476729081,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.7075531476729081,
        "precision": 0.6882251370275323,
        "recall": 0.7544910179640718
      },
      {
        "accuracy": 0.9427811044577512,
        "f1": 0.9284985584386782,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9284985584386782,
        "precision": 0.9222554890219562,
        "recall": 0.9427811044577512
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9379463295630959,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9379463295630959,
        "precision": 0.9325681969394545,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.9607451763140386,
        "f1": 0.9509869150587713,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9509869150587713,
        "precision": 0.946717675759592,
        "recall": 0.9607451763140386
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.010079948957937054,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.010079948957937054,
        "precision": 0.008451692456476093,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.959414504324684,
        "f1": 0.9485695276114436,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9485695276114436,
        "precision": 0.9439454424484365,
        "recall": 0.959414504324684
      },
      {
        "accuracy": 0.9640718562874252,
        "f1": 0.9549789310268352,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9549789310268352,
        "precision": 0.9510423597249945,
        "recall": 0.9640718562874252
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9240629851408294,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9240629851408294,
        "precision": 0.9169993346640053,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.8715901530272788,
        "f1": 0.8419584112198883,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.8419584112198883,
        "precision": 0.8295963628298957,
        "recall": 0.8715901530272788
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.005038337403688796,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.005038337403688796,
        "precision": 0.003925251672023923,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.7198935462408517,
        "f1": 0.6714396603618161,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.6714396603618161,
        "precision": 0.6520786709409463,
        "recall": 0.7198935462408517
      },
      {
        "accuracy": 0.9021956087824351,
        "f1": 0.883174391956827,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.883174391956827,
        "precision": 0.874661787536039,
        "recall": 0.9021956087824351
      },
      {
        "accuracy": 0.9441117764471058,
        "f1": 0.9313721762823558,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9313721762823558,
        "precision": 0.9260035484586383,
        "recall": 0.9441117764471058
      },
      {
        "accuracy": 0.9767132401862941,
        "f1": 0.9706586826347307,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9706586826347307,
        "precision": 0.968119316921712,
        "recall": 0.9767132401862941
      },
      {
        "accuracy": 0.6879574184963406,
        "f1": 0.6417245835409509,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6417245835409509,
        "precision": 0.6239616246103272,
        "recall": 0.6879574184963406
      },
      {
        "accuracy": 0.7305389221556886,
        "f1": 0.6815369741517446,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6815369741517446,
        "precision": 0.6623636325233131,
        "recall": 0.7305389221556886
      },
      {
        "accuracy": 0.2801064537591484,
        "f1": 0.23072594589560655,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23072594589560655,
        "precision": 0.21336374869309,
        "recall": 0.2801064537591484
      },
      {
        "accuracy": 0.6453759148369926,
        "f1": 0.5957224079978571,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5957224079978571,
        "precision": 0.5754960977515867,
        "recall": 0.6453759148369926
      },
      {
        "accuracy": 0.7631403858948769,
        "f1": 0.7171023033298484,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7171023033298484,
        "precision": 0.697939042549821,
        "recall": 0.7631403858948769
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6933149573868136,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6933149573868136,
        "precision": 0.6769872952507684,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.7498336660013307,
        "f1": 0.7075599310130248,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7075599310130248,
        "precision": 0.6914702175181217,
        "recall": 0.7498336660013307
      },
      {
        "accuracy": 0.6620093147039254,
        "f1": 0.6158819926284996,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6158819926284996,
        "precision": 0.5978994392168044,
        "recall": 0.6620093147039254
      },
      {
        "accuracy": 0.5375914836992681,
        "f1": 0.48274778005316926,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.48274778005316926,
        "precision": 0.4612726927098185,
        "recall": 0.5375914836992681
      },
      {
        "accuracy": 0.7145708582834331,
        "f1": 0.6679413659453579,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6679413659453579,
        "precision": 0.6490621930741692,
        "recall": 0.7145708582834331
      },
      {
        "accuracy": 0.7032601463739189,
        "f1": 0.6521618139382611,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6521618139382611,
        "precision": 0.6316430630801888,
        "recall": 0.7032601463739189
      },
      {
        "accuracy": 0.7717897538256819,
        "f1": 0.7267148243196148,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7267148243196148,
        "precision": 0.7086797544881377,
        "recall": 0.7717897538256819
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.011982973651069265,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.011982973651069265,
        "precision": 0.009853782628093022,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.7285429141716567,
        "f1": 0.6833835455591942,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6833835455591942,
        "precision": 0.6651926306117922,
        "recall": 0.7285429141716567
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.6765173356989724,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6765173356989724,
        "precision": 0.6582865847835908,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.697272122421823,
        "f1": 0.6486545907703593,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6486545907703593,
        "precision": 0.630095916872364,
        "recall": 0.697272122421823
      },
      {
        "accuracy": 0.6287425149700598,
        "f1": 0.5758082200197968,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.5758082200197968,
        "precision": 0.5560498051516016,
        "recall": 0.6287425149700598
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.006771426666150346,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006771426666150346,
        "precision": 0.004961758189242662,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.5988023952095808,
        "f1": 0.5509504799923961,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5509504799923961,
        "precision": 0.5316430630801888,
        "recall": 0.5988023952095808
      },
      {
        "accuracy": 0.614105123087159,
        "f1": 0.5596051763716435,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5596051763716435,
        "precision": 0.5381918702277985,
        "recall": 0.614105123087159
      },
      {
        "accuracy": 0.6946107784431138,
        "f1": 0.6435399043183474,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6435399043183474,
        "precision": 0.6238713050090297,
        "recall": 0.6946107784431138
      },
      {
        "accuracy": 0.716566866267465,
        "f1": 0.666128028104076,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.666128028104076,
        "precision": 0.6457643155247946,
        "recall": 0.716566866267465
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8942020720463834,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8942020720463834,
        "precision": 0.8852849855843867,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.9441117764471058,
        "f1": 0.9296961632290974,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.9296961632290974,
        "precision": 0.9229540918163671,
        "recall": 0.9441117764471058
      },
      {
        "accuracy": 0.3226879574184963,
        "f1": 0.26685359439850453,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.26685359439850453,
        "precision": 0.24693785367438062,
        "recall": 0.3226879574184963
      },
      {
        "accuracy": 0.8310046573519627,
        "f1": 0.7944666223109337,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.7944666223109337,
        "precision": 0.7785492507049393,
        "recall": 0.8310046573519627
      },
      {
        "accuracy": 0.9600798403193613,
        "f1": 0.9506542470614326,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9506542470614326,
        "precision": 0.9462408516300731,
        "recall": 0.9600798403193613
      },
      {
        "accuracy": 0.7571523619427811,
        "f1": 0.7092835973075493,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.7092835973075493,
        "precision": 0.6894396392400385,
        "recall": 0.7571523619427811
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9406425244748597,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9406425244748597,
        "precision": 0.9352406298514083,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.8695941450432468,
        "f1": 0.8417978857100614,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.8417978857100614,
        "precision": 0.8295242847638058,
        "recall": 0.8695941450432468
      },
      {
        "accuracy": 0.7345309381237525,
        "f1": 0.6847653898552101,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.6847653898552101,
        "precision": 0.6634793904254982,
        "recall": 0.7345309381237525
      },
      {
        "accuracy": 0.9374584165003327,
        "f1": 0.9235307163450875,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.9235307163450875,
        "precision": 0.91715457972943,
        "recall": 0.9374584165003327
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9140385894876912,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.9140385894876912,
        "precision": 0.9067642492792194,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9372366378354401,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9372366378354401,
        "precision": 0.9321579064094034,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.007166327264565016,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.007166327264565016,
        "precision": 0.005171330122934747,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9295187402971834,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9295187402971834,
        "precision": 0.9231204258150366,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9302284320248392,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.9302284320248392,
        "precision": 0.9242847638057219,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.9268130405854956,
        "f1": 0.908183632734531,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.908183632734531,
        "precision": 0.9000332667997338,
        "recall": 0.9268130405854956
      },
      {
        "accuracy": 0.8449767132401863,
        "f1": 0.810235085384786,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.810235085384786,
        "precision": 0.7951937395051165,
        "recall": 0.8449767132401863
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.009019168798995144,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.009019168798995144,
        "precision": 0.0074833840515343,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.7478376580172987,
        "f1": 0.7049731225379928,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.7049731225379928,
        "precision": 0.6873789458120795,
        "recall": 0.7478376580172987
      },
      {
        "accuracy": 0.8642714570858283,
        "f1": 0.8361995585548481,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.8361995585548481,
        "precision": 0.8237913062763362,
        "recall": 0.8642714570858283
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.894736453019886,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.894736453019886,
        "precision": 0.8852794411177644,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.9580838323353293,
        "f1": 0.948769128409847,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.948769128409847,
        "precision": 0.9443335551119981,
        "recall": 0.9580838323353293
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8892880904856952,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8892880904856952,
        "precision": 0.8806387225548902,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.9567531603459747,
        "f1": 0.9460634286981593,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9460634286981593,
        "precision": 0.9412286538035042,
        "recall": 0.9567531603459747
      },
      {
        "accuracy": 0.3213572854291417,
        "f1": 0.26008038313427534,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.26008038313427534,
        "precision": 0.2378612737894175,
        "recall": 0.3213572854291417
      },
      {
        "accuracy": 0.8496340652029275,
        "f1": 0.8147884125928037,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8147884125928037,
        "precision": 0.7999390108671546,
        "recall": 0.8496340652029275
      },
      {
        "accuracy": 0.9667332002661344,
        "f1": 0.9585052117986249,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9585052117986249,
        "precision": 0.9550011088933246,
        "recall": 0.9667332002661344
      },
      {
        "accuracy": 0.7471723220226214,
        "f1": 0.7089461769102487,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7089461769102487,
        "precision": 0.6937663947643988,
        "recall": 0.7471723220226214
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9310521813515826,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9310521813515826,
        "precision": 0.9261920603237969,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8581683194457645,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8581683194457645,
        "precision": 0.8478542914171657,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.7511643379906853,
        "f1": 0.7030679381976787,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7030679381976787,
        "precision": 0.6828470044038906,
        "recall": 0.7511643379906853
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9162025156037134,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9162025156037134,
        "precision": 0.9095364825903748,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9134397870924817,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9134397870924817,
        "precision": 0.9064870259481037,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9367265469061877,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9367265469061877,
        "precision": 0.9317476158793525,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.010009481741740415,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.010009481741740415,
        "precision": 0.007666855739237973,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9263805721889553,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9263805721889553,
        "precision": 0.92060957450179,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.9346750942559325,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9346750942559325,
        "precision": 0.9292922092323289,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9116116972404397,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9116116972404397,
        "precision": 0.9042914171656687,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.8562874251497006,
        "f1": 0.8253841523302601,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.8253841523302601,
        "precision": 0.8116116972404398,
        "recall": 0.8562874251497006
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.0056913911860600915,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0056913911860600915,
        "precision": 0.0040963281460404686,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.7338656021290751,
        "f1": 0.6887003770237304,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6887003770237304,
        "precision": 0.6702228059513489,
        "recall": 0.7338656021290751
      },
      {
        "accuracy": 0.8915502328675982,
        "f1": 0.8702520884157611,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8702520884157611,
        "precision": 0.8606952761144377,
        "recall": 0.8915502328675982
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9093495548585369,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9093495548585369,
        "precision": 0.9023286759813707,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.9600798403193613,
        "f1": 0.950410290530051,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.950410290530051,
        "precision": 0.9462186737635838,
        "recall": 0.9600798403193613
      },
      {
        "accuracy": 0.8270126413838988,
        "f1": 0.7926290276589677,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7926290276589677,
        "precision": 0.7775290688464341,
        "recall": 0.8270126413838988
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8550343756930583,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.8550343756930583,
        "precision": 0.8434860437854449,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.29008649367930806,
        "f1": 0.23645196379727318,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.23645196379727318,
        "precision": 0.21901094396104373,
        "recall": 0.29008649367930806
      },
      {
        "accuracy": 0.7504990019960079,
        "f1": 0.7089661945949371,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.7089661945949371,
        "precision": 0.6910844976713241,
        "recall": 0.7504990019960079
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.8825713652060957,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.8825713652060957,
        "precision": 0.8729651807496118,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.6806387225548902,
        "f1": 0.6313278205493775,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.6313278205493775,
        "precision": 0.6105012197826568,
        "recall": 0.6806387225548902
      },
      {
        "accuracy": 0.8616101131071191,
        "f1": 0.8398995659474702,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.8398995659474702,
        "precision": 0.8307855189092712,
        "recall": 0.8616101131071191
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8660932104045874,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.8660932104045874,
        "precision": 0.855367043690397,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.6287425149700598,
        "f1": 0.5738348699426543,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.5738348699426543,
        "precision": 0.5507492950606724,
        "recall": 0.6287425149700598
      },
      {
        "accuracy": 0.8496340652029275,
        "f1": 0.8222127174222982,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.8222127174222982,
        "precision": 0.8103903304502107,
        "recall": 0.8496340652029275
      },
      {
        "accuracy": 0.8802395209580839,
        "f1": 0.8559896080854166,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.8559896080854166,
        "precision": 0.8454424484364604,
        "recall": 0.8802395209580839
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8534412656169142,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.8534412656169142,
        "precision": 0.842564870259481,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.008852158471341158,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.008852158471341158,
        "precision": 0.006546326967381541,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.8642714570858283,
        "f1": 0.8370259481037925,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.8370259481037925,
        "precision": 0.8256772169945822,
        "recall": 0.8642714570858283
      },
      {
        "accuracy": 0.8802395209580839,
        "f1": 0.854690618762475,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.854690618762475,
        "precision": 0.8436016855178532,
        "recall": 0.8802395209580839
      },
      {
        "accuracy": 0.8376580172987359,
        "f1": 0.8051822281363199,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.8051822281363199,
        "precision": 0.7909532786279293,
        "recall": 0.8376580172987359
      },
      {
        "accuracy": 0.7724550898203593,
        "f1": 0.7297405189620758,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.7297405189620758,
        "precision": 0.7112885340430251,
        "recall": 0.7724550898203593
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.005878508992806713,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.005878508992806713,
        "precision": 0.0044329614095022654,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.6447105788423154,
        "f1": 0.5963343154959921,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.5963343154959921,
        "precision": 0.5759924595253937,
        "recall": 0.6447105788423154
      },
      {
        "accuracy": 0.8409846972721224,
        "f1": 0.8076196812723759,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.8076196812723759,
        "precision": 0.7928587269904634,
        "recall": 0.8409846972721224
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8599245952539366,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.8599245952539366,
        "precision": 0.847682412951874,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.884896872920825,
        "f1": 0.8566422710135283,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.8566422710135283,
        "precision": 0.8444888001774229,
        "recall": 0.884896872920825
      },
      {
        "accuracy": 0.6906187624750499,
        "f1": 0.641998542597345,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.641998542597345,
        "precision": 0.6221926517335699,
        "recall": 0.6906187624750499
      },
      {
        "accuracy": 0.7258815701929474,
        "f1": 0.6787124164369672,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.6787124164369672,
        "precision": 0.6601109949413342,
        "recall": 0.7258815701929474
      },
      {
        "accuracy": 0.2528276779773786,
        "f1": 0.20367531974969272,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.20367531974969272,
        "precision": 0.18700101000500202,
        "recall": 0.2528276779773786
      },
      {
        "accuracy": 0.6081170991350632,
        "f1": 0.5618609342162236,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.5618609342162236,
        "precision": 0.5436262395843234,
        "recall": 0.6081170991350632
      },
      {
        "accuracy": 0.7498336660013307,
        "f1": 0.6981581809925125,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.6981581809925125,
        "precision": 0.6774839210467953,
        "recall": 0.7498336660013307
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.48265743644985165,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.48265743644985165,
        "precision": 0.46232596347073274,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.7105788423153693,
        "f1": 0.6669877176863204,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.6669877176863204,
        "precision": 0.6492932365187853,
        "recall": 0.7105788423153693
      },
      {
        "accuracy": 0.7312042581503659,
        "f1": 0.6859085248306805,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.6859085248306805,
        "precision": 0.6679931143004996,
        "recall": 0.7312042581503659
      },
      {
        "accuracy": 0.605455755156354,
        "f1": 0.5576650930942348,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.5576650930942348,
        "precision": 0.5396418802606427,
        "recall": 0.605455755156354
      },
      {
        "accuracy": 0.7212242182302062,
        "f1": 0.6759851149072706,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.6759851149072706,
        "precision": 0.6570095499237215,
        "recall": 0.7212242182302062
      },
      {
        "accuracy": 0.6753160345974717,
        "f1": 0.6273468935145582,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.6273468935145582,
        "precision": 0.6075689890061147,
        "recall": 0.6753160345974717
      },
      {
        "accuracy": 0.7152361942781105,
        "f1": 0.669462661977632,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.669462661977632,
        "precision": 0.6505510383753896,
        "recall": 0.7152361942781105
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.013312770738942286,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.013312770738942286,
        "precision": 0.011438487304092224,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.7272122421823021,
        "f1": 0.6842352332372292,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.6842352332372292,
        "precision": 0.666619406689267,
        "recall": 0.7272122421823021
      },
      {
        "accuracy": 0.7152361942781105,
        "f1": 0.6668689076872709,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.6668689076872709,
        "precision": 0.6476903336184774,
        "recall": 0.7152361942781105
      },
      {
        "accuracy": 0.7405189620758483,
        "f1": 0.6938192398272239,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.6938192398272239,
        "precision": 0.6747618519574606,
        "recall": 0.7405189620758483
      },
      {
        "accuracy": 0.605455755156354,
        "f1": 0.5424177286452736,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.5424177286452736,
        "precision": 0.5173689657721594,
        "recall": 0.605455755156354
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007604911350999736,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007604911350999736,
        "precision": 0.006114846041308932,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.543579507651364,
        "f1": 0.49188976544265967,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.49188976544265967,
        "precision": 0.4716020340271837,
        "recall": 0.543579507651364
      },
      {
        "accuracy": 0.6227544910179641,
        "f1": 0.5670685084856741,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.5670685084856741,
        "precision": 0.5446023297320702,
        "recall": 0.6227544910179641
      },
      {
        "accuracy": 0.6819693945442449,
        "f1": 0.6307068402876786,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.6307068402876786,
        "precision": 0.6098913284542027,
        "recall": 0.6819693945442449
      },
      {
        "accuracy": 0.7658017298735862,
        "f1": 0.7188892057155531,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.7188892057155531,
        "precision": 0.6993124861388335,
        "recall": 0.7658017298735862
      },
      {
        "accuracy": 0.8915502328675982,
        "f1": 0.8682191173209137,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8682191173209137,
        "precision": 0.8577511643379906,
        "recall": 0.8915502328675982
      },
      {
        "accuracy": 0.9334664005322688,
        "f1": 0.917099135063207,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.917099135063207,
        "precision": 0.9094810379241516,
        "recall": 0.9334664005322688
      },
      {
        "accuracy": 0.2867598137059215,
        "f1": 0.23600185391602557,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23600185391602557,
        "precision": 0.21864236894177014,
        "recall": 0.2867598137059215
      },
      {
        "accuracy": 0.8143712574850299,
        "f1": 0.7762860522341561,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7762860522341561,
        "precision": 0.7601693438519785,
        "recall": 0.8143712574850299
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.9338656021290751,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9338656021290751,
        "precision": 0.9282546019072966,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.7325349301397206,
        "f1": 0.6870918724212136,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6870918724212136,
        "precision": 0.668413965719355,
        "recall": 0.7325349301397206
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9080949212685739,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9080949212685739,
        "precision": 0.9007207806609004,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.9328010645375915,
        "f1": 0.917797737857618,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.917797737857618,
        "precision": 0.9109954693787028,
        "recall": 0.9328010645375915
      },
      {
        "accuracy": 0.8296739853626082,
        "f1": 0.794882193285387,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.794882193285387,
        "precision": 0.7798532564500629,
        "recall": 0.8296739853626082
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.677967873776257,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.677967873776257,
        "precision": 0.6589944689745089,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.9001996007984032,
        "f1": 0.8802965497576275,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8802965497576275,
        "precision": 0.8713683743623862,
        "recall": 0.9001996007984032
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9057440674207141,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9057440674207141,
        "precision": 0.898591705477933,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008582528350834876,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008582528350834876,
        "precision": 0.007031423587086201,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.9131292969616324,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9131292969616324,
        "precision": 0.9060767354180528,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.904359534898457,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.904359534898457,
        "precision": 0.8965846085606565,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8946012736431899,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8946012736431899,
        "precision": 0.8862497227766689,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.7999027585853933,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7999027585853933,
        "precision": 0.7848857839875805,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007609870951382275,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007609870951382275,
        "precision": 0.006320139823081808,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.7152361942781105,
        "f1": 0.6668726039983526,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6668726039983526,
        "precision": 0.647029750023762,
        "recall": 0.7152361942781105
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8071338803873734,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8071338803873734,
        "precision": 0.793651585717454,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.8875582168995343,
        "f1": 0.865182333745208,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.865182333745208,
        "precision": 0.855184868358521,
        "recall": 0.8875582168995343
      },
      {
        "accuracy": 0.9454424484364604,
        "f1": 0.9311503976174633,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9311503976174633,
        "precision": 0.9245398092703482,
        "recall": 0.9454424484364604
      },
      {
        "accuracy": 0.8842315369261478,
        "f1": 0.859937268320502,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.859937268320502,
        "precision": 0.8497634360907813,
        "recall": 0.8842315369261478
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9241643696733518,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9241643696733518,
        "precision": 0.9186626746506986,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.2934131736526946,
        "f1": 0.23957324925388795,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.23957324925388795,
        "precision": 0.22049239414215344,
        "recall": 0.2934131736526946
      },
      {
        "accuracy": 0.7884231536926147,
        "f1": 0.7470756898900612,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.7470756898900612,
        "precision": 0.7295822723808857,
        "recall": 0.7884231536926147
      },
      {
        "accuracy": 0.9567531603459747,
        "f1": 0.9472610334885784,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9472610334885784,
        "precision": 0.9432135728542915,
        "recall": 0.9567531603459747
      },
      {
        "accuracy": 0.7019294743845642,
        "f1": 0.6567827788386671,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.6567827788386671,
        "precision": 0.6386457244241676,
        "recall": 0.7019294743845642
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9089598580616545,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9089598580616545,
        "precision": 0.9032712353071636,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9174001203941323,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.9174001203941323,
        "precision": 0.911055666444888,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.8715901530272788,
        "f1": 0.8437178552947017,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.8437178552947017,
        "precision": 0.8318862275449103,
        "recall": 0.8715901530272788
      },
      {
        "accuracy": 0.6939454424484365,
        "f1": 0.6458041588780111,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.6458041588780111,
        "precision": 0.625662167728036,
        "recall": 0.6939454424484365
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8806735734879447,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.8806735734879447,
        "precision": 0.8715790640940342,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9092185998373624,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9092185998373624,
        "precision": 0.9016134397870925,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.007870823302514651,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.007870823302514651,
        "precision": 0.006266219328652815,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.9194943446440452,
        "f1": 0.9017399544345653,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.9017399544345653,
        "precision": 0.8938345531159902,
        "recall": 0.9194943446440452
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9121439660361814,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.9121439660361814,
        "precision": 0.9060323796850743,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.9041916167664671,
        "f1": 0.8823575072078067,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.8823575072078067,
        "precision": 0.873015873015873,
        "recall": 0.9041916167664671
      },
      {
        "accuracy": 0.8356620093147039,
        "f1": 0.8039920159680639,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.8039920159680639,
        "precision": 0.7905427240756582,
        "recall": 0.8356620093147039
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005457491773095858,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.005457491773095858,
        "precision": 0.0044900133538581105,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.6806387225548902,
        "f1": 0.632408727518508,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.632408727518508,
        "precision": 0.6132423224738593,
        "recall": 0.6806387225548902
      },
      {
        "accuracy": 0.8815701929474384,
        "f1": 0.8605930995152552,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.8605930995152552,
        "precision": 0.8510423597249945,
        "recall": 0.8815701929474384
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8900548110128949,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.8900548110128949,
        "precision": 0.8816145486804169,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.9414504324683965,
        "f1": 0.9273358045813135,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.9273358045813135,
        "precision": 0.920935905965846,
        "recall": 0.9414504324683965
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8867503089059975,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8867503089059975,
        "precision": 0.8775227323131514,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9351740962519407,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9351740962519407,
        "precision": 0.9291971612330894,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.28476380572188953,
        "f1": 0.23477807769224934,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23477807769224934,
        "precision": 0.21769452917157509,
        "recall": 0.28476380572188953
      },
      {
        "accuracy": 0.823020625415835,
        "f1": 0.7846782625225739,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7846782625225739,
        "precision": 0.7683632734530937,
        "recall": 0.823020625415835
      },
      {
        "accuracy": 0.9660678642714571,
        "f1": 0.956974939010867,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.956974939010867,
        "precision": 0.9527833222444001,
        "recall": 0.9660678642714571
      },
      {
        "accuracy": 0.7697937458416501,
        "f1": 0.7274256201401911,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7274256201401911,
        "precision": 0.7098662463432922,
        "recall": 0.7697937458416501
      },
      {
        "accuracy": 0.93812375249501,
        "f1": 0.9269017520514525,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9269017520514525,
        "precision": 0.9218230206254159,
        "recall": 0.93812375249501
      },
      {
        "accuracy": 0.9534264803725881,
        "f1": 0.9429363495231758,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9429363495231758,
        "precision": 0.9381791971612332,
        "recall": 0.9534264803725881
      },
      {
        "accuracy": 0.8642714570858283,
        "f1": 0.8343867819915725,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8343867819915725,
        "precision": 0.8215299559610936,
        "recall": 0.8642714570858283
      },
      {
        "accuracy": 0.7212242182302062,
        "f1": 0.6754871209961031,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6754871209961031,
        "precision": 0.6563349491493204,
        "recall": 0.7212242182302062
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9090929252605898,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9090929252605898,
        "precision": 0.9014748281215346,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9149257041472609,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9149257041472609,
        "precision": 0.9078731426036815,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.01100333319889306,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01100333319889306,
        "precision": 0.008969673329100255,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9165890441339543,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9165890441339543,
        "precision": 0.9099578620536705,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.9434464404524284,
        "f1": 0.9304723885562209,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9304723885562209,
        "precision": 0.9245952539365712,
        "recall": 0.9434464404524284
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9071967176757596,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9071967176757596,
        "precision": 0.8996514906694546,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.8496340652029275,
        "f1": 0.8205842283686595,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.8205842283686595,
        "precision": 0.8086345826864789,
        "recall": 0.8496340652029275
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.00807625032589834,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00807625032589834,
        "precision": 0.006515176800974374,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.7039254823685961,
        "f1": 0.6596099287716054,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6596099287716054,
        "precision": 0.6423383391946266,
        "recall": 0.7039254823685961
      },
      {
        "accuracy": 0.8762475049900199,
        "f1": 0.85395874916833,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.85395874916833,
        "precision": 0.8436903969838101,
        "recall": 0.8762475049900199
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.8964515413617211,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8964515413617211,
        "precision": 0.8885451319583056,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.9514304723885563,
        "f1": 0.9407850964737192,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9407850964737192,
        "precision": 0.9359281437125747,
        "recall": 0.9514304723885563
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0056132845282147025,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0056132845282147025,
        "precision": 0.004819807954258681,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.007808594193244361,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.007808594193244361,
        "precision": 0.00693434717044108,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.007013916726014271,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.007013916726014271,
        "precision": 0.005817448914886327,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004136728687626891,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.004136728687626891,
        "precision": 0.0034360234957658948,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0061899074606276555,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0061899074606276555,
        "precision": 0.0053602216745381225,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.0070005125274070785,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0070005125274070785,
        "precision": 0.00591592617614104,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004207553880168985,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.004207553880168985,
        "precision": 0.0038948877894436906,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005619988097364012,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.005619988097364012,
        "precision": 0.005064222248383338,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0038952297838645,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0038952297838645,
        "precision": 0.0033193307664505073,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0066337283586100785,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0066337283586100785,
        "precision": 0.005884388136988201,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005049939023150158,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.005049939023150158,
        "precision": 0.00401719628130982,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0031741044370973874,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0031741044370973874,
        "precision": 0.002571610994519102,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0041166494732036325,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0041166494732036325,
        "precision": 0.0036368524325464807,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005423976382245889,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.005423976382245889,
        "precision": 0.004265471665274506,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.008154460738528223,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.008154460738528223,
        "precision": 0.00745295793320442,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005132887435964208,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.005132887435964208,
        "precision": 0.00451418554579779,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0058683907395785965,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0058683907395785965,
        "precision": 0.005235449170466629,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.03046451589365761,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.03046451589365761,
        "precision": 0.027558948863398786,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.006030726152729948,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.006030726152729948,
        "precision": 0.004808091624601017,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0035376084731548354,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0035376084731548354,
        "precision": 0.0029740296627574704,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.005140645141153677,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.005140645141153677,
        "precision": 0.004330472470457001,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.007181022454398786,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.007181022454398786,
        "precision": 0.006143215039048879,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8976269682856508,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8976269682856508,
        "precision": 0.8894655134176092,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.9494344644045243,
        "f1": 0.937569305832779,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.937569305832779,
        "precision": 0.9321579064094034,
        "recall": 0.9494344644045243
      },
      {
        "accuracy": 0.30805056553559546,
        "f1": 0.2567055551087487,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2567055551087487,
        "precision": 0.23940215547001975,
        "recall": 0.30805056553559546
      },
      {
        "accuracy": 0.8389886892880905,
        "f1": 0.8029734182428794,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8029734182428794,
        "precision": 0.7875756423660615,
        "recall": 0.8389886892880905
      },
      {
        "accuracy": 0.9647371922821024,
        "f1": 0.9557995120869371,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9557995120869371,
        "precision": 0.9517298735861609,
        "recall": 0.9647371922821024
      },
      {
        "accuracy": 0.7278775781769794,
        "f1": 0.6848361958142397,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6848361958142397,
        "precision": 0.6677478376580173,
        "recall": 0.7278775781769794
      },
      {
        "accuracy": 0.9354624085163007,
        "f1": 0.9216899534264803,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9216899534264803,
        "precision": 0.9156353958749167,
        "recall": 0.9354624085163007
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9385673098247949,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9385673098247949,
        "precision": 0.9332667997338655,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.863606121091151,
        "f1": 0.8338560973291512,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8338560973291512,
        "precision": 0.821490352628077,
        "recall": 0.863606121091151
      },
      {
        "accuracy": 0.7391882900864937,
        "f1": 0.6953220543040902,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6953220543040902,
        "precision": 0.6762094857903241,
        "recall": 0.7391882900864937
      },
      {
        "accuracy": 0.9328010645375915,
        "f1": 0.9175205145265025,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9175205145265025,
        "precision": 0.9108117099135062,
        "recall": 0.9328010645375915
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9062985140829452,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9062985140829452,
        "precision": 0.8978931026835218,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.9414504324683965,
        "f1": 0.9299622976269682,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9299622976269682,
        "precision": 0.9249168330006653,
        "recall": 0.9414504324683965
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.012317276116434319,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.012317276116434319,
        "precision": 0.010024311265118177,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.9467731204258151,
        "f1": 0.9346640053226879,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9346640053226879,
        "precision": 0.9292747837658016,
        "recall": 0.9467731204258151
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9028736178436777,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9028736178436777,
        "precision": 0.8947327567088046,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.863606121091151,
        "f1": 0.8347210341222318,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.8347210341222318,
        "precision": 0.8224772676868486,
        "recall": 0.863606121091151
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.010693329003133413,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.010693329003133413,
        "precision": 0.008606234228513818,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.7085828343313373,
        "f1": 0.6640607673541805,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6640607673541805,
        "precision": 0.6456594747013908,
        "recall": 0.7085828343313373
      },
      {
        "accuracy": 0.863606121091151,
        "f1": 0.8366283306403065,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8366283306403065,
        "precision": 0.8247837658017297,
        "recall": 0.863606121091151
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9017668366969763,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9017668366969763,
        "precision": 0.8936737635839432,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9627411842980705,
        "f1": 0.9541710230332986,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9541710230332986,
        "precision": 0.9503215790640941,
        "recall": 0.9627411842980705
      },
      {
        "accuracy": 0.9174983366600133,
        "f1": 0.8990019960079839,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8990019960079839,
        "precision": 0.8907407407407407,
        "recall": 0.9174983366600133
      },
      {
        "accuracy": 0.9554224883566201,
        "f1": 0.9445775116433798,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9445775116433798,
        "precision": 0.93973164781548,
        "recall": 0.9554224883566201
      },
      {
        "accuracy": 0.3140385894876913,
        "f1": 0.2554019093939254,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.2554019093939254,
        "precision": 0.2358188385134493,
        "recall": 0.3140385894876913
      },
      {
        "accuracy": 0.8270126413838988,
        "f1": 0.791084497671324,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.791084497671324,
        "precision": 0.7752901604199008,
        "recall": 0.8270126413838988
      },
      {
        "accuracy": 0.9660678642714571,
        "f1": 0.957418496340652,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.957418496340652,
        "precision": 0.9534264803725881,
        "recall": 0.9660678642714571
      },
      {
        "accuracy": 0.737857618097139,
        "f1": 0.6952365111047746,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.6952365111047746,
        "precision": 0.6784864134165532,
        "recall": 0.737857618097139
      },
      {
        "accuracy": 0.9394544244843646,
        "f1": 0.9265025504546462,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9265025504546462,
        "precision": 0.9209248170326015,
        "recall": 0.9394544244843646
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9410955866045687,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.9410955866045687,
        "precision": 0.9362386338434243,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.8485726958780851,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.8485726958780851,
        "precision": 0.8376912840984697,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.7265469061876247,
        "f1": 0.6807622849539018,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.6807622849539018,
        "precision": 0.6609299918681156,
        "recall": 0.7265469061876247
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9144821468174762,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.9144821468174762,
        "precision": 0.9071190951430471,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9208028387669106,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9208028387669106,
        "precision": 0.9143934353515193,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.9447771124417831,
        "f1": 0.9310046573519627,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9310046573519627,
        "precision": 0.9247283211355068,
        "recall": 0.9447771124417831
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.010808111723507664,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.010808111723507664,
        "precision": 0.009019450420414852,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.9454424484364604,
        "f1": 0.9330671989354624,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9330671989354624,
        "precision": 0.9274229319139498,
        "recall": 0.9454424484364604
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9062098026169882,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.9062098026169882,
        "precision": 0.8986138833444224,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.8589487691284099,
        "f1": 0.8327271383159607,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.8327271383159607,
        "precision": 0.821813779847712,
        "recall": 0.8589487691284099
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.00892376049352099,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00892376049352099,
        "precision": 0.007031406658712525,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.7059214903526281,
        "f1": 0.6593421622363739,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.6593421622363739,
        "precision": 0.6405641098754871,
        "recall": 0.7059214903526281
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8567088046129961,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.8567088046129961,
        "precision": 0.845420270569971,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9079840319361276,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.9079840319361276,
        "precision": 0.9002550454646262,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.9600798403193613,
        "f1": 0.9520292747837659,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9520292747837659,
        "precision": 0.9483810157462851,
        "recall": 0.9600798403193613
      },
      {
        "accuracy": 0.8942115768463074,
        "f1": 0.8720115324905743,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8720115324905743,
        "precision": 0.86187624750499,
        "recall": 0.8942115768463074
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9265152235212115,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9265152235212115,
        "precision": 0.920292747837658,
        "recall": 0.9407850964737192
      },
      {
        "accuracy": 0.2980705256154358,
        "f1": 0.2438504092196707,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.2438504092196707,
        "precision": 0.224889638711994,
        "recall": 0.2980705256154358
      },
      {
        "accuracy": 0.8296739853626082,
        "f1": 0.7950912988837141,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.7950912988837141,
        "precision": 0.7800898203592814,
        "recall": 0.8296739853626082
      },
      {
        "accuracy": 0.9580838323353293,
        "f1": 0.9476729081519499,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9476729081519499,
        "precision": 0.9431913949878021,
        "recall": 0.9580838323353293
      },
      {
        "accuracy": 0.7132401862940785,
        "f1": 0.6714454688506585,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.6714454688506585,
        "precision": 0.6543521422762939,
        "recall": 0.7132401862940785
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9235307163450875,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9235307163450875,
        "precision": 0.9175759591927257,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9387669106231981,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.9387669106231981,
        "precision": 0.9338434242625859,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.8476380572188955,
        "f1": 0.8155245065424704,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.8155245065424704,
        "precision": 0.8015873015873015,
        "recall": 0.8476380572188955
      },
      {
        "accuracy": 0.7411842980705257,
        "f1": 0.6919975345125046,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.6919975345125046,
        "precision": 0.670847194499889,
        "recall": 0.7411842980705257
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9144156132180085,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.9144156132180085,
        "precision": 0.9073741406076735,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8926813040585494,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.8926813040585494,
        "precision": 0.8841095586604568,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.9328010645375915,
        "f1": 0.9191394987802174,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9191394987802174,
        "precision": 0.9129740518962076,
        "recall": 0.9328010645375915
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.012959996417272966,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.012959996417272966,
        "precision": 0.010962529282585464,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9258720653930236,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9258720653930236,
        "precision": 0.9197604790419163,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9153470836105568,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.9153470836105568,
        "precision": 0.9080727434020848,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.8363273453093812,
        "f1": 0.8000126730665653,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.8000126730665653,
        "precision": 0.7845436111903177,
        "recall": 0.8363273453093812
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.00927876710958347,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.00927876710958347,
        "precision": 0.007130309109832586,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.7258815701929474,
        "f1": 0.6751180179323891,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.6751180179323891,
        "precision": 0.6533380569308712,
        "recall": 0.7258815701929474
      },
      {
        "accuracy": 0.8536260811709914,
        "f1": 0.8254728637962171,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.8254728637962171,
        "precision": 0.8129186072299844,
        "recall": 0.8536260811709914
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8883787979596363,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.8883787979596363,
        "precision": 0.8794854734974497,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.9587491683300067,
        "f1": 0.9487913062763362,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.9487913062763362,
        "precision": 0.9445220669771569,
        "recall": 0.9587491683300067
      },
      {
        "accuracy": 0.8223552894211577,
        "f1": 0.787684947565187,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.787684947565187,
        "precision": 0.773164781548015,
        "recall": 0.8223552894211577
      },
      {
        "accuracy": 0.8622754491017964,
        "f1": 0.8338244146627382,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8338244146627382,
        "precision": 0.8216788644932358,
        "recall": 0.8622754491017964
      },
      {
        "accuracy": 0.2528276779773786,
        "f1": 0.20800419363293615,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.20800419363293615,
        "precision": 0.19251974646186223,
        "recall": 0.2528276779773786
      },
      {
        "accuracy": 0.7112441783100466,
        "f1": 0.6625880994144467,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6625880994144467,
        "precision": 0.6427462535246966,
        "recall": 0.7112441783100466
      },
      {
        "accuracy": 0.8769128409846972,
        "f1": 0.8533045021068973,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8533045021068973,
        "precision": 0.8428442297703775,
        "recall": 0.8769128409846972
      },
      {
        "accuracy": 0.6413838988689288,
        "f1": 0.5939063671598601,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5939063671598601,
        "precision": 0.575079206666033,
        "recall": 0.6413838988689288
      },
      {
        "accuracy": 0.8389886892880905,
        "f1": 0.812776035231125,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.812776035231125,
        "precision": 0.8019432035400098,
        "recall": 0.8389886892880905
      },
      {
        "accuracy": 0.8542914171656687,
        "f1": 0.8267327778305822,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8267327778305822,
        "precision": 0.8156092576751259,
        "recall": 0.8542914171656687
      },
      {
        "accuracy": 0.7618097139055223,
        "f1": 0.725846719259893,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.725846719259893,
        "precision": 0.7119330362843339,
        "recall": 0.7618097139055223
      },
      {
        "accuracy": 0.6240851630073186,
        "f1": 0.5765237202362951,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5765237202362951,
        "precision": 0.5570541456769001,
        "recall": 0.6240851630073186
      },
      {
        "accuracy": 0.8409846972721224,
        "f1": 0.8119332763045337,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8119332763045337,
        "precision": 0.7998400025346133,
        "recall": 0.8409846972721224
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8090279757944429,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8090279757944429,
        "precision": 0.7965465893609607,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.8616101131071191,
        "f1": 0.8384288809438509,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8384288809438509,
        "precision": 0.8287536039033045,
        "recall": 0.8616101131071191
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.009928050063538849,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009928050063538849,
        "precision": 0.0080050140948338,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.8602794411177644,
        "f1": 0.8339986693280107,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8339986693280107,
        "precision": 0.8231278184371996,
        "recall": 0.8602794411177644
      },
      {
        "accuracy": 0.8576180971390552,
        "f1": 0.8302870449577037,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8302870449577037,
        "precision": 0.8186801001172258,
        "recall": 0.8576180971390552
      },
      {
        "accuracy": 0.8376580172987359,
        "f1": 0.8054325212009843,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8054325212009843,
        "precision": 0.7925664543928016,
        "recall": 0.8376580172987359
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005562541678034478,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005562541678034478,
        "precision": 0.0042012416199336475,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.5988023952095808,
        "f1": 0.5508938979996864,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5508938979996864,
        "precision": 0.5322886214103779,
        "recall": 0.5988023952095808
      },
      {
        "accuracy": 0.7717897538256819,
        "f1": 0.7336554884459077,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7336554884459077,
        "precision": 0.7182808985204193,
        "recall": 0.7717897538256819
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.8032294385587798,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8032294385587798,
        "precision": 0.7907666149183115,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.8682634730538922,
        "f1": 0.8406916326078001,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8406916326078001,
        "precision": 0.8298096927837445,
        "recall": 0.8682634730538922
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.007819696378240697,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.007819696378240697,
        "precision": 0.006970670464007146,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005424441070785259,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.005424441070785259,
        "precision": 0.004655578557589761,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.006900321493954898,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.006900321493954898,
        "precision": 0.005726103689995995,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004522268701538409,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.004522268701538409,
        "precision": 0.0035765547804686632,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.007408543905453721,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.007408543905453721,
        "precision": 0.006385959478194455,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005885550964234177,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.005885550964234177,
        "precision": 0.004778143599621671,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005521775762337337,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.005521775762337337,
        "precision": 0.005020883087812743,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.00513106781060005,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.00513106781060005,
        "precision": 0.004547167480536237,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004606628702025411,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.004606628702025411,
        "precision": 0.0039485998435746,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.006612622051774817,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.006612622051774817,
        "precision": 0.005678884951203517,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007761951216370554,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.007761951216370554,
        "precision": 0.006620312479032289,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0035983869605118583,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0035983869605118583,
        "precision": 0.0032240909531313644,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0050863795239166065,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0050863795239166065,
        "precision": 0.004702876818683572,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.032587494563542464,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.032587494563542464,
        "precision": 0.027849063777207486,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.005393024441958541,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.005393024441958541,
        "precision": 0.004458298401695554,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.006332538913030105,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.006332538913030105,
        "precision": 0.005964484854029474,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.006184076338157783,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.006184076338157783,
        "precision": 0.005468414051775735,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0055556971679967026,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0055556971679967026,
        "precision": 0.004590676429068921,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.004910475286857062,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.004910475286857062,
        "precision": 0.003862324945220265,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004422151923997944,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.004422151923997944,
        "precision": 0.00373487592715803,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0039018240767680307,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0039018240767680307,
        "precision": 0.003484598341999824,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.006187810041995715,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.006187810041995715,
        "precision": 0.0054486418598112514,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.6600133067198936,
        "f1": 0.6070832361251522,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6070832361251522,
        "precision": 0.5868050335116204,
        "recall": 0.6600133067198936
      },
      {
        "accuracy": 0.7019294743845642,
        "f1": 0.6475034488947838,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6475034488947838,
        "precision": 0.6263841364889269,
        "recall": 0.7019294743845642
      },
      {
        "accuracy": 0.3033932135728543,
        "f1": 0.2531387441567082,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2531387441567082,
        "precision": 0.23537501716144427,
        "recall": 0.3033932135728543
      },
      {
        "accuracy": 0.669328010645376,
        "f1": 0.6241035633251203,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6241035633251203,
        "precision": 0.6067906515012303,
        "recall": 0.669328010645376
      },
      {
        "accuracy": 0.7245508982035929,
        "f1": 0.6723673532056766,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6723673532056766,
        "precision": 0.651775508811437,
        "recall": 0.7245508982035929
      },
      {
        "accuracy": 0.58416500332668,
        "f1": 0.5336062510713209,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5336062510713209,
        "precision": 0.5140795369338282,
        "recall": 0.58416500332668
      },
      {
        "accuracy": 0.7178975382568197,
        "f1": 0.6714655825434269,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6714655825434269,
        "precision": 0.6534750604610884,
        "recall": 0.7178975382568197
      },
      {
        "accuracy": 0.7305389221556886,
        "f1": 0.6821183030763869,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6821183030763869,
        "precision": 0.6636901041591661,
        "recall": 0.7305389221556886
      },
      {
        "accuracy": 0.6147704590818364,
        "f1": 0.5641258128284077,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5641258128284077,
        "precision": 0.5453404385881536,
        "recall": 0.6147704590818364
      },
      {
        "accuracy": 0.5455755156353959,
        "f1": 0.48656131700043875,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.48656131700043875,
        "precision": 0.46434406319635857,
        "recall": 0.5455755156353959
      },
      {
        "accuracy": 0.6912840984697272,
        "f1": 0.6417281838439522,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6417281838439522,
        "precision": 0.6225989819303193,
        "recall": 0.6912840984697272
      },
      {
        "accuracy": 0.6746506986027944,
        "f1": 0.622634360907814,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.622634360907814,
        "precision": 0.6028672813103951,
        "recall": 0.6746506986027944
      },
      {
        "accuracy": 0.6946107784431138,
        "f1": 0.6462775851563494,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6462775851563494,
        "precision": 0.6280683462320189,
        "recall": 0.6946107784431138
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.008324586656282667,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008324586656282667,
        "precision": 0.0068100883649618105,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.6986027944111777,
        "f1": 0.650429300129899,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.650429300129899,
        "precision": 0.6322371130754364,
        "recall": 0.6986027944111777
      },
      {
        "accuracy": 0.6819693945442449,
        "f1": 0.6269530966079045,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6269530966079045,
        "precision": 0.6055868421886385,
        "recall": 0.6819693945442449
      },
      {
        "accuracy": 0.6986027944111777,
        "f1": 0.6475926453970365,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6475926453970365,
        "precision": 0.6286508992596817,
        "recall": 0.6986027944111777
      },
      {
        "accuracy": 0.5761809713905522,
        "f1": 0.5176328679821693,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.5176328679821693,
        "precision": 0.4970271338035809,
        "recall": 0.5761809713905522
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.0037085643919750016,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0037085643919750016,
        "precision": 0.0027991730505792763,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5622232207062546,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5622232207062546,
        "precision": 0.5436461673829045,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.6500332667997338,
        "f1": 0.5960898309201702,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5960898309201702,
        "precision": 0.574971221578008,
        "recall": 0.6500332667997338
      },
      {
        "accuracy": 0.7178975382568197,
        "f1": 0.6641589023824552,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6641589023824552,
        "precision": 0.6435943168977101,
        "recall": 0.7178975382568197
      },
      {
        "accuracy": 0.8210246174318031,
        "f1": 0.7874574084154922,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7874574084154922,
        "precision": 0.7731809109054617,
        "recall": 0.8210246174318031
      },
      {
        "accuracy": 0.8842315369261478,
        "f1": 0.8584756413099726,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8584756413099726,
        "precision": 0.8469560878243513,
        "recall": 0.8842315369261478
      },
      {
        "accuracy": 0.26746506986027946,
        "f1": 0.21702459955952969,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.21702459955952969,
        "precision": 0.20011275034355808,
        "recall": 0.26746506986027946
      },
      {
        "accuracy": 0.7238855622089155,
        "f1": 0.6751362354655768,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.6751362354655768,
        "precision": 0.6553794767367621,
        "recall": 0.7238855622089155
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.8729900468423422,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8729900468423422,
        "precision": 0.863301175426924,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.6413838988689288,
        "f1": 0.5918032141585036,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.5918032141585036,
        "precision": 0.5721773624468235,
        "recall": 0.6413838988689288
      },
      {
        "accuracy": 0.8516300731869594,
        "f1": 0.8254876490405432,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.8254876490405432,
        "precision": 0.8142437347527168,
        "recall": 0.8516300731869594
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8630395774108348,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.8630395774108348,
        "precision": 0.8525467583351815,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.8276779773785762,
        "f1": 0.7945131382257129,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.7945131382257129,
        "precision": 0.780705256154358,
        "recall": 0.8276779773785762
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5723956848208346,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.5723956848208346,
        "precision": 0.5498352501346514,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.8436460412508316,
        "f1": 0.8131736526946106,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.8131736526946106,
        "precision": 0.7998215689832455,
        "recall": 0.8436460412508316
      },
      {
        "accuracy": 0.8689288090485695,
        "f1": 0.8439787092481703,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.8439787092481703,
        "precision": 0.8327677977378577,
        "recall": 0.8689288090485695
      },
      {
        "accuracy": 0.8669328010645376,
        "f1": 0.840520546209169,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.840520546209169,
        "precision": 0.8291258752336597,
        "recall": 0.8669328010645376
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.006677365430615921,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.006677365430615921,
        "precision": 0.005359993411356813,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.8542914171656687,
        "f1": 0.8244833565192847,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8244833565192847,
        "precision": 0.81122833697684,
        "recall": 0.8542914171656687
      },
      {
        "accuracy": 0.867598137059215,
        "f1": 0.8395985806165446,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.8395985806165446,
        "precision": 0.8271631340493615,
        "recall": 0.867598137059215
      },
      {
        "accuracy": 0.8403193612774451,
        "f1": 0.8093701485917055,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.8093701485917055,
        "precision": 0.7958812533662833,
        "recall": 0.8403193612774451
      },
      {
        "accuracy": 0.7691284098469727,
        "f1": 0.7236372188467997,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.7236372188467997,
        "precision": 0.703637170104236,
        "recall": 0.7691284098469727
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.005256064006160712,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.005256064006160712,
        "precision": 0.004225714334966605,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.6300731869594145,
        "f1": 0.5838040849517895,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.5838040849517895,
        "precision": 0.5658265479622765,
        "recall": 0.6300731869594145
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.8497005988023951,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.8497005988023951,
        "precision": 0.8385451319583057,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.8749168330006654,
        "f1": 0.8494815083637438,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.8494815083637438,
        "precision": 0.838107119095143,
        "recall": 0.8749168330006654
      },
      {
        "accuracy": 0.8835662009314704,
        "f1": 0.8609891328454202,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8609891328454202,
        "precision": 0.8514592748125682,
        "recall": 0.8835662009314704
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9153692614770459,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9153692614770459,
        "precision": 0.9087602572632514,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.28409846972721225,
        "f1": 0.23090010878844977,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.23090010878844977,
        "precision": 0.21396090694992892,
        "recall": 0.28409846972721225
      },
      {
        "accuracy": 0.7737857618097139,
        "f1": 0.7298508802500818,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.7298508802500818,
        "precision": 0.7118293136726856,
        "recall": 0.7737857618097139
      },
      {
        "accuracy": 0.9414504324683965,
        "f1": 0.9279916357760668,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9279916357760668,
        "precision": 0.9222111332889775,
        "recall": 0.9414504324683965
      },
      {
        "accuracy": 0.697272122421823,
        "f1": 0.6512081656792236,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.6512081656792236,
        "precision": 0.6328702383592603,
        "recall": 0.697272122421823
      },
      {
        "accuracy": 0.9068529607451763,
        "f1": 0.8901804855896672,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8901804855896672,
        "precision": 0.8834275892659125,
        "recall": 0.9068529607451763
      },
      {
        "accuracy": 0.9301397205588823,
        "f1": 0.9161914266704685,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9161914266704685,
        "precision": 0.9101637993853562,
        "recall": 0.9301397205588823
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8526185723790513,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.8526185723790513,
        "precision": 0.8436460412508316,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.6433498083198682,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6433498083198682,
        "precision": 0.6253667268637328,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.8740107087412475,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8740107087412475,
        "precision": 0.8644599689509869,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8940341539143933,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8940341539143933,
        "precision": 0.8861942781104458,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.8978392421506194,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8978392421506194,
        "precision": 0.8906298514082946,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.007520343154994905,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.007520343154994905,
        "precision": 0.005343382023122121,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.9135063206919495,
        "f1": 0.8941022716471819,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8941022716471819,
        "precision": 0.8858125019801666,
        "recall": 0.9135063206919495
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9102255805848619,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9102255805848619,
        "precision": 0.9025900579792795,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8652240972600252,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8652240972600252,
        "precision": 0.8562161391502708,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7906452127011008,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7906452127011008,
        "precision": 0.7765527386784871,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.0074545367110715206,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0074545367110715206,
        "precision": 0.006172056649589956,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.6506986027944112,
        "f1": 0.6014647952771706,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.6014647952771706,
        "precision": 0.5814719766815575,
        "recall": 0.6506986027944112
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8587935240629851,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.8587935240629851,
        "precision": 0.8489687292082502,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.9328010645375915,
        "f1": 0.9183078287868707,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9183078287868707,
        "precision": 0.9120710959034313,
        "recall": 0.9328010645375915
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8922931913949879,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8922931913949879,
        "precision": 0.8849142983873524,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.9520958083832335,
        "f1": 0.9413395431359505,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9413395431359505,
        "precision": 0.9366267465069861,
        "recall": 0.9520958083832335
      },
      {
        "accuracy": 0.2967398536260812,
        "f1": 0.2421949418955407,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.2421949418955407,
        "precision": 0.22311957651279007,
        "recall": 0.2967398536260812
      },
      {
        "accuracy": 0.850964737192282,
        "f1": 0.819373950511675,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.819373950511675,
        "precision": 0.8060672306181289,
        "recall": 0.850964737192282
      },
      {
        "accuracy": 0.9740518962075848,
        "f1": 0.9678199157241073,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9678199157241073,
        "precision": 0.9651807496118873,
        "recall": 0.9740518962075848
      },
      {
        "accuracy": 0.7245508982035929,
        "f1": 0.6796783057262099,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6796783057262099,
        "precision": 0.662411156522933,
        "recall": 0.7245508982035929
      },
      {
        "accuracy": 0.9461077844311377,
        "f1": 0.9333776890663119,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9333776890663119,
        "precision": 0.927977378576181,
        "recall": 0.9461077844311377
      },
      {
        "accuracy": 0.9647371922821024,
        "f1": 0.9566866267465071,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9566866267465071,
        "precision": 0.9531492570414726,
        "recall": 0.9647371922821024
      },
      {
        "accuracy": 0.8609447771124418,
        "f1": 0.8323754607187741,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.8323754607187741,
        "precision": 0.8207862053670437,
        "recall": 0.8609447771124418
      },
      {
        "accuracy": 0.7664670658682635,
        "f1": 0.724409910338054,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.724409910338054,
        "precision": 0.7065820739473433,
        "recall": 0.7664670658682635
      },
      {
        "accuracy": 0.9427811044577512,
        "f1": 0.9300066533599467,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9300066533599467,
        "precision": 0.9242625859392325,
        "recall": 0.9427811044577512
      },
      {
        "accuracy": 0.936127744510978,
        "f1": 0.9220891550232868,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9220891550232868,
        "precision": 0.915956974939011,
        "recall": 0.936127744510978
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9386116655577732,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9386116655577732,
        "precision": 0.9334109558660456,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.012533958849332198,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.012533958849332198,
        "precision": 0.009886848530613631,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.9454424484364604,
        "f1": 0.9317808826790863,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9317808826790863,
        "precision": 0.9257263251275226,
        "recall": 0.9454424484364604
      },
      {
        "accuracy": 0.9500998003992016,
        "f1": 0.9377910844976713,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9377910844976713,
        "precision": 0.9321800842758926,
        "recall": 0.9500998003992016
      },
      {
        "accuracy": 0.9407850964737192,
        "f1": 0.9264581947216678,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9264581947216678,
        "precision": 0.9202040363717011,
        "recall": 0.9407850964737192
      },
      {
        "accuracy": 0.8556220891550232,
        "f1": 0.8252859360643792,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.8252859360643792,
        "precision": 0.8121772328359155,
        "recall": 0.8556220891550232
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008723286899173305,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.008723286899173305,
        "precision": 0.0071181242411053015,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.7119095143047239,
        "f1": 0.667199991551289,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.667199991551289,
        "precision": 0.6492644340947734,
        "recall": 0.7119095143047239
      },
      {
        "accuracy": 0.8789088489687292,
        "f1": 0.8574961188733643,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8574961188733643,
        "precision": 0.8480325064157399,
        "recall": 0.8789088489687292
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.9139403732218104,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9139403732218104,
        "precision": 0.90806165446884,
        "recall": 0.9281437125748503
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}