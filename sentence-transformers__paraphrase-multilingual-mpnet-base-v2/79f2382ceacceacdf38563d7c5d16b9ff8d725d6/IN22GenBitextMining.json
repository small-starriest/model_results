{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 23.049295663833618,
  "kg_co2_emissions": 0.003835708335880874,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.66796875,
        "f1": 0.6298041449652778,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.6298041449652778,
        "precision": 0.6164550021453381,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05388912914499494,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.05388912914499494,
        "precision": 0.047084666153593024,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.4072265625,
        "f1": 0.35752315989132394,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.35752315989132394,
        "precision": 0.3405359604779412,
        "recall": 0.4072265625
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5450393229115655,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.5450393229115655,
        "precision": 0.5237802003689095,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.36328125,
        "f1": 0.3136923650351385,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.3136923650351385,
        "precision": 0.2965304904513889,
        "recall": 0.36328125
      },
      {
        "accuracy": 0.552734375,
        "f1": 0.5097447824498605,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.5097447824498605,
        "precision": 0.494403605926524,
        "recall": 0.552734375
      },
      {
        "accuracy": 0.572265625,
        "f1": 0.5375847251592523,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.5375847251592523,
        "precision": 0.5245566891318845,
        "recall": 0.572265625
      },
      {
        "accuracy": 0.5048828125,
        "f1": 0.4518756200396825,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.4518756200396825,
        "precision": 0.43255667401175213,
        "recall": 0.5048828125
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.20156257045905482,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.20156257045905482,
        "precision": 0.18514936573587767,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.48046875,
        "f1": 0.43958732297034103,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.43958732297034103,
        "precision": 0.4260779255089717,
        "recall": 0.48046875
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.46644655257936507,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.46644655257936507,
        "precision": 0.4474961973976993,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.5048828125,
        "f1": 0.45961714764030615,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.45961714764030615,
        "precision": 0.4440497856635552,
        "recall": 0.5048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001489968913143521,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0001489968913143521,
        "precision": 7.784555512005444e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.5576171875,
        "f1": 0.5213518451294583,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.5213518451294583,
        "precision": 0.5084833758906024,
        "recall": 0.5576171875
      },
      {
        "accuracy": 0.4794921875,
        "f1": 0.4259437953311308,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.4259437953311308,
        "precision": 0.4069013099530677,
        "recall": 0.4794921875
      },
      {
        "accuracy": 0.470703125,
        "f1": 0.4180858529491342,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.4180858529491342,
        "precision": 0.4004851882250205,
        "recall": 0.470703125
      },
      {
        "accuracy": 0.3935546875,
        "f1": 0.33944498697916664,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.33944498697916664,
        "precision": 0.3192899132309174,
        "recall": 0.3935546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00046463010767967665,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.00046463010767967665,
        "precision": 0.00026732227132874426,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.291015625,
        "f1": 0.24581586508642997,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.24581586508642997,
        "precision": 0.2305809560448232,
        "recall": 0.291015625
      },
      {
        "accuracy": 0.521484375,
        "f1": 0.48191382998511906,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.48191382998511906,
        "precision": 0.4663597470238095,
        "recall": 0.521484375
      },
      {
        "accuracy": 0.51953125,
        "f1": 0.4709991939484127,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.4709991939484127,
        "precision": 0.4534512362637363,
        "recall": 0.51953125
      },
      {
        "accuracy": 0.6015625,
        "f1": 0.5532486908707611,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.5532486908707611,
        "precision": 0.5355974327160539,
        "recall": 0.6015625
      },
      {
        "accuracy": 0.74609375,
        "f1": 0.6903831845238095,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.6903831845238095,
        "precision": 0.6660319010416667,
        "recall": 0.74609375
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.06822476568570318,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.06822476568570318,
        "precision": 0.058873683824855694,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.681640625,
        "f1": 0.6247395833333333,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.6247395833333333,
        "precision": 0.6013834635416666,
        "recall": 0.681640625
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.9019694010416667,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9019694010416667,
        "precision": 0.8929617745535714,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.6162109375,
        "f1": 0.5539922805059524,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.5539922805059524,
        "precision": 0.5284272693452381,
        "recall": 0.6162109375
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8272786458333333,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8272786458333333,
        "precision": 0.8140834263392858,
        "recall": 0.859375
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8892822265625,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.8892822265625,
        "precision": 0.8816228693181819,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6858654203869048,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.6858654203869048,
        "precision": 0.664218284970238,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.3837890625,
        "f1": 0.31432679191468255,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.31432679191468255,
        "precision": 0.28904073899191085,
        "recall": 0.3837890625
      },
      {
        "accuracy": 0.81640625,
        "f1": 0.7801432291666667,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.7801432291666667,
        "precision": 0.7643954190340909,
        "recall": 0.81640625
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7708658854166666,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.7708658854166666,
        "precision": 0.7518717447916667,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8142113095238095,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.8142113095238095,
        "precision": 0.7981770833333334,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004584851853566573,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0004584851853566573,
        "precision": 0.00027846004327663804,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8787760416666667,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8787760416666667,
        "precision": 0.869482421875,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7009114583333333,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.7009114583333333,
        "precision": 0.6762858072916667,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.75283203125,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.75283203125,
        "precision": 0.7333333333333334,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.619140625,
        "f1": 0.5558671254960317,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.5558671254960317,
        "precision": 0.5294677734375,
        "recall": 0.619140625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013147521304458694,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0013147521304458694,
        "precision": 0.0011557759332224793,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.4206528876939033,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.4206528876939033,
        "precision": 0.39546828497023806,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.8525390625,
        "f1": 0.8190104166666667,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8190104166666667,
        "precision": 0.8042805989583334,
        "recall": 0.8525390625
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.7985212053571429,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.7985212053571429,
        "precision": 0.7805826822916667,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8951497395833333,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.8951497395833333,
        "precision": 0.8846354166666666,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.051113197990338186,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.051113197990338186,
        "precision": 0.04731364190867162,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.05315028213902692,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.05315028213902692,
        "precision": 0.05041219655699414,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0791751850962459,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0791751850962459,
        "precision": 0.0759061201609886,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07720735537429288,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07720735537429288,
        "precision": 0.07398705017918367,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0840499686716792,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.0840499686716792,
        "precision": 0.08108554734969493,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.06024275923154662,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.06024275923154662,
        "precision": 0.05692078590814225,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07679829386598719,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.07679829386598719,
        "precision": 0.07410036521669683,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.042667959033812326,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.042667959033812326,
        "precision": 0.03912646314934829,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.09375,
        "f1": 0.0781867162408093,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0781867162408093,
        "precision": 0.07383019179894179,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.08383759292922979,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08383759292922979,
        "precision": 0.08088757964600643,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.0543647716549575,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0543647716549575,
        "precision": 0.05177363137435675,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.07031086968730331,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07031086968730331,
        "precision": 0.06758426380751784,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029957780934343438,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029957780934343438,
        "precision": 0.0026522634054723018,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07677424396082033,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07677424396082033,
        "precision": 0.07367873975683877,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.0365607441678293,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0365607441678293,
        "precision": 0.03424890689563765,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.058468129641151306,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.058468129641151306,
        "precision": 0.055986919030016756,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05756002804356254,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.05756002804356254,
        "precision": 0.05417446385243354,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0020182291666666664,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0020182291666666664,
        "precision": 0.001708984375,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.09172625590349442,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.09172625590349442,
        "precision": 0.088322406540627,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.04444358463823239,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.04444358463823239,
        "precision": 0.04125647503722637,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05890661497790403,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.05890661497790403,
        "precision": 0.055709942258710454,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.07739825581395349,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.07739825581395349,
        "precision": 0.07531596716067379,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.4306640625,
        "f1": 0.3768446180555556,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.3768446180555556,
        "precision": 0.35643556476076005,
        "recall": 0.4306640625
      },
      {
        "accuracy": 0.6435546875,
        "f1": 0.6006937398538961,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6006937398538961,
        "precision": 0.5845621744791667,
        "recall": 0.6435546875
      },
      {
        "accuracy": 0.1669921875,
        "f1": 0.12109888047369516,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12109888047369516,
        "precision": 0.10946398574153356,
        "recall": 0.1669921875
      },
      {
        "accuracy": 0.80078125,
        "f1": 0.7613041689213564,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7613041689213564,
        "precision": 0.7454771980406747,
        "recall": 0.80078125
      },
      {
        "accuracy": 0.6259765625,
        "f1": 0.5784100990155678,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5784100990155678,
        "precision": 0.5591145833333333,
        "recall": 0.6259765625
      },
      {
        "accuracy": 0.6865234375,
        "f1": 0.6444117731227106,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6444117731227106,
        "precision": 0.6287523239054145,
        "recall": 0.6865234375
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.7614094771661009,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7614094771661009,
        "precision": 0.751506537077675,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.4754645934577575,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4754645934577575,
        "precision": 0.4536962467870671,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.3586899266098485,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3586899266098485,
        "precision": 0.33818043393238706,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.7646484375,
        "f1": 0.7346082261029412,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7346082261029412,
        "precision": 0.722900144018308,
        "recall": 0.7646484375
      },
      {
        "accuracy": 0.5830078125,
        "f1": 0.5314943229896125,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5314943229896125,
        "precision": 0.5120432424021291,
        "recall": 0.5830078125
      },
      {
        "accuracy": 0.6845703125,
        "f1": 0.6431240127443023,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6431240127443023,
        "precision": 0.6274349524715735,
        "recall": 0.6845703125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00012195375098600905,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00012195375098600905,
        "precision": 6.341093983325037e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.7529296875,
        "f1": 0.7243807353670635,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7243807353670635,
        "precision": 0.7139724750076313,
        "recall": 0.7529296875
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.4642042495265152,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.4642042495265152,
        "precision": 0.4443797630321068,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.56640625,
        "f1": 0.515702892485119,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.515702892485119,
        "precision": 0.49656343005952375,
        "recall": 0.56640625
      },
      {
        "accuracy": 0.5322265625,
        "f1": 0.4772050161210318,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4772050161210318,
        "precision": 0.4553180028521825,
        "recall": 0.5322265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00040182860538025896,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00040182860538025896,
        "precision": 0.00021747187274531024,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.576171875,
        "f1": 0.5313499813988095,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5313499813988095,
        "precision": 0.5136668724071067,
        "recall": 0.576171875
      },
      {
        "accuracy": 0.626953125,
        "f1": 0.5830932503209617,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5830932503209617,
        "precision": 0.5673892066592262,
        "recall": 0.626953125
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5820907608016983,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5820907608016983,
        "precision": 0.5632003484987744,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.7646484375,
        "f1": 0.7264225862884374,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7264225862884374,
        "precision": 0.7114667992597681,
        "recall": 0.7646484375
      },
      {
        "accuracy": 0.658203125,
        "f1": 0.5806222098214285,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.5806222098214285,
        "precision": 0.5487141927083333,
        "recall": 0.658203125
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9189127604166667,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9189127604166667,
        "precision": 0.91015625,
        "recall": 0.9375
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.10581276342390411,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.10581276342390411,
        "precision": 0.09162635586287703,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.7888857886904762,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.7888857886904762,
        "precision": 0.768798828125,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6712425595238095,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6712425595238095,
        "precision": 0.6451985677083334,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8876627604166667,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.8876627604166667,
        "precision": 0.87548828125,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.765625,
        "f1": 0.7045433407738095,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.7045433407738095,
        "precision": 0.6785753038194444,
        "recall": 0.765625
      },
      {
        "accuracy": 0.513671875,
        "f1": 0.4326622812950938,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.4326622812950938,
        "precision": 0.4031870039682539,
        "recall": 0.513671875
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.92578125,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.92578125,
        "precision": 0.9171549479166667,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8233398437499999,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.8233398437499999,
        "precision": 0.8067057291666666,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8853841145833333,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.8853841145833333,
        "precision": 0.87353515625,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 6.286038573700955e-05,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 6.286038573700955e-05,
        "precision": 3.1957034935986164e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9745117187500001,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9745117187500001,
        "precision": 0.9717610677083333,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.7958984375,
        "f1": 0.7429222470238095,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.7429222470238095,
        "precision": 0.7199055989583334,
        "recall": 0.7958984375
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8041666666666667,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8041666666666667,
        "precision": 0.7855631510416666,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6272344680059524,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.6272344680059524,
        "precision": 0.5986909412202381,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013625843056380192,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00013625843056380192,
        "precision": 7.00003055006131e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.642578125,
        "f1": 0.5760332115800866,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.5760332115800866,
        "precision": 0.5493760850694445,
        "recall": 0.642578125
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.88525390625,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.88525390625,
        "precision": 0.8723958333333334,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.862109375,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.862109375,
        "precision": 0.8479817708333333,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.4052734375,
        "f1": 0.34630075870310245,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.34630075870310245,
        "precision": 0.3244411892361111,
        "recall": 0.4052734375
      },
      {
        "accuracy": 0.5703125,
        "f1": 0.5224067544868326,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5224067544868326,
        "precision": 0.5036732879750457,
        "recall": 0.5703125
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.12269141591458614,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12269141591458614,
        "precision": 0.11286551405145276,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.61328125,
        "f1": 0.5750279017857143,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5750279017857143,
        "precision": 0.5591482736013986,
        "recall": 0.61328125
      },
      {
        "accuracy": 0.6962890625,
        "f1": 0.6461015004960318,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6461015004960318,
        "precision": 0.6265447090886545,
        "recall": 0.6962890625
      },
      {
        "accuracy": 0.625,
        "f1": 0.580210642222361,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.580210642222361,
        "precision": 0.5634296974940607,
        "recall": 0.625
      },
      {
        "accuracy": 0.6875,
        "f1": 0.6543613922449041,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6543613922449041,
        "precision": 0.6416366185897435,
        "recall": 0.6875
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.4450506036931818,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4450506036931818,
        "precision": 0.4247535342261905,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.3662109375,
        "f1": 0.3162176274018379,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3162176274018379,
        "precision": 0.29820850807178934,
        "recall": 0.3662109375
      },
      {
        "accuracy": 0.65234375,
        "f1": 0.6169724742818323,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6169724742818323,
        "precision": 0.6039496058050746,
        "recall": 0.65234375
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.49723391842532466,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.49723391842532466,
        "precision": 0.4751345063356782,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.631653800843254,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.631653800843254,
        "precision": 0.6194286254833129,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010060815974187705,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0010060815974187705,
        "precision": 0.0009914354346264368,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.6572265625,
        "f1": 0.623326433821423,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.623326433821423,
        "precision": 0.6115099968773567,
        "recall": 0.6572265625
      },
      {
        "accuracy": 0.46875,
        "f1": 0.40918952466804026,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.40918952466804026,
        "precision": 0.38741319444444444,
        "recall": 0.46875
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.4684469556051587,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4684469556051587,
        "precision": 0.44962332589285714,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.4912109375,
        "f1": 0.44159930781024526,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.44159930781024526,
        "precision": 0.4230620236967893,
        "recall": 0.4912109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007598105786254627,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007598105786254627,
        "precision": 0.0005455303127130198,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.4775390625,
        "f1": 0.43007431287819614,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.43007431287819614,
        "precision": 0.4130455323405404,
        "recall": 0.4775390625
      },
      {
        "accuracy": 0.5673828125,
        "f1": 0.5219857833139083,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5219857833139083,
        "precision": 0.5048525855654762,
        "recall": 0.5673828125
      },
      {
        "accuracy": 0.58984375,
        "f1": 0.5387109662256147,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5387109662256147,
        "precision": 0.5198401072668651,
        "recall": 0.58984375
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6300728332380445,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6300728332380445,
        "precision": 0.6147176106770833,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.603515625,
        "f1": 0.5422433035714286,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.5422433035714286,
        "precision": 0.5174641927083332,
        "recall": 0.603515625
      },
      {
        "accuracy": 0.84375,
        "f1": 0.8230960525212433,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.8230960525212433,
        "precision": 0.8142903645833334,
        "recall": 0.84375
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.08683800151258111,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.08683800151258111,
        "precision": 0.07673376713518572,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.72265625,
        "f1": 0.6770143539186508,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.6770143539186508,
        "precision": 0.6579764229910714,
        "recall": 0.72265625
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.9104227478250916,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9104227478250916,
        "precision": 0.906005859375,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.6767578125,
        "f1": 0.6239429028003246,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.6239429028003246,
        "precision": 0.6021859873169815,
        "recall": 0.6767578125
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8988854895104895,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.8988854895104895,
        "precision": 0.8949717881944443,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.69189453125,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.69189453125,
        "precision": 0.6713053385416666,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.44140625,
        "f1": 0.3756121699481074,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.3756121699481074,
        "precision": 0.35153276627886004,
        "recall": 0.44140625
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.8118280319940476,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.8118280319940476,
        "precision": 0.8016054751642037,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.7861328125,
        "f1": 0.75224609375,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.75224609375,
        "precision": 0.7366861979166667,
        "recall": 0.7861328125
      },
      {
        "accuracy": 0.849609375,
        "f1": 0.8214525383470695,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.8214525383470695,
        "precision": 0.8095279947916667,
        "recall": 0.849609375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005567501574175531,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0005567501574175531,
        "precision": 0.00036027678068693695,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.9033203125,
        "f1": 0.8924014136904761,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.8924014136904761,
        "precision": 0.8881618923611112,
        "recall": 0.9033203125
      },
      {
        "accuracy": 0.734375,
        "f1": 0.6892113095238095,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.6892113095238095,
        "precision": 0.669677734375,
        "recall": 0.734375
      },
      {
        "accuracy": 0.7705078125,
        "f1": 0.7351827840511204,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.7351827840511204,
        "precision": 0.7207416240985578,
        "recall": 0.7705078125
      },
      {
        "accuracy": 0.6474609375,
        "f1": 0.5890685319077813,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.5890685319077813,
        "precision": 0.5651107545882936,
        "recall": 0.6474609375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001394389743753152,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.001394389743753152,
        "precision": 0.0009472704668918237,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.537109375,
        "f1": 0.4764214409722222,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.4764214409722222,
        "precision": 0.45410034030639496,
        "recall": 0.537109375
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7777623273324274,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.7777623273324274,
        "precision": 0.7652018858800774,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.8025716145833333,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.8025716145833333,
        "precision": 0.7908854166666667,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.9032118055555556,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.9032118055555556,
        "precision": 0.8988254475559163,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.654296875,
        "f1": 0.5790876116071428,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5790876116071428,
        "precision": 0.5481329055059524,
        "recall": 0.654296875
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.91064453125,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.91064453125,
        "precision": 0.900390625,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.11812316783728705,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11812316783728705,
        "precision": 0.10264742718173728,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7885959201388889,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7885959201388889,
        "precision": 0.7711995442708334,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9910481770833333,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9910481770833333,
        "precision": 0.9900716145833333,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.75390625,
        "f1": 0.6984700520833333,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6984700520833333,
        "precision": 0.674755859375,
        "recall": 0.75390625
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8856119791666667,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8856119791666667,
        "precision": 0.873291015625,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.76953125,
        "f1": 0.7093145461309522,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7093145461309522,
        "precision": 0.683447265625,
        "recall": 0.76953125
      },
      {
        "accuracy": 0.4921875,
        "f1": 0.41548626612103173,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.41548626612103173,
        "precision": 0.38763014871413304,
        "recall": 0.4921875
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.9235026041666666,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9235026041666666,
        "precision": 0.9153645833333333,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8240931919642858,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8240931919642858,
        "precision": 0.8086263020833333,
        "recall": 0.859375
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8941080729166666,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8941080729166666,
        "precision": 0.883056640625,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0002674651893439811,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0002674651893439811,
        "precision": 0.0001450105986918047,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.970703125,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.970703125,
        "precision": 0.9674479166666666,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.7410016741071428,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7410016741071428,
        "precision": 0.7181477864583333,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8014322916666666,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8014322916666666,
        "precision": 0.7833170572916667,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.712890625,
        "f1": 0.6517182849702381,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.6517182849702381,
        "precision": 0.6271620360975829,
        "recall": 0.712890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00013030061422159226,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00013030061422159226,
        "precision": 6.793850050420354e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.6591796875,
        "f1": 0.5925579737103175,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5925579737103175,
        "precision": 0.565725368923611,
        "recall": 0.6591796875
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8798502604166667,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8798502604166667,
        "precision": 0.8670247395833334,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8608072916666666,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8608072916666666,
        "precision": 0.8465494791666666,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833333,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9793294270833333,
        "precision": 0.9768880208333333,
        "recall": 0.984375
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.45828993055555556,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.45828993055555556,
        "precision": 0.43739027086195054,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.6806640625,
        "f1": 0.6607407211899399,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.6607407211899399,
        "precision": 0.6526507608251634,
        "recall": 0.6806640625
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06262701057622932,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.06262701057622932,
        "precision": 0.05515444299623987,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.4736049107142857,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.4736049107142857,
        "precision": 0.455078125,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.75,
        "f1": 0.720734303131764,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.720734303131764,
        "precision": 0.7097737630208334,
        "recall": 0.75
      },
      {
        "accuracy": 0.482421875,
        "f1": 0.4370384942100133,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.4370384942100133,
        "precision": 0.42009257967509916,
        "recall": 0.482421875
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.6600577427151416,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.6600577427151416,
        "precision": 0.6483448402326921,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.7158766889100658,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.7158766889100658,
        "precision": 0.7100982814872783,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.22406691073683258,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.22406691073683258,
        "precision": 0.20816136350373482,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.623046875,
        "f1": 0.5920843562330236,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.5920843562330236,
        "precision": 0.5800248212755026,
        "recall": 0.623046875
      },
      {
        "accuracy": 0.673828125,
        "f1": 0.644723849826389,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.644723849826389,
        "precision": 0.6327274836546986,
        "recall": 0.673828125
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6434446304563493,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.6434446304563493,
        "precision": 0.6335025046569163,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006987657746208936,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0006987657746208936,
        "precision": 0.0005123499993910069,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6891213809742647,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.6891213809742647,
        "precision": 0.6809828490736693,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.623046875,
        "f1": 0.5859117231110447,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.5859117231110447,
        "precision": 0.5711907478007796,
        "recall": 0.623046875
      },
      {
        "accuracy": 0.6142578125,
        "f1": 0.5823567708333333,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.5823567708333333,
        "precision": 0.5681477864583333,
        "recall": 0.6142578125
      },
      {
        "accuracy": 0.5009765625,
        "f1": 0.4568111359126984,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.4568111359126984,
        "precision": 0.4388125465029762,
        "recall": 0.5009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018437002336570594,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0018437002336570594,
        "precision": 0.0015074941339278107,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.3662109375,
        "f1": 0.3111025855654762,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.3111025855654762,
        "precision": 0.2911985367063492,
        "recall": 0.3662109375
      },
      {
        "accuracy": 0.6572265625,
        "f1": 0.6286604790982484,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.6286604790982484,
        "precision": 0.6176847647794913,
        "recall": 0.6572265625
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.6623272343975469,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.6623272343975469,
        "precision": 0.6505998883928572,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.744140625,
        "f1": 0.7198071676587301,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.7198071676587301,
        "precision": 0.709431640625,
        "recall": 0.744140625
      },
      {
        "accuracy": 0.267578125,
        "f1": 0.22294671979143965,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.22294671979143965,
        "precision": 0.20872868674860012,
        "recall": 0.267578125
      },
      {
        "accuracy": 0.333984375,
        "f1": 0.29924943109066904,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.29924943109066904,
        "precision": 0.2884569319492941,
        "recall": 0.333984375
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.0909428708280847,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.0909428708280847,
        "precision": 0.0811230442969705,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.3837890625,
        "f1": 0.3484029121919747,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3484029121919747,
        "precision": 0.33620262815241225,
        "recall": 0.3837890625
      },
      {
        "accuracy": 0.474609375,
        "f1": 0.42298172805737166,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.42298172805737166,
        "precision": 0.40671954270715577,
        "recall": 0.474609375
      },
      {
        "accuracy": 0.35546875,
        "f1": 0.31431886933595915,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.31431886933595915,
        "precision": 0.30109129833959725,
        "recall": 0.35546875
      },
      {
        "accuracy": 0.3828125,
        "f1": 0.3436359117989354,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.3436359117989354,
        "precision": 0.33078453369829897,
        "recall": 0.3828125
      },
      {
        "accuracy": 0.423828125,
        "f1": 0.39594200539704105,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.39594200539704105,
        "precision": 0.38581869259591217,
        "recall": 0.423828125
      },
      {
        "accuracy": 0.26171875,
        "f1": 0.2180395528488468,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.2180395528488468,
        "precision": 0.20481704100478515,
        "recall": 0.26171875
      },
      {
        "accuracy": 0.396484375,
        "f1": 0.3654228305905695,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.3654228305905695,
        "precision": 0.3543225523727948,
        "recall": 0.396484375
      },
      {
        "accuracy": 0.306640625,
        "f1": 0.26786526732815796,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.26786526732815796,
        "precision": 0.25488526682374335,
        "recall": 0.306640625
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.32128170803244893,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.32128170803244893,
        "precision": 0.31180584148706086,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00042357568027210886,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.00042357568027210886,
        "precision": 0.0002607623903774303,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.390625,
        "f1": 0.3574780324885224,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3574780324885224,
        "precision": 0.3468928205752216,
        "recall": 0.390625
      },
      {
        "accuracy": 0.2578125,
        "f1": 0.21501025513001254,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.21501025513001254,
        "precision": 0.20146622879718923,
        "recall": 0.2578125
      },
      {
        "accuracy": 0.322265625,
        "f1": 0.27871935786733093,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.27871935786733093,
        "precision": 0.2639015139485557,
        "recall": 0.322265625
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.25341796875,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.25341796875,
        "precision": 0.2413720881982601,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00012871359481292518,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00012871359481292518,
        "precision": 6.843714448236632e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.2929225532901489,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.2929225532901489,
        "precision": 0.2823824179292929,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.29275810665214685,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.29275810665214685,
        "precision": 0.28090052890647443,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.330078125,
        "f1": 0.29168002487453315,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.29168002487453315,
        "precision": 0.2779062774790314,
        "recall": 0.330078125
      },
      {
        "accuracy": 0.4873046875,
        "f1": 0.45024481450518783,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.45024481450518783,
        "precision": 0.4379069366347258,
        "recall": 0.4873046875
      },
      {
        "accuracy": 0.5439453125,
        "f1": 0.4730738824977106,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4730738824977106,
        "precision": 0.44483351934523807,
        "recall": 0.5439453125
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7639346168154761,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7639346168154761,
        "precision": 0.746347191220238,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.1669921875,
        "f1": 0.11088238626953434,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11088238626953434,
        "precision": 0.09800889069385557,
        "recall": 0.1669921875
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.764736793154762,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.764736793154762,
        "precision": 0.7469401041666666,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9056175595238095,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9056175595238095,
        "precision": 0.8964029947916667,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.634024677579365,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.634024677579365,
        "precision": 0.6079020182291667,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.828125,
        "f1": 0.789391966540404,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.789391966540404,
        "precision": 0.7724202473958333,
        "recall": 0.828125
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9158203125,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9158203125,
        "precision": 0.9095377604166667,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.6806640625,
        "f1": 0.6178162475927871,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6178162475927871,
        "precision": 0.5933994838169643,
        "recall": 0.6806640625
      },
      {
        "accuracy": 0.462890625,
        "f1": 0.3912744915674603,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3912744915674603,
        "precision": 0.36551695103941195,
        "recall": 0.462890625
      },
      {
        "accuracy": 0.736328125,
        "f1": 0.6834457859848484,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6834457859848484,
        "precision": 0.6608235677083334,
        "recall": 0.736328125
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8114009796626984,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8114009796626984,
        "precision": 0.7966227213541666,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.973402453710673e-05,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 3.973402453710673e-05,
        "precision": 2.0005790753538308e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8997581845238095,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8997581845238095,
        "precision": 0.8919542100694444,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.6533203125,
        "f1": 0.5912055121527777,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5912055121527777,
        "precision": 0.5664012474071067,
        "recall": 0.6533203125
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.639732142857143,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.639732142857143,
        "precision": 0.61396484375,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.650390625,
        "f1": 0.587149677579365,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.587149677579365,
        "precision": 0.5605573381696428,
        "recall": 0.650390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010440564747868002,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0010440564747868002,
        "precision": 0.00101136472734255,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.591796875,
        "f1": 0.5258913070436508,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5258913070436508,
        "precision": 0.4999701605902778,
        "recall": 0.591796875
      },
      {
        "accuracy": 0.7783203125,
        "f1": 0.7347819010416666,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7347819010416666,
        "precision": 0.7163016183035714,
        "recall": 0.7783203125
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7446335565476191,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7446335565476191,
        "precision": 0.725390625,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8751636059253247,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8751636059253247,
        "precision": 0.8649251302083333,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.580078125,
        "f1": 0.5201195126488095,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.5201195126488095,
        "precision": 0.4953055245535714,
        "recall": 0.580078125
      },
      {
        "accuracy": 0.8125,
        "f1": 0.782941158234127,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.782941158234127,
        "precision": 0.770298101963141,
        "recall": 0.8125
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.08797984170417184,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.08797984170417184,
        "precision": 0.07925015764367042,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5691429501488094,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5691429501488094,
        "precision": 0.5479747953869047,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.849609375,
        "f1": 0.8199575175632556,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.8199575175632556,
        "precision": 0.8083868117559524,
        "recall": 0.849609375
      },
      {
        "accuracy": 0.5859375,
        "f1": 0.526664806547619,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.526664806547619,
        "precision": 0.5024034288194444,
        "recall": 0.5859375
      },
      {
        "accuracy": 0.7841796875,
        "f1": 0.7522406684027778,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.7522406684027778,
        "precision": 0.7398848276289682,
        "recall": 0.7841796875
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.8119564083919553,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.8119564083919553,
        "precision": 0.8038295516523917,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.7255859375,
        "f1": 0.6737490699404762,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.6737490699404762,
        "precision": 0.6516350023674242,
        "recall": 0.7255859375
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.2900631107174076,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.2900631107174076,
        "precision": 0.2684900060876623,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.73046875,
        "f1": 0.6943160187251983,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.6943160187251983,
        "precision": 0.6793805803571429,
        "recall": 0.73046875
      },
      {
        "accuracy": 0.7802734375,
        "f1": 0.7449716605392156,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.7449716605392156,
        "precision": 0.7301717122395833,
        "recall": 0.7802734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00045138888888888887,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.00045138888888888887,
        "precision": 0.0002749819545873905,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7955354078707548,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.7955354078707548,
        "precision": 0.7857115134214744,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.693359375,
        "f1": 0.6460890997023809,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.6460890997023809,
        "precision": 0.6261981670673077,
        "recall": 0.693359375
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6715812562003969,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.6715812562003969,
        "precision": 0.6548193496148459,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.5986328125,
        "f1": 0.5419634510454823,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.5419634510454823,
        "precision": 0.5196923828125,
        "recall": 0.5986328125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003761290874880933,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0003761290874880933,
        "precision": 0.00021257377421307505,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.38515070541437735,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.38515070541437735,
        "precision": 0.3625635540674603,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7747107872596154,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.7747107872596154,
        "precision": 0.7627859933035714,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7838402157738096,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.7838402157738096,
        "precision": 0.7708170572916666,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.8525390625,
        "f1": 0.8263522930684954,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.8263522930684954,
        "precision": 0.8152804904513888,
        "recall": 0.8525390625
      },
      {
        "accuracy": 0.5947265625,
        "f1": 0.5353538876488095,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5353538876488095,
        "precision": 0.510458519345238,
        "recall": 0.5947265625
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8234235491071429,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8234235491071429,
        "precision": 0.812353515625,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.11004761287358819,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11004761287358819,
        "precision": 0.09972867107178077,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6744869171626984,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6744869171626984,
        "precision": 0.6559837704613096,
        "recall": 0.71875
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8837614054667919,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8837614054667919,
        "precision": 0.8773050394144144,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.708984375,
        "f1": 0.6674525669642857,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6674525669642857,
        "precision": 0.6498697916666667,
        "recall": 0.708984375
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.8031933867296919,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8031933867296919,
        "precision": 0.7908650716145833,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8884222109977884,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8884222109977884,
        "precision": 0.8828504774305556,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6590243252840909,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6590243252840909,
        "precision": 0.6382905505952381,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.421875,
        "f1": 0.3680826822916667,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3680826822916667,
        "precision": 0.34817047102203347,
        "recall": 0.421875
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.8119253711783008,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8119253711783008,
        "precision": 0.8023600260416667,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.7861328125,
        "f1": 0.7511166779891305,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7511166779891305,
        "precision": 0.7365776909722223,
        "recall": 0.7861328125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.4713845837076966e-05,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 2.4713845837076966e-05,
        "precision": 1.2440758293838863e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8720822704081632,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8720822704081632,
        "precision": 0.8653361002604166,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.744140625,
        "f1": 0.6928352864583333,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.6928352864583333,
        "precision": 0.6712576729910714,
        "recall": 0.744140625
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6975697596560055,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6975697596560055,
        "precision": 0.6808780533145767,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.6611328125,
        "f1": 0.6063769531250001,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.6063769531250001,
        "precision": 0.5834507533482143,
        "recall": 0.6611328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0014984446638510573,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0014984446638510573,
        "precision": 0.0012639441410638667,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.548828125,
        "f1": 0.495135013640873,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.495135013640873,
        "precision": 0.47509644208560614,
        "recall": 0.548828125
      },
      {
        "accuracy": 0.8056640625,
        "f1": 0.7771158854166667,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7771158854166667,
        "precision": 0.76435546875,
        "recall": 0.8056640625
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.804736328125,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.804736328125,
        "precision": 0.7921316964285714,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8799153645833333,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8799153645833333,
        "precision": 0.87367741308171,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.3731773997569864e-06,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 2.3731773997569864e-06,
        "precision": 1.1880322384428224e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1183568329718005e-06,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 2.1183568329718005e-06,
        "precision": 1.060328447339848e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000391756697585771,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.000391756697585771,
        "precision": 0.00021563875320556642,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9110812133072406e-06,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 1.9110812133072406e-06,
        "precision": 9.564764936336925e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.2346967963386728e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.2346967963386728e-06,
        "precision": 1.1186282932416954e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.061324451410658e-06,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 3.061324451410658e-06,
        "precision": 1.5330651491365778e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.944620253164557e-06,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 4.944620253164557e-06,
        "precision": 2.4785850253807105e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.0850694444444445e-05,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 1.0850694444444445e-05,
        "precision": 5.455656424581006e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.342869178921569e-05,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 6.342869178921569e-05,
        "precision": 3.2700252325351275e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00017957450929752066,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00017957450929752066,
        "precision": 9.866613883143744e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.8233595646386345e-05,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 3.8233595646386345e-05,
        "precision": 1.945910701806928e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.5968828846092428e-05,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 1.5968828846092428e-05,
        "precision": 8.03444566538669e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9357036669970267e-06,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 1.9357036669970267e-06,
        "precision": 9.68812003968254e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.2380880485614295e-05,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 2.2380880485614295e-05,
        "precision": 1.125861528822055e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.914828431372549e-06,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 1.914828431372549e-06,
        "precision": 9.583537782139352e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 2.1028268886131787e-05,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 2.1028268886131787e-05,
        "precision": 1.0556982841065839e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.0498795303334196,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.0498795303334196,
        "precision": 0.043466829050793444,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010674549624594607,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0010674549624594607,
        "precision": 0.0010237902171517078,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.5155415450078336e-05,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 3.5155415450078336e-05,
        "precision": 1.786416408317923e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9299654150197627e-06,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 1.9299654150197627e-06,
        "precision": 9.659371909000989e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9054878048780488e-06,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 1.9054878048780488e-06,
        "precision": 9.5367431640625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.6552734375,
        "f1": 0.5880402800324676,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5880402800324676,
        "precision": 0.560546875,
        "recall": 0.6552734375
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8882486979166666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8882486979166666,
        "precision": 0.877197265625,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.11046846471046476,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11046846471046476,
        "precision": 0.09647847706872023,
        "recall": 0.1689453125
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7566917782738096,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7566917782738096,
        "precision": 0.7365234375,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9655598958333333,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9655598958333333,
        "precision": 0.9618326822916667,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6872721354166667,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6872721354166667,
        "precision": 0.6638346354166667,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8722594246031745,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8722594246031745,
        "precision": 0.8607177734375,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9824869791666666,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9824869791666666,
        "precision": 0.980712890625,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.759765625,
        "f1": 0.7020066034226191,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7020066034226191,
        "precision": 0.6778847346230159,
        "recall": 0.759765625
      },
      {
        "accuracy": 0.46875,
        "f1": 0.39199761284722223,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.39199761284722223,
        "precision": 0.3643435259402056,
        "recall": 0.46875
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9076171875,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9076171875,
        "precision": 0.898193359375,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.7934105282738094,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7934105282738094,
        "precision": 0.7746907552083333,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8917317708333333,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8917317708333333,
        "precision": 0.8805338541666666,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005070920850409836,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0005070920850409836,
        "precision": 0.0003349725969201649,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.7822265625,
        "f1": 0.7306501116071429,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7306501116071429,
        "precision": 0.7086499763257577,
        "recall": 0.7822265625
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7783365885416667,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7783365885416667,
        "precision": 0.7582775297619048,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6592385912698412,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.6592385912698412,
        "precision": 0.6329857235863096,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0009839200792694648,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009839200792694648,
        "precision": 0.0006626007418955688,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.6025390625,
        "f1": 0.534965587797619,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.534965587797619,
        "precision": 0.5084418402777778,
        "recall": 0.6025390625
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8703450520833333,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8703450520833333,
        "precision": 0.8565266927083334,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8521019345238094,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8521019345238094,
        "precision": 0.8385416666666667,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9609375,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9609375,
        "precision": 0.9569010416666666,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.4516353546626984,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.4516353546626984,
        "precision": 0.4283989800347222,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.724609375,
        "f1": 0.6876240079365079,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.6876240079365079,
        "precision": 0.6721952174040262,
        "recall": 0.724609375
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04217395742718427,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.04217395742718427,
        "precision": 0.035253090079644084,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.486328125,
        "f1": 0.43112993777056274,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.43112993777056274,
        "precision": 0.41046232413419914,
        "recall": 0.486328125
      },
      {
        "accuracy": 0.7421875,
        "f1": 0.6966208251766616,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.6966208251766616,
        "precision": 0.6786598488136575,
        "recall": 0.7421875
      },
      {
        "accuracy": 0.44921875,
        "f1": 0.39857087899080085,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.39857087899080085,
        "precision": 0.38003859747023805,
        "recall": 0.44921875
      },
      {
        "accuracy": 0.6982421875,
        "f1": 0.6561732700892857,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.6561732700892857,
        "precision": 0.6392907873376623,
        "recall": 0.6982421875
      },
      {
        "accuracy": 0.755859375,
        "f1": 0.7258235254329004,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.7258235254329004,
        "precision": 0.714179236147584,
        "recall": 0.755859375
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5951788784674527,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.5951788784674527,
        "precision": 0.5731039536530338,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.2089681694173882,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.2089681694173882,
        "precision": 0.1932853577628968,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.6162109375,
        "f1": 0.5682168363320707,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.5682168363320707,
        "precision": 0.5496725415426587,
        "recall": 0.6162109375
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6240800865800866,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.6240800865800866,
        "precision": 0.6065140335648148,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.67578125,
        "f1": 0.6279720487091411,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.6279720487091411,
        "precision": 0.6088415897253788,
        "recall": 0.67578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 4.881841820054369e-05,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 4.881841820054369e-05,
        "precision": 2.464287687886826e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6701980364945603,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.6701980364945603,
        "precision": 0.6549152236652237,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.6708984375,
        "f1": 0.6250372023809524,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.6250372023809524,
        "precision": 0.6060167100694445,
        "recall": 0.6708984375
      },
      {
        "accuracy": 0.4794921875,
        "f1": 0.4223082527281746,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.4223082527281746,
        "precision": 0.4004568917410714,
        "recall": 0.4794921875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00017336035976890757,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00017336035976890757,
        "precision": 9.132218068955874e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.3349609375,
        "f1": 0.28231685577876986,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.28231685577876986,
        "precision": 0.26421712239583334,
        "recall": 0.3349609375
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.6205264136904762,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.6205264136904762,
        "precision": 0.6017252604166666,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6842408942617153,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.6842408942617153,
        "precision": 0.6683761876144689,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.7103326735820792,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.7103326735820792,
        "precision": 0.6933252728174604,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.525390625,
        "f1": 0.4551022219967532,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.4551022219967532,
        "precision": 0.4282552083333333,
        "recall": 0.525390625
      },
      {
        "accuracy": 0.767578125,
        "f1": 0.7197986421130952,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.7197986421130952,
        "precision": 0.700296843998016,
        "recall": 0.767578125
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.07391721585195851,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.07391721585195851,
        "precision": 0.06405859539404461,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.6044921875,
        "f1": 0.5455171130952381,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.5455171130952381,
        "precision": 0.5222819010416666,
        "recall": 0.6044921875
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7710774739583333,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.7710774739583333,
        "precision": 0.7537384869904401,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.5224609375,
        "f1": 0.4669828869047619,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.4669828869047619,
        "precision": 0.44515206473214286,
        "recall": 0.5224609375
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7118939112103174,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.7118939112103174,
        "precision": 0.6944254557291667,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.7911972394308102,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.7911972394308102,
        "precision": 0.7783111460479625,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.640625,
        "f1": 0.5731880044868327,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.5731880044868327,
        "precision": 0.5463739304315476,
        "recall": 0.640625
      },
      {
        "accuracy": 0.3447265625,
        "f1": 0.2893423633658009,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.2893423633658009,
        "precision": 0.2696386295995671,
        "recall": 0.3447265625
      },
      {
        "accuracy": 0.66015625,
        "f1": 0.609327017383658,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.609327017383658,
        "precision": 0.5887951078869048,
        "recall": 0.66015625
      },
      {
        "accuracy": 0.7216796875,
        "f1": 0.6692553323412698,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.6692553323412698,
        "precision": 0.6475613064236111,
        "recall": 0.7216796875
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6633951822916666,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.6633951822916666,
        "precision": 0.6437042124542124,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 4.519061500730113e-05,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 4.519061500730113e-05,
        "precision": 2.277557227365674e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.7685546875,
        "f1": 0.7271423075622294,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.7271423075622294,
        "precision": 0.7104142818986567,
        "recall": 0.7685546875
      },
      {
        "accuracy": 0.677734375,
        "f1": 0.6186763702876984,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.6186763702876984,
        "precision": 0.5944618830605158,
        "recall": 0.677734375
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.4726422991071429,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.4726422991071429,
        "precision": 0.448162780145202,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00037056413090420445,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.00037056413090420445,
        "precision": 0.0001973965913987729,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.3482800456921551,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.3482800456921551,
        "precision": 0.3258471292162698,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.6846417994281047,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.6846417994281047,
        "precision": 0.6638224283854166,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.748046875,
        "f1": 0.6994489397321428,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.6994489397321428,
        "precision": 0.6800168960813492,
        "recall": 0.748046875
      },
      {
        "accuracy": 0.8095703125,
        "f1": 0.7712751116071428,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.7712751116071428,
        "precision": 0.755300564236111,
        "recall": 0.8095703125
      },
      {
        "accuracy": 0.38671875,
        "f1": 0.32651057167658726,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.32651057167658726,
        "precision": 0.305305284992785,
        "recall": 0.38671875
      },
      {
        "accuracy": 0.5517578125,
        "f1": 0.5117447529141865,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5117447529141865,
        "precision": 0.4963766264374253,
        "recall": 0.5517578125
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.08486570936446179,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.08486570936446179,
        "precision": 0.07636858223189472,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.474609375,
        "f1": 0.4246687851426166,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4246687851426166,
        "precision": 0.40746265132379955,
        "recall": 0.474609375
      },
      {
        "accuracy": 0.6279296875,
        "f1": 0.5767291356646825,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5767291356646825,
        "precision": 0.5570190890996103,
        "recall": 0.6279296875
      },
      {
        "accuracy": 0.44140625,
        "f1": 0.39370666768127704,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.39370666768127704,
        "precision": 0.3782585641241069,
        "recall": 0.44140625
      },
      {
        "accuracy": 0.5556640625,
        "f1": 0.5174670186584249,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5174670186584249,
        "precision": 0.5042622024315908,
        "recall": 0.5556640625
      },
      {
        "accuracy": 0.619140625,
        "f1": 0.5854794668945409,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5854794668945409,
        "precision": 0.5729483380118146,
        "recall": 0.619140625
      },
      {
        "accuracy": 0.4677734375,
        "f1": 0.41439569621934286,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.41439569621934286,
        "precision": 0.39615658093505546,
        "recall": 0.4677734375
      },
      {
        "accuracy": 0.291015625,
        "f1": 0.24610972429310574,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.24610972429310574,
        "precision": 0.23044958513708513,
        "recall": 0.291015625
      },
      {
        "accuracy": 0.5634765625,
        "f1": 0.5280395787576394,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5280395787576394,
        "precision": 0.5159265886653823,
        "recall": 0.5634765625
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.4677205298970658,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4677205298970658,
        "precision": 0.45105382396211324,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.531849135022963,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.531849135022963,
        "precision": 0.5201763649761697,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.510418375157181e-05,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 8.510418375157181e-05,
        "precision": 4.331977377404146e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.619140625,
        "f1": 0.587147298260422,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.587147298260422,
        "precision": 0.5758661881720982,
        "recall": 0.619140625
      },
      {
        "accuracy": 0.427734375,
        "f1": 0.3748590889362374,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3748590889362374,
        "precision": 0.356640247843755,
        "recall": 0.427734375
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.43636129927261413,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.43636129927261413,
        "precision": 0.4211819830302811,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007247969959310267,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007247969959310267,
        "precision": 0.0004223306339347774,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.33203125,
        "f1": 0.2867110852802089,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2867110852802089,
        "precision": 0.2716369151872943,
        "recall": 0.33203125
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.4526344766116559,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4526344766116559,
        "precision": 0.4392423935720121,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.5028065646644672,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5028065646644672,
        "precision": 0.48481853964031696,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5642215965458153,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5642215965458153,
        "precision": 0.5479056031455423,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009787064352360043,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0009787064352360043,
        "precision": 0.0009776356456043956,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.000639329776453892,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.000639329776453892,
        "precision": 0.000362955290663285,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.912952987267385e-06,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 1.912952987267385e-06,
        "precision": 9.574142156862745e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010050250694285388,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0010050250694285388,
        "precision": 0.000990975659691454,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010266426282051282,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0010266426282051282,
        "precision": 0.0010022615131578948,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009878195208093523,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0009878195208093523,
        "precision": 0.0009822075553420698,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009924415650406505,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0009924415650406505,
        "precision": 0.0009845671106557376,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019758621944121073,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.00019758621944121073,
        "precision": 0.00010964512917637917,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011955572458868607,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0011955572458868607,
        "precision": 0.0010996242465101524,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010250978643278333,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0010250978643278333,
        "precision": 0.0010013983501651422,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014820672535516286,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0014820672535516286,
        "precision": 0.0013107545576501228,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.04146719337406015,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.04146719337406015,
        "precision": 0.03589863997707336,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000978481090373281,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.000978481090373281,
        "precision": 0.000977522738446411,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009817987600536193,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0009817987600536193,
        "precision": 0.0009791876680107527,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9204768928220257e-06,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 1.9204768928220257e-06,
        "precision": 9.61183562992126e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000995509285234764,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.000995509285234764,
        "precision": 0.0009860687353757621,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0029384299555629853,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0029384299555629853,
        "precision": 0.0029340685698621555,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001955138530927835,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.001955138530927835,
        "precision": 0.0019541328044375642,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001955068407960199,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.001955068407960199,
        "precision": 0.001954097671812749,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009784698486328125,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0009784698486328125,
        "precision": 0.0009775171065493646,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.3125,
        "f1": 0.2639198811545255,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.2639198811545255,
        "precision": 0.2467610433186605,
        "recall": 0.3125
      },
      {
        "accuracy": 0.42578125,
        "f1": 0.37577261605581913,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.37577261605581913,
        "precision": 0.35920233033026,
        "recall": 0.42578125
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.1348457946420063,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1348457946420063,
        "precision": 0.12205467329979047,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.5625,
        "f1": 0.5195948040674603,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5195948040674603,
        "precision": 0.5042576753758394,
        "recall": 0.5625
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5710351985254329,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5710351985254329,
        "precision": 0.5532376728360615,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.4716796875,
        "f1": 0.42134016699446386,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.42134016699446386,
        "precision": 0.40376280620421245,
        "recall": 0.4716796875
      },
      {
        "accuracy": 0.5009765625,
        "f1": 0.4537752666170635,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.4537752666170635,
        "precision": 0.4381288767733143,
        "recall": 0.5009765625
      },
      {
        "accuracy": 0.6025390625,
        "f1": 0.5645038065128476,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5645038065128476,
        "precision": 0.5522114840655414,
        "recall": 0.6025390625
      },
      {
        "accuracy": 0.375,
        "f1": 0.31816887356994056,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.31816887356994056,
        "precision": 0.2996313406103445,
        "recall": 0.375
      },
      {
        "accuracy": 0.357421875,
        "f1": 0.3083333333333333,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3083333333333333,
        "precision": 0.290701934574448,
        "recall": 0.357421875
      },
      {
        "accuracy": 0.546875,
        "f1": 0.5053750335854829,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5053750335854829,
        "precision": 0.49113698308743037,
        "recall": 0.546875
      },
      {
        "accuracy": 0.3994140625,
        "f1": 0.3506428610834631,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3506428610834631,
        "precision": 0.3350287619798594,
        "recall": 0.3994140625
      },
      {
        "accuracy": 0.5263671875,
        "f1": 0.479622882284393,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.479622882284393,
        "precision": 0.4648586453151882,
        "recall": 0.5263671875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012253018266182637,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0012253018266182637,
        "precision": 0.0011106916725023344,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.552734375,
        "f1": 0.5054617325617199,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5054617325617199,
        "precision": 0.4894040890845521,
        "recall": 0.552734375
      },
      {
        "accuracy": 0.3447265625,
        "f1": 0.2946371600664488,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2946371600664488,
        "precision": 0.2784461327875275,
        "recall": 0.3447265625
      },
      {
        "accuracy": 0.384765625,
        "f1": 0.33179066755726916,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.33179066755726916,
        "precision": 0.3145104895104895,
        "recall": 0.384765625
      },
      {
        "accuracy": 0.3759765625,
        "f1": 0.3259500915750916,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.3259500915750916,
        "precision": 0.3090982829019938,
        "recall": 0.3759765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007201465164181624,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007201465164181624,
        "precision": 0.0004076959008443633,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.4267578125,
        "f1": 0.3749901038207404,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3749901038207404,
        "precision": 0.35844959664539744,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.4560546875,
        "f1": 0.3982466849372967,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3982466849372967,
        "precision": 0.3792281045328594,
        "recall": 0.4560546875
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.5159191313244047,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5159191313244047,
        "precision": 0.4987080275410354,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.5908203125,
        "f1": 0.5228639632936507,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.5228639632936507,
        "precision": 0.4955810546875001,
        "recall": 0.5908203125
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.8001325334821427,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8001325334821427,
        "precision": 0.7861095610119048,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.07643946358545968,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.07643946358545968,
        "precision": 0.06536199400677728,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5926269531249999,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.5926269531249999,
        "precision": 0.5691662016369047,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8701488095238095,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.8701488095238095,
        "precision": 0.8612386067708333,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.6123046875,
        "f1": 0.5528041294642857,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.5528041294642857,
        "precision": 0.5283962673611111,
        "recall": 0.6123046875
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.7608568948412698,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7608568948412698,
        "precision": 0.7450788225446429,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8566662016369048,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.8566662016369048,
        "precision": 0.8483758591668747,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.7021484375,
        "f1": 0.6409396701388889,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.6409396701388889,
        "precision": 0.6158718532986112,
        "recall": 0.7021484375
      },
      {
        "accuracy": 0.3779296875,
        "f1": 0.30921820150335777,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.30921820150335777,
        "precision": 0.2862615059636544,
        "recall": 0.3779296875
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7205337317136886,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.7205337317136886,
        "precision": 0.7046549479166666,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.768603515625,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.768603515625,
        "precision": 0.7519949776785714,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7710672790750915,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.7710672790750915,
        "precision": 0.7556966145833334,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005717714777209969,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0005717714777209969,
        "precision": 0.00036791511633488727,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8290604848710317,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.8290604848710317,
        "precision": 0.8186324114960748,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6488018437725469,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.6488018437725469,
        "precision": 0.6270844959077381,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.736328125,
        "f1": 0.6901340060763889,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.6901340060763889,
        "precision": 0.6703834170386904,
        "recall": 0.736328125
      },
      {
        "accuracy": 0.591796875,
        "f1": 0.5304719206574675,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.5304719206574675,
        "precision": 0.5062755766369047,
        "recall": 0.591796875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0014957812362024815,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0014957812362024815,
        "precision": 0.0010039448375759878,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.46875,
        "f1": 0.40291251717032966,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.40291251717032966,
        "precision": 0.3781202900831807,
        "recall": 0.46875
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7868675595238095,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.7868675595238095,
        "precision": 0.7727647569444445,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.851973896329365,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.851973896329365,
        "precision": 0.8418294270833333,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.5751953125,
        "f1": 0.5076543898809524,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.5076543898809524,
        "precision": 0.4809353298611111,
        "recall": 0.5751953125
      },
      {
        "accuracy": 0.8076171875,
        "f1": 0.7786724668560605,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.7786724668560605,
        "precision": 0.7662662003391473,
        "recall": 0.8076171875
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.08451573507725851,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.08451573507725851,
        "precision": 0.07401547681473301,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.6669921875,
        "f1": 0.6121930803571428,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.6121930803571428,
        "precision": 0.589311290922619,
        "recall": 0.6669921875
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8477957589285714,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8477957589285714,
        "precision": 0.8380517756982601,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.6103515625,
        "f1": 0.5557212969322345,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.5557212969322345,
        "precision": 0.5340603298611111,
        "recall": 0.6103515625
      },
      {
        "accuracy": 0.8125,
        "f1": 0.7818739149305556,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.7818739149305556,
        "precision": 0.7695723628584956,
        "recall": 0.8125
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8392027309484649,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.8392027309484649,
        "precision": 0.8312031094990079,
        "recall": 0.859375
      },
      {
        "accuracy": 0.75,
        "f1": 0.6991396949404761,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.6991396949404761,
        "precision": 0.677490234375,
        "recall": 0.75
      },
      {
        "accuracy": 0.3798828125,
        "f1": 0.3180347628015367,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.3180347628015367,
        "precision": 0.2965043325272817,
        "recall": 0.3798828125
      },
      {
        "accuracy": 0.771484375,
        "f1": 0.7376844618055556,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.7376844618055556,
        "precision": 0.7235978951790845,
        "recall": 0.771484375
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.761662241838023,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.761662241838023,
        "precision": 0.7454020182291666,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7919456845238095,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.7919456845238095,
        "precision": 0.7797309027777778,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0008579030736187178,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0008579030736187178,
        "precision": 0.0005271286723979044,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.8184105282738094,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8184105282738094,
        "precision": 0.8083025698260073,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.6852608816964286,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.6852608816964286,
        "precision": 0.6651460193452381,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.7421875,
        "f1": 0.7049530564692983,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.7049530564692983,
        "precision": 0.6894422743055555,
        "recall": 0.7421875
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5656775841346153,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.5656775841346153,
        "precision": 0.5427920386904761,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00028975214097496705,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.00028975214097496705,
        "precision": 0.00015784876511166482,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.458984375,
        "f1": 0.3931693686088217,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.3931693686088217,
        "precision": 0.36807570684523805,
        "recall": 0.458984375
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7854041466346153,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.7854041466346153,
        "precision": 0.7723795572916667,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8450892857142858,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.8450892857142858,
        "precision": 0.8348679315476191,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.5905133928571429,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.5905133928571429,
        "precision": 0.5582139756944444,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.90966796875,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.90966796875,
        "precision": 0.9002278645833333,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.10629635130380402,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.10629635130380402,
        "precision": 0.09184647623891486,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.80859375,
        "f1": 0.7619652157738095,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7619652157738095,
        "precision": 0.7409179687499999,
        "recall": 0.80859375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.74609375,
        "f1": 0.6943684895833333,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6943684895833333,
        "precision": 0.67138671875,
        "recall": 0.74609375
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8923177083333333,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.8923177083333333,
        "precision": 0.8814290364583333,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9798828124999999,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9798828124999999,
        "precision": 0.977783203125,
        "recall": 0.984375
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.6955496651785714,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.6955496651785714,
        "precision": 0.668212890625,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.537109375,
        "f1": 0.46844695560515875,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.46844695560515875,
        "precision": 0.4432919456845238,
        "recall": 0.537109375
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.90234375,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.90234375,
        "precision": 0.8926106770833333,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.861328125,
        "f1": 0.8250325520833333,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8250325520833333,
        "precision": 0.8085774739583333,
        "recall": 0.861328125
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8833658854166666,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.8833658854166666,
        "precision": 0.871337890625,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 6.517053521033474e-05,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 6.517053521033474e-05,
        "precision": 3.304636995902095e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9685872395833333,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9685872395833333,
        "precision": 0.9651692708333334,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.80078125,
        "f1": 0.75126953125,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.75126953125,
        "precision": 0.7293131510416666,
        "recall": 0.80078125
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8062499999999999,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8062499999999999,
        "precision": 0.7888997395833333,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.701171875,
        "f1": 0.6366466703869047,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.6366466703869047,
        "precision": 0.6109305245535714,
        "recall": 0.701171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00011916238837159395,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00011916238837159395,
        "precision": 6.078473179757829e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.611328125,
        "f1": 0.544438244047619,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.544438244047619,
        "precision": 0.5187031447285353,
        "recall": 0.611328125
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8822265625,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8822265625,
        "precision": 0.8702311197916667,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.8486979166666666,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8486979166666666,
        "precision": 0.833251953125,
        "recall": 0.880859375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}