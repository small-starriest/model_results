{
  "dataset_revision": "46958b007a63fdbf239b7672c25d0bea67b5ea1a",
  "evaluation_time": 19.50262475013733,
  "kg_co2_emissions": 0.002902788029668077,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.41869999999999996,
        "f1": 0.4177162540202916,
        "f1_weighted": 0.4177162540202916,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.41869999999999996,
        "scores_per_experiment": [
          {
            "accuracy": 0.43033333333333335,
            "f1": 0.4304696910034523,
            "f1_weighted": 0.4304696910034523
          },
          {
            "accuracy": 0.36666666666666664,
            "f1": 0.36629043302296765,
            "f1_weighted": 0.36629043302296765
          },
          {
            "accuracy": 0.4063333333333333,
            "f1": 0.40689826495154074,
            "f1_weighted": 0.4068982649515408
          },
          {
            "accuracy": 0.4136666666666667,
            "f1": 0.4145427377710566,
            "f1_weighted": 0.41454273777105655
          },
          {
            "accuracy": 0.4156666666666667,
            "f1": 0.4150319283068052,
            "f1_weighted": 0.4150319283068052
          },
          {
            "accuracy": 0.43466666666666665,
            "f1": 0.43059660369345965,
            "f1_weighted": 0.43059660369345965
          },
          {
            "accuracy": 0.43,
            "f1": 0.42801244940494243,
            "f1_weighted": 0.4280124494049425
          },
          {
            "accuracy": 0.43166666666666664,
            "f1": 0.4304853755985964,
            "f1_weighted": 0.4304853755985964
          },
          {
            "accuracy": 0.424,
            "f1": 0.4222726618081117,
            "f1_weighted": 0.4222726618081116
          },
          {
            "accuracy": 0.434,
            "f1": 0.4325623946419837,
            "f1_weighted": 0.4325623946419837
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4128333333333334,
        "f1": 0.4117690682370892,
        "f1_weighted": 0.41176906823708903,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.4128333333333334,
        "scores_per_experiment": [
          {
            "accuracy": 0.41633333333333333,
            "f1": 0.4162424502818049,
            "f1_weighted": 0.41624245028180484
          },
          {
            "accuracy": 0.356,
            "f1": 0.3551692509491153,
            "f1_weighted": 0.3551692509491152
          },
          {
            "accuracy": 0.39966666666666667,
            "f1": 0.40008963916724255,
            "f1_weighted": 0.40008963916724255
          },
          {
            "accuracy": 0.4116666666666667,
            "f1": 0.41177555107950264,
            "f1_weighted": 0.4117755510795026
          },
          {
            "accuracy": 0.42633333333333334,
            "f1": 0.42425841124339825,
            "f1_weighted": 0.42425841124339825
          },
          {
            "accuracy": 0.42433333333333334,
            "f1": 0.4206595622929125,
            "f1_weighted": 0.42065956229291246
          },
          {
            "accuracy": 0.43433333333333335,
            "f1": 0.4327089274468244,
            "f1_weighted": 0.43270892744682443
          },
          {
            "accuracy": 0.409,
            "f1": 0.407542487226166,
            "f1_weighted": 0.40754248722616604
          },
          {
            "accuracy": 0.4266666666666667,
            "f1": 0.426009672353995,
            "f1_weighted": 0.426009672353995
          },
          {
            "accuracy": 0.424,
            "f1": 0.4232347303299293,
            "f1_weighted": 0.4232347303299293
          }
        ]
      }
    ]
  },
  "task_name": "MultilingualSentiment"
}