{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 30.535186052322388,
  "kg_co2_emissions": 0.005579684017366948,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.575,
        "f1": 0.4561453451550512,
        "f1_weighted": 0.6108984273799323,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.575,
        "scores_per_experiment": [
          {
            "accuracy": 0.5865384615384616,
            "f1": 0.4619769456938684,
            "f1_weighted": 0.6293161294767697
          },
          {
            "accuracy": 0.625,
            "f1": 0.48609869520068627,
            "f1_weighted": 0.6646316729006693
          },
          {
            "accuracy": 0.5769230769230769,
            "f1": 0.47315985549785505,
            "f1_weighted": 0.6207426576584401
          },
          {
            "accuracy": 0.5865384615384616,
            "f1": 0.4571175278622087,
            "f1_weighted": 0.6309796586392332
          },
          {
            "accuracy": 0.6634615384615384,
            "f1": 0.49458204334365324,
            "f1_weighted": 0.6890231801222514
          },
          {
            "accuracy": 0.4423076923076923,
            "f1": 0.35793204922418403,
            "f1_weighted": 0.454337984113265
          },
          {
            "accuracy": 0.6057692307692307,
            "f1": 0.5058808054718515,
            "f1_weighted": 0.6485034456622919
          },
          {
            "accuracy": 0.6538461538461539,
            "f1": 0.4907166406385563,
            "f1_weighted": 0.6819998932180089
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.4091198979591837,
            "f1_weighted": 0.536421539769754
          },
          {
            "accuracy": 0.5,
            "f1": 0.4248689906584643,
            "f1_weighted": 0.5530281122386385
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5666666666666667,
        "f1": 0.4403080846032529,
        "f1_weighted": 0.6130243498065309,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5666666666666667,
        "scores_per_experiment": [
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.4428773584905661,
            "f1_weighted": 0.6174681042228212
          },
          {
            "accuracy": 0.580952380952381,
            "f1": 0.45810196362465794,
            "f1_weighted": 0.6469273336245814
          },
          {
            "accuracy": 0.5238095238095238,
            "f1": 0.429657725452118,
            "f1_weighted": 0.6049580681890429
          },
          {
            "accuracy": 0.6,
            "f1": 0.45918367346938777,
            "f1_weighted": 0.6477162293488824
          },
          {
            "accuracy": 0.6,
            "f1": 0.43055812519272274,
            "f1_weighted": 0.6244647078689631
          },
          {
            "accuracy": 0.45714285714285713,
            "f1": 0.36533813446455876,
            "f1_weighted": 0.49205581902272083
          },
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.48122529644268774,
            "f1_weighted": 0.6242173285651548
          },
          {
            "accuracy": 0.6095238095238096,
            "f1": 0.4373723621511232,
            "f1_weighted": 0.6290295741623175
          },
          {
            "accuracy": 0.5904761904761905,
            "f1": 0.44603761948812826,
            "f1_weighted": 0.6303687062243954
          },
          {
            "accuracy": 0.5619047619047619,
            "f1": 0.45272858725657733,
            "f1_weighted": 0.6130376268364287
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}