{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "evaluation_time": 6.96406364440918,
  "kg_co2_emissions": 0.0010807341004093565,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.258349609375,
        "f1": 0.22807852280931215,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "lrap": 0.3751627604166591,
        "main_score": 0.258349609375,
        "scores_per_experiment": [
          {
            "accuracy": 0.240234375,
            "f1": 0.16827564150195523,
            "lrap": 0.32877604166665936
          },
          {
            "accuracy": 0.25732421875,
            "f1": 0.22975291425272268,
            "lrap": 0.3761664496527703
          },
          {
            "accuracy": 0.24267578125,
            "f1": 0.20275305432974844,
            "lrap": 0.3616129557291589
          },
          {
            "accuracy": 0.275390625,
            "f1": 0.2351175909853057,
            "lrap": 0.38749186197915875
          },
          {
            "accuracy": 0.224609375,
            "f1": 0.18549097097379943,
            "lrap": 0.3343370225694371
          },
          {
            "accuracy": 0.2646484375,
            "f1": 0.2276780216401926,
            "lrap": 0.3699408637152702
          },
          {
            "accuracy": 0.271484375,
            "f1": 0.27100130794905497,
            "lrap": 0.39539252387151996
          },
          {
            "accuracy": 0.263671875,
            "f1": 0.2520261594459406,
            "lrap": 0.41128879123263096
          },
          {
            "accuracy": 0.29248046875,
            "f1": 0.26585189510452073,
            "lrap": 0.41156684027776996
          },
          {
            "accuracy": 0.2509765625,
            "f1": 0.24283767190988106,
            "lrap": 0.37505425347221466
          }
        ]
      }
    ]
  },
  "task_name": "SensitiveTopicsClassification"
}