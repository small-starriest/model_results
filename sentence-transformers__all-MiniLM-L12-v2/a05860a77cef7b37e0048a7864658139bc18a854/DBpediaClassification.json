{
  "dataset_revision": "9abd46cf7fc8b4c64290f26993c540b92aa145ac",
  "evaluation_time": 10.3937828540802,
  "kg_co2_emissions": 0.0015746782510455066,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.871533203125,
        "f1": 0.8672795205870371,
        "f1_weighted": 0.8673139046569276,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.871533203125,
        "scores_per_experiment": [
          {
            "accuracy": 0.8671875,
            "f1": 0.8626101903247878,
            "f1_weighted": 0.8626266622256857
          },
          {
            "accuracy": 0.87890625,
            "f1": 0.8754515744381614,
            "f1_weighted": 0.8754764867443026
          },
          {
            "accuracy": 0.87353515625,
            "f1": 0.8698936792064098,
            "f1_weighted": 0.86994486231556
          },
          {
            "accuracy": 0.85693359375,
            "f1": 0.8507122896671412,
            "f1_weighted": 0.8507558653169044
          },
          {
            "accuracy": 0.86962890625,
            "f1": 0.8660117783719475,
            "f1_weighted": 0.8660282415088796
          },
          {
            "accuracy": 0.884765625,
            "f1": 0.8819785567174581,
            "f1_weighted": 0.881969058603408
          },
          {
            "accuracy": 0.87353515625,
            "f1": 0.8689605615805612,
            "f1_weighted": 0.8689999402776329
          },
          {
            "accuracy": 0.87841796875,
            "f1": 0.8745275617767184,
            "f1_weighted": 0.8745774025407924
          },
          {
            "accuracy": 0.87451171875,
            "f1": 0.870777916996066,
            "f1_weighted": 0.8708043204011973
          },
          {
            "accuracy": 0.85791015625,
            "f1": 0.8518710967911192,
            "f1_weighted": 0.8519562066349126
          }
        ]
      }
    ]
  },
  "task_name": "DBpediaClassification"
}