{
  "dataset_revision": "3f756ab4572e071eb53e887ab629f19fa747d39e",
  "evaluation_time": 10.887115478515625,
  "kg_co2_emissions": 0.001636199846282925,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.5820143884892086,
        "ap": 0.5512691568584224,
        "ap_weighted": 0.5512691568584224,
        "f1": 0.577430801230417,
        "f1_weighted": 0.577430801230417,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ],
        "main_score": 0.5820143884892086,
        "scores_per_experiment": [
          {
            "accuracy": 0.60431654676259,
            "ap": 0.5621920374148442,
            "ap_weighted": 0.5621920374148442,
            "f1": 0.6036084207285705,
            "f1_weighted": 0.6036084207285705
          },
          {
            "accuracy": 0.6560251798561151,
            "ap": 0.6093803404553297,
            "ap_weighted": 0.6093803404553297,
            "f1": 0.6516586731638404,
            "f1_weighted": 0.6516586731638404
          },
          {
            "accuracy": 0.6294964028776978,
            "ap": 0.5848858710008236,
            "ap_weighted": 0.5848858710008236,
            "f1": 0.6268866637619666,
            "f1_weighted": 0.6268866637619666
          },
          {
            "accuracy": 0.5301258992805755,
            "ap": 0.5159632329818571,
            "ap_weighted": 0.5159632329818571,
            "f1": 0.5301182043612183,
            "f1_weighted": 0.5301182043612184
          },
          {
            "accuracy": 0.585431654676259,
            "ap": 0.5558061615223949,
            "ap_weighted": 0.5558061615223949,
            "f1": 0.564098813973817,
            "f1_weighted": 0.5640988139738169
          },
          {
            "accuracy": 0.5148381294964028,
            "ap": 0.507588496676707,
            "ap_weighted": 0.507588496676707,
            "f1": 0.5037117755367986,
            "f1_weighted": 0.5037117755367985
          },
          {
            "accuracy": 0.5710431654676259,
            "ap": 0.5417300009549881,
            "ap_weighted": 0.5417300009549881,
            "f1": 0.5672579887218046,
            "f1_weighted": 0.5672579887218044
          },
          {
            "accuracy": 0.529226618705036,
            "ap": 0.515376253214296,
            "ap_weighted": 0.515376253214296,
            "f1": 0.5275369499807954,
            "f1_weighted": 0.5275369499807953
          },
          {
            "accuracy": 0.5998201438848921,
            "ap": 0.5595616712205149,
            "ap_weighted": 0.5595616712205149,
            "f1": 0.5997152610376795,
            "f1_weighted": 0.5997152610376795
          },
          {
            "accuracy": 0.5998201438848921,
            "ap": 0.5602075031424675,
            "ap_weighted": 0.5602075031424675,
            "f1": 0.5997152610376795,
            "f1_weighted": 0.5997152610376795
          }
        ]
      }
    ]
  },
  "task_name": "DutchBookReviewSentimentClassification"
}