{
  "dataset_revision": "557bf94ac6177cc442f42d0b09b6e4b76e8f47c9",
  "evaluation_time": 10.11212968826294,
  "kg_co2_emissions": 0.0015215542657458056,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.5119431279620853,
        "ap": 0.1994472003569248,
        "ap_weighted": 0.1994472003569248,
        "f1": 0.46942149230438135,
        "f1_weighted": 0.5671861834665957,
        "hf_subset": "default",
        "languages": [
          "ara-Arab"
        ],
        "main_score": 0.5119431279620853,
        "scores_per_experiment": [
          {
            "accuracy": 0.5848341232227489,
            "ap": 0.2097883204272064,
            "ap_weighted": 0.2097883204272064,
            "f1": 0.5206679467111466,
            "f1_weighted": 0.6386938154241972
          },
          {
            "accuracy": 0.49146919431279623,
            "ap": 0.1968077971770811,
            "ap_weighted": 0.1968077971770811,
            "f1": 0.4587207090856016,
            "f1_weighted": 0.5483215742544193
          },
          {
            "accuracy": 0.4729857819905213,
            "ap": 0.20805114735422253,
            "ap_weighted": 0.20805114735422253,
            "f1": 0.4518845498310558,
            "f1_weighted": 0.5242607567548264
          },
          {
            "accuracy": 0.5037914691943128,
            "ap": 0.22224233992677142,
            "ap_weighted": 0.22224233992677142,
            "f1": 0.4789176000730261,
            "f1_weighted": 0.5555355917264471
          },
          {
            "accuracy": 0.4758293838862559,
            "ap": 0.20784719779667898,
            "ap_weighted": 0.20784719779667898,
            "f1": 0.4537727007595866,
            "f1_weighted": 0.5276417810423
          },
          {
            "accuracy": 0.5113744075829384,
            "ap": 0.18649158125274398,
            "ap_weighted": 0.18649158125274398,
            "f1": 0.46404889318006953,
            "f1_weighted": 0.5712294840127231
          },
          {
            "accuracy": 0.518957345971564,
            "ap": 0.1577350822694901,
            "ap_weighted": 0.1577350822694901,
            "f1": 0.436054538383129,
            "f1_weighted": 0.58156997321079
          },
          {
            "accuracy": 0.4260663507109005,
            "ap": 0.17121827164069076,
            "ap_weighted": 0.17121827164069076,
            "f1": 0.400833979933926,
            "f1_weighted": 0.4835821704727338
          },
          {
            "accuracy": 0.5981042654028436,
            "ap": 0.21372701487420007,
            "ap_weighted": 0.21372701487420007,
            "f1": 0.5302365829888765,
            "f1_weighted": 0.650401307462484
          },
          {
            "accuracy": 0.5360189573459716,
            "ap": 0.22056325085016257,
            "ap_weighted": 0.22056325085016257,
            "f1": 0.4990774220973958,
            "f1_weighted": 0.5906253803050355
          }
        ]
      }
    ]
  },
  "task_name": "TweetSarcasmClassification"
}