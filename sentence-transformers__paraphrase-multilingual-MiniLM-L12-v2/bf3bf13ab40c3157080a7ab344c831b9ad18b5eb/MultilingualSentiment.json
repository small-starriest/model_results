{
  "dataset_revision": "46958b007a63fdbf239b7672c25d0bea67b5ea1a",
  "evaluation_time": 19.74241805076599,
  "kg_co2_emissions": 0.0029506642517875686,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.6269666666666668,
        "f1": 0.6251012687430721,
        "f1_weighted": 0.6251012687430723,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.6269666666666668,
        "scores_per_experiment": [
          {
            "accuracy": 0.6106666666666667,
            "f1": 0.6084307127917059,
            "f1_weighted": 0.6084307127917059
          },
          {
            "accuracy": 0.5913333333333334,
            "f1": 0.5832065284903268,
            "f1_weighted": 0.5832065284903268
          },
          {
            "accuracy": 0.628,
            "f1": 0.6262096375203434,
            "f1_weighted": 0.6262096375203434
          },
          {
            "accuracy": 0.6606666666666666,
            "f1": 0.6628017919174509,
            "f1_weighted": 0.6628017919174509
          },
          {
            "accuracy": 0.6326666666666667,
            "f1": 0.6343807380589112,
            "f1_weighted": 0.6343807380589112
          },
          {
            "accuracy": 0.582,
            "f1": 0.5828286346663022,
            "f1_weighted": 0.5828286346663022
          },
          {
            "accuracy": 0.6373333333333333,
            "f1": 0.6341838583369386,
            "f1_weighted": 0.6341838583369386
          },
          {
            "accuracy": 0.6533333333333333,
            "f1": 0.6504650648263566,
            "f1_weighted": 0.6504650648263566
          },
          {
            "accuracy": 0.6396666666666667,
            "f1": 0.6346905125997425,
            "f1_weighted": 0.6346905125997426
          },
          {
            "accuracy": 0.634,
            "f1": 0.6338152082226438,
            "f1_weighted": 0.6338152082226439
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.619,
        "f1": 0.6169716492849942,
        "f1_weighted": 0.6169716492849942,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.619,
        "scores_per_experiment": [
          {
            "accuracy": 0.617,
            "f1": 0.615787767725397,
            "f1_weighted": 0.6157877677253969
          },
          {
            "accuracy": 0.5703333333333334,
            "f1": 0.5633139170698557,
            "f1_weighted": 0.5633139170698558
          },
          {
            "accuracy": 0.6233333333333333,
            "f1": 0.6216450900218357,
            "f1_weighted": 0.6216450900218355
          },
          {
            "accuracy": 0.6513333333333333,
            "f1": 0.6516655688313118,
            "f1_weighted": 0.6516655688313118
          },
          {
            "accuracy": 0.6293333333333333,
            "f1": 0.6311697040416048,
            "f1_weighted": 0.6311697040416048
          },
          {
            "accuracy": 0.5796666666666667,
            "f1": 0.5793096673446889,
            "f1_weighted": 0.5793096673446889
          },
          {
            "accuracy": 0.6213333333333333,
            "f1": 0.6184319310361087,
            "f1_weighted": 0.6184319310361087
          },
          {
            "accuracy": 0.641,
            "f1": 0.6380217267479869,
            "f1_weighted": 0.6380217267479869
          },
          {
            "accuracy": 0.6366666666666667,
            "f1": 0.6310089481478677,
            "f1_weighted": 0.6310089481478676
          },
          {
            "accuracy": 0.62,
            "f1": 0.6193621718832852,
            "f1_weighted": 0.6193621718832852
          }
        ]
      }
    ]
  },
  "task_name": "MultilingualSentiment"
}