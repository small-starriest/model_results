{
  "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
  "mteb_dataset_name": "MassiveScenarioClassification",
  "mteb_version": "1.0.3.dev0",
  "test": {
    "da": {
      "accuracy": 0.5717215870880968,
      "accuracy_stderr": 0.01895496555185814,
      "f1": 0.558288037474631,
      "f1_stderr": 0.015524261880187573,
      "main_score": 0.5717215870880968
    },
    "evaluation_time": 114.16,
    "nb": {
      "accuracy": 0.6068594485541358,
      "accuracy_stderr": 0.015256745320521025,
      "f1": 0.5946730795751348,
      "f1_stderr": 0.01239100086035453,
      "main_score": 0.6068594485541358
    },
    "sv": {
      "accuracy": 0.5353059852051111,
      "accuracy_stderr": 0.01471903892238592,
      "f1": 0.5155600722383158,
      "f1_stderr": 0.013275569510287046,
      "main_score": 0.5353059852051111
    }
  },
  "validation": {
    "da": {
      "accuracy": 0.5652238071815051,
      "accuracy_stderr": 0.02460939028912748,
      "f1": 0.5546547420141412,
      "f1_stderr": 0.022138616004502325,
      "main_score": 0.5652238071815051
    },
    "evaluation_time": 89.7,
    "nb": {
      "accuracy": 0.6048204623708805,
      "accuracy_stderr": 0.022822777608722453,
      "f1": 0.5976444866423012,
      "f1_stderr": 0.021953139895541627,
      "main_score": 0.6048204623708805
    },
    "sv": {
      "accuracy": 0.5289227742252829,
      "accuracy_stderr": 0.022682249556145638,
      "f1": 0.5151870624117973,
      "f1_stderr": 0.02192375300990614,
      "main_score": 0.5289227742252829
    }
  }
}