{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.0.1.dev0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8410323657388091,
      "accuracy_threshold": 0.7044795751571655,
      "ap": 0.6660137415520323,
      "f1": 0.6212845010615712,
      "f1_threshold": 0.6694471836090088,
      "precision": 0.6249332621462894,
      "recall": 0.6176781002638523
    },
    "dot": {
      "accuracy": 0.8185015199380103,
      "accuracy_threshold": 7075.5693359375,
      "ap": 0.5885464421136508,
      "f1": 0.5615180082185158,
      "f1_threshold": 6276.49755859375,
      "precision": 0.518064228367529,
      "recall": 0.612928759894459
    },
    "euclidean": {
      "accuracy": 0.836681170650295,
      "accuracy_threshold": 72.81046295166016,
      "ap": 0.6493555585305604,
      "f1": 0.6102775195857125,
      "f1_threshold": 79.39328002929688,
      "precision": 0.6142742582197274,
      "recall": 0.6063324538258575
    },
    "evaluation_time": 47.96,
    "manhattan": {
      "accuracy": 0.8373368301841807,
      "accuracy_threshold": 3711.131103515625,
      "ap": 0.6545422483039611,
      "f1": 0.6158552806597499,
      "f1_threshold": 4024.435546875,
      "precision": 0.6209763948497854,
      "recall": 0.6108179419525066
    },
    "max": {
      "accuracy": 0.8410323657388091,
      "ap": 0.6660137415520323,
      "f1": 0.6212845010615712
    }
  }
}