{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 17.34189224243164,
  "kg_co2_emissions": 0.00266616112880566,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.0498046875,
        "f1": 0.03035094156113044,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.03035094156113044,
        "precision": 0.026696401566036004,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000338703425665983,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.000338703425665983,
        "precision": 0.00020193200209444023,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010089302028138132,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0010089302028138132,
        "precision": 0.0009929824810957937,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.786917812058866e-05,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 6.786917812058866e-05,
        "precision": 3.44149751034096e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014677508652444385,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0014677508652444385,
        "precision": 0.001253328995231323,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003610528487616311,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.003610528487616311,
        "precision": 0.002770311052767789,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001201025536963037,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.001201025536963037,
        "precision": 0.0008175227131336666,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009788602941176471,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0009788602941176471,
        "precision": 0.000977712750294464,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.469138543516874e-06,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 3.469138543516874e-06,
        "precision": 1.7376556939501778e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004611545138888889,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.004611545138888889,
        "precision": 0.004060872395833333,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021414040032975063,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0021414040032975063,
        "precision": 0.0017443676226897517,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030872955953843164,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0030872955953843164,
        "precision": 0.0027104103909512136,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0049181234095468825,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0049181234095468825,
        "precision": 0.0042076832819732965,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013218976449275361,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0013218976449275361,
        "precision": 0.0009095893141945773,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01301372416014773,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.01301372416014773,
        "precision": 0.011551696089191136,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0023025835882598653,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0023025835882598653,
        "precision": 0.002142293188895055,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0024606086078939045,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0024606086078939045,
        "precision": 0.0022269477782809986,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019550626240079365,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0019550626240079365,
        "precision": 0.00195409477408143,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00020456901658767772,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.00020456901658767772,
        "precision": 0.00011315724206349205,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013695435012062724,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0013695435012062724,
        "precision": 0.0012218825483091787,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020400931533744037,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0020400931533744037,
        "precision": 0.0016171134031105069,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 8.91837899543379e-06,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 8.91837899543379e-06,
        "precision": 4.479644495412844e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.020196643504517945,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.020196643504517945,
        "precision": 0.01893181301433108,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.3645581113801454e-06,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 2.3645581113801454e-06,
        "precision": 1.1837121212121212e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.116061755146262e-06,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 2.116061755146262e-06,
        "precision": 1.0591784164859002e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009805648053278688,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0009805648053278688,
        "precision": 0.0009785677618069815,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002559962113437329,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.002559962113437329,
        "precision": 0.0023116429809289544,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.833024913546769e-06,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 8.833024913546769e-06,
        "precision": 4.427892080745341e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.4672983893616422e-05,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 1.4672983893616422e-05,
        "precision": 7.364287103848331e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004902783103271983,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0004902783103271983,
        "precision": 0.00032652038553394744,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0006510416666666666,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.00048828125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009880466805233662,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0009880466805233662,
        "precision": 0.0009823264713364995,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003904850041292695,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.003904850041292695,
        "precision": 0.003598786462684489,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016384791986384921,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0016384791986384921,
        "precision": 0.0014702987947635693,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002377713555781391,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.002377713555781391,
        "precision": 0.0022143969879921863,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009789707922318125,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0009789707922318125,
        "precision": 0.0009777681327160495,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.2830369015957447e-05,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 1.2830369015957447e-05,
        "precision": 6.444490271930822e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9054878048780488e-06,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9054878048780488e-06,
        "precision": 9.5367431640625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009860718594122749,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0009860718594122749,
        "precision": 0.0009813297752434035,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009852257895953535,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0009852257895953535,
        "precision": 0.0009809039745571262,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001018898615340003,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.001018898615340003,
        "precision": 0.000998053242627445,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.344392123287671e-06,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 3.344392123287671e-06,
        "precision": 1.6750643224699828e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000568908658958001,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.000568908658958001,
        "precision": 0.00032485369372569175,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.994120654396728e-06,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 3.994120654396728e-06,
        "precision": 2.0011526639344263e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2568359375,
        "f1": 0.2335432525373931,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2335432525373931,
        "precision": 0.22535707108030176,
        "recall": 0.2568359375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.010503584489346372,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.010503584489346372,
        "precision": 0.009076757073443412,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.2451171875,
        "f1": 0.21937703680867746,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.21937703680867746,
        "precision": 0.21120105209460677,
        "recall": 0.2451171875
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.016580581169890085,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.016580581169890085,
        "precision": 0.013859717665870009,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.251953125,
        "f1": 0.22250837869413112,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.22250837869413112,
        "precision": 0.2118978921469156,
        "recall": 0.251953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003255208333333333,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0028557054924242425,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.0575980967743061,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0575980967743061,
        "precision": 0.04968744970681259,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.05340180388404804,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05340180388404804,
        "precision": 0.04813194821266814,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.09243575158601286,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.09243575158601286,
        "precision": 0.08463549676748688,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.043434278395215895,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.043434278395215895,
        "precision": 0.03786562872320479,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002325923859126984,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002325923859126984,
        "precision": 0.0018529412096949102,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04063389581224697,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04063389581224697,
        "precision": 0.035107457104527416,
        "recall": 0.0625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003071446572580645,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0003071446572580645,
        "precision": 0.0001720610119047619,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.12418208845174308,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12418208845174308,
        "precision": 0.11852330222649457,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.038346193423633594,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.038346193423633594,
        "precision": 0.03421531649668573,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009881771286035057,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009881771286035057,
        "precision": 0.0009823902811680269,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.234375,
        "f1": 0.20636738478535355,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.20636738478535355,
        "precision": 0.19678589567281937,
        "recall": 0.234375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11313835490882865,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11313835490882865,
        "precision": 0.10348116192788612,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11836382617420321,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11836382617420321,
        "precision": 0.11014557071075626,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07441909327651515,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.07441909327651515,
        "precision": 0.0675690223255552,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.929542203147354e-05,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 6.929542203147354e-05,
        "precision": 3.577470337411939e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013083034766454352,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0013083034766454352,
        "precision": 0.0011749950079872203,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2568359375,
        "f1": 0.22800547434336496,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.22800547434336496,
        "precision": 0.21887548757665948,
        "recall": 0.2568359375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010393657308288609,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.010393657308288609,
        "precision": 0.009360863438011876,
        "recall": 0.015625
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.2627615556203585,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2627615556203585,
        "precision": 0.25113489483606666,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014517114601407366,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.014517114601407366,
        "precision": 0.012295057362574873,
        "recall": 0.03125
      },
      {
        "accuracy": 0.4677734375,
        "f1": 0.4124589928300866,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4124589928300866,
        "precision": 0.393177238343254,
        "recall": 0.4677734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003485887570488722,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.003485887570488722,
        "precision": 0.002893462355503796,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.059377893922356234,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.059377893922356234,
        "precision": 0.05167326658236354,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.17648382274678745,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.17648382274678745,
        "precision": 0.16298865761273607,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08801005309794373,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08801005309794373,
        "precision": 0.08140525993663594,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.058323070788418564,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.058323070788418564,
        "precision": 0.05292124609076586,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00217919415454437,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00217919415454437,
        "precision": 0.0015213294759988073,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.12270337084790209,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12270337084790209,
        "precision": 0.11116841883989172,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010167247722824451,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0010167247722824451,
        "precision": 0.0006408312305900621,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11983769950704418,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.11983769950704418,
        "precision": 0.1148541713199758,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.033528628033151056,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.033528628033151056,
        "precision": 0.029335108017323093,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001725597938268049,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001725597938268049,
        "precision": 0.0015159659500539931,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.32421875,
        "f1": 0.2862934591450216,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2862934591450216,
        "precision": 0.2744723027132276,
        "recall": 0.32421875
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.126203247250739,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.126203247250739,
        "precision": 0.11783276035774885,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11060420420205064,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11060420420205064,
        "precision": 0.10227038016686578,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08772419656783167,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.08772419656783167,
        "precision": 0.0802669983507841,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00014787946428571427,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.00014787946428571427,
        "precision": 7.685908564814814e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1945224719101123e-05,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 2.1945224719101123e-05,
        "precision": 1.1097301136363637e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.030489032489301883,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.030489032489301883,
        "precision": 0.02375377343336721,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.03559629995464095,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.03559629995464095,
        "precision": 0.028009242528179348,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03130287952065296,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.03130287952065296,
        "precision": 0.025518728547357247,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.0067010139228145475,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0067010139228145475,
        "precision": 0.00459292754116453,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.035580439465781905,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.035580439465781905,
        "precision": 0.02880757796529281,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00039793494152046783,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.00039793494152046783,
        "precision": 0.00021701388888888888,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.020156531881962966,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.020156531881962966,
        "precision": 0.015223024753165473,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008138020833333334,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0008138020833333334,
        "precision": 0.0005011852479849468,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.03174288249117119,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.03174288249117119,
        "precision": 0.025667587800534998,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013950892857142857,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0013950892857142857,
        "precision": 0.001220703125,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000772664835164835,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.000772664835164835,
        "precision": 0.0005511623475609757,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022530691964285712,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0022530691964285712,
        "precision": 0.0018283876050420168,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0019102230235042736,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0019102230235042736,
        "precision": 0.0015462239583333333,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.05165401341391141,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.05165401341391141,
        "precision": 0.041658833387152046,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004163447229853479,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.004163447229853479,
        "precision": 0.003411708733974359,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015766940585254538,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0015766940585254538,
        "precision": 0.0012986687243340816,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.032516830118205164,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.032516830118205164,
        "precision": 0.027277375944368132,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.032149953649328426,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.032149953649328426,
        "precision": 0.027528171982513908,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04387250399410177,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.04387250399410177,
        "precision": 0.03611537926071909,
        "recall": 0.078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020882480812957422,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.020882480812957422,
        "precision": 0.01606763954304559,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011936682647459816,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0011936682647459816,
        "precision": 0.0010891133559493915,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021515376984126985,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00021515376984126985,
        "precision": 0.0001184944166048008,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.19671660433636173,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.19671660433636173,
        "precision": 0.18536626038636608,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.283203125,
        "f1": 0.25029141865079363,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.25029141865079363,
        "precision": 0.2393381349191896,
        "recall": 0.283203125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.008241742688923394,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.008241742688923394,
        "precision": 0.0072738499783917415,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.015629306890009114,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015629306890009114,
        "precision": 0.013228502093248187,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.28549646920485916,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.28549646920485916,
        "precision": 0.2701024967870671,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001282394573252688,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.001282394573252688,
        "precision": 0.0008895210597826087,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.04960386542657931,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.04960386542657931,
        "precision": 0.042199835475556405,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.08824788283677631,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08824788283677631,
        "precision": 0.0799877474206074,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.08691560970017546,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08691560970017546,
        "precision": 0.07905435286093604,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.23991001674107143,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.23991001674107143,
        "precision": 0.2217107247136544,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013978201690954335,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0013978201690954335,
        "precision": 0.0011951906092848717,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07156611437766164,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07156611437766164,
        "precision": 0.0645844959077381,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008626913964598997,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0008626913964598997,
        "precision": 0.0004725893563023568,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.12197039631859533,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12197039631859533,
        "precision": 0.11602565814971678,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.0586985175605938,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.0586985175605938,
        "precision": 0.05339444632701831,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012369791666666666,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0012369791666666666,
        "precision": 0.0008652001096491227,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.271484375,
        "f1": 0.2250571856528888,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2250571856528888,
        "precision": 0.21190074159398606,
        "recall": 0.271484375
      },
      {
        "accuracy": 0.140625,
        "f1": 0.10797974476286144,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.10797974476286144,
        "precision": 0.09839384390209949,
        "recall": 0.140625
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.11000013441419691,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11000013441419691,
        "precision": 0.10062267077198205,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07206925190580618,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.07206925190580618,
        "precision": 0.06518980964781747,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00025640503546839295,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.00025640503546839295,
        "precision": 0.00013668114041755344,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010917288832776916,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0010917288832776916,
        "precision": 0.0010358558190099048,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.011694921495668479,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.011694921495668479,
        "precision": 0.011274280840909524,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01799843158084282,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.01799843158084282,
        "precision": 0.017333696394249108,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0033710200168295132,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.0033710200168295132,
        "precision": 0.0031849726486943906,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013932670644002377,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.013932670644002377,
        "precision": 0.012997049735905434,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.017191339616875054,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.017191339616875054,
        "precision": 0.01643061115376776,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.1334025655716832,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.1334025655716832,
        "precision": 0.12304477884311868,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00410001240079365,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.00410001240079365,
        "precision": 0.003759240591397849,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001261952506641145,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.001261952506641145,
        "precision": 0.0011253469209883684,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07710433013167389,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.07710433013167389,
        "precision": 0.07073454973845598,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023617690457004206,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0023617690457004206,
        "precision": 0.002177689785700543,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08301873365349927,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.08301873365349927,
        "precision": 0.07388509114583333,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00046033092795310445,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.00046033092795310445,
        "precision": 0.00024717532496928686,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.05958944619833291,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.05958944619833291,
        "precision": 0.05289996059747824,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.05417253644792708,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.05417253644792708,
        "precision": 0.04881698430899625,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004478980215981705,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0004478980215981705,
        "precision": 0.00025971748218391445,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07546362058080808,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.07546362058080808,
        "precision": 0.06883743783286342,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.009735942932566084,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.009735942932566084,
        "precision": 0.008345756728525203,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.025284900389263825,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.025284900389263825,
        "precision": 0.02442774869221388,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.09575139372853304,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.09575139372853304,
        "precision": 0.08888975201231061,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.007303372588259441,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.007303372588259441,
        "precision": 0.006912261838423598,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.6613961813842484e-06,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 4.6613961813842484e-06,
        "precision": 2.336273923444976e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009821111505681818,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0009821111505681818,
        "precision": 0.0009793447293447294,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.263671875,
        "f1": 0.2318791454304811,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2318791454304811,
        "precision": 0.22128203803857677,
        "recall": 0.263671875
      },
      {
        "accuracy": 0.474609375,
        "f1": 0.4161630253427129,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4161630253427129,
        "precision": 0.3958685140814047,
        "recall": 0.474609375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005827832173398835,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.005827832173398835,
        "precision": 0.004423863271090255,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.3310546875,
        "f1": 0.29475566872108694,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.29475566872108694,
        "precision": 0.2828549029880859,
        "recall": 0.3310546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015707384869585086,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015707384869585086,
        "precision": 0.012763936744234981,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006140890459444647,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.006140890459444647,
        "precision": 0.006023385816794707,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.049533023673739934,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.049533023673739934,
        "precision": 0.041740184247830915,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.2977216224530677,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2977216224530677,
        "precision": 0.27930015469026026,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08799041904510654,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08799041904510654,
        "precision": 0.0810166327339865,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.13396506921897547,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.13396506921897547,
        "precision": 0.12159629735441824,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012621787524131273,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0012621787524131273,
        "precision": 0.0011426332980225989,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.19522033955627704,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.19522033955627704,
        "precision": 0.1783141121031746,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016149894212698639,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0016149894212698639,
        "precision": 0.0013468252500704425,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.09791536564155448,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.09791536564155448,
        "precision": 0.09255605917197185,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05366671093611867,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.05366671093611867,
        "precision": 0.0480249694073798,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0021125873766447366,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0021125873766447366,
        "precision": 0.002039128124555088,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.373046875,
        "f1": 0.32674836082602127,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.32674836082602127,
        "precision": 0.3118842759345689,
        "recall": 0.373046875
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11012567077020202,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11012567077020202,
        "precision": 0.10135348135964913,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.10130661225990958,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.10130661225990958,
        "precision": 0.0930587898971688,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.0777361621231191,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0777361621231191,
        "precision": 0.06957422661211704,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.037633274456181e-05,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 7.037633274456181e-05,
        "precision": 3.568212469809291e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010162594944032992,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0010162594944032992,
        "precision": 0.000996780403700363,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006866613526158317,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0006866613526158317,
        "precision": 0.00037712106810425803,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002051946011180649,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.002051946011180649,
        "precision": 0.0016385775320199958,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002434675556077694,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0002434675556077694,
        "precision": 0.0001287476629273504,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0006163575250311277,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0006163575250311277,
        "precision": 0.0003498577654078416,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.11068173363095238,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.11068173363095238,
        "precision": 0.09760939472853536,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023198911513994613,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0023198911513994613,
        "precision": 0.002149563019842548,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014995050395968323,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0014995050395968323,
        "precision": 0.0012814376876876877,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012269189242419942,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.0012269189242419942,
        "precision": 0.0011078430995984923,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.0588600499977453,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.0588600499977453,
        "precision": 0.05086108010912698,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002603298131550401,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.002603298131550401,
        "precision": 0.002308829196201638,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08061252170138888,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.08061252170138888,
        "precision": 0.07216674655639499,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0025898813263348468,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0025898813263348468,
        "precision": 0.0020029250454916816,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.08295636310773029,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.08295636310773029,
        "precision": 0.07250452205029739,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.02747765743371212,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.02747765743371212,
        "precision": 0.022501198002154582,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013870295022622855,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0013870295022622855,
        "precision": 0.0012306591553734965,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05309631116701066,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.05309631116701066,
        "precision": 0.046161454376786405,
        "recall": 0.078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030208710124707177,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0030208710124707177,
        "precision": 0.0026986806341126194,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0009290805137844611,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0009290805137844611,
        "precision": 0.0005428538602941177,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.125,
        "f1": 0.092633541046627,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.092633541046627,
        "precision": 0.081492918431395,
        "recall": 0.125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007512543630017452,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0007512543630017452,
        "precision": 0.00044270587696261434,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004014756944444445,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0004014756944444445,
        "precision": 0.000249596281424581,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000751608546875091,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.000751608546875091,
        "precision": 0.0005400422274122739,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.11157364723516217,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.11157364723516217,
        "precision": 0.10588120556382274,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.1265715270483193,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1265715270483193,
        "precision": 0.11941155726613562,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017676943824404764,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.017676943824404764,
        "precision": 0.01693860675375356,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.09920837924011751,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.09920837924011751,
        "precision": 0.09356607910950183,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011402579104680993,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.011402579104680993,
        "precision": 0.009505085000922505,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.12021484375,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.12021484375,
        "precision": 0.11448144954004327,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.999165602507546e-06,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 9.999165602507546e-06,
        "precision": 5.013885728621521e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0036845049763266713,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0036845049763266713,
        "precision": 0.003072238656415018,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.059715317234848485,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.059715317234848485,
        "precision": 0.053637670922827174,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001775568181818182,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0001775568181818182,
        "precision": 9.300595238095238e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00013020833333333333,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.00013020833333333333,
        "precision": 6.975446428571428e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010843151180926916,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0010843151180926916,
        "precision": 0.0010316664988007896,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.10970222548788575,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.10970222548788575,
        "precision": 0.10280903811177247,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002096015963203463,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.002096015963203463,
        "precision": 0.0020292622257236225,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.381859756097561e-05,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 2.381859756097561e-05,
        "precision": 1.2056327160493826e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.10707909513525937,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.10707909513525937,
        "precision": 0.1014943386932319,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.07742420802364505,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.07742420802364505,
        "precision": 0.07145349968417383,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08081987149257569,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.08081987149257569,
        "precision": 0.07348726688828941,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.22107711488815004,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.22107711488815004,
        "precision": 0.21216337745648878,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002269955458144796,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.002269955458144796,
        "precision": 0.0018736633820399474,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024476462659744408,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0024476462659744408,
        "precision": 0.0017934945913461538,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.04744176881125411,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.04744176881125411,
        "precision": 0.04269367540593569,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.14242304276612458,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.14242304276612458,
        "precision": 0.1293220816170035,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.794170243204578e-06,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 2.794170243204578e-06,
        "precision": 1.399086676217765e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.08407119048442066,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08407119048442066,
        "precision": 0.07744151103526103,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0032414648116074747,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0032414648116074747,
        "precision": 0.0025338450124430256,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.3017578125,
        "f1": 0.23771518954136142,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.23771518954136142,
        "precision": 0.21887091491152844,
        "recall": 0.3017578125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0034856193638635375,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0034856193638635375,
        "precision": 0.0029146863441035682,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002113148760896059,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.002113148760896059,
        "precision": 0.0020352546192030437,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002225857160832449,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.002225857160832449,
        "precision": 0.002107079753325942,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.14094377844377845,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.14094377844377845,
        "precision": 0.1318691433620633,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031206704125615763,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0031206704125615763,
        "precision": 0.0026632546067106707,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.3271484375,
        "f1": 0.2686484685019841,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2686484685019841,
        "precision": 0.24832050273944806,
        "recall": 0.3271484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0032073679680469525,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0032073679680469525,
        "precision": 0.0024162948858194007,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019756062621294253,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0019756062621294253,
        "precision": 0.001964463273250402,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.0671750992063492,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.0671750992063492,
        "precision": 0.060730613138988594,
        "recall": 0.09375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018835778696223082,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0018835778696223082,
        "precision": 0.0015313350690094015,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.06995309649118242,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.06995309649118242,
        "precision": 0.06263012783840288,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005312965029761904,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.005312965029761904,
        "precision": 0.005124616457313078,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013614328278050366,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0013614328278050366,
        "precision": 0.001182787322306028,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012411965536965534,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0012411965536965534,
        "precision": 0.0011163695245726495,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.0604832117981562e-05,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 1.0604832117981562e-05,
        "precision": 5.319867098713252e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00013225349040139615,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.00013225349040139615,
        "precision": 7.07781147050015e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.035257751069190345,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.035257751069190345,
        "precision": 0.032167052952941394,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05926575751986543,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.05926575751986543,
        "precision": 0.05379758397055106,
        "recall": 0.078125
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.021924866002908477,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.021924866002908477,
        "precision": 0.019618723062390826,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04519765689544264,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.04519765689544264,
        "precision": 0.04061499212192908,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06272730479042157,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.06272730479042157,
        "precision": 0.05422754329004329,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.05463443725240229,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.05463443725240229,
        "precision": 0.049169099236232784,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.07749798487103174,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.07749798487103174,
        "precision": 0.06991141183035714,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.01832814500513854,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.01832814500513854,
        "precision": 0.01571442034941655,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006187334191635456,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.0006187334191635456,
        "precision": 0.00035638189935064936,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00012226134585289515,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.00012226134585289515,
        "precision": 6.437082811848143e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.035018302010489506,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.035018302010489506,
        "precision": 0.029881935555763683,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000393009768009768,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.000393009768009768,
        "precision": 0.00024533446668704154,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.028898864233193274,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.028898864233193274,
        "precision": 0.025246078249007937,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.15316937103184808,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.15316937103184808,
        "precision": 0.1457932734232424,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00029002848245779795,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.00029002848245779795,
        "precision": 0.0001628773939674554,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.022155664478464353,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.022155664478464353,
        "precision": 0.019035581389097014,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.034538498497755685,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.034538498497755685,
        "precision": 0.03054650459133066,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.07575841584630646,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.07575841584630646,
        "precision": 0.07137527644621824,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.18768889701763877,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.18768889701763877,
        "precision": 0.17823783650989533,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018170555984813798,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.018170555984813798,
        "precision": 0.015438496236836078,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002514494481730716,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.002514494481730716,
        "precision": 0.002077101648853925,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012228153555458345,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0012228153555458345,
        "precision": 0.0011134097450657893,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.043281807521451415,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.043281807521451415,
        "precision": 0.03908434291968599,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.057438987915819806,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.057438987915819806,
        "precision": 0.050936904709800584,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002817418808527595,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0002817418808527595,
        "precision": 0.00016412433077281192,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.20039040991446416,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.20039040991446416,
        "precision": 0.1802994368912338,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.008782355339972528,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.008782355339972528,
        "precision": 0.006939529888748639,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.1144477348823052,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1144477348823052,
        "precision": 0.10439083836659664,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032863970071363505,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0032863970071363505,
        "precision": 0.002768250465664074,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0013871422496668706,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0013871422496668706,
        "precision": 0.0011983965140866639,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1875,
        "f1": 0.1429878079745654,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1429878079745654,
        "precision": 0.13009424250879328,
        "recall": 0.1875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00043043608449477356,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.00043043608449477356,
        "precision": 0.00024317860978086597,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002645464886675824,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002645464886675824,
        "precision": 0.0023219072691875796,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.11712811726855482,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.11712811726855482,
        "precision": 0.10680969014709249,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004504679475957049,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.004504679475957049,
        "precision": 0.0039056474316125052,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001987971955213781,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.001987971955213781,
        "precision": 0.001970668448875686,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.0667509250677497,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.0667509250677497,
        "precision": 0.060248632315229624,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0032984683388157894,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0032984683388157894,
        "precision": 0.0026262312358085946,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06231320290404556,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.06231320290404556,
        "precision": 0.05567411008874703,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0015584793556645752,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0015584793556645752,
        "precision": 0.0011099897399362412,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0019454585318474994,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0019454585318474994,
        "precision": 0.0012173600372635146,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002230481197766354,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.002230481197766354,
        "precision": 0.002097074868033749,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007066805589615405,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0007066805589615405,
        "precision": 0.0005163658785305328,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011146357171583669,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0011146357171583669,
        "precision": 0.0010497176203756997,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0016741363908417133,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0016741363908417133,
        "precision": 0.0013639484324341796,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001017585503501115,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.001017585503501115,
        "precision": 0.000997331503381115,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.3445966607546936e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 3.3445966607546936e-05,
        "precision": 1.689176051518168e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001651549635312005,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.001651549635312005,
        "precision": 0.0014768762039462525,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.09548706501831501,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.09548706501831501,
        "precision": 0.08542049662532433,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0032562945759616784,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0032562945759616784,
        "precision": 0.003101242320967539,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.0871887134442938,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0871887134442938,
        "precision": 0.0781229038431187,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0537592008412197e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 2.0537592008412197e-06,
        "precision": 1.0279605263157895e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00207155986639825,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00207155986639825,
        "precision": 0.0020139283823372212,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.027881898646058802,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.027881898646058802,
        "precision": 0.023339532567644247,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00224095750004475,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.00224095750004475,
        "precision": 0.0021088118848258475,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004441704063909501,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0004441704063909501,
        "precision": 0.00025646751804516777,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.05124895685118305,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.05124895685118305,
        "precision": 0.044135682195395945,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.037765078707461514,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.037765078707461514,
        "precision": 0.03141150841346154,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0008122281899279896,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0008122281899279896,
        "precision": 0.0005054083163925874,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.08193119125736312,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.08193119125736312,
        "precision": 0.0736086353922666,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006905266498459411,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0006905266498459411,
        "precision": 0.000508367778125401,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0007858179147241648,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0007858179147241648,
        "precision": 0.000430827100370365,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.049529335418007296,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.049529335418007296,
        "precision": 0.043892131480135654,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.59634670487106e-06,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 5.59634670487106e-06,
        "precision": 2.80621408045977e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0035700817273054755,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0035700817273054755,
        "precision": 0.0033161594885425267,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015099770466150994,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0015099770466150994,
        "precision": 0.0010320132485508592,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03701654374574069,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03701654374574069,
        "precision": 0.03296208438212114,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.11233764493392488,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.11233764493392488,
        "precision": 0.10388844147389069,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000197984353625171,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.000197984353625171,
        "precision": 0.0001098447012937595,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07033892223298095,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.07033892223298095,
        "precision": 0.06380068110543285,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004033536992521367,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004033536992521367,
        "precision": 0.003973176042261565,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.16910504494467637,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.16910504494467637,
        "precision": 0.15309304681863278,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005666756465517241,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.005666756465517241,
        "precision": 0.005079473843232044,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021751189624212644,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0021751189624212644,
        "precision": 0.0020719539850223793,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.2700490048146298,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2700490048146298,
        "precision": 0.25131994470373376,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001759240544150731,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.001759240544150731,
        "precision": 0.001472594246031746,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.11698899324990777,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.11698899324990777,
        "precision": 0.10871489744658798,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0038281100592847577,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0038281100592847577,
        "precision": 0.0030925536052489174,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006393382478778751,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.006393382478778751,
        "precision": 0.005878127821872348,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.323371712841166e-05,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 9.323371712841166e-05,
        "precision": 4.809194955691017e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.06134055314834267,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.06134055314834267,
        "precision": 0.057477072894553366,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004739413630529226,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004739413630529226,
        "precision": 0.004424222982049665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04990897338061108,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04990897338061108,
        "precision": 0.04490693303718906,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0031293187877275046,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0031293187877275046,
        "precision": 0.0027329209374505822,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0022890068170044174,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0022890068170044174,
        "precision": 0.001751598075127487,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016536458333333334,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0016536458333333334,
        "precision": 0.0014780405405405406,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006628903166615741,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0006628903166615741,
        "precision": 0.000494229187347893,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010519628366712707,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0010519628366712707,
        "precision": 0.0010149726005637882,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013393146230002693,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0013393146230002693,
        "precision": 0.0011710289832238072,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0012316025733773407,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0012316025733773407,
        "precision": 0.0007489112780971691,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.685141509433962e-05,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 3.685141509433962e-05,
        "precision": 1.8780048076923078e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011343741314309172,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0011343741314309172,
        "precision": 0.0010608852542446292,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.07681987552952052,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.07681987552952052,
        "precision": 0.0683093030453949,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027928955296034168,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0027928955296034168,
        "precision": 0.002467049853377136,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.09514652014652014,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.09514652014652014,
        "precision": 0.08500899057539682,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.621305418719212e-06,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 9.621305418719212e-06,
        "precision": 4.834467821782178e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0003703515663456336,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0003703515663456336,
        "precision": 0.00019675812997882482,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.02371201864483051,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.02371201864483051,
        "precision": 0.020060669381852296,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026319775001924393,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0026319775001924393,
        "precision": 0.0023780112882509034,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07050721981500933,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.07050721981500933,
        "precision": 0.061913184870302285,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016790364583333334,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0016790364583333334,
        "precision": 0.0010433932427580208,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.015208300086358269,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.015208300086358269,
        "precision": 0.01242497503234186,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0015868767799216313,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0015868767799216313,
        "precision": 0.0011284934988647175,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03882145224056988,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.03882145224056988,
        "precision": 0.03367996856945903,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002104804686143522,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.002104804686143522,
        "precision": 0.0014779468957117643,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004413397439392738,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0004413397439392738,
        "precision": 0.0002434307572739206,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03932411491459119,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.03932411491459119,
        "precision": 0.03374962308776573,
        "recall": 0.0625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003932361296791444,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0003932361296791444,
        "precision": 0.000245447937583668,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 8.870826341207215e-05,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 8.870826341207215e-05,
        "precision": 4.599795338390229e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009938040967110184,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0009938040967110184,
        "precision": 0.0009852405991848366,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06278211115056004,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.06278211115056004,
        "precision": 0.054607243789718894,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09472376731224902,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.09472376731224902,
        "precision": 0.08634287590633258,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.032913448279626764,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.032913448279626764,
        "precision": 0.028362744748298863,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0814513563460707,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.0814513563460707,
        "precision": 0.07466952492802675,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06200126085473651,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.06200126085473651,
        "precision": 0.05358448490528568,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.08611478499288702,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.08611478499288702,
        "precision": 0.07762704146111377,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03993721393623738,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.03993721393623738,
        "precision": 0.03496019767992424,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03462272953752556,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.03462272953752556,
        "precision": 0.03043286290841294,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009500157147988506,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.0009500157147988506,
        "precision": 0.0006454820774112666,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.15181129092261902,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.15181129092261902,
        "precision": 0.14028320312499998,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0026396979787831646,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0026396979787831646,
        "precision": 0.0021581608495670995,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.06144438244047619,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.06144438244047619,
        "precision": 0.055575062729667994,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004099219445754099,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0004099219445754099,
        "precision": 0.0002197882365640864,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.02953636532738095,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.02953636532738095,
        "precision": 0.026477184924450548,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0014624843812576114,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0014624843812576114,
        "precision": 0.0009208355093867502,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03392127684407096,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.03392127684407096,
        "precision": 0.03003401763167388,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.07023851120326147,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.07023851120326147,
        "precision": 0.06297890875255031,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09929308662567592,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.09929308662567592,
        "precision": 0.09139889198426396,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.24609375,
        "f1": 0.214582205988456,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.214582205988456,
        "precision": 0.2034085958415214,
        "recall": 0.24609375
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.03999447873875406,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.03999447873875406,
        "precision": 0.03482713237370806,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030148326544455423,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0030148326544455423,
        "precision": 0.002410015284779692,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005752013930288234,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0005752013930288234,
        "precision": 0.0003289782498581598,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.027329185927036835,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.027329185927036835,
        "precision": 0.023383393672837767,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.03248241279110263,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.03248241279110263,
        "precision": 0.028596423811267563,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000280642196834293,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.000280642196834293,
        "precision": 0.00015792641769794204,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.053437069005810515,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.053437069005810515,
        "precision": 0.04705633179754273,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004649811050528204,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004649811050528204,
        "precision": 0.003960955244556704,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.05815158479707749,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.05815158479707749,
        "precision": 0.051393589249520574,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006659700452803901,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.006659700452803901,
        "precision": 0.005840078457405838,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001759538670257505,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.001759538670257505,
        "precision": 0.0015327507900160784,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09352665653935185,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.09352665653935185,
        "precision": 0.08382820792488761,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0029771052077795495,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0029771052077795495,
        "precision": 0.0023317981038569273,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.08264748489357863,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.08264748489357863,
        "precision": 0.07386218924304862,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005113599401509238,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005113599401509238,
        "precision": 0.0043345316983873965,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.081003371468962,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.081003371468962,
        "precision": 0.07377182144027847,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006302543420549174,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.006302543420549174,
        "precision": 0.005411214057389618,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016382960831448669,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0016382960831448669,
        "precision": 0.0014702043871984277,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005583551028584511,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005583551028584511,
        "precision": 0.005095090194894383,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.033314963700155506,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.033314963700155506,
        "precision": 0.029406540453903736,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00494384765625,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.00494384765625,
        "precision": 0.004588793682795698,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024875217013888887,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0024875217013888887,
        "precision": 0.0022488064236111114,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003519144144144144,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0003519144144144144,
        "precision": 0.0002086900684931507,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.4363998822365043e-05,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 3.4363998822365043e-05,
        "precision": 1.7331334032068912e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024000550741129787,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0024000550741129787,
        "precision": 0.0022261942903147062,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013406675272227952,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0013406675272227952,
        "precision": 0.0011772565458492983,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002777274115941688,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.002777274115941688,
        "precision": 0.0024326440695021383,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00234375,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.00234375,
        "precision": 0.002197265625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0002494747154558818,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0002494747154558818,
        "precision": 0.0001322567486697124,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.06485896701322962,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.06485896701322962,
        "precision": 0.055205273848032206,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003932369700671082,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.003932369700671082,
        "precision": 0.003354554290754232,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.04713464161706349,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.04713464161706349,
        "precision": 0.04245633466953368,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012226880081300812,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0012226880081300812,
        "precision": 0.0011170648797413168,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00022673271261888965,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.00022673271261888965,
        "precision": 0.0001224928366559045,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01759639695383627,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.01759639695383627,
        "precision": 0.014823735580091806,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001824661779537509,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.001824661779537509,
        "precision": 0.0015683831161185666,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06092575501755189,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.06092575501755189,
        "precision": 0.05066305493551587,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0029689353874869776,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0029689353874869776,
        "precision": 0.0026566985063078813,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03525071303580049,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.03525071303580049,
        "precision": 0.031147560602734353,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.025563405488168912,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.025563405488168912,
        "precision": 0.02163456591336412,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0016375631660553065,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0016375631660553065,
        "precision": 0.0013927099573046132,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0021290238590558853,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0021290238590558853,
        "precision": 0.002047456124604562,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001498006138669618,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.001498006138669618,
        "precision": 0.0009688985325050309,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.033797046950633326,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.033797046950633326,
        "precision": 0.02777901884685301,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00014544547872340425,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.00014544547872340425,
        "precision": 7.809751700281427e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.953694331983806e-06,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 3.953694331983806e-06,
        "precision": 1.9808569979716024e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016704819732315216,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0016704819732315216,
        "precision": 0.00141068942625134,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.21360420612373737,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.21360420612373737,
        "precision": 0.20486579663825757,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.337890625,
        "f1": 0.3049563576614358,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3049563576614358,
        "precision": 0.2932540034834957,
        "recall": 0.337890625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.009966884479712007,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.009966884479712007,
        "precision": 0.008925475430255842,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.3076171875,
        "f1": 0.2760967651929723,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2760967651929723,
        "precision": 0.26532408787525125,
        "recall": 0.3076171875
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.022730260688024362,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.022730260688024362,
        "precision": 0.019543224933582515,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.35836495535714286,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.35836495535714286,
        "precision": 0.34535128770968615,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.006653111769789482,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.006653111769789482,
        "precision": 0.0063267158826671695,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.06936554313550522,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.06936554313550522,
        "precision": 0.06159817819779943,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09951938469516594,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.09951938469516594,
        "precision": 0.09138342126623376,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.0926570492154391,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0926570492154391,
        "precision": 0.08494159062460135,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.07196775573357655,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07196775573357655,
        "precision": 0.06470717596205877,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003042689732142857,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003042689732142857,
        "precision": 0.002687316009963768,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06263919186282467,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.06263919186282467,
        "precision": 0.05640380935919587,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0036763536508781073,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0036763536508781073,
        "precision": 0.003062249894694367,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.10748325687181445,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10748325687181445,
        "precision": 0.10194883049599052,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.035547372065305,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.035547372065305,
        "precision": 0.0318620007583895,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000782139792438228,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.000782139792438228,
        "precision": 0.0005574673651132751,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.11813759157509157,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.11813759157509157,
        "precision": 0.1096377418154762,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.10890354051624822,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.10890354051624822,
        "precision": 0.10049790858309358,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.08082928898358585,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.08082928898358585,
        "precision": 0.07302550151671246,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001956702152014652,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.001956702152014652,
        "precision": 0.0015480158161314983,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0021183830189684567,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0021183830189684567,
        "precision": 0.00204315380921895,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07860111351322288,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.07860111351322288,
        "precision": 0.07336145112359482,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.11088751132484667,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.11088751132484667,
        "precision": 0.10425995270650584,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.016222912932268154,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.016222912932268154,
        "precision": 0.014491344045209176,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.09069569696418878,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.09069569696418878,
        "precision": 0.08423188383881744,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.033406558262643785,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.033406558262643785,
        "precision": 0.02726934523809524,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.09914802709792758,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.09914802709792758,
        "precision": 0.09277571567610629,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.01139155483702153,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.01139155483702153,
        "precision": 0.01042813740079365,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04655955481150793,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.04655955481150793,
        "precision": 0.042067050245761184,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002706166510164672,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.002706166510164672,
        "precision": 0.0024164542799395877,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.13001172908399472,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.13001172908399472,
        "precision": 0.12225191641527175,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0026073727598601637,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0026073727598601637,
        "precision": 0.0023036198625542735,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.011314227343249656,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.011314227343249656,
        "precision": 0.010149784026737151,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004979212724715995,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.004979212724715995,
        "precision": 0.004625608842797795,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.012644934275793652,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.012644934275793652,
        "precision": 0.011749136351080984,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.14432198660714285,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.14432198660714285,
        "precision": 0.13810961174242425,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0033824209870445894,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0033824209870445894,
        "precision": 0.003167866217843917,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008507649034992786,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.008507649034992786,
        "precision": 0.007543915545799105,
        "recall": 0.015625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.085102998550257,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.085102998550257,
        "precision": 0.07938965789901739,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.15942571323414173,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.15942571323414173,
        "precision": 0.1539394996279762,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.03886617397359585,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.03886617397359585,
        "precision": 0.03458045653157096,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.145585317460317e-06,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 9.145585317460317e-06,
        "precision": 4.583898698143699e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.041953058397272e-05,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 4.041953058397272e-05,
        "precision": 2.0593886017410228e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05466666465049311,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.05466666465049311,
        "precision": 0.05001420407647654,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07462434107082712,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.07462434107082712,
        "precision": 0.06823353076175823,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.026106398847041336,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.026106398847041336,
        "precision": 0.023999916583351016,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06337297394090333,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.06337297394090333,
        "precision": 0.05862448403850863,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.08643242237249227,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.08643242237249227,
        "precision": 0.07411705001293996,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07199001115972073,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.07199001115972073,
        "precision": 0.06515590599115667,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.125,
        "f1": 0.09593416024080087,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.09593416024080087,
        "precision": 0.08571005817099567,
        "recall": 0.125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02896103627792325,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.02896103627792325,
        "precision": 0.02655227607301741,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00024379293919670673,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.00024379293919670673,
        "precision": 0.00012688871678078476,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.2197265625,
        "f1": 0.188330078125,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.188330078125,
        "precision": 0.17654664671266235,
        "recall": 0.2197265625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017248674337692824,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.0017248674337692824,
        "precision": 0.0014409816167628667,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.052945998771194075,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.052945998771194075,
        "precision": 0.047787620907738096,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021410870295698927,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.00021410870295698927,
        "precision": 0.00011347541207247981,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03612239987707039,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.03612239987707039,
        "precision": 0.030603538171897548,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.20255354996565933,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.20255354996565933,
        "precision": 0.19385381456961492,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003950017507002801,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0003950017507002801,
        "precision": 0.0002232142857142857,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.036319669913419915,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.036319669913419915,
        "precision": 0.03182234974227162,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.045180444779174114,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.045180444779174114,
        "precision": 0.03903982308813546,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.0910873214995972,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.0910873214995972,
        "precision": 0.08440813444305487,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.025960080278334692,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.025960080278334692,
        "precision": 0.02284804525659919,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010190217391304348,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0010190217391304348,
        "precision": 0.0009982638888888888,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00032033137077294683,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.00032033137077294683,
        "precision": 0.00017630718329253366,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.11242614696832123,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.11242614696832123,
        "precision": 0.10666930838577049,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.12951050685425686,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.12951050685425686,
        "precision": 0.12186841207837301,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.013414417613636364,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.013414417613636364,
        "precision": 0.011700383126845699,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.10956000643500644,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.10956000643500644,
        "precision": 0.10306877367424241,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.010770816910953628,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.010770816910953628,
        "precision": 0.008441732802490574,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.13037189111016745,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.13037189111016745,
        "precision": 0.12191773372310057,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.527439024390244e-06,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 9.527439024390244e-06,
        "precision": 4.7870710784313725e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.2243668005045405,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.2243668005045405,
        "precision": 0.2102503687909823,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000858233468066104,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.000858233468066104,
        "precision": 0.0006008913982259571,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.04972489883737585,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.04972489883737585,
        "precision": 0.043185989577116,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004957932692307692,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0004957932692307692,
        "precision": 0.0002712673611111111,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020231341694538617,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0020231341694538617,
        "precision": 0.001988583519345238,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.0080128205128203e-05,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 5.0080128205128203e-05,
        "precision": 2.5699013157894735e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.09617865536037501,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.09617865536037501,
        "precision": 0.08889343923296503,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002957393061216335,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.002957393061216335,
        "precision": 0.0026181390467939366,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009790761743886745,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0009790761743886745,
        "precision": 0.000977820956829897,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.11495426457213143,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.11495426457213143,
        "precision": 0.10859943877437815,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07250958676739926,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.07250958676739926,
        "precision": 0.065159208865838,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.08701847911089275,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.08701847911089275,
        "precision": 0.07936828184141831,
        "recall": 0.115234375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}