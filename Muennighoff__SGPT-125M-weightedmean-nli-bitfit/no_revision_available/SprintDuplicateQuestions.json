{
    "test": {
        "cos_sim": {
            "accuracy": 0.9949306930693069,
            "accuracy_threshold": 0.7870972752571106,
            "ap": 0.7773085502917281,
            "f1": 0.7178978681209718,
            "f1_threshold": 0.7572916746139526,
            "precision": 0.711897738446411,
            "recall": 0.724
        },
        "dot": {
            "accuracy": 0.9908118811881188,
            "accuracy_threshold": 1571.5850830078125,
            "ap": 0.30267748833368235,
            "f1": 0.34335201222618444,
            "f1_threshold": 1329.530029296875,
            "precision": 0.34994807892004154,
            "recall": 0.337
        },
        "euclidean": {
            "accuracy": 0.9951683168316832,
            "accuracy_threshold": 25.715721130371094,
            "ap": 0.7864498778235628,
            "f1": 0.7309149972929074,
            "f1_threshold": 26.336116790771484,
            "precision": 0.7969303423848878,
            "recall": 0.675
        },
        "evaluation_time": 6.6,
        "manhattan": {
            "accuracy": 0.9953168316831683,
            "accuracy_threshold": 534.224609375,
            "ap": 0.7945274878693959,
            "f1": 0.7419863373620599,
            "f1_threshold": 562.244140625,
            "precision": 0.7818383167220376,
            "recall": 0.706
        },
        "max": {
            "accuracy": 0.9953168316831683,
            "ap": 0.7945274878693959,
            "f1": 0.7419863373620599
        }
    },
    "mteb_version": "0.0.2",
    "mteb_dataset_name": "SprintDuplicateQuestions",
    "dataset_revision": "5a8256d0dff9c4bd3be3ba3e67e4e70173f802ea"
}