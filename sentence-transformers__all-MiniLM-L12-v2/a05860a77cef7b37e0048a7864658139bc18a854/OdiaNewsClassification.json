{
  "dataset_revision": "ffb8a34c9637fb20256e8c7be02504d16af4bd6b",
  "evaluation_time": 10.2582528591156,
  "kg_co2_emissions": 0.0015021091480735458,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.535888671875,
        "f1": 0.5301378917227442,
        "f1_weighted": 0.5302304732022662,
        "hf_subset": "default",
        "languages": [
          "ory-Orya"
        ],
        "main_score": 0.5301378917227442,
        "scores_per_experiment": [
          {
            "accuracy": 0.564453125,
            "f1": 0.570655568030321,
            "f1_weighted": 0.5694445519219589
          },
          {
            "accuracy": 0.4912109375,
            "f1": 0.5031390448895617,
            "f1_weighted": 0.5028120355551868
          },
          {
            "accuracy": 0.53271484375,
            "f1": 0.5493019070117193,
            "f1_weighted": 0.5340757251677163
          },
          {
            "accuracy": 0.5283203125,
            "f1": 0.5148992126257664,
            "f1_weighted": 0.5249175410735805
          },
          {
            "accuracy": 0.59228515625,
            "f1": 0.5435007644575549,
            "f1_weighted": 0.5603278173840065
          },
          {
            "accuracy": 0.58935546875,
            "f1": 0.5836781669796149,
            "f1_weighted": 0.5849730743759248
          },
          {
            "accuracy": 0.49462890625,
            "f1": 0.47054534392907515,
            "f1_weighted": 0.478168403794997
          },
          {
            "accuracy": 0.52197265625,
            "f1": 0.5246745956326638,
            "f1_weighted": 0.5200377507763555
          },
          {
            "accuracy": 0.5439453125,
            "f1": 0.5348339711504574,
            "f1_weighted": 0.5337249153468431
          },
          {
            "accuracy": 0.5,
            "f1": 0.5061503425207072,
            "f1_weighted": 0.4938229166260928
          }
        ]
      }
    ]
  },
  "task_name": "OdiaNewsClassification"
}