{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.9941386138613861,
            "accuracy_threshold": 0.9067416787147522,
            "ap": 0.7162935027705802,
            "f1": 0.6814292903875188,
            "f1_threshold": 0.8930895924568176,
            "precision": 0.6859169199594731,
            "recall": 0.677
        },
        "dot": {
            "accuracy": 0.9933960396039604,
            "accuracy_threshold": 432.6776123046875,
            "ap": 0.6764558182353655,
            "f1": 0.6392344497607656,
            "f1_threshold": 418.6991271972656,
            "precision": 0.6128440366972477,
            "recall": 0.668
        },
        "euclidean": {
            "accuracy": 0.993990099009901,
            "accuracy_threshold": 9.182230949401855,
            "ap": 0.7017532210387429,
            "f1": 0.6725025746652935,
            "f1_threshold": 9.913853645324707,
            "precision": 0.6932059447983014,
            "recall": 0.653
        },
        "evaluation_time": 6.88,
        "manhattan": {
            "accuracy": 0.993960396039604,
            "accuracy_threshold": 206.7137451171875,
            "ap": 0.7025315680643374,
            "f1": 0.6786606696651675,
            "f1_threshold": 221.44918823242188,
            "precision": 0.6783216783216783,
            "recall": 0.679
        },
        "max": {
            "accuracy": 0.9941386138613861,
            "ap": 0.7162935027705802,
            "f1": 0.6814292903875188
        }
    },
    "mteb_dataset_name": "SprintDuplicateQuestions",
    "dataset_revision": "5a8256d0dff9c4bd3be3ba3e67e4e70173f802ea"
}