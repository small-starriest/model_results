{
  "dataset_revision": "bd1a7370caf712125fac1fda375834ca8ddefaca",
  "evaluation_time": 26.19960045814514,
  "kg_co2_emissions": 0.004891584676486457,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.453369140625,
        "f1": 0.44270392726953867,
        "f1_weighted": 0.45192655452627184,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.453369140625,
        "scores_per_experiment": [
          {
            "accuracy": 0.44677734375,
            "f1": 0.4332540148010617,
            "f1_weighted": 0.4452678093856669
          },
          {
            "accuracy": 0.45751953125,
            "f1": 0.4577852589019313,
            "f1_weighted": 0.4606434233015253
          },
          {
            "accuracy": 0.4931640625,
            "f1": 0.48336436371519653,
            "f1_weighted": 0.500743761509758
          },
          {
            "accuracy": 0.46484375,
            "f1": 0.45226675252760157,
            "f1_weighted": 0.4645380274221519
          },
          {
            "accuracy": 0.5087890625,
            "f1": 0.48639527071909044,
            "f1_weighted": 0.5048565992737772
          },
          {
            "accuracy": 0.36669921875,
            "f1": 0.3673385374528125,
            "f1_weighted": 0.35898402466884716
          },
          {
            "accuracy": 0.51953125,
            "f1": 0.4818718224198355,
            "f1_weighted": 0.5043902630522488
          },
          {
            "accuracy": 0.41943359375,
            "f1": 0.4103728325689036,
            "f1_weighted": 0.4144056980640809
          },
          {
            "accuracy": 0.4384765625,
            "f1": 0.4355745314969728,
            "f1_weighted": 0.4498533509775563
          },
          {
            "accuracy": 0.41845703125,
            "f1": 0.41881588809198084,
            "f1_weighted": 0.41558258760710576
          }
        ]
      }
    ]
  },
  "task_name": "KorHateClassification"
}