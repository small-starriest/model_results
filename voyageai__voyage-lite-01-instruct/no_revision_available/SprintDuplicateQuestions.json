{
  "dataset_revision": "d66bd1f72af766a5cc4b0ca5e00c162f89e8cc46",
  "mteb_dataset_name": "SprintDuplicateQuestions",
  "mteb_version": "1.1.1.dev0",
  "test": {
    "cos_sim": {
      "accuracy": 0.9983861386138614,
      "accuracy_threshold": 0.8370740413665771,
      "ap": 0.9600730952215838,
      "f1": 0.9170483460559796,
      "f1_threshold": 0.8364102244377136,
      "precision": 0.933678756476684,
      "recall": 0.901
    },
    "dot": {
      "accuracy": 0.9983861386138614,
      "accuracy_threshold": 0.8370740413665771,
      "ap": 0.9600730591597015,
      "f1": 0.9170483460559796,
      "f1_threshold": 0.8364102840423584,
      "precision": 0.933678756476684,
      "recall": 0.901
    },
    "euclidean": {
      "accuracy": 0.9983861386138614,
      "accuracy_threshold": 0.5708343982696533,
      "ap": 0.9600730952215837,
      "f1": 0.9170483460559796,
      "f1_threshold": 0.5719960927963257,
      "precision": 0.933678756476684,
      "recall": 0.901
    },
    "evaluation_time": 27.3,
    "manhattan": {
      "accuracy": 0.9983861386138614,
      "accuracy_threshold": 14.592785835266113,
      "ap": 0.9601315909570357,
      "f1": 0.9184592296148075,
      "f1_threshold": 14.968973159790039,
      "precision": 0.918918918918919,
      "recall": 0.918
    },
    "max": {
      "accuracy": 0.9983861386138614,
      "ap": 0.9601315909570357,
      "f1": 0.9184592296148075
    }
  },
  "validation": {
    "cos_sim": {
      "accuracy": 0.9985247524752475,
      "accuracy_threshold": 0.8233826160430908,
      "ap": 0.9644117271797761,
      "f1": 0.9255372313843079,
      "f1_threshold": 0.8233826160430908,
      "precision": 0.9250749250749251,
      "recall": 0.926
    },
    "dot": {
      "accuracy": 0.9985247524752475,
      "accuracy_threshold": 0.8233826756477356,
      "ap": 0.9644117271797761,
      "f1": 0.9255372313843079,
      "f1_threshold": 0.8233826756477356,
      "precision": 0.9250749250749251,
      "recall": 0.926
    },
    "euclidean": {
      "accuracy": 0.9985247524752475,
      "accuracy_threshold": 0.5943355560302734,
      "ap": 0.9644117271797762,
      "f1": 0.9255372313843079,
      "f1_threshold": 0.5943355560302734,
      "precision": 0.9250749250749251,
      "recall": 0.926
    },
    "evaluation_time": 29.59,
    "manhattan": {
      "accuracy": 0.9984950495049505,
      "accuracy_threshold": 15.13698959350586,
      "ap": 0.9636193730271969,
      "f1": 0.923923923923924,
      "f1_threshold": 15.13698959350586,
      "precision": 0.9248496993987976,
      "recall": 0.923
    },
    "max": {
      "accuracy": 0.9985247524752475,
      "ap": 0.9644117271797762,
      "f1": 0.9255372313843079
    }
  }
}