{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.9968217821782178,
            "accuracy_threshold": 0.6832115650177002,
            "ap": 0.8926374055718889,
            "f1": 0.834319526627219,
            "f1_threshold": 0.6612635254859924,
            "precision": 0.8229571984435797,
            "recall": 0.846
        },
        "dot": {
            "accuracy": 0.9968217821782178,
            "accuracy_threshold": 0.683211624622345,
            "ap": 0.892637442450044,
            "f1": 0.834319526627219,
            "f1_threshold": 0.6612635254859924,
            "precision": 0.8229571984435797,
            "recall": 0.846
        },
        "euclidean": {
            "accuracy": 0.9968217821782178,
            "accuracy_threshold": 0.7959754467010498,
            "ap": 0.8926374055718889,
            "f1": 0.834319526627219,
            "f1_threshold": 0.8230873346328735,
            "precision": 0.8229571984435797,
            "recall": 0.846
        },
        "evaluation_time": 11.44,
        "manhattan": {
            "accuracy": 0.9967425742574257,
            "accuracy_threshold": 17.19844627380371,
            "ap": 0.8885929556527079,
            "f1": 0.8295566502463054,
            "f1_threshold": 18.042034149169922,
            "precision": 0.8174757281553398,
            "recall": 0.842
        },
        "max": {
            "accuracy": 0.9968217821782178,
            "ap": 0.892637442450044,
            "f1": 0.834319526627219
        }
    },
    "mteb_dataset_name": "SprintDuplicateQuestions",
    "dataset_revision": "5a8256d0dff9c4bd3be3ba3e67e4e70173f802ea"
}