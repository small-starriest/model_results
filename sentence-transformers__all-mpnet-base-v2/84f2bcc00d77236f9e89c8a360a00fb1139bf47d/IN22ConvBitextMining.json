{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 28.373634815216064,
  "kg_co2_emissions": 0.004571320225606996,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.13639387890884896,
        "f1": 0.09666866363473149,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.09666866363473149,
        "precision": 0.0848144407525645,
        "recall": 0.13639387890884896
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0030912691455450333,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0030912691455450333,
        "precision": 0.002474676338712971,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.006166884478681936,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.006166884478681936,
        "precision": 0.005353009893928057,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 2.80355604747765e-05,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 2.80355604747765e-05,
        "precision": 1.4148926613386761e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005947610264075435,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.005947610264075435,
        "precision": 0.004620159808107904,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003604187636123764,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.003604187636123764,
        "precision": 0.0030551922973975415,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003509650380314911,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.003509650380314911,
        "precision": 0.0030430382857527453,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00036108398675757485,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.00036108398675757485,
        "precision": 0.00023614845607224485,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 5.1179691898254774e-05,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 5.1179691898254774e-05,
        "precision": 2.6613439787092483e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004941569851749492,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.004941569851749492,
        "precision": 0.004016155142473933,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0011655930604629937,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0011655930604629937,
        "precision": 0.0010268799796450984,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0061494994197747385,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0061494994197747385,
        "precision": 0.005281851200627459,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003230047840826284,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.003230047840826284,
        "precision": 0.0025488705129423695,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.0076180818028233985,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0076180818028233985,
        "precision": 0.006220898453147439,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0016887300962511698,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0016887300962511698,
        "precision": 0.0015652176232151369,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0027270582034730094,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0027270582034730094,
        "precision": 0.0023154318417441203,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0039148119053525636,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0039148119053525636,
        "precision": 0.003423067056145726,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002723038770942963,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.002723038770942963,
        "precision": 0.00240410669749549,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.002137496167539529,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.002137496167539529,
        "precision": 0.0016871624711653841,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0021992051932171693,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0021992051932171693,
        "precision": 0.0021058201526533153,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00227067233055257,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.00227067233055257,
        "precision": 0.0019448558080970675,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0001855359287222618,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0001855359287222618,
        "precision": 9.928832523789376e-05,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.1051230871590153,
        "f1": 0.06802916469236003,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.06802916469236003,
        "precision": 0.05913015002348697,
        "recall": 0.1051230871590153
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0025495434503250733,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0025495434503250733,
        "precision": 0.00231537809827733,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.003546835740379742,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.003546835740379742,
        "precision": 0.0031832645487057092,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007503878490248895,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.007503878490248895,
        "precision": 0.006068685476590939,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008694521900181492,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0008694521900181492,
        "precision": 0.0007795034361619501,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.005165980138770625,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.005165980138770625,
        "precision": 0.004592627442298113,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010026565647270381,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0010026565647270381,
        "precision": 0.0008679092188520344,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.000998003992015968,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.000998003992015968,
        "precision": 0.0008871146595697493,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.006606284540581963,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.006606284540581963,
        "precision": 0.005605046831977076,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006966226277603522,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0006966226277603522,
        "precision": 0.0006811217097774712,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.008227358397096702,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.008227358397096702,
        "precision": 0.007370279861141681,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0019858009444054746,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0019858009444054746,
        "precision": 0.0015126107137305449,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.006616397553364781,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.006616397553364781,
        "precision": 0.0053499204082961315,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006860940374558299,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0006860940374558299,
        "precision": 0.0006757767651886456,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.001118489147622988,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.001118489147622988,
        "precision": 0.0010028281311801229,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.008044458307717018,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.008044458307717018,
        "precision": 0.007155394040002719,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007102945171865485,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0007102945171865485,
        "precision": 0.00042212967277472415,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0032027568311436216,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0032027568311436216,
        "precision": 0.0026672744505485723,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.002415057658262377,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.002415057658262377,
        "precision": 0.002052627485783832,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013750277223331113,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0013750277223331113,
        "precision": 0.001164337990685296,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0013807005181124723,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0013807005181124723,
        "precision": 0.0010658896877523865,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0018380679362924163,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0018380679362924163,
        "precision": 0.0016451195058891945,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027549776783194002,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0027549776783194002,
        "precision": 0.0024965908831821866,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.07850964737192283,
        "f1": 0.06395098211465476,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.06395098211465476,
        "precision": 0.059162489236551645,
        "recall": 0.07850964737192283
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028057991441085774,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0028057991441085774,
        "precision": 0.0025673732755912477,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.049810964869083915,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.049810964869083915,
        "precision": 0.046332025420906475,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.011706683375317937,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011706683375317937,
        "precision": 0.009493610360787686,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.07784431137724551,
        "f1": 0.06221237274629682,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.06221237274629682,
        "precision": 0.05825830629644055,
        "recall": 0.07784431137724551
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0012529724334463023,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0012529724334463023,
        "precision": 0.00107747297375428,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.023804227463484224,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.023804227463484224,
        "precision": 0.021591124944362477,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.01928792727195921,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.01928792727195921,
        "precision": 0.017585199970429514,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.021856048916724807,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.021856048916724807,
        "precision": 0.019852490173434722,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.020048937778994903,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.020048937778994903,
        "precision": 0.017336560790510165,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004052067412706584,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004052067412706584,
        "precision": 0.0034094861020399626,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.019922852707283844,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.019922852707283844,
        "precision": 0.01805957463064302,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0012657526562977243,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0012657526562977243,
        "precision": 0.0010435396670698662,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.027517808574291435,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.027517808574291435,
        "precision": 0.026324722727923203,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.01849969675299053,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.01849969675299053,
        "precision": 0.016280167136577883,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0030546843816725896,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0030546843816725896,
        "precision": 0.002451498147127793,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.07052561543579508,
        "f1": 0.057406399322566984,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.057406399322566984,
        "precision": 0.05363741750967299,
        "recall": 0.07052561543579508
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.01990739674083143,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.01990739674083143,
        "precision": 0.018307644304566866,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.026062567579533645,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.026062567579533645,
        "precision": 0.02393652023438503,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.029527530684041188,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.029527530684041188,
        "precision": 0.028072147563202993,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0016008815127968126,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0016008815127968126,
        "precision": 0.001287683514024217,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0026211790429221346,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0026211790429221346,
        "precision": 0.002340790843873323,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.055312425771450506,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.055312425771450506,
        "precision": 0.05013267858062139,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003172823085291149,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003172823085291149,
        "precision": 0.0028070530636338455,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.09780439121756487,
        "f1": 0.07950111029170302,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.07950111029170302,
        "precision": 0.07395263938354228,
        "recall": 0.09780439121756487
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.013927905078151755,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.013927905078151755,
        "precision": 0.011820785328608393,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.2714570858283433,
        "f1": 0.2170227771151311,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2170227771151311,
        "precision": 0.20023590385366832,
        "recall": 0.2714570858283433
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007693094220040329,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0007693094220040329,
        "precision": 0.000721000703048927,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.025974358691682665,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.025974358691682665,
        "precision": 0.02397122668159542,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.14437791084497673,
        "f1": 0.10536667319767784,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10536667319767784,
        "precision": 0.09374716545375228,
        "recall": 0.14437791084497673
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.020920613575159553,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.020920613575159553,
        "precision": 0.01906420489631426,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.09780439121756487,
        "f1": 0.07315475608888783,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07315475608888783,
        "precision": 0.0660604022280669,
        "recall": 0.09780439121756487
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.003886116825670788,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003886116825670788,
        "precision": 0.003205024702877553,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.14171656686626746,
        "f1": 0.10836423870356005,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.10836423870356005,
        "precision": 0.0976528424632217,
        "recall": 0.14171656686626746
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0016083418858414014,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0016083418858414014,
        "precision": 0.0012515159221746048,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.02305832689059311,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.02305832689059311,
        "precision": 0.021451253864678752,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.05322687957418496,
        "f1": 0.032789631470597706,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.032789631470597706,
        "precision": 0.028352759452920432,
        "recall": 0.05322687957418496
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0035119089544891407,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0035119089544891407,
        "precision": 0.0027819429275946048,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.13409952581609266,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.13409952581609266,
        "precision": 0.12100362178626703,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.019353544726527575,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.019353544726527575,
        "precision": 0.017620063637983407,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.029098887362360416,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.029098887362360416,
        "precision": 0.02636694425942018,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.043912175648702596,
        "f1": 0.03387751756666102,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.03387751756666102,
        "precision": 0.03161379347134772,
        "recall": 0.043912175648702596
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.719958724810598e-05,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 3.719958724810598e-05,
        "precision": 1.878370986928066e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0009973745006143263,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0009973745006143263,
        "precision": 0.0008560221604720841,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.004184153498824019,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.004184153498824019,
        "precision": 0.0028814897117840307,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005646223168195674,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.005646223168195674,
        "precision": 0.004775173642513317,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007804464205829736,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.007804464205829736,
        "precision": 0.006548492191181263,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0050154486304333935,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0050154486304333935,
        "precision": 0.0038891692986950744,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.006451027154898727,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.006451027154898727,
        "precision": 0.005025638277895904,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 5.0692266261128544e-05,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 5.0692266261128544e-05,
        "precision": 2.6126046317967372e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005194594204482339,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.005194594204482339,
        "precision": 0.0038198406780919356,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002459778367298366,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.002459778367298366,
        "precision": 0.0019883200738595214,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004642495958643908,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.004642495958643908,
        "precision": 0.0038515682929044486,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0011755195171283615,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0011755195171283615,
        "precision": 0.0009495641208327625,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 4.6644007631102045e-05,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 4.6644007631102045e-05,
        "precision": 2.369095064103718e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0021353658532352786,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0021353658532352786,
        "precision": 0.0016896572755480536,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.143756217319236e-05,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 3.143756217319236e-05,
        "precision": 1.5863990227118375e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007214699280466852,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.007214699280466852,
        "precision": 0.005886292330252784,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0013367224314457366,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.0013367224314457366,
        "precision": 0.0011186286635388432,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.001007786197774884,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.001007786197774884,
        "precision": 0.0008473780042960522,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0037146819102848194,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.0037146819102848194,
        "precision": 0.002471051890580508,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0033781804110484173,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.0033781804110484173,
        "precision": 0.002363120773946556,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.005025505267605103,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.005025505267605103,
        "precision": 0.003685541648657024,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.004208036428277137,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.004208036428277137,
        "precision": 0.0033595456371373848,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0027372841879395905,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0027372841879395905,
        "precision": 0.002441527004267649,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0035141034211820634,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0035141034211820634,
        "precision": 0.0032242717025325724,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.05453155857998348,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.05453155857998348,
        "precision": 0.05111591925461326,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.09660838533094022,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.09660838533094022,
        "precision": 0.08943728704207746,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.003303781220412555,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.003303781220412555,
        "precision": 0.0031028908458455096,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01552262746540857,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01552262746540857,
        "precision": 0.013391617467675875,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.12508316699933467,
        "f1": 0.10152535237365574,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.10152535237365574,
        "precision": 0.09449635896741684,
        "recall": 0.12508316699933467
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0010534486582390774,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0010534486582390774,
        "precision": 0.0009160423115122412,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.02194788361146098,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.02194788361146098,
        "precision": 0.020491093911124515,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.07651363938789088,
        "f1": 0.05426882873831081,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05426882873831081,
        "precision": 0.048086894993082614,
        "recall": 0.07651363938789088
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.022987728247209283,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.022987728247209283,
        "precision": 0.021205177364569106,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.24085163007318697,
        "f1": 0.18899819408801444,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.18899819408801444,
        "precision": 0.17043003939211523,
        "recall": 0.24085163007318697
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.003548894406302588,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003548894406302588,
        "precision": 0.002700943617231572,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.07518296739853626,
        "f1": 0.053385100890090915,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.053385100890090915,
        "precision": 0.047122685845240736,
        "recall": 0.07518296739853626
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0005463648929357726,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0005463648929357726,
        "precision": 0.00034456085295938443,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.026034394483211137,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.026034394483211137,
        "precision": 0.025049075094650188,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.035263878577251835,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.035263878577251835,
        "precision": 0.030210340623724383,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004038826324735789,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004038826324735789,
        "precision": 0.0031395007183057638,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.1264138389886893,
        "f1": 0.09912353724141913,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.09912353724141913,
        "precision": 0.09079713348675425,
        "recall": 0.1264138389886893
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.018840230520241058,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.018840230520241058,
        "precision": 0.017319272308645658,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.031957208903316686,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.031957208903316686,
        "precision": 0.030172670531951964,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.030496944034574654,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.030496944034574654,
        "precision": 0.028457343626219357,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00024945892572341804,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.00024945892572341804,
        "precision": 0.00013588569143233316,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662326739154217,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0006662326739154217,
        "precision": 0.0006657846366157323,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0031172223454325916,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.0031172223454325916,
        "precision": 0.0027580244222709417,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.004339278165498472,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.004339278165498472,
        "precision": 0.0042211301732490766,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002357894729181688,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.002357894729181688,
        "precision": 0.0022065350701273804,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.005842491820899968,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.005842491820899968,
        "precision": 0.0056952658151189885,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.005412191038570655,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.005412191038570655,
        "precision": 0.005369265444463885,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.02323920258051994,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.02323920258051994,
        "precision": 0.020457206895923664,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.00809897423371243,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.00809897423371243,
        "precision": 0.00787517245187272,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.290531871433054e-05,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 8.290531871433054e-05,
        "precision": 4.3903192967910615e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.02815497752290833,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.02815497752290833,
        "precision": 0.026015128510138492,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007640826943398271,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0007640826943398271,
        "precision": 0.000717315369261477,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.028910959359739218,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.028910959359739218,
        "precision": 0.024361965671451963,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000751500002997009,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.000751500002997009,
        "precision": 0.0007111936147769672,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.02323631935882913,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.02323631935882913,
        "precision": 0.02052769899576287,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.036105653974915455,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.036105653974915455,
        "precision": 0.033421397969829784,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007912928459244109,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0007912928459244109,
        "precision": 0.0007326622072421466,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.024938324824522278,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.024938324824522278,
        "precision": 0.02143464393963396,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.00514289821706102,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.00514289821706102,
        "precision": 0.005011301091464191,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.004696333575417513,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.004696333575417513,
        "precision": 0.004148144642053291,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.039083794373215526,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.039083794373215526,
        "precision": 0.03605648251356834,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00536798343050246,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.00536798343050246,
        "precision": 0.005156824160865548,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0009438871025941257,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0009438871025941257,
        "precision": 0.0008097986992963251,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0026833046707589073,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0026833046707589073,
        "precision": 0.0024669116785279717,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05639279849613053,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.05639279849613053,
        "precision": 0.05134143198351593,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.2554890219560878,
        "f1": 0.21086746660598954,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.21086746660598954,
        "precision": 0.19555026551034535,
        "recall": 0.2554890219560878
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00179087291347255,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00179087291347255,
        "precision": 0.0016717036520036855,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.08996170933406859,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08996170933406859,
        "precision": 0.08357079943612761,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.012768966504624371,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.012768966504624371,
        "precision": 0.010282942690807375,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0015126655025044676,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0015126655025044676,
        "precision": 0.0012572806037323945,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.02436374141879704,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.02436374141879704,
        "precision": 0.022510743626892194,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.13003135697746476,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13003135697746476,
        "precision": 0.11670811815522394,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.022484646277061444,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.022484646277061444,
        "precision": 0.02048870989373443,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.09514304723885562,
        "f1": 0.06409017021540124,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06409017021540124,
        "precision": 0.05682294372120602,
        "recall": 0.09514304723885562
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0017340204860184537,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0017340204860184537,
        "precision": 0.0013575642960894198,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.1317365269461078,
        "f1": 0.09358542775361312,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09358542775361312,
        "precision": 0.08244683896507185,
        "recall": 0.1317365269461078
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011968656963698729,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0011968656963698729,
        "precision": 0.0009985979004161693,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.02484120927202891,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.02484120927202891,
        "precision": 0.02354201147450922,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.02917443246720238,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.02917443246720238,
        "precision": 0.02489646878556094,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0027405506447422613,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0027405506447422613,
        "precision": 0.0020752146500649495,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.20159680638722555,
        "f1": 0.1579761955195299,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1579761955195299,
        "precision": 0.1445170505549747,
        "recall": 0.20159680638722555
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.01928057928513158,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.01928057928513158,
        "precision": 0.017362575461869832,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.028502558775346534,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.028502558775346534,
        "precision": 0.02663769828151756,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.06121091151031271,
        "f1": 0.04400196577149113,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.04400196577149113,
        "precision": 0.03977792326011853,
        "recall": 0.06121091151031271
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0002335757910170582,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0002335757910170582,
        "precision": 0.00012386750706299212,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000724107739326314,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.000724107739326314,
        "precision": 0.0006960370760681923,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007663155338393099,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0007663155338393099,
        "precision": 0.0007171626184440421,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006764341942414159,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0006764341942414159,
        "precision": 0.000670910110853753,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008708058908410085,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0008708058908410085,
        "precision": 0.0007760096272726185,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013735968922370314,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0013735968922370314,
        "precision": 0.0013528498558438677,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.023419712541469028,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.023419712541469028,
        "precision": 0.020534126269713918,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007163080163301712,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0007163080163301712,
        "precision": 0.000691302396037525,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013318290954323238,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0013318290954323238,
        "precision": 0.001331251045920923,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.577096803360626e-05,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 3.577096803360626e-05,
        "precision": 1.8258813609289126e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.02217030862240443,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.02217030862240443,
        "precision": 0.01871663583723335,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.02234059767040346,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.02234059767040346,
        "precision": 0.018618972718298005,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006995353316414498,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0006995353316414498,
        "precision": 0.0006828080533610649,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.01561679446253739,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.01561679446253739,
        "precision": 0.012998082374103168,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.009171320168308779,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.009171320168308779,
        "precision": 0.007317867840150754,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007529305358047614,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0007529305358047614,
        "precision": 0.000710363623062232,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.012938672918712838,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.012938672918712838,
        "precision": 0.01110342715408446,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000700647397409738,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.000700647397409738,
        "precision": 0.0006832622671533086,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.0030659511947921537,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0030659511947921537,
        "precision": 0.002124520381305778,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.03716926536938686,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.03716926536938686,
        "precision": 0.032197475857215205,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009007314651345738,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0009007314651345738,
        "precision": 0.0007996401520261513,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013735968922370314,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0013735968922370314,
        "precision": 0.0013528498558438677,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007128153708232987,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0007128153708232987,
        "precision": 0.0006894708036961347,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.022563104244186526,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.022563104244186526,
        "precision": 0.02110032397717896,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.02660304272748056,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.02660304272748056,
        "precision": 0.02539309060855333,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.002677759269117246,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.002677759269117246,
        "precision": 0.002669595646225001,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.019325402409487245,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.019325402409487245,
        "precision": 0.018618671747414262,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.007907641507109238,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.007907641507109238,
        "precision": 0.006337998976087286,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.017947353218477635,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.017947353218477635,
        "precision": 0.016626819561999046,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0020226214238190285,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0020226214238190285,
        "precision": 0.0020095862696375955,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00083613065252466,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.00083613065252466,
        "precision": 0.0005079182554020113,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.015413617210024395,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.015413617210024395,
        "precision": 0.014437791084497671,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0032084249255003284,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0032084249255003284,
        "precision": 0.003049456642271013,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0012422097719564124,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0012422097719564124,
        "precision": 0.001010525602503821,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0016473571646365185,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0016473571646365185,
        "precision": 0.0012591606879446295,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007287013275037226,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0007287013275037226,
        "precision": 0.000453877910939835,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.02052614143751019,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.02052614143751019,
        "precision": 0.019740310166980763,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0027612715788994813,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0027612715788994813,
        "precision": 0.002714139984678806,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0030933449654734478,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0030933449654734478,
        "precision": 0.0025499272829946876,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.02152684308372931,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.02152684308372931,
        "precision": 0.02066934281932366,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.011842980705256153,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.011842980705256153,
        "precision": 0.010979262476268464,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.020758483033932136,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.020758483033932136,
        "precision": 0.01961262659865454,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.09846972721224219,
        "f1": 0.07589556430462853,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.07589556430462853,
        "precision": 0.06948250764784364,
        "recall": 0.09846972721224219
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017246484946269601,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0017246484946269601,
        "precision": 0.0015575828096190082,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0025432141084557186,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0025432141084557186,
        "precision": 0.0023847659783353867,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.016182417912291497,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.016182417912291497,
        "precision": 0.013465299194672856,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.1324018629407851,
        "f1": 0.09896109656588697,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.09896109656588697,
        "precision": 0.08883580677825006,
        "recall": 0.1324018629407851
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00012090356192951101,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00012090356192951101,
        "precision": 6.249029578523899e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0665335994677312,
        "f1": 0.04831003866354218,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04831003866354218,
        "precision": 0.04359396399316559,
        "recall": 0.0665335994677312
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0036306175527732417,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0036306175527732417,
        "precision": 0.003130146326731879,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.16633399866932802,
        "f1": 0.12524560026104922,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.12524560026104922,
        "precision": 0.11247198502687526,
        "recall": 0.16633399866932802
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 1.3592155151732626e-06,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 1.3592155151732626e-06,
        "precision": 6.803026530442864e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0027064951844146005,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0027064951844146005,
        "precision": 0.0021973366641067347,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0020370960117734073,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0020370960117734073,
        "precision": 0.0016325455648593759,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.09314703925482369,
        "f1": 0.06886073679329273,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06886073679329273,
        "precision": 0.06135051325919588,
        "recall": 0.09314703925482369
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0029045294412864357,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029045294412864357,
        "precision": 0.002267119379952537,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.16833000665335995,
        "f1": 0.12749722370480854,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12749722370480854,
        "precision": 0.11442963039769427,
        "recall": 0.16833000665335995
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000921230323967145,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.000921230323967145,
        "precision": 0.0006826058955514009,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0021449165161740013,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0021449165161740013,
        "precision": 0.002077950301984162,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.07917498336660013,
        "f1": 0.055857272627527176,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.055857272627527176,
        "precision": 0.04993907234914296,
        "recall": 0.07917498336660013
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0020171731520201622,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0020171731520201622,
        "precision": 0.0017452804122112563,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05404287673433592,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.05404287673433592,
        "precision": 0.04837727493372087,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0009781679568115697,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0009781679568115697,
        "precision": 0.0006616803023988653,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011643890760657228,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0011643890760657228,
        "precision": 0.0009549765332277062,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.004523454214403578,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.004523454214403578,
        "precision": 0.003650514929044826,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00010385123606083461,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.00010385123606083461,
        "precision": 5.365324806018174e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662284641537404,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0006662284641537404,
        "precision": 0.0006657825289019278,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.008704836672002643,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.008704836672002643,
        "precision": 0.008123246261100985,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.009213272800803621,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.009213272800803621,
        "precision": 0.008787181605406376,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.004471787629251572,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.004471787629251572,
        "precision": 0.004010596884255507,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.012005618392843942,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.012005618392843942,
        "precision": 0.011658501179459263,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.024871493244424794,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.024871493244424794,
        "precision": 0.02193068902182644,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.009356031102012823,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.009356031102012823,
        "precision": 0.009003031119756573,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.043912175648702596,
        "f1": 0.028149312500862566,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.028149312500862566,
        "precision": 0.024731561921665497,
        "recall": 0.043912175648702596
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.010725627064378133,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.010725627064378133,
        "precision": 0.01009145190460486,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.221445428773891e-05,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 3.221445428773891e-05,
        "precision": 1.640643375783658e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0007185628742514971,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0007185628742514971,
        "precision": 0.0006930583277888668,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.010541287154726941,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.010541287154726941,
        "precision": 0.008872275559489367,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006973863949196918,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0006973863949196918,
        "precision": 0.0006816601794533123,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.015613204763165711,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.015613204763165711,
        "precision": 0.013302454919221387,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.035323686131747425,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.035323686131747425,
        "precision": 0.033232298336300856,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007567462627144716,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0007567462627144716,
        "precision": 0.0007123682659567413,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.005323508709419815,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.005323508709419815,
        "precision": 0.004383351961724628,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.010390767001725369,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.010390767001725369,
        "precision": 0.009909234204044418,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.007601461062959119,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.007601461062959119,
        "precision": 0.006573175935328823,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.06453759148369927,
        "f1": 0.04989530683771214,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.04989530683771214,
        "precision": 0.04623604773484043,
        "recall": 0.06453759148369927
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.012050907930727241,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.012050907930727241,
        "precision": 0.011350316551299252,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0012992216444420905,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0012992216444420905,
        "precision": 0.0010132749545573572,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014376961679865776,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0014376961679865776,
        "precision": 0.0011818291128184557,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.016974687224970968,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.016974687224970968,
        "precision": 0.014211625127293789,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.09913506320691949,
        "f1": 0.07390438496226918,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.07390438496226918,
        "precision": 0.06689726667597012,
        "recall": 0.09913506320691949
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0014522929842049228,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0014522929842049228,
        "precision": 0.0013941089341637492,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.24550898203592814,
        "f1": 0.19096309545411339,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.19096309545411339,
        "precision": 0.17231538144711794,
        "recall": 0.24550898203592814
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.004132884276370888,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004132884276370888,
        "precision": 0.003801588015917977,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.09314703925482369,
        "f1": 0.06147046012315473,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.06147046012315473,
        "precision": 0.053478995529105844,
        "recall": 0.09314703925482369
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0016535591803459562,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0016535591803459562,
        "precision": 0.00151157204409191,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0030341376356562474,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0030341376356562474,
        "precision": 0.0026233247790134018,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.10379241516966067,
        "f1": 0.07242495805370057,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.07242495805370057,
        "precision": 0.06350435864828133,
        "recall": 0.10379241516966067
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0024981385735487285,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0024981385735487285,
        "precision": 0.002096043635433515,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004153340542868098,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004153340542868098,
        "precision": 0.003569798417285646,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.1111111111111111,
        "f1": 0.07920245644796543,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07920245644796543,
        "precision": 0.06999715156228217,
        "recall": 0.1111111111111111
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007193665467364286,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0007193665467364286,
        "precision": 0.0006926319843665503,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0010239837784747966,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0010239837784747966,
        "precision": 0.0009003224222201958,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0552228875582169,
        "f1": 0.03608683583733484,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.03608683583733484,
        "precision": 0.031622012693203645,
        "recall": 0.0552228875582169
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.00307979865856341,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00307979865856341,
        "precision": 0.002492071892940602,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.04920557191016273,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04920557191016273,
        "precision": 0.043142814899301926,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.001711120152184438,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.001711120152184438,
        "precision": 0.0012793835532907475,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.004633382840993069,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.004633382840993069,
        "precision": 0.0039489104579512,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0023272327266126444,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0023272327266126444,
        "precision": 0.0019637353422369596,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0003215827238527111,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0003215827238527111,
        "precision": 0.0001866301800507347,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007043416080050002,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0007043416080050002,
        "precision": 0.0006853982730994634,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008150621440171372,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0008150621440171372,
        "precision": 0.0007447541712345437,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006757494340309014,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0006757494340309014,
        "precision": 0.0006705586127138726,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008079232764912272,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0008079232764912272,
        "precision": 0.0007413170853616695,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000740230682093681,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.000740230682093681,
        "precision": 0.000704957991704066,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.028092772649654308,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.028092772649654308,
        "precision": 0.023928143957509685,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00067114526772727,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.00067114526772727,
        "precision": 0.0006682485626237466,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.019981064932266507,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.019981064932266507,
        "precision": 0.016897227176210103,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006672842699179484,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0006672842699179484,
        "precision": 0.0006663115606519122,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 4.608011231580015e-06,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 4.608011231580015e-06,
        "precision": 2.3084570207621488e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.011829019953379859,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.011829019953379859,
        "precision": 0.010551246727313944,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008182011414982093,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0008182011414982093,
        "precision": 0.0007492954800880649,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007362130426346821,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0007362130426346821,
        "precision": 0.0007025295475633303,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.024141879775246358,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.024141879775246358,
        "precision": 0.020597676256763026,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.02031430171118536,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.02031430171118536,
        "precision": 0.017686319223477607,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008367377991268518,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0008367377991268518,
        "precision": 0.0007629237168186853,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.033113420363919364,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.033113420363919364,
        "precision": 0.030262262901822493,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006717009582941679,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0006717009582941679,
        "precision": 0.0006685280123048804,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0024918277029469193,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0024918277029469193,
        "precision": 0.0019836354371559318,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.01755429831569797,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.01755429831569797,
        "precision": 0.015319017138137514,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006664655973847438,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0006664655973847438,
        "precision": 0.0006659012758962392,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0009610408812005619,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0009610408812005619,
        "precision": 0.0008467912659529426,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004484509377911363,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.004484509377911363,
        "precision": 0.004090671001109847,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.025856560088097013,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.025856560088097013,
        "precision": 0.022459314175881043,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.1370592149035263,
        "f1": 0.10144367349956171,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.10144367349956171,
        "precision": 0.08996480343785732,
        "recall": 0.1370592149035263
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.000735667162474656,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.000735667162474656,
        "precision": 0.0007012416702179621,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.06520292747837658,
        "f1": 0.045225803677321694,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.045225803677321694,
        "precision": 0.03940930068674579,
        "recall": 0.06520292747837658
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0033545840376272575,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0033545840376272575,
        "precision": 0.0029286740634160736,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.12375249500998003,
        "f1": 0.08883666049334712,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.08883666049334712,
        "precision": 0.0789420871010888,
        "recall": 0.12375249500998003
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0015760321831723332,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0015760321831723332,
        "precision": 0.0014657858737387114,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0026349373762390867,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0026349373762390867,
        "precision": 0.002153850621914494,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.17564870259481039,
        "f1": 0.13375410351458256,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13375410351458256,
        "precision": 0.1198840008221246,
        "recall": 0.17564870259481039
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003932678974262474,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.003932678974262474,
        "precision": 0.003535480620360097,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.1111111111111111,
        "f1": 0.08172420034348352,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.08172420034348352,
        "precision": 0.07302818605213814,
        "recall": 0.1111111111111111
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.004188297749424232,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004188297749424232,
        "precision": 0.003505409463762181,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0013900965606797639,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0013900965606797639,
        "precision": 0.0013607191640805799,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007052911934420421,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0007052911934420421,
        "precision": 0.00048053094546315005,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.07252162341982701,
        "f1": 0.053783658668007606,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.053783658668007606,
        "precision": 0.04841998302577144,
        "recall": 0.07252162341982701
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.004004365610888218,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004004365610888218,
        "precision": 0.003400262442947574,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.06719893546240852,
        "f1": 0.04889647813212449,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04889647813212449,
        "precision": 0.04400523233484247,
        "recall": 0.06719893546240852
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.00477278728131481,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.00477278728131481,
        "precision": 0.004477574548112911,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0034498108885140447,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0034498108885140447,
        "precision": 0.0028926246783733674,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005559432527002763,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.005559432527002763,
        "precision": 0.004568593632047267,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0005285642268832608,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0005285642268832608,
        "precision": 0.0003149853699389174,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000856344037014909,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.000856344037014909,
        "precision": 0.0007681517131752464,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008314572799049226,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0008314572799049226,
        "precision": 0.0007540802261220579,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006745954784089041,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0006745954784089041,
        "precision": 0.0006699780436007778,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007966720878793243,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0007966720878793243,
        "precision": 0.0007349666433816016,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001504897600178659,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.001504897600178659,
        "precision": 0.0014246681240693217,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.05322687957418496,
        "f1": 0.03373024076489509,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.03373024076489509,
        "precision": 0.02858251535064576,
        "recall": 0.05322687957418496
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007069183021913322,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0007069183021913322,
        "precision": 0.0006866600424737315,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.019996226882454424,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.019996226882454424,
        "precision": 0.016980694412060494,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006671688762053486,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0006671688762053486,
        "precision": 0.0006662536994975567,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 7.810960953535739e-05,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 7.810960953535739e-05,
        "precision": 4.123240283760976e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.01522830562842644,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.01522830562842644,
        "precision": 0.01356375094993748,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008332318986364539,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0008332318986364539,
        "precision": 0.0007586219286712106,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0499001996007984,
        "f1": 0.029128736973364527,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.029128736973364527,
        "precision": 0.024777503392332555,
        "recall": 0.0499001996007984
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007429278425329801,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0007429278425329801,
        "precision": 0.0007063087882897703,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.02335313843410369,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.02335313843410369,
        "precision": 0.020387442934088344,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008510504793547548,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0008510504793547548,
        "precision": 0.0007648372804835259,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.020858550224817692,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.020858550224817692,
        "precision": 0.01780879906159729,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008085006636893265,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0008085006636893265,
        "precision": 0.0007396499978297116,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.001490822133734297,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.001490822133734297,
        "precision": 0.0011312549364447335,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.017077725261357996,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.017077725261357996,
        "precision": 0.013364643165506555,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013317181151324185,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0013317181151324185,
        "precision": 0.0013311954637800195,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0002896069946283245,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.0002896069946283245,
        "precision": 0.00016430488234450921,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008326300741470402,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0008326300741470402,
        "precision": 0.000760864380916695,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.013013163893755649,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.013013163893755649,
        "precision": 0.012258635108452135,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.011143086863029814,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.011143086863029814,
        "precision": 0.010594843837805179,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003935211991272005,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.003935211991272005,
        "precision": 0.003747714024153626,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.0208417703876698,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.0208417703876698,
        "precision": 0.020047292702719353,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.03720294418790279,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.03720294418790279,
        "precision": 0.03241159024547999,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.012701850772581702,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.012701850772581702,
        "precision": 0.012118381747597287,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.01163583061216366,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.01163583061216366,
        "precision": 0.009614537159447338,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.015749852692589203,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.015749852692589203,
        "precision": 0.014528291088074746,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.277634202255548e-05,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 8.277634202255548e-05,
        "precision": 4.3838296876508e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.03267379320034878,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.03267379320034878,
        "precision": 0.030922470586955905,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007351315767848147,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0007351315767848147,
        "precision": 0.0007013745660681596,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.030294778777812708,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.030294778777812708,
        "precision": 0.026011599277040224,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007476720826865317,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0007476720826865317,
        "precision": 0.0007089535623089055,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.023044099206536845,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.023044099206536845,
        "precision": 0.020172269149151986,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007891363115859757,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0007891363115859757,
        "precision": 0.000732305151518237,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.03336734959742814,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.03336734959742814,
        "precision": 0.028101432624095247,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.013539060556849631,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.013539060556849631,
        "precision": 0.013090238026370896,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.009919373343397191,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.009919373343397191,
        "precision": 0.009246609652847362,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.05788423153692615,
        "f1": 0.04295233190534612,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.04295233190534612,
        "precision": 0.0393736141618945,
        "recall": 0.05788423153692615
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.021780299624611,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.021780299624611,
        "precision": 0.020592967406719974,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0030165034672890324,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0030165034672890324,
        "precision": 0.002488633078543645,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.00324993798008113,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00324993798008113,
        "precision": 0.0028082723442004885,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.02123342722791934,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.02123342722791934,
        "precision": 0.01880496099081883,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.03196924300970079,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.03196924300970079,
        "precision": 0.02797135683862231,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001163744137330232,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.001163744137330232,
        "precision": 0.0010258494375499788,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.059214903526280775,
        "f1": 0.04191444697201476,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04191444697201476,
        "precision": 0.037527450955433694,
        "recall": 0.059214903526280775
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.004138197963048262,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004138197963048262,
        "precision": 0.0035828649023312326,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.05256154357950765,
        "f1": 0.03562127986857303,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.03562127986857303,
        "precision": 0.03238552575044799,
        "recall": 0.05256154357950765
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0018740297183410955,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0018740297183410955,
        "precision": 0.0016525390776887781,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003169949309249656,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.003169949309249656,
        "precision": 0.002805306494594585,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05149169231005558,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05149169231005558,
        "precision": 0.04570149109197947,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.004246192742909931,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.004246192742909931,
        "precision": 0.004141558153534202,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.04198587691601663,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04198587691601663,
        "precision": 0.037903593166400885,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.0038198148089476545,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0038198148089476545,
        "precision": 0.003160593354441342,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05221861496155015,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.05221861496155015,
        "precision": 0.04656309225210638,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.002025142768256393,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002025142768256393,
        "precision": 0.002010716803106611,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0006895981597604098,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0006895981597604098,
        "precision": 0.0006775267697330307,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0020717829448754694,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0020717829448754694,
        "precision": 0.001795173989196856,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.029117265893712996,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.029117265893712996,
        "precision": 0.026303751041334703,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0033984820499694374,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0033984820499694374,
        "precision": 0.003147145356126122,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0033084019682904295,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0033084019682904295,
        "precision": 0.0025563416032477904,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.003168528842697746,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.003168528842697746,
        "precision": 0.0029763607607918986,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00012618522077983084,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.00012618522077983084,
        "precision": 6.914782708909382e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 2.0039531728228636e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 2.0039531728228636e-05,
        "precision": 1.015791547683679e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 7.090008000668745e-05,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 7.090008000668745e-05,
        "precision": 3.6622224698713794e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006755301089918749,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0006755301089918749,
        "precision": 0.0006704481528054198,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008157549425198259,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0008157549425198259,
        "precision": 0.0005746146969950932,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007363863678693973,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0007363863678693973,
        "precision": 0.0007028069955649911,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.024016859143014553,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.024016859143014553,
        "precision": 0.020563030496734518,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007241347391403049,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0007241347391403049,
        "precision": 0.0006958510476009914,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.007574873019392329,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.007574873019392329,
        "precision": 0.006402724366980867,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0011114771535677298,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0011114771535677298,
        "precision": 0.000999298420021177,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.760939999801822e-05,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 8.760939999801822e-05,
        "precision": 4.6580896339020474e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.004939670186293644,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.004939670186293644,
        "precision": 0.004099293735274852,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.7455715388985e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 8.7455715388985e-05,
        "precision": 4.5776330147885535e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.030026506127529884,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.030026506127529884,
        "precision": 0.02575391075347684,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.724078856484114e-05,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 8.724078856484114e-05,
        "precision": 4.639611548304161e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.016151102625486,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.016151102625486,
        "precision": 0.014838902461987971,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.024055276727383494,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.024055276727383494,
        "precision": 0.02165506247668011,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000198737749572237,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.000198737749572237,
        "precision": 0.00010626289648601538,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.0495422705701793e-05,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 3.0495422705701793e-05,
        "precision": 1.5481029436936144e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.002678980972486317,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.002678980972486317,
        "precision": 0.002073231884923153,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.014303002914415525,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.014303002914415525,
        "precision": 0.01234355602474204,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 1.2648973282838632e-06,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 1.2648973282838632e-06,
        "precision": 6.330504230992503e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.001510525680838019,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.001510525680838019,
        "precision": 0.0011424098721233337,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0011088933244621866,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0011088933244621866,
        "precision": 0.000998003992015968,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.07052561543579508,
        "f1": 0.05737903202386001,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.05737903202386001,
        "precision": 0.05395811311479974,
        "recall": 0.07052561543579508
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.1394856271103776,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.1394856271103776,
        "precision": 0.1266221525203561,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.002003842049570609,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.002003842049570609,
        "precision": 0.001999936923078854,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.11976047904191617,
        "f1": 0.09503740511724543,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.09503740511724543,
        "precision": 0.08707021304652128,
        "recall": 0.11976047904191617
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.014368657911411113,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.014368657911411113,
        "precision": 0.012194087246699228,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.20625415834996674,
        "f1": 0.1666533952587233,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1666533952587233,
        "precision": 0.15438635715581822,
        "recall": 0.20625415834996674
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.026874152190186785,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.026874152190186785,
        "precision": 0.02450475858454116,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.07385229540918163,
        "f1": 0.05190576038879432,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05190576038879432,
        "precision": 0.04569062932336385,
        "recall": 0.07385229540918163
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.023509455725024584,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.023509455725024584,
        "precision": 0.02166223109336882,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.0825016633399867,
        "f1": 0.0566683789921525,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.0566683789921525,
        "precision": 0.04979039035925264,
        "recall": 0.0825016633399867
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.00409874670589712,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00409874670589712,
        "precision": 0.0031667705154065765,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04729540438123272,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04729540438123272,
        "precision": 0.04267364741416638,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014848132893701454,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0014848132893701454,
        "precision": 0.00117987450482922,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.02922902679672768,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.02922902679672768,
        "precision": 0.02831246106214227,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.027535941884696345,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.027535941884696345,
        "precision": 0.0238432013634805,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0021524794538742547,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0021524794538742547,
        "precision": 0.0016239069045710162,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.01719965630746959,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.01719965630746959,
        "precision": 0.015575778679898764,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.029863614681926408,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.029863614681926408,
        "precision": 0.02757081895913069,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.03483401954317267,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.03483401954317267,
        "precision": 0.03274019995045376,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011189741728663885,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0011189741728663885,
        "precision": 0.000925421883505716,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014603455677490081,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.014603455677490081,
        "precision": 0.01357770746377779,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.010524208563292326,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.010524208563292326,
        "precision": 0.009494241220321983,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003947269774828007,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.003947269774828007,
        "precision": 0.003708063558121507,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.01611282125905054,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.01611282125905054,
        "precision": 0.015404878747824284,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.015358172543801285,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.015358172543801285,
        "precision": 0.013463597096331626,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.011724746754686873,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.011724746754686873,
        "precision": 0.011120325103952052,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0023432885919935954,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.0023432885919935954,
        "precision": 0.0021951265826089276,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.008471944998891106,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.008471944998891106,
        "precision": 0.007950765136393879,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014718500281854462,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0014718500281854462,
        "precision": 0.0012142931118894287,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.025465182254216127,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.025465182254216127,
        "precision": 0.024061587786036422,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0010733644743322393,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0010733644743322393,
        "precision": 0.0008957382428236591,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.002051984670771018,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.002051984670771018,
        "precision": 0.0013046077557969497,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009874431032115664,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.0009874431032115664,
        "precision": 0.0008475350411239112,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0035683194142395137,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.0035683194142395137,
        "precision": 0.002861520825592682,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.022695610344256715,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.022695610344256715,
        "precision": 0.021883217691600926,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027617604297577687,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0027617604297577687,
        "precision": 0.0024617903739501657,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003760732503247473,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003760732503247473,
        "precision": 0.0033340725955496413,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014560734809367974,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.014560734809367974,
        "precision": 0.013552869840294992,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.03204225398783651,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.03204225398783651,
        "precision": 0.02970931133564201,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.009916873778778817,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.009916873778778817,
        "precision": 0.009227997745699185,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00012953146893711332,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.00012953146893711332,
        "precision": 6.757267923702356e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 8.948702013144749e-07,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 8.948702013144749e-07,
        "precision": 4.4773620099415346e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.009305373263265517,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.009305373263265517,
        "precision": 0.008590700839536503,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.008659644902465383,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.008659644902465383,
        "precision": 0.008321859543900589,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.004740697195873812,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.004740697195873812,
        "precision": 0.004510899264256449,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.011119175789834472,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.011119175789834472,
        "precision": 0.010993516842284425,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.03639225695191164,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.03639225695191164,
        "precision": 0.03225924505571095,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.008474067694698769,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.008474067694698769,
        "precision": 0.008007667193211372,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.05854956753160346,
        "f1": 0.03928512908945872,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.03928512908945872,
        "precision": 0.03318170420013246,
        "recall": 0.05854956753160346
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.01128960889923617,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.01128960889923617,
        "precision": 0.010335423646554013,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.2842310968334106e-05,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 3.2842310968334106e-05,
        "precision": 1.6733218131861726e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.04999846387071935,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.04999846387071935,
        "precision": 0.04603403144147742,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.01184922586273404,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.01184922586273404,
        "precision": 0.010051244973505716,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.2642851198480865e-05,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 3.2642851198480865e-05,
        "precision": 1.6633235389429172e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.016748768996057237,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.016748768996057237,
        "precision": 0.014395244841059673,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.05322687957418496,
        "f1": 0.04164701956425012,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.04164701956425012,
        "precision": 0.039321677859205484,
        "recall": 0.05322687957418496
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 7.179086351865742e-05,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 7.179086351865742e-05,
        "precision": 3.654760834403694e-05,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.01272540509718328,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.01272540509718328,
        "precision": 0.01098378845371249,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.012058530871363922,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.012058530871363922,
        "precision": 0.01168622232418148,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.007293010646508255,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.007293010646508255,
        "precision": 0.006149880797920383,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.01276984109184876,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.01276984109184876,
        "precision": 0.011854537197175882,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0002141017111076991,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0002141017111076991,
        "precision": 0.00011937068432253534,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012189977466432991,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0012189977466432991,
        "precision": 0.000998940466078652,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.022662097618947205,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.022662097618947205,
        "precision": 0.021283596633808716,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.028691836677709356,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.028691836677709356,
        "precision": 0.026308418459477765,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00233656833789901,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00233656833789901,
        "precision": 0.002221744780970802,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.027816362946934313,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.027816362946934313,
        "precision": 0.026262936433758884,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.008316465989727061,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.008316465989727061,
        "precision": 0.00672765141653452,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.044577511643379905,
        "f1": 0.032513452218385974,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.032513452218385974,
        "precision": 0.030163505284701072,
        "recall": 0.044577511643379905
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00071285999429712,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.00071285999429712,
        "precision": 0.0006899780685542495,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.09447771124417831,
        "f1": 0.06875124647379495,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.06875124647379495,
        "precision": 0.06227710424317211,
        "recall": 0.09447771124417831
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0026049533505210385,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0026049533505210385,
        "precision": 0.00213530582498529,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.018797325982954725,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.018797325982954725,
        "precision": 0.01732091372809936,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0026112012609605657,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0026112012609605657,
        "precision": 0.002181394786185205,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0018716320574352085,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0018716320574352085,
        "precision": 0.0014509712563364927,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015246050452809405,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0015246050452809405,
        "precision": 0.0014331747336326413,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000393526864531005,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.000393526864531005,
        "precision": 0.00025288224719862903,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.025934011042637414,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.025934011042637414,
        "precision": 0.02460295333758933,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.002442190424332267,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.002442190424332267,
        "precision": 0.0022618667784977163,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00042916553033573894,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00042916553033573894,
        "precision": 0.00027128631970473933,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.028488999013467315,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.028488999013467315,
        "precision": 0.026685781875402634,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014590900572198844,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.014590900572198844,
        "precision": 0.013573217322162856,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.023884516274735836,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.023884516274735836,
        "precision": 0.022665557759679437,
        "recall": 0.028609447771124417
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}