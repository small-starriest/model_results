{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 9.519173383712769,
  "kg_co2_emissions": 0.001406360333867018,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8414999999999999,
        "ap": 0.6528686659566526,
        "ap_weighted": 0.6528686659566526,
        "f1": 0.8212462303607296,
        "f1_weighted": 0.8422597519266578,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8414999999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.832,
            "ap": 0.6361035247173575,
            "ap_weighted": 0.6361035247173575,
            "f1": 0.8117469879518072,
            "f1_weighted": 0.8333584337349397
          },
          {
            "accuracy": 0.848,
            "ap": 0.6627087050880154,
            "ap_weighted": 0.6627087050880154,
            "f1": 0.8259403799996335,
            "f1_weighted": 0.8476282086516792
          },
          {
            "accuracy": 0.833,
            "ap": 0.6384003496503496,
            "ap_weighted": 0.6384003496503496,
            "f1": 0.8135476084410458,
            "f1_weighted": 0.8346260513067856
          },
          {
            "accuracy": 0.849,
            "ap": 0.6652252085264134,
            "ap_weighted": 0.6652252085264134,
            "f1": 0.828866290172505,
            "f1_weighted": 0.8494108920372958
          },
          {
            "accuracy": 0.818,
            "ap": 0.6189994097973637,
            "ap_weighted": 0.6189994097973637,
            "f1": 0.8020327537896588,
            "f1_weighted": 0.8217106980629667
          },
          {
            "accuracy": 0.848,
            "ap": 0.6622522068095839,
            "ap_weighted": 0.6622522068095839,
            "f1": 0.8238906268103348,
            "f1_weighted": 0.8466967906383964
          },
          {
            "accuracy": 0.85,
            "ap": 0.6671284361284362,
            "ap_weighted": 0.6671284361284362,
            "f1": 0.8301315008674619,
            "f1_weighted": 0.8504647602136266
          },
          {
            "accuracy": 0.841,
            "ap": 0.6504638694638694,
            "ap_weighted": 0.6504638694638694,
            "f1": 0.8195181475070235,
            "f1_weighted": 0.8413113311955503
          },
          {
            "accuracy": 0.848,
            "ap": 0.6635694603903559,
            "ap_weighted": 0.6635694603903559,
            "f1": 0.8281320669380371,
            "f1_weighted": 0.8485843509724107
          },
          {
            "accuracy": 0.848,
            "ap": 0.6638354889947811,
            "ap_weighted": 0.6638354889947811,
            "f1": 0.8286559411297887,
            "f1_weighted": 0.8488060024529256
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}