{
    "test": {
        "cos_sim": {
            "accuracy": 0.8207665256005245,
            "accuracy_threshold": 0.7753598093986511,
            "ap": 0.5956789548901481,
            "f1": 0.5697118332311466,
            "f1_threshold": 0.7282990217208862,
            "precision": 0.5321878579610538,
            "recall": 0.612928759894459
        },
        "dot": {
            "accuracy": 0.7919771115217261,
            "accuracy_threshold": 0.29487645626068115,
            "ap": 0.46260703584680707,
            "f1": 0.4874578809434669,
            "f1_threshold": 0.24640625715255737,
            "precision": 0.46246744020838265,
            "recall": 0.5153034300791557
        },
        "euclidean": {
            "accuracy": 0.8066400429158967,
            "accuracy_threshold": 0.3704949915409088,
            "ap": 0.5403708142853088,
            "f1": 0.5144664402014759,
            "f1_threshold": 0.41998252272605896,
            "precision": 0.46260796292395195,
            "recall": 0.5794195250659631
        },
        "evaluation_time": 9.27,
        "manhattan": {
            "accuracy": 0.7983548906240686,
            "accuracy_threshold": 6.359255790710449,
            "ap": 0.497610338575302,
            "f1": 0.48250116658889414,
            "f1_threshold": 8.010211944580078,
            "precision": 0.43245503973232957,
            "recall": 0.545646437994723
        },
        "max": {
            "accuracy": 0.8207665256005245,
            "ap": 0.5956789548901481,
            "f1": 0.5697118332311466
        }
    },
    "mteb_version": "0.0.2",
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}