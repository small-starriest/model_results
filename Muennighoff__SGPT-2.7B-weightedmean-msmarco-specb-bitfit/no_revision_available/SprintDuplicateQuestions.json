{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.9976831683168317,
            "accuracy_threshold": 0.7241246104240417,
            "ap": 0.9347124923047998,
            "f1": 0.8806122448979592,
            "f1_threshold": 0.7241246104240417,
            "precision": 0.8989583333333333,
            "recall": 0.863
        },
        "dot": {
            "accuracy": 0.9957326732673267,
            "accuracy_threshold": 2443.231201171875,
            "ap": 0.8406577868167208,
            "f1": 0.7782629791363417,
            "f1_threshold": 2222.54931640625,
            "precision": 0.7558906691800189,
            "recall": 0.802
        },
        "euclidean": {
            "accuracy": 0.9974257425742574,
            "accuracy_threshold": 41.9460334777832,
            "ap": 0.921904681653555,
            "f1": 0.8674821610601428,
            "f1_threshold": 41.9460334777832,
            "precision": 0.8846153846153846,
            "recall": 0.851
        },
        "evaluation_time": 69.95,
        "manhattan": {
            "accuracy": 0.9974554455445545,
            "accuracy_threshold": 1650.22705078125,
            "ap": 0.9243377908099479,
            "f1": 0.8686765457332654,
            "f1_threshold": 1650.22705078125,
            "precision": 0.8881922675026124,
            "recall": 0.85
        },
        "max": {
            "accuracy": 0.9976831683168317,
            "ap": 0.9347124923047998,
            "f1": 0.8806122448979592
        }
    },
    "mteb_dataset_name": "SprintDuplicateQuestions",
    "dataset_revision": "5a8256d0dff9c4bd3be3ba3e67e4e70173f802ea"
}