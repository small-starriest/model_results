{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 9.726606607437134,
  "kg_co2_emissions": 0.0014467090305753624,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8396999999999999,
        "ap": 0.6501754006594348,
        "ap_weighted": 0.6501754006594348,
        "f1": 0.8196722777761863,
        "f1_weighted": 0.8406313783174333,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8396999999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.851,
            "ap": 0.6691465201465201,
            "ap_weighted": 0.6691465201465201,
            "f1": 0.8316534456246278,
            "f1_weighted": 0.8516277643012656
          },
          {
            "accuracy": 0.851,
            "ap": 0.6680221216691805,
            "ap_weighted": 0.6680221216691805,
            "f1": 0.8275141548367231,
            "f1_weighted": 0.8497907017395603
          },
          {
            "accuracy": 0.834,
            "ap": 0.6429353846153847,
            "ap_weighted": 0.6429353846153847,
            "f1": 0.8175824175824176,
            "f1_weighted": 0.8367362637362639
          },
          {
            "accuracy": 0.841,
            "ap": 0.6516189624329158,
            "ap_weighted": 0.6516189624329158,
            "f1": 0.8214363926108358,
            "f1_weighted": 0.8421229865268703
          },
          {
            "accuracy": 0.819,
            "ap": 0.6221076923076924,
            "ap_weighted": 0.6221076923076924,
            "f1": 0.8041920216362407,
            "f1_weighted": 0.8230385395537525
          },
          {
            "accuracy": 0.848,
            "ap": 0.6626255763164279,
            "ap_weighted": 0.6626255763164279,
            "f1": 0.8256552837919058,
            "f1_weighted": 0.84750067673278
          },
          {
            "accuracy": 0.838,
            "ap": 0.6449667991582885,
            "ap_weighted": 0.6449667991582885,
            "f1": 0.8159684828987008,
            "f1_weighted": 0.8382546996196681
          },
          {
            "accuracy": 0.831,
            "ap": 0.63277015755329,
            "ap_weighted": 0.63277015755329,
            "f1": 0.8084662452924063,
            "f1_weighted": 0.8314598725450529
          },
          {
            "accuracy": 0.848,
            "ap": 0.6627087050880154,
            "ap_weighted": 0.6627087050880154,
            "f1": 0.8259403799996335,
            "f1_weighted": 0.8476282086516792
          },
          {
            "accuracy": 0.836,
            "ap": 0.6448520873066328,
            "ap_weighted": 0.6448520873066328,
            "f1": 0.8183139534883721,
            "f1_weighted": 0.8381540697674418
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}