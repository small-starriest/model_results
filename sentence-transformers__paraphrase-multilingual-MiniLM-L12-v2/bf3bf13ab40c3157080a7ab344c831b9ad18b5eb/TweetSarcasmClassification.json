{
  "dataset_revision": "557bf94ac6177cc442f42d0b09b6e4b76e8f47c9",
  "evaluation_time": 9.51033616065979,
  "kg_co2_emissions": 0.001406095898347894,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.5406635071090048,
        "ap": 0.18467452703844445,
        "ap_weighted": 0.18467452703844445,
        "f1": 0.4726819684886393,
        "f1_weighted": 0.594220663728577,
        "hf_subset": "default",
        "languages": [
          "ara-Arab"
        ],
        "main_score": 0.5406635071090048,
        "scores_per_experiment": [
          {
            "accuracy": 0.5862559241706161,
            "ap": 0.2030845160299243,
            "ap_weighted": 0.2030845160299243,
            "f1": 0.5165908716942322,
            "f1_weighted": 0.6400919634750877
          },
          {
            "accuracy": 0.5265402843601896,
            "ap": 0.17194349159404126,
            "ap_weighted": 0.17194349159404126,
            "f1": 0.4591097169030619,
            "f1_weighted": 0.5876350938012113
          },
          {
            "accuracy": 0.5620853080568721,
            "ap": 0.19947566321574406,
            "ap_weighted": 0.19947566321574406,
            "f1": 0.5014223594288467,
            "f1_weighted": 0.618462287488352
          },
          {
            "accuracy": 0.5625592417061611,
            "ap": 0.19705099405157336,
            "ap_weighted": 0.19705099405157336,
            "f1": 0.49987558071960825,
            "f1_weighted": 0.6190332763031493
          },
          {
            "accuracy": 0.49715639810426543,
            "ap": 0.17570885566879446,
            "ap_weighted": 0.17570885566879446,
            "f1": 0.4474246133013906,
            "f1_weighted": 0.5589872269192141
          },
          {
            "accuracy": 0.4872037914691943,
            "ap": 0.1764232914995939,
            "ap_weighted": 0.1764232914995939,
            "f1": 0.44241733292693414,
            "f1_weighted": 0.5487664485289566
          },
          {
            "accuracy": 0.48009478672985784,
            "ap": 0.1541773996775027,
            "ap_weighted": 0.1541773996775027,
            "f1": 0.4126507438068957,
            "f1_weighted": 0.546595556325226
          },
          {
            "accuracy": 0.43459715639810426,
            "ap": 0.17861476618946226,
            "ap_weighted": 0.17861476618946226,
            "f1": 0.4111548474464304,
            "f1_weighted": 0.4902239180197722
          },
          {
            "accuracy": 0.7440758293838863,
            "ap": 0.18582834911229126,
            "ap_weighted": 0.18582834911229126,
            "f1": 0.5518012914920132,
            "f1_weighted": 0.7493626835372084
          },
          {
            "accuracy": 0.5260663507109005,
            "ap": 0.204437943345517,
            "ap_weighted": 0.204437943345517,
            "f1": 0.4843723271669803,
            "f1_weighted": 0.5830481828875914
          }
        ]
      }
    ]
  },
  "task_name": "TweetSarcasmClassification"
}