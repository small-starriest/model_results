{
  "dataset_revision": "5911f26666ac11af46cb9c6849d0dc80a378af24",
  "evaluation_time": 36.761512756347656,
  "kg_co2_emissions": 0.008792799565897578,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.6425333333333333,
        "f1": 0.6159124064651188,
        "f1_weighted": 0.6159124064651188,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6425333333333333,
        "scores_per_experiment": [
          {
            "accuracy": 0.5873333333333334,
            "f1": 0.5718361265158024,
            "f1_weighted": 0.5718361265158024
          },
          {
            "accuracy": 0.6073333333333333,
            "f1": 0.5651081078842642,
            "f1_weighted": 0.5651081078842642
          },
          {
            "accuracy": 0.6486666666666666,
            "f1": 0.6233924980025897,
            "f1_weighted": 0.6233924980025897
          },
          {
            "accuracy": 0.654,
            "f1": 0.6268986628104868,
            "f1_weighted": 0.6268986628104868
          },
          {
            "accuracy": 0.638,
            "f1": 0.6203801789755566,
            "f1_weighted": 0.6203801789755566
          },
          {
            "accuracy": 0.672,
            "f1": 0.6496274460853835,
            "f1_weighted": 0.6496274460853835
          },
          {
            "accuracy": 0.6466666666666666,
            "f1": 0.6106816417177391,
            "f1_weighted": 0.6106816417177391
          },
          {
            "accuracy": 0.662,
            "f1": 0.642178052304648,
            "f1_weighted": 0.6421780523046481
          },
          {
            "accuracy": 0.662,
            "f1": 0.6332511037278649,
            "f1_weighted": 0.6332511037278649
          },
          {
            "accuracy": 0.6473333333333333,
            "f1": 0.6157702466268525,
            "f1_weighted": 0.6157702466268525
          }
        ]
      }
    ]
  },
  "task_name": "KinopoiskClassification"
}