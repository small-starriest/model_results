{
  "dataset_revision": "339287def212450dcaa9df8c22bf93e9980c7023",
  "evaluation_time": 24.849771738052368,
  "kg_co2_emissions": 0.004575003500804632,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8683,
        "ap": 0.7019588857782837,
        "ap_weighted": 0.7019588857782837,
        "f1": 0.8513310687190694,
        "f1_weighted": 0.8689028933393516,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.8683,
        "scores_per_experiment": [
          {
            "accuracy": 0.87,
            "ap": 0.7050057405281286,
            "ap_weighted": 0.7050057405281286,
            "f1": 0.8530076888285844,
            "f1_weighted": 0.8704997738579827
          },
          {
            "accuracy": 0.87,
            "ap": 0.7049880028228652,
            "ap_weighted": 0.7049880028228652,
            "f1": 0.8520871638965247,
            "f1_weighted": 0.8701029473339279
          },
          {
            "accuracy": 0.864,
            "ap": 0.693799331103679,
            "ap_weighted": 0.693799331103679,
            "f1": 0.847379643137695,
            "f1_weighted": 0.8650072943552911
          },
          {
            "accuracy": 0.872,
            "ap": 0.7088796488796489,
            "ap_weighted": 0.7088796488796489,
            "f1": 0.8550455474069008,
            "f1_weighted": 0.8723965953822946
          },
          {
            "accuracy": 0.862,
            "ap": 0.6905417118093174,
            "ap_weighted": 0.6905417118093174,
            "f1": 0.8462566844919787,
            "f1_weighted": 0.863475935828877
          },
          {
            "accuracy": 0.873,
            "ap": 0.710923076923077,
            "ap_weighted": 0.710923076923077,
            "f1": 0.8551549442916792,
            "f1_weighted": 0.8729491593854464
          },
          {
            "accuracy": 0.874,
            "ap": 0.7129259347463682,
            "ap_weighted": 0.7129259347463682,
            "f1": 0.8561801446416831,
            "f1_weighted": 0.8738987508218278
          },
          {
            "accuracy": 0.866,
            "ap": 0.6974480036092939,
            "ap_weighted": 0.6974480036092939,
            "f1": 0.8491745118431775,
            "f1_weighted": 0.8668060114087099
          },
          {
            "accuracy": 0.866,
            "ap": 0.6975066158331464,
            "ap_weighted": 0.6975066158331464,
            "f1": 0.849400298502095,
            "f1_weighted": 0.8668999838161514
          },
          {
            "accuracy": 0.866,
            "ap": 0.6975707915273133,
            "ap_weighted": 0.6975707915273133,
            "f1": 0.849624060150376,
            "f1_weighted": 0.8669924812030075
          }
        ]
      }
    ]
  },
  "task_name": "Waimai"
}