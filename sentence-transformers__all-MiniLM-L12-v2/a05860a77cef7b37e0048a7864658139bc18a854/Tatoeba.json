{
  "dataset_revision": "69e8f12da6e31d59addadda9a9c8a2e601a0e282",
  "evaluation_time": 82.47552466392517,
  "kg_co2_emissions": 0.012506563634548037,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.01,
        "f1": 0.007530484414352533,
        "hf_subset": "tat-eng",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.007530484414352533,
        "precision": 0.007348744519728975,
        "recall": 0.01
      },
      {
        "accuracy": 0.0047169811320754715,
        "f1": 0.0018592315477481388,
        "hf_subset": "yid-eng",
        "languages": [
          "yid-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0018592315477481388,
        "precision": 0.0016191906181289959,
        "recall": 0.0047169811320754715
      },
      {
        "accuracy": 0.09615384615384616,
        "f1": 0.06872710622710622,
        "hf_subset": "tzl-eng",
        "languages": [
          "tzl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06872710622710622,
        "precision": 0.06324059445047892,
        "recall": 0.09615384615384616
      },
      {
        "accuracy": 0.002,
        "f1": 0.00015637459885247496,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.00015637459885247496,
        "precision": 8.459915611814346e-05,
        "recall": 0.002
      },
      {
        "accuracy": 0.074,
        "f1": 0.05863608675425028,
        "hf_subset": "sqi-eng",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05863608675425028,
        "precision": 0.055395428282683186,
        "recall": 0.074
      },
      {
        "accuracy": 0.074,
        "f1": 0.06183170842349788,
        "hf_subset": "war-eng",
        "languages": [
          "war-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06183170842349788,
        "precision": 0.059183606931583796,
        "recall": 0.074
      },
      {
        "accuracy": 0.147,
        "f1": 0.12557599155840163,
        "hf_subset": "nld-eng",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12557599155840163,
        "precision": 0.1195006414981788,
        "recall": 0.147
      },
      {
        "accuracy": 0.12598425196850394,
        "f1": 0.0999015748031496,
        "hf_subset": "ast-eng",
        "languages": [
          "ast-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0999015748031496,
        "precision": 0.09194640143666251,
        "recall": 0.12598425196850394
      },
      {
        "accuracy": 0.008658008658008658,
        "f1": 0.0043824488268932715,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0043824488268932715,
        "precision": 0.004355892554650318,
        "recall": 0.008658008658008658
      },
      {
        "accuracy": 0.035,
        "f1": 0.021833246107714192,
        "hf_subset": "jpn-eng",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.021833246107714192,
        "precision": 0.019894133018798398,
        "recall": 0.035
      },
      {
        "accuracy": 0.006702412868632708,
        "f1": 0.004490995289377622,
        "hf_subset": "kat-eng",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ],
        "main_score": 0.004490995289377622,
        "precision": 0.00430100135193969,
        "recall": 0.006702412868632708
      },
      {
        "accuracy": 0.004,
        "f1": 0.0030024968789013735,
        "hf_subset": "pes-eng",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0030024968789013735,
        "precision": 0.0030012499999999996,
        "recall": 0.004
      },
      {
        "accuracy": 0.199,
        "f1": 0.17525110478479863,
        "hf_subset": "fra-eng",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.17525110478479863,
        "precision": 0.16780478021978024,
        "recall": 0.199
      },
      {
        "accuracy": 0.148,
        "f1": 0.1135280298232068,
        "hf_subset": "nds-eng",
        "languages": [
          "nds-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1135280298232068,
        "precision": 0.1034569356082514,
        "recall": 0.148
      },
      {
        "accuracy": 0.05,
        "f1": 0.030813785658073203,
        "hf_subset": "gle-eng",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030813785658073203,
        "precision": 0.02803289265773786,
        "recall": 0.05
      },
      {
        "accuracy": 0.0020964360587002098,
        "f1": 1.145593474699568e-05,
        "hf_subset": "arz-eng",
        "languages": [
          "arz-Arab",
          "eng-Latn"
        ],
        "main_score": 1.145593474699568e-05,
        "precision": 5.743660434795095e-06,
        "recall": 0.0020964360587002098
      },
      {
        "accuracy": 0.03,
        "f1": 0.02221922515400776,
        "hf_subset": "srp-eng",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.02221922515400776,
        "precision": 0.02092445586259433,
        "recall": 0.03
      },
      {
        "accuracy": 0.003,
        "f1": 2.289068121851763e-05,
        "hf_subset": "mhr-eng",
        "languages": [
          "mhr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 2.289068121851763e-05,
        "precision": 1.1494584598032874e-05,
        "recall": 0.003
      },
      {
        "accuracy": 0.0903954802259887,
        "f1": 0.0704972915888676,
        "hf_subset": "bos-eng",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0704972915888676,
        "precision": 0.06578542808114962,
        "recall": 0.0903954802259887
      },
      {
        "accuracy": 0.004,
        "f1": 0.0030069444444444445,
        "hf_subset": "heb-eng",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0030069444444444445,
        "precision": 0.0030034843205574914,
        "recall": 0.004
      },
      {
        "accuracy": 0.003592814371257485,
        "f1": 0.0015428210560182955,
        "hf_subset": "orv-eng",
        "languages": [
          "orv-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0015428210560182955,
        "precision": 0.0013987292590391736,
        "recall": 0.003592814371257485
      },
      {
        "accuracy": 0.01217391304347826,
        "f1": 0.008161052638388438,
        "hf_subset": "kaz-eng",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.008161052638388438,
        "precision": 0.00784885067264378,
        "recall": 0.01217391304347826
      },
      {
        "accuracy": 0.089,
        "f1": 0.06575830384009501,
        "hf_subset": "eus-eng",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06575830384009501,
        "precision": 0.06098792651062388,
        "recall": 0.089
      },
      {
        "accuracy": 0.045548654244306416,
        "f1": 0.02893231565197035,
        "hf_subset": "hsb-eng",
        "languages": [
          "hsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02893231565197035,
        "precision": 0.02581962999564131,
        "recall": 0.045548654244306416
      },
      {
        "accuracy": 0.09859154929577464,
        "f1": 0.08400497683068105,
        "hf_subset": "max-eng",
        "languages": [
          "max-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08400497683068105,
        "precision": 0.08018010905492748,
        "recall": 0.09859154929577464
      },
      {
        "accuracy": 0.017,
        "f1": 0.009101620470775677,
        "hf_subset": "kab-eng",
        "languages": [
          "kab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009101620470775677,
        "precision": 0.007729839652396391,
        "recall": 0.017
      },
      {
        "accuracy": 0.079,
        "f1": 0.05683647365438166,
        "hf_subset": "hrv-eng",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05683647365438166,
        "precision": 0.05222410435277995,
        "recall": 0.079
      },
      {
        "accuracy": 0.174,
        "f1": 0.13893203634989348,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13893203634989348,
        "precision": 0.1277854374834787,
        "recall": 0.174
      },
      {
        "accuracy": 0.012,
        "f1": 0.009003110419906687,
        "hf_subset": "kor-eng",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ],
        "main_score": 0.009003110419906687,
        "precision": 0.00836822429906542,
        "recall": 0.012
      },
      {
        "accuracy": 0.056,
        "f1": 0.042024938565039804,
        "hf_subset": "slk-eng",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.042024938565039804,
        "precision": 0.03924922088780784,
        "recall": 0.056
      },
      {
        "accuracy": 0.056,
        "f1": 0.03686606799334286,
        "hf_subset": "tur-eng",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03686606799334286,
        "precision": 0.03269869928178752,
        "recall": 0.056
      },
      {
        "accuracy": 0.111,
        "f1": 0.08773862252719573,
        "hf_subset": "ron-eng",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08773862252719573,
        "precision": 0.08236585255540478,
        "recall": 0.111
      },
      {
        "accuracy": 0.097,
        "f1": 0.07451631493506494,
        "hf_subset": "nno-eng",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07451631493506494,
        "precision": 0.06863390740666282,
        "recall": 0.097
      },
      {
        "accuracy": 0.133,
        "f1": 0.11083295083893675,
        "hf_subset": "ido-eng",
        "languages": [
          "ido-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11083295083893675,
        "precision": 0.10480022823040536,
        "recall": 0.133
      },
      {
        "accuracy": 0.036,
        "f1": 0.02604300825593395,
        "hf_subset": "est-eng",
        "languages": [
          "est-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02604300825593395,
        "precision": 0.0238798527625298,
        "recall": 0.036
      },
      {
        "accuracy": 0.058333333333333334,
        "f1": 0.039519892390863384,
        "hf_subset": "ceb-eng",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.039519892390863384,
        "precision": 0.03700824372936054,
        "recall": 0.058333333333333334
      },
      {
        "accuracy": 0.058,
        "f1": 0.03684075011021052,
        "hf_subset": "bre-eng",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03684075011021052,
        "precision": 0.03276435263908668,
        "recall": 0.058
      },
      {
        "accuracy": 0.091,
        "f1": 0.07521090502394441,
        "hf_subset": "lfn-eng",
        "languages": [
          "lfn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07521090502394441,
        "precision": 0.07216464151436605,
        "recall": 0.091
      },
      {
        "accuracy": 0.292,
        "f1": 0.2536454334416584,
        "hf_subset": "ina-eng",
        "languages": [
          "ina-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2536454334416584,
        "precision": 0.24118301433864092,
        "recall": 0.292
      },
      {
        "accuracy": 0.22568093385214008,
        "f1": 0.1945171850668217,
        "hf_subset": "nov-eng",
        "languages": [
          "nov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1945171850668217,
        "precision": 0.18602861639572854,
        "recall": 0.22568093385214008
      },
      {
        "accuracy": 0.061968408262454436,
        "f1": 0.045153879001411046,
        "hf_subset": "slv-eng",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.045153879001411046,
        "precision": 0.04244127394737643,
        "recall": 0.061968408262454436
      },
      {
        "accuracy": 0.19653179190751446,
        "f1": 0.145322168103535,
        "hf_subset": "fry-eng",
        "languages": [
          "fry-Latn",
          "eng-Latn"
        ],
        "main_score": 0.145322168103535,
        "precision": 0.13410310787478416,
        "recall": 0.19653179190751446
      },
      {
        "accuracy": 0.124,
        "f1": 0.09755405742649645,
        "hf_subset": "cbk-eng",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09755405742649645,
        "precision": 0.09165981350607143,
        "recall": 0.124
      },
      {
        "accuracy": 0.048,
        "f1": 0.03448524464254237,
        "hf_subset": "lvs-eng",
        "languages": [
          "lvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03448524464254237,
        "precision": 0.031477475181823006,
        "recall": 0.048
      },
      {
        "accuracy": 0.029,
        "f1": 0.018889979501933267,
        "hf_subset": "yue-eng",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ],
        "main_score": 0.018889979501933267,
        "precision": 0.017623690801065062,
        "recall": 0.029
      },
      {
        "accuracy": 0.06,
        "f1": 0.04196216088537517,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04196216088537517,
        "precision": 0.038491807962272064,
        "recall": 0.06
      },
      {
        "accuracy": 0.101,
        "f1": 0.07593959386118473,
        "hf_subset": "afr-eng",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07593959386118473,
        "precision": 0.0710671421756993,
        "recall": 0.101
      },
      {
        "accuracy": 0.003,
        "f1": 0.0006749365804160323,
        "hf_subset": "rus-eng",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0006749365804160323,
        "precision": 0.0005041436170890241,
        "recall": 0.003
      },
      {
        "accuracy": 0.005952380952380952,
        "f1": 7.348618459729571e-05,
        "hf_subset": "amh-eng",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ],
        "main_score": 7.348618459729571e-05,
        "precision": 3.6971310263235726e-05,
        "recall": 0.005952380952380952
      },
      {
        "accuracy": 0.208955223880597,
        "f1": 0.1463260619977038,
        "hf_subset": "ang-eng",
        "languages": [
          "ang-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1463260619977038,
        "precision": 0.13129507962579448,
        "recall": 0.208955223880597
      },
      {
        "accuracy": 0.145,
        "f1": 0.11787464594939019,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11787464594939019,
        "precision": 0.1107303646054682,
        "recall": 0.145
      },
      {
        "accuracy": 0.006925207756232687,
        "f1": 0.0041854125147348,
        "hf_subset": "khm-eng",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ],
        "main_score": 0.0041854125147348,
        "precision": 0.004170365049820573,
        "recall": 0.006925207756232687
      },
      {
        "accuracy": 0.058,
        "f1": 0.047284733893557425,
        "hf_subset": "pam-eng",
        "languages": [
          "pam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.047284733893557425,
        "precision": 0.0446500222000222,
        "recall": 0.058
      },
      {
        "accuracy": 0.10666666666666667,
        "f1": 0.08935156341136408,
        "hf_subset": "pms-eng",
        "languages": [
          "pms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08935156341136408,
        "precision": 0.0860029559792802,
        "recall": 0.10666666666666667
      },
      {
        "accuracy": 0.15384615384615385,
        "f1": 0.09902319902319902,
        "hf_subset": "gsw-eng",
        "languages": [
          "gsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09902319902319902,
        "precision": 0.08392348392348394,
        "recall": 0.15384615384615385
      },
      {
        "accuracy": 0.17857142857142858,
        "f1": 0.1189809446505875,
        "hf_subset": "swg-eng",
        "languages": [
          "swg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1189809446505875,
        "precision": 0.10479624542124541,
        "recall": 0.17857142857142858
      },
      {
        "accuracy": 0.021367521367521368,
        "f1": 0.006740944240944241,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.006740944240944241,
        "precision": 0.004584580116495009,
        "recall": 0.021367521367521368
      },
      {
        "accuracy": 0.097,
        "f1": 0.08023493074512184,
        "hf_subset": "nob-eng",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08023493074512184,
        "precision": 0.07482018463992147,
        "recall": 0.097
      },
      {
        "accuracy": 0.005,
        "f1": 0.004003372681281619,
        "hf_subset": "uig-eng",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ],
        "main_score": 0.004003372681281619,
        "precision": 0.00400168918918919,
        "recall": 0.005
      },
      {
        "accuracy": 0.011,
        "f1": 0.008512684564277482,
        "hf_subset": "bel-eng",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.008512684564277482,
        "precision": 0.008339700479481911,
        "recall": 0.011
      },
      {
        "accuracy": 0.024,
        "f1": 0.015613353757476274,
        "hf_subset": "lit-eng",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015613353757476274,
        "precision": 0.013931978759544501,
        "recall": 0.024
      },
      {
        "accuracy": 0.043,
        "f1": 0.03440520282186949,
        "hf_subset": "isl-eng",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03440520282186949,
        "precision": 0.03241408663799968,
        "recall": 0.043
      },
      {
        "accuracy": 0.08461538461538462,
        "f1": 0.05817608317608317,
        "hf_subset": "swh-eng",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05817608317608317,
        "precision": 0.05219983643616254,
        "recall": 0.08461538461538462
      },
      {
        "accuracy": 0.009124087591240875,
        "f1": 0.006699426285239066,
        "hf_subset": "tha-eng",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 0.006699426285239066,
        "precision": 0.0063910854284941875,
        "recall": 0.009124087591240875
      },
      {
        "accuracy": 0.006818181818181818,
        "f1": 0.0005840899006748473,
        "hf_subset": "mon-eng",
        "languages": [
          "mon-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0005840899006748473,
        "precision": 0.0003240740740740741,
        "recall": 0.006818181818181818
      },
      {
        "accuracy": 0.002,
        "f1": 1.0466232796329884e-05,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0466232796329884e-05,
        "precision": 5.24989274989275e-06,
        "recall": 0.002
      },
      {
        "accuracy": 0.095,
        "f1": 0.07310479865182301,
        "hf_subset": "swe-eng",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07310479865182301,
        "precision": 0.06727880952380953,
        "recall": 0.095
      },
      {
        "accuracy": 0.113,
        "f1": 0.08499890834884641,
        "hf_subset": "epo-eng",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08499890834884641,
        "precision": 0.07946014598991594,
        "recall": 0.113
      },
      {
        "accuracy": 0.062,
        "f1": 0.05295520227303477,
        "hf_subset": "ind-eng",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05295520227303477,
        "precision": 0.050580945607261396,
        "recall": 0.062
      },
      {
        "accuracy": 0.043,
        "f1": 0.03339261143053713,
        "hf_subset": "tgl-eng",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03339261143053713,
        "precision": 0.03140235180438099,
        "recall": 0.043
      },
      {
        "accuracy": 0.005488474204171241,
        "f1": 0.0027560792121338754,
        "hf_subset": "arq-eng",
        "languages": [
          "arq-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0027560792121338754,
        "precision": 0.0025672257242729626,
        "recall": 0.005488474204171241
      },
      {
        "accuracy": 0.019,
        "f1": 0.014714268638876437,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014714268638876437,
        "precision": 0.013724288337924702,
        "recall": 0.019
      },
      {
        "accuracy": 0.144,
        "f1": 0.11356982875140026,
        "hf_subset": "por-eng",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11356982875140026,
        "precision": 0.10594455579455578,
        "recall": 0.144
      },
      {
        "accuracy": 0.054,
        "f1": 0.03927218045112782,
        "hf_subset": "hun-eng",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03927218045112782,
        "precision": 0.036019535003974444,
        "recall": 0.054
      },
      {
        "accuracy": 0.1024390243902439,
        "f1": 0.07299313902413489,
        "hf_subset": "kur-eng",
        "languages": [
          "kur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07299313902413489,
        "precision": 0.06605803077317456,
        "recall": 0.1024390243902439
      },
      {
        "accuracy": 0.001,
        "f1": 2.5284450063211125e-06,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 2.5284450063211125e-06,
        "precision": 1.2658227848101265e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.07114624505928854,
        "f1": 0.05210297235182819,
        "hf_subset": "csb-eng",
        "languages": [
          "csb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05210297235182819,
        "precision": 0.0505357381538856,
        "recall": 0.07114624505928854
      },
      {
        "accuracy": 0.15,
        "f1": 0.1260266466301655,
        "hf_subset": "glg-eng",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1260266466301655,
        "precision": 0.11961061653436712,
        "recall": 0.15
      },
      {
        "accuracy": 0.026,
        "f1": 0.018891088180112568,
        "hf_subset": "wuu-eng",
        "languages": [
          "wuu-Hans",
          "eng-Latn"
        ],
        "main_score": 0.018891088180112568,
        "precision": 0.01736479860718991,
        "recall": 0.026
      },
      {
        "accuracy": 0.03271028037383177,
        "f1": 0.021998708304840058,
        "hf_subset": "uzb-eng",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021998708304840058,
        "precision": 0.019334112149532706,
        "recall": 0.03271028037383177
      },
      {
        "accuracy": 0.08396946564885496,
        "f1": 0.059223699266357545,
        "hf_subset": "fao-eng",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.059223699266357545,
        "precision": 0.0540598873137041,
        "recall": 0.08396946564885496
      },
      {
        "accuracy": 0.004366812227074236,
        "f1": 0.002430534332712306,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.002430534332712306,
        "precision": 0.002185673409605173,
        "recall": 0.004366812227074236
      },
      {
        "accuracy": 0.04384133611691023,
        "f1": 0.030565450369413622,
        "hf_subset": "dsb-eng",
        "languages": [
          "dsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030565450369413622,
        "precision": 0.029310311001652694,
        "recall": 0.04384133611691023
      },
      {
        "accuracy": 0.05365853658536585,
        "f1": 0.03497558876249505,
        "hf_subset": "jav-eng",
        "languages": [
          "jav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03497558876249505,
        "precision": 0.03307206965743551,
        "recall": 0.05365853658536585
      },
      {
        "accuracy": 0.056338028169014086,
        "f1": 0.0366025518188496,
        "hf_subset": "xho-eng",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0366025518188496,
        "precision": 0.035941049522944114,
        "recall": 0.056338028169014086
      },
      {
        "accuracy": 0.127,
        "f1": 0.10214179258763595,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10214179258763595,
        "precision": 0.0957939615939616,
        "recall": 0.127
      },
      {
        "accuracy": 0.039806996381182146,
        "f1": 0.02583498047119403,
        "hf_subset": "gla-eng",
        "languages": [
          "gla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02583498047119403,
        "precision": 0.022331079942132827,
        "recall": 0.039806996381182146
      },
      {
        "accuracy": 0.127,
        "f1": 0.1125955937004418,
        "hf_subset": "spa-eng",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1125955937004418,
        "precision": 0.10891624524008545,
        "recall": 0.127
      },
      {
        "accuracy": 0.058,
        "f1": 0.047205888794884014,
        "hf_subset": "ber-eng",
        "languages": [
          "ber-Tfng",
          "eng-Latn"
        ],
        "main_score": 0.047205888794884014,
        "precision": 0.04504224974101477,
        "recall": 0.058
      },
      {
        "accuracy": 0.007,
        "f1": 0.005668717948717948,
        "hf_subset": "ukr-eng",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.005668717948717948,
        "precision": 0.005501026694045175,
        "recall": 0.007
      },
      {
        "accuracy": 0.07652173913043478,
        "f1": 0.05134088558765761,
        "hf_subset": "cym-eng",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05134088558765761,
        "precision": 0.04561190817744733,
        "recall": 0.07652173913043478
      },
      {
        "accuracy": 0.18248175182481752,
        "f1": 0.13072202116856474,
        "hf_subset": "cha-eng",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13072202116856474,
        "precision": 0.12057264511644072,
        "recall": 0.18248175182481752
      },
      {
        "accuracy": 0.063,
        "f1": 0.04286513121219003,
        "hf_subset": "pol-eng",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04286513121219003,
        "precision": 0.038714004137906266,
        "recall": 0.063
      },
      {
        "accuracy": 0.047,
        "f1": 0.03648934343434343,
        "hf_subset": "fin-eng",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03648934343434343,
        "precision": 0.03473704989147343,
        "recall": 0.047
      },
      {
        "accuracy": 0.005,
        "f1": 0.002289183693231335,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.002289183693231335,
        "precision": 0.0021576804837674405,
        "recall": 0.005
      },
      {
        "accuracy": 0.04433497536945813,
        "f1": 0.026574433148167556,
        "hf_subset": "tuk-eng",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026574433148167556,
        "precision": 0.024127229153221755,
        "recall": 0.04433497536945813
      },
      {
        "accuracy": 0.003257328990228013,
        "f1": 0.003257328990228013,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.003257328990228013,
        "precision": 0.003257328990228013,
        "recall": 0.003257328990228013
      },
      {
        "accuracy": 0.002,
        "f1": 0.00040254452926208654,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00040254452926208654,
        "precision": 0.0002512738853503185,
        "recall": 0.002
      },
      {
        "accuracy": 0.068,
        "f1": 0.05056025232892644,
        "hf_subset": "vie-eng",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05056025232892644,
        "precision": 0.04660385120655299,
        "recall": 0.068
      },
      {
        "accuracy": 0.003,
        "f1": 0.002005813953488372,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ],
        "main_score": 0.002005813953488372,
        "precision": 0.002002915451895044,
        "recall": 0.003
      },
      {
        "accuracy": 0.1,
        "f1": 0.07138784577491472,
        "hf_subset": "lat-eng",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07138784577491472,
        "precision": 0.06533909443656252,
        "recall": 0.1
      },
      {
        "accuracy": 0.079,
        "f1": 0.05988761682714935,
        "hf_subset": "zsm-eng",
        "languages": [
          "zsm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05988761682714935,
        "precision": 0.056259671975030415,
        "recall": 0.079
      },
      {
        "accuracy": 0.152,
        "f1": 0.12569355909960256,
        "hf_subset": "ita-eng",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12569355909960256,
        "precision": 0.11975961385025893,
        "recall": 0.152
      },
      {
        "accuracy": 0.006,
        "f1": 0.004336359051941503,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ],
        "main_score": 0.004336359051941503,
        "precision": 0.004001515151515152,
        "recall": 0.006
      },
      {
        "accuracy": 0.043,
        "f1": 0.024688071522555873,
        "hf_subset": "cor-eng",
        "languages": [
          "cor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024688071522555873,
        "precision": 0.021431751015940824,
        "recall": 0.043
      },
      {
        "accuracy": 0.117,
        "f1": 0.08717378109157396,
        "hf_subset": "oci-eng",
        "languages": [
          "oci-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08717378109157396,
        "precision": 0.08042268715655623,
        "recall": 0.117
      },
      {
        "accuracy": 0.002,
        "f1": 7.673011657075402e-05,
        "hf_subset": "mkd-eng",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ],
        "main_score": 7.673011657075402e-05,
        "precision": 3.979132569558102e-05,
        "recall": 0.002
      },
      {
        "accuracy": 0.21,
        "f1": 0.17430615884115883,
        "hf_subset": "ile-eng",
        "languages": [
          "ile-Latn",
          "eng-Latn"
        ],
        "main_score": 0.17430615884115883,
        "precision": 0.16490497063309845,
        "recall": 0.21
      },
      {
        "accuracy": 0.044,
        "f1": 0.0364220841693677,
        "hf_subset": "kzj-eng",
        "languages": [
          "kzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0364220841693677,
        "precision": 0.034972039342297964,
        "recall": 0.044
      },
      {
        "accuracy": 0.031,
        "f1": 0.024475370636059302,
        "hf_subset": "cmn-eng",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.024475370636059302,
        "precision": 0.022641512345679012,
        "recall": 0.031
      },
      {
        "accuracy": 0.044,
        "f1": 0.03311265095594265,
        "hf_subset": "dtp-eng",
        "languages": [
          "dtp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03311265095594265,
        "precision": 0.031167847659839574,
        "recall": 0.044
      },
      {
        "accuracy": 0.006738544474393531,
        "f1": 0.004954558020595756,
        "hf_subset": "hye-eng",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ],
        "main_score": 0.004954558020595756,
        "precision": 0.004723491803065224,
        "recall": 0.006738544474393531
      }
    ]
  },
  "task_name": "Tatoeba"
}