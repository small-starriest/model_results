{
    "mteb_version": "0.0.2",
    "test": {
        "de": {
            "accuracy": 0.6192448577063963,
            "accuracy_stderr": 0.014007686081825572,
            "f1": 0.4312593997578186,
            "f1_stderr": 0.015483786767283151,
            "main_score": 0.6192448577063963
        },
        "en": {
            "accuracy": 0.7134290925672594,
            "accuracy_stderr": 0.019029162671865333,
            "f1": 0.5444803151449109,
            "f1_stderr": 0.01280263780405634,
            "main_score": 0.7134290925672594
        },
        "es": {
            "accuracy": 0.7448965977318213,
            "accuracy_stderr": 0.01179938863747858,
            "f1": 0.518553536874667,
            "f1_stderr": 0.008044663814813483,
            "main_score": 0.7448965977318213
        },
        "evaluation_time": 1511.03,
        "fr": {
            "accuracy": 0.6911994989038521,
            "accuracy_stderr": 0.02390363546962472,
            "f1": 0.5057872704171278,
            "f1_stderr": 0.01393415879062004,
            "main_score": 0.6911994989038521
        },
        "hi": {
            "accuracy": 0.6484761563284331,
            "accuracy_stderr": 0.013548501316451252,
            "f1": 0.43613229707613943,
            "f1_stderr": 0.00698275402593528,
            "main_score": 0.6484761563284331
        },
        "th": {
            "accuracy": 0.4935623869801085,
            "accuracy_stderr": 0.009990103307568438,
            "f1": 0.3348547326952042,
            "f1_stderr": 0.0070855138122569335,
            "main_score": 0.4935623869801085
        }
    },
    "mteb_dataset_name": "MTOPIntentClassification",
    "dataset_revision": "6299947a7777084cc2d4b64235bf7190381ce755"
}