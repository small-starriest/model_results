{
  "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
  "mteb_dataset_name": "MassiveIntentClassification",
  "mteb_version": "1.0.3.dev0",
  "test": {
    "da": {
      "accuracy": 0.5316408876933423,
      "accuracy_stderr": 0.012734371666112038,
      "f1": 0.4941850564815886,
      "f1_stderr": 0.011522372307766442,
      "main_score": 0.5316408876933423
    },
    "evaluation_time": 231.61,
    "nb": {
      "accuracy": 0.5420309347679892,
      "accuracy_stderr": 0.03226819732461905,
      "f1": 0.5175454060291674,
      "f1_stderr": 0.025767650031151914,
      "main_score": 0.5420309347679892
    },
    "sv": {
      "accuracy": 0.5207800941492938,
      "accuracy_stderr": 0.010445126195213953,
      "f1": 0.490789956227084,
      "f1_stderr": 0.008844251479020312,
      "main_score": 0.5207800941492938
    }
  },
  "validation": {
    "da": {
      "accuracy": 0.5328578455484506,
      "accuracy_stderr": 0.011656818581498644,
      "f1": 0.49779592757479146,
      "f1_stderr": 0.012241811530746858,
      "main_score": 0.5328578455484506
    },
    "evaluation_time": 206.85,
    "nb": {
      "accuracy": 0.5559272011805214,
      "accuracy_stderr": 0.034678897465459595,
      "f1": 0.5263371871285855,
      "f1_stderr": 0.02941793652128257,
      "main_score": 0.5559272011805214
    },
    "sv": {
      "accuracy": 0.5259714707329071,
      "accuracy_stderr": 0.013264550653560626,
      "f1": 0.5014009008968655,
      "f1_stderr": 0.014773659894006344,
      "main_score": 0.5259714707329071
    }
  }
}