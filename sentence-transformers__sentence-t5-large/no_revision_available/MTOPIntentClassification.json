{
    "mteb_version": "0.0.2",
    "test": {
        "de": {
            "accuracy": 0.5250211327134404,
            "accuracy_stderr": 0.02973437448500998,
            "f1": 0.3414695437320193,
            "f1_stderr": 0.012360684938388872,
            "main_score": 0.5250211327134404
        },
        "en": {
            "accuracy": 0.6497720018239854,
            "accuracy_stderr": 0.01394948292727595,
            "f1": 0.4694497717647649,
            "f1_stderr": 0.010902338225975543,
            "main_score": 0.6497720018239854
        },
        "es": {
            "accuracy": 0.5206804536357572,
            "accuracy_stderr": 0.028608503171957393,
            "f1": 0.3323635090650249,
            "f1_stderr": 0.01016979847519464,
            "main_score": 0.5206804536357572
        },
        "evaluation_time": 116.72,
        "fr": {
            "accuracy": 0.47729408080175384,
            "accuracy_stderr": 0.03859909384744548,
            "f1": 0.3345316116675577,
            "f1_stderr": 0.014181791575631703,
            "main_score": 0.47729408080175384
        },
        "hi": {
            "accuracy": 0.03743277160272499,
            "accuracy_stderr": 0.01552092993569341,
            "f1": 0.010439177600298558,
            "f1_stderr": 0.0030235037270695607,
            "main_score": 0.03743277160272499
        },
        "th": {
            "accuracy": 0.049584086799276665,
            "accuracy_stderr": 0.018423169193115374,
            "f1": 0.016086090720855064,
            "f1_stderr": 0.005558648069847224,
            "main_score": 0.049584086799276665
        }
    },
    "mteb_dataset_name": "MTOPIntentClassification",
    "dataset_revision": "6299947a7777084cc2d4b64235bf7190381ce755"
}