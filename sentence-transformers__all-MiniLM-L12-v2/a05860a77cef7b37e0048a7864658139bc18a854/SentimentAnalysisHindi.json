{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 9.713332414627075,
  "kg_co2_emissions": 0.001471454874811256,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.4107421875,
        "f1": 0.3935006316131385,
        "f1_weighted": 0.4235048115442351,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.3935006316131385,
        "scores_per_experiment": [
          {
            "accuracy": 0.45849609375,
            "f1": 0.4230576163649067,
            "f1_weighted": 0.4781043534681697
          },
          {
            "accuracy": 0.37353515625,
            "f1": 0.36702062761043713,
            "f1_weighted": 0.38280081461836596
          },
          {
            "accuracy": 0.4169921875,
            "f1": 0.40039192940393,
            "f1_weighted": 0.4310831776380112
          },
          {
            "accuracy": 0.39990234375,
            "f1": 0.39448501184269275,
            "f1_weighted": 0.4136703655167243
          },
          {
            "accuracy": 0.3935546875,
            "f1": 0.37154501216269703,
            "f1_weighted": 0.3953421261464492
          },
          {
            "accuracy": 0.43310546875,
            "f1": 0.4191737606309945,
            "f1_weighted": 0.4494546772636119
          },
          {
            "accuracy": 0.4296875,
            "f1": 0.4013618979875928,
            "f1_weighted": 0.44208629362336466
          },
          {
            "accuracy": 0.4189453125,
            "f1": 0.40069153477213254,
            "f1_weighted": 0.4395979786790475
          },
          {
            "accuracy": 0.32421875,
            "f1": 0.32456503157703637,
            "f1_weighted": 0.3344412820409899
          },
          {
            "accuracy": 0.458984375,
            "f1": 0.4327138937789649,
            "f1_weighted": 0.46846704644761705
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}