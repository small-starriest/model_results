{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.8304226023722954,
            "accuracy_threshold": 0.7418354153633118,
            "ap": 0.6368133990830133,
            "f1": 0.6034918447048012,
            "f1_threshold": 0.643256425857544,
            "precision": 0.5343775427176566,
            "recall": 0.6931398416886544
        },
        "dot": {
            "accuracy": 0.8146271681468678,
            "accuracy_threshold": 2533.845947265625,
            "ap": 0.5778072296265885,
            "f1": 0.5628769265132901,
            "f1_threshold": 2075.621826171875,
            "precision": 0.487993803253292,
            "recall": 0.6649076517150396
        },
        "euclidean": {
            "accuracy": 0.8216606067830959,
            "accuracy_threshold": 40.57570266723633,
            "ap": 0.5997453037120352,
            "f1": 0.568560235063663,
            "f1_threshold": 46.821205139160156,
            "precision": 0.5303791685701233,
            "recall": 0.612664907651715
        },
        "evaluation_time": 110.55,
        "manhattan": {
            "accuracy": 0.8216606067830959,
            "accuracy_threshold": 1594.75048828125,
            "ap": 0.5998962379571767,
            "f1": 0.5698153158451947,
            "f1_threshold": 1863.289306640625,
            "precision": 0.5141158989598811,
            "recall": 0.6390501319261214
        },
        "max": {
            "accuracy": 0.8304226023722954,
            "ap": 0.6368133990830133,
            "f1": 0.6034918447048012
        }
    },
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}