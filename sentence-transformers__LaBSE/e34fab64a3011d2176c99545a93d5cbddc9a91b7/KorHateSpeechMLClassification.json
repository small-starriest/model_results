{
  "dataset_revision": "c657d15baf277c48d467f0625f7d33c50d4352ef",
  "evaluation_time": 5.95599889755249,
  "kg_co2_emissions": 0.000921905950857386,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.06622484045164456,
        "f1": 0.16370435037469566,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "lrap": 0.2014045709921944,
        "main_score": 0.06622484045164456,
        "scores_per_experiment": [
          {
            "accuracy": 0.06480117820324006,
            "f1": 0.1565814893434075,
            "lrap": 0.1971035837015164
          },
          {
            "accuracy": 0.06283750613647521,
            "f1": 0.176709542319826,
            "lrap": 0.19794905361915124
          },
          {
            "accuracy": 0.038782523318605794,
            "f1": 0.13502460957870785,
            "lrap": 0.1695576283205119
          },
          {
            "accuracy": 0.07118311242022582,
            "f1": 0.1827942340413117,
            "lrap": 0.20970381279659034
          },
          {
            "accuracy": 0.07511045655375552,
            "f1": 0.18181233579513242,
            "lrap": 0.21817214858451242
          },
          {
            "accuracy": 0.06774668630338733,
            "f1": 0.17387229895588185,
            "lrap": 0.19996727213221482
          },
          {
            "accuracy": 0.06381934216985763,
            "f1": 0.17141351231142804,
            "lrap": 0.2053128238695193
          },
          {
            "accuracy": 0.062346588119784,
            "f1": 0.15162112760427723,
            "lrap": 0.1966399389079752
          },
          {
            "accuracy": 0.07952871870397643,
            "f1": 0.14954341630413573,
            "lrap": 0.2096356297387166
          },
          {
            "accuracy": 0.07609229258713794,
            "f1": 0.1576709374928482,
            "lrap": 0.21000381825123549
          }
        ]
      }
    ]
  },
  "task_name": "KorHateSpeechMLClassification"
}