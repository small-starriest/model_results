{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 24.168683290481567,
  "kg_co2_emissions": 0.0036251606481021432,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.15701929474384566,
        "f1": 0.125275903220015,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.125275903220015,
        "precision": 0.11460467712962721,
        "recall": 0.15701929474384566
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0021547085369231873,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0021547085369231873,
        "precision": 0.0018383401264697495,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.016056225880408403,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.016056225880408403,
        "precision": 0.014922633666627159,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.07917498336660013,
        "f1": 0.061474347355222975,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.061474347355222975,
        "precision": 0.057511138743343175,
        "recall": 0.07917498336660013
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.018049540813330003,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.018049540813330003,
        "precision": 0.01663661164849841,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.0665335994677312,
        "f1": 0.04906898008994469,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.04906898008994469,
        "precision": 0.04520054982639013,
        "recall": 0.0665335994677312
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.0516696113430314,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0516696113430314,
        "precision": 0.048688386148875794,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.0718562874251497,
        "f1": 0.05265077385835868,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.05265077385835868,
        "precision": 0.046791601981222744,
        "recall": 0.0718562874251497
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.009863308865304872,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.009863308865304872,
        "precision": 0.008987580394766024,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.029520145104147376,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.029520145104147376,
        "precision": 0.027533038392941103,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.07385229540918163,
        "f1": 0.056381123991859954,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.056381123991859954,
        "precision": 0.05179630917069084,
        "recall": 0.07385229540918163
      },
      {
        "accuracy": 0.05256154357950765,
        "f1": 0.04055827152720801,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.04055827152720801,
        "precision": 0.03794220709445458,
        "recall": 0.05256154357950765
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027704413740783427,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0027704413740783427,
        "precision": 0.0023063739876858142,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.058555937082509654,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.058555937082509654,
        "precision": 0.05427264301926481,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.11842980705256155,
        "f1": 0.08776799455442169,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.08776799455442169,
        "precision": 0.0785479379790757,
        "recall": 0.11842980705256155
      },
      {
        "accuracy": 0.11310711909514305,
        "f1": 0.08743111128340668,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.08743111128340668,
        "precision": 0.07909448059148658,
        "recall": 0.11310711909514305
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.029176903587759293,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.029176903587759293,
        "precision": 0.02703446620361744,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0019927322206465536,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0019927322206465536,
        "precision": 0.001563328534924991,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.01442803337561766,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.01442803337561766,
        "precision": 0.013391382170733452,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.07651363938789088,
        "f1": 0.056509218215805034,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.056509218215805034,
        "precision": 0.05080870006019706,
        "recall": 0.07651363938789088
      },
      {
        "accuracy": 0.09381237524950099,
        "f1": 0.0714228324192606,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0714228324192606,
        "precision": 0.06550671588871051,
        "recall": 0.09381237524950099
      },
      {
        "accuracy": 0.05256154357950765,
        "f1": 0.04281315535224291,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.04281315535224291,
        "precision": 0.04035145605854189,
        "recall": 0.05256154357950765
      },
      {
        "accuracy": 0.2215568862275449,
        "f1": 0.17509047838389155,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.17509047838389155,
        "precision": 0.1585295258448951,
        "recall": 0.2215568862275449
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.007962795622563806,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.007962795622563806,
        "precision": 0.007051818448369333,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.07052561543579508,
        "f1": 0.05629835306351839,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.05629835306351839,
        "precision": 0.052562557311882196,
        "recall": 0.07052561543579508
      },
      {
        "accuracy": 0.22288755821689954,
        "f1": 0.1876271573351989,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.1876271573351989,
        "precision": 0.17697150496871117,
        "recall": 0.22288755821689954
      },
      {
        "accuracy": 0.059880239520958084,
        "f1": 0.047627672344904545,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.047627672344904545,
        "precision": 0.04402304467174727,
        "recall": 0.059880239520958084
      },
      {
        "accuracy": 0.18496340652029275,
        "f1": 0.15221018185078566,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.15221018185078566,
        "precision": 0.14318183575800544,
        "recall": 0.18496340652029275
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.1573779136111178,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.1573779136111178,
        "precision": 0.15043679994130427,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.10246174318030606,
        "f1": 0.07458401846467819,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.07458401846467819,
        "precision": 0.06585151528091734,
        "recall": 0.10246174318030606
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.02143348063600582,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.02143348063600582,
        "precision": 0.019914932040680542,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.08383233532934131,
        "f1": 0.06999087136479694,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.06999087136479694,
        "precision": 0.06640946330528935,
        "recall": 0.08383233532934131
      },
      {
        "accuracy": 0.1550232867598137,
        "f1": 0.11794703559174616,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.11794703559174616,
        "precision": 0.1060928407734795,
        "recall": 0.1550232867598137
      },
      {
        "accuracy": 0.16367265469061876,
        "f1": 0.14085391702761318,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.14085391702761318,
        "precision": 0.13564602351106977,
        "recall": 0.16367265469061876
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0022235553178675226,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0022235553178675226,
        "precision": 0.001735732048018584,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.19095143047238855,
        "f1": 0.15885143290983783,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.15885143290983783,
        "precision": 0.14947518745968358,
        "recall": 0.19095143047238855
      },
      {
        "accuracy": 0.21290751829673984,
        "f1": 0.1642037208588317,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.1642037208588317,
        "precision": 0.14848931286057032,
        "recall": 0.21290751829673984
      },
      {
        "accuracy": 0.2162341982701264,
        "f1": 0.17762856123562626,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.17762856123562626,
        "precision": 0.16578813404338824,
        "recall": 0.2162341982701264
      },
      {
        "accuracy": 0.08715901530272788,
        "f1": 0.06788127716121324,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.06788127716121324,
        "precision": 0.06252799013269206,
        "recall": 0.08715901530272788
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0014545772461228607,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0014545772461228607,
        "precision": 0.0009781214518283208,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.05322687957418496,
        "f1": 0.042704752551622274,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.042704752551622274,
        "precision": 0.040043488479656816,
        "recall": 0.05322687957418496
      },
      {
        "accuracy": 0.14238190286094476,
        "f1": 0.10164649056864625,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.10164649056864625,
        "precision": 0.08927300060034592,
        "recall": 0.14238190286094476
      },
      {
        "accuracy": 0.19693945442448438,
        "f1": 0.15069301152786355,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.15069301152786355,
        "precision": 0.13648470650713304,
        "recall": 0.19693945442448438
      },
      {
        "accuracy": 0.1536926147704591,
        "f1": 0.13506851165703862,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.13506851165703862,
        "precision": 0.12989455052866233,
        "recall": 0.1536926147704591
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.006992993699580526,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.006992993699580526,
        "precision": 0.005817729620124828,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.011129904692778943,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.011129904692778943,
        "precision": 0.009764181753536378,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.028202641007951435,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.028202641007951435,
        "precision": 0.026463401896745738,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.02016127874702292,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.02016127874702292,
        "precision": 0.018918004295800293,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.019838148455681732,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.019838148455681732,
        "precision": 0.018645024882108237,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.01872361618108528,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01872361618108528,
        "precision": 0.01733537689823723,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.025750296436095825,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.025750296436095825,
        "precision": 0.023061484263642202,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0028551471384982443,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0028551471384982443,
        "precision": 0.0020710623006032188,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.018200107721065804,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.018200107721065804,
        "precision": 0.016511709625482082,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.02772989618965781,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.02772989618965781,
        "precision": 0.02540802266185047,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.008298218378058697,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.008298218378058697,
        "precision": 0.006855510177127811,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.027671142439835143,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.027671142439835143,
        "precision": 0.02560242791772486,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0017491674874706026,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0017491674874706026,
        "precision": 0.0013812626878629704,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.020096147206505866,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.020096147206505866,
        "precision": 0.017656907434479483,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.009389872614434589,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.009389872614434589,
        "precision": 0.008254804554952738,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.011494585690008526,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.011494585690008526,
        "precision": 0.010425075721939788,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.017612922303541067,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.017612922303541067,
        "precision": 0.016114577720579202,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00047053166998892263,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00047053166998892263,
        "precision": 0.00029338769789437997,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.029073459057608404,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.029073459057608404,
        "precision": 0.0266937168214401,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.010674073000060411,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.010674073000060411,
        "precision": 0.0090000014401212,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.01304716574177652,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.01304716574177652,
        "precision": 0.01229280477440504,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.01897870780863669,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.01897870780863669,
        "precision": 0.017666297177459732,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.06786427145708583,
        "f1": 0.03613683758394337,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.03613683758394337,
        "precision": 0.029222802775696985,
        "recall": 0.06786427145708583
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.08311276448685839,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.08311276448685839,
        "precision": 0.07098318994526578,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.031084480548092024,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.031084480548092024,
        "precision": 0.028000988065418026,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.34930139720558884,
        "f1": 0.29716083711644314,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.29716083711644314,
        "precision": 0.28053456512377556,
        "recall": 0.34930139720558884
      },
      {
        "accuracy": 0.17564870259481039,
        "f1": 0.1417555276836714,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.1417555276836714,
        "precision": 0.1306595803102789,
        "recall": 0.17564870259481039
      },
      {
        "accuracy": 0.2222222222222222,
        "f1": 0.1863965191310501,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.1863965191310501,
        "precision": 0.17423302283581726,
        "recall": 0.2222222222222222
      },
      {
        "accuracy": 0.35196274118429804,
        "f1": 0.3105098865508481,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3105098865508481,
        "precision": 0.2964729751655899,
        "recall": 0.35196274118429804
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.019185624906536025,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.019185624906536025,
        "precision": 0.014779982000932258,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.08183632734530938,
        "f1": 0.05292505840820975,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.05292505840820975,
        "precision": 0.04543080766729959,
        "recall": 0.08183632734530938
      },
      {
        "accuracy": 0.25016633399866933,
        "f1": 0.21697177101432527,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21697177101432527,
        "precision": 0.20523338717870704,
        "recall": 0.25016633399866933
      },
      {
        "accuracy": 0.07984031936127745,
        "f1": 0.04798053825063744,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.04798053825063744,
        "precision": 0.039686533520923564,
        "recall": 0.07984031936127745
      },
      {
        "accuracy": 0.29008649367930806,
        "f1": 0.24905949192376337,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.24905949192376337,
        "precision": 0.2355937943105713,
        "recall": 0.29008649367930806
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0008702349303036582,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0008702349303036582,
        "precision": 0.0005015442438402809,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.2435129740518962,
        "f1": 0.1967505105229656,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1967505105229656,
        "precision": 0.18076949967874,
        "recall": 0.2435129740518962
      },
      {
        "accuracy": 0.10113107119095142,
        "f1": 0.060902973502716805,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.060902973502716805,
        "precision": 0.050717642518251824,
        "recall": 0.10113107119095142
      },
      {
        "accuracy": 0.13639387890884896,
        "f1": 0.10075662121570304,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10075662121570304,
        "precision": 0.09036798626041195,
        "recall": 0.13639387890884896
      },
      {
        "accuracy": 0.15103127079174983,
        "f1": 0.11820324275414094,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.11820324275414094,
        "precision": 0.10723291272193468,
        "recall": 0.15103127079174983
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 3.995547944147096e-05,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 3.995547944147096e-05,
        "precision": 2.0365106540225524e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.20825016633399868,
        "f1": 0.17063539405407388,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.17063539405407388,
        "precision": 0.15748639805526032,
        "recall": 0.20825016633399868
      },
      {
        "accuracy": 0.06986027944111776,
        "f1": 0.042032486992566835,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.042032486992566835,
        "precision": 0.03510718474212539,
        "recall": 0.06986027944111776
      },
      {
        "accuracy": 0.0998003992015968,
        "f1": 0.06152883727146965,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.06152883727146965,
        "precision": 0.052003978160874896,
        "recall": 0.0998003992015968
      },
      {
        "accuracy": 0.2934131736526946,
        "f1": 0.2551531044545017,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2551531044545017,
        "precision": 0.2420129730292014,
        "recall": 0.2934131736526946
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.07007747874180642,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.07007747874180642,
        "precision": 0.055976904263430785,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.2934131736526946,
        "f1": 0.20116569187838415,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.20116569187838415,
        "precision": 0.17351057403452613,
        "recall": 0.2934131736526946
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.026875476676452383,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.026875476676452383,
        "precision": 0.02259254485557029,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.40119760479041916,
        "f1": 0.31786956667196187,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.31786956667196187,
        "precision": 0.28969206848448364,
        "recall": 0.40119760479041916
      },
      {
        "accuracy": 0.2867598137059215,
        "f1": 0.21424203060929606,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.21424203060929606,
        "precision": 0.19150598415196154,
        "recall": 0.2867598137059215
      },
      {
        "accuracy": 0.6899534264803726,
        "f1": 0.6156501811192431,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.6156501811192431,
        "precision": 0.5838933244621868,
        "recall": 0.6899534264803726
      },
      {
        "accuracy": 0.8815701929474384,
        "f1": 0.8516522510534487,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.8516522510534487,
        "precision": 0.8379352406298515,
        "recall": 0.8815701929474384
      },
      {
        "accuracy": 0.09913506320691949,
        "f1": 0.042685611524537745,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.042685611524537745,
        "precision": 0.03358243766845201,
        "recall": 0.09913506320691949
      },
      {
        "accuracy": 0.1377245508982036,
        "f1": 0.0851084374847194,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.0851084374847194,
        "precision": 0.07228830315483097,
        "recall": 0.1377245508982036
      },
      {
        "accuracy": 0.46706586826347307,
        "f1": 0.39208558869237503,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.39208558869237503,
        "precision": 0.36401557893573855,
        "recall": 0.46706586826347307
      },
      {
        "accuracy": 0.18695941450432468,
        "f1": 0.1059346019966261,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.1059346019966261,
        "precision": 0.08626602608178671,
        "recall": 0.18695941450432468
      },
      {
        "accuracy": 0.7751164337990686,
        "f1": 0.7193390995786204,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.7193390995786204,
        "precision": 0.694623451509679,
        "recall": 0.7751164337990686
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00030646495369519584,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.00030646495369519584,
        "precision": 0.00016297440940761746,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.520292747837658,
        "f1": 0.4248891106675538,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.4248891106675538,
        "precision": 0.3891917463773752,
        "recall": 0.520292747837658
      },
      {
        "accuracy": 0.24085163007318697,
        "f1": 0.1467638308838262,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.1467638308838262,
        "precision": 0.12176002326060267,
        "recall": 0.24085163007318697
      },
      {
        "accuracy": 0.37658017298735863,
        "f1": 0.2791961961563934,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.2791961961563934,
        "precision": 0.24732904321227678,
        "recall": 0.37658017298735863
      },
      {
        "accuracy": 0.3060545575515635,
        "f1": 0.22402506194921362,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.22402506194921362,
        "precision": 0.19781156532360006,
        "recall": 0.3060545575515635
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0010253358325801078,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0010253358325801078,
        "precision": 0.0008570296136803986,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.28476380572188953,
        "f1": 0.21312354506618153,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.21312354506618153,
        "precision": 0.19078229082221096,
        "recall": 0.28476380572188953
      },
      {
        "accuracy": 0.15701929474384566,
        "f1": 0.08611966964686849,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.08611966964686849,
        "precision": 0.0700664278674924,
        "recall": 0.15701929474384566
      },
      {
        "accuracy": 0.23020625415834997,
        "f1": 0.14003689124090984,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.14003689124090984,
        "precision": 0.11725119267240906,
        "recall": 0.23020625415834997
      },
      {
        "accuracy": 0.8642714570858283,
        "f1": 0.8299084370940657,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.8299084370940657,
        "precision": 0.8145265025504547,
        "recall": 0.8642714570858283
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.03240511545743188,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.03240511545743188,
        "precision": 0.02767223101260908,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.10445775116433799,
        "f1": 0.07014146310553497,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.07014146310553497,
        "precision": 0.05989528878750436,
        "recall": 0.10445775116433799
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.028753321353209293,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.028753321353209293,
        "precision": 0.02637813506076979,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.18562874251497005,
        "f1": 0.15442230188990536,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15442230188990536,
        "precision": 0.14409316288058804,
        "recall": 0.18562874251497005
      },
      {
        "accuracy": 0.27012641383898867,
        "f1": 0.22631918854852495,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.22631918854852495,
        "precision": 0.21219029017773633,
        "recall": 0.27012641383898867
      },
      {
        "accuracy": 0.18762475049900199,
        "f1": 0.14936662546442986,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.14936662546442986,
        "precision": 0.13588563613513713,
        "recall": 0.18762475049900199
      },
      {
        "accuracy": 0.2528276779773786,
        "f1": 0.21661443844489517,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.21661443844489517,
        "precision": 0.20493212720928344,
        "recall": 0.2528276779773786
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.017503575045148247,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.017503575045148247,
        "precision": 0.013647556312191765,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.06719893546240852,
        "f1": 0.0460834943868876,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0460834943868876,
        "precision": 0.04022508872808274,
        "recall": 0.06719893546240852
      },
      {
        "accuracy": 0.19161676646706588,
        "f1": 0.16275203321111506,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.16275203321111506,
        "precision": 0.1522756795211885,
        "recall": 0.19161676646706588
      },
      {
        "accuracy": 0.07451763140385895,
        "f1": 0.043421248105996256,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.043421248105996256,
        "precision": 0.03601116069928446,
        "recall": 0.07451763140385895
      },
      {
        "accuracy": 0.2774451097804391,
        "f1": 0.23841467174800504,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.23841467174800504,
        "precision": 0.22514991535371828,
        "recall": 0.2774451097804391
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002216911838607456,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002216911838607456,
        "precision": 0.001836717736054715,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.16092793008373613,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.16092793008373613,
        "precision": 0.14669397634966494,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.07252162341982701,
        "f1": 0.040372602927493145,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.040372602927493145,
        "precision": 0.032661444787193294,
        "recall": 0.07252162341982701
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.07379232236184999,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.07379232236184999,
        "precision": 0.06446863552651975,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.11909514304723885,
        "f1": 0.0943223849411474,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.0943223849411474,
        "precision": 0.08619591024780646,
        "recall": 0.11909514304723885
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008254435869793391,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008254435869793391,
        "precision": 0.0007510616826336532,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.1550232867598137,
        "f1": 0.12761144377910846,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.12761144377910846,
        "precision": 0.11760654515145534,
        "recall": 0.1550232867598137
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.029755259355693373,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.029755259355693373,
        "precision": 0.024612571394008517,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.08383233532934131,
        "f1": 0.0528381632040877,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0528381632040877,
        "precision": 0.04565571727204345,
        "recall": 0.08383233532934131
      },
      {
        "accuracy": 0.22954091816367264,
        "f1": 0.19090037902447282,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.19090037902447282,
        "precision": 0.17855572809218148,
        "recall": 0.22954091816367264
      },
      {
        "accuracy": 0.1383898868928809,
        "f1": 0.08468659545916794,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.08468659545916794,
        "precision": 0.07061557039101948,
        "recall": 0.1383898868928809
      },
      {
        "accuracy": 0.2834331337325349,
        "f1": 0.20968659122351738,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.20968659122351738,
        "precision": 0.1846413474157985,
        "recall": 0.2834331337325349
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.018265973765331588,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.018265973765331588,
        "precision": 0.014797898608538198,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.2481703260146374,
        "f1": 0.20155637131441617,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.20155637131441617,
        "precision": 0.18566535071066992,
        "recall": 0.2481703260146374
      },
      {
        "accuracy": 0.6999334664005322,
        "f1": 0.6523106272263131,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.6523106272263131,
        "precision": 0.6336116460737806,
        "recall": 0.6999334664005322
      },
      {
        "accuracy": 0.19228210246174318,
        "f1": 0.15198005242446092,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.15198005242446092,
        "precision": 0.13949256434358506,
        "recall": 0.19228210246174318
      },
      {
        "accuracy": 0.6473719228210246,
        "f1": 0.6099101562682597,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.6099101562682597,
        "precision": 0.5939042642235187,
        "recall": 0.6473719228210246
      },
      {
        "accuracy": 0.09647371922821024,
        "f1": 0.051314251320894386,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.051314251320894386,
        "precision": 0.04205208060536619,
        "recall": 0.09647371922821024
      },
      {
        "accuracy": 0.09580838323353294,
        "f1": 0.060297117040152705,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.060297117040152705,
        "precision": 0.05145064147060154,
        "recall": 0.09580838323353294
      },
      {
        "accuracy": 0.29607451763140386,
        "f1": 0.24710314820095258,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.24710314820095258,
        "precision": 0.22868339799477524,
        "recall": 0.29607451763140386
      },
      {
        "accuracy": 0.18762475049900199,
        "f1": 0.11998547316008368,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.11998547316008368,
        "precision": 0.10147652764918233,
        "recall": 0.18762475049900199
      },
      {
        "accuracy": 0.5914836992681304,
        "f1": 0.5451530800832197,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.5451530800832197,
        "precision": 0.5264305678182744,
        "recall": 0.5914836992681304
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0012149155877717093,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0012149155877717093,
        "precision": 0.0009726904177432331,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.3925482368596141,
        "f1": 0.32691471404799466,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.32691471404799466,
        "precision": 0.3016705904430455,
        "recall": 0.3925482368596141
      },
      {
        "accuracy": 0.22954091816367264,
        "f1": 0.1584972098944155,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.1584972098944155,
        "precision": 0.13601094941834516,
        "recall": 0.22954091816367264
      },
      {
        "accuracy": 0.3087159015302728,
        "f1": 0.23978366019284178,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.23978366019284178,
        "precision": 0.21584111718842258,
        "recall": 0.3087159015302728
      },
      {
        "accuracy": 0.21157684630738524,
        "f1": 0.15664860754681112,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.15664860754681112,
        "precision": 0.13824678684958128,
        "recall": 0.21157684630738524
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00035175785172573124,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.00035175785172573124,
        "precision": 0.00018787173703038116,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.17564870259481039,
        "f1": 0.13327650677739622,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.13327650677739622,
        "precision": 0.12050814596556447,
        "recall": 0.17564870259481039
      },
      {
        "accuracy": 0.1536926147704591,
        "f1": 0.09776873904586221,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.09776873904586221,
        "precision": 0.08236179433784223,
        "recall": 0.1536926147704591
      },
      {
        "accuracy": 0.2109115103127079,
        "f1": 0.142468574698233,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.142468574698233,
        "precision": 0.12289907207278347,
        "recall": 0.2109115103127079
      },
      {
        "accuracy": 0.6227544910179641,
        "f1": 0.581820185063698,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.581820185063698,
        "precision": 0.565751464354805,
        "recall": 0.6227544910179641
      },
      {
        "accuracy": 0.13506320691949433,
        "f1": 0.07192828595513422,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.07192828595513422,
        "precision": 0.05862867537051139,
        "recall": 0.13506320691949433
      },
      {
        "accuracy": 0.28409846972721225,
        "f1": 0.194033145829553,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.194033145829553,
        "precision": 0.16687974736876934,
        "recall": 0.28409846972721225
      },
      {
        "accuracy": 0.05854956753160346,
        "f1": 0.03253781791978876,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03253781791978876,
        "precision": 0.026818664052677636,
        "recall": 0.05854956753160346
      },
      {
        "accuracy": 0.4091816367265469,
        "f1": 0.329559333251948,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.329559333251948,
        "precision": 0.30103391101395094,
        "recall": 0.4091816367265469
      },
      {
        "accuracy": 0.8556220891550232,
        "f1": 0.8204036371701042,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8204036371701042,
        "precision": 0.8046351740962521,
        "recall": 0.8556220891550232
      },
      {
        "accuracy": 0.2967398536260812,
        "f1": 0.2320699297745206,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2320699297745206,
        "precision": 0.21025718998195098,
        "recall": 0.2967398536260812
      },
      {
        "accuracy": 0.656686626746507,
        "f1": 0.5829373000031682,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5829373000031682,
        "precision": 0.5522241231822069,
        "recall": 0.656686626746507
      },
      {
        "accuracy": 0.08915502328675981,
        "f1": 0.0380371370720252,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0380371370720252,
        "precision": 0.02966571957050752,
        "recall": 0.08915502328675981
      },
      {
        "accuracy": 0.12974051896207583,
        "f1": 0.08001078895543835,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08001078895543835,
        "precision": 0.06827948859367766,
        "recall": 0.12974051896207583
      },
      {
        "accuracy": 0.447771124417831,
        "f1": 0.3792202966538506,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3792202966538506,
        "precision": 0.3540944565894666,
        "recall": 0.447771124417831
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.1052493842106567,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1052493842106567,
        "precision": 0.08861124364372255,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.7538256819693946,
        "f1": 0.6975667712194658,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6975667712194658,
        "precision": 0.673342204479929,
        "recall": 0.7538256819693946
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.000546557861259202,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.000546557861259202,
        "precision": 0.0002950102310990363,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.48502994011976047,
        "f1": 0.3993563618314117,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3993563618314117,
        "precision": 0.36761156157363745,
        "recall": 0.48502994011976047
      },
      {
        "accuracy": 0.2315369261477046,
        "f1": 0.14365282459094833,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.14365282459094833,
        "precision": 0.11984852331002137,
        "recall": 0.2315369261477046
      },
      {
        "accuracy": 0.38323353293413176,
        "f1": 0.28548209017270887,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.28548209017270887,
        "precision": 0.252735886252187,
        "recall": 0.38323353293413176
      },
      {
        "accuracy": 0.2774451097804391,
        "f1": 0.202468185496247,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.202468185496247,
        "precision": 0.17865499160409337,
        "recall": 0.2774451097804391
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0004077353676401195,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004077353676401195,
        "precision": 0.0002166996177270599,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.2907518296739854,
        "f1": 0.222896237716597,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.222896237716597,
        "precision": 0.20161970305105084,
        "recall": 0.2907518296739854
      },
      {
        "accuracy": 0.1483699268130406,
        "f1": 0.0756799464218265,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0756799464218265,
        "precision": 0.05889709019727178,
        "recall": 0.1483699268130406
      },
      {
        "accuracy": 0.20958083832335328,
        "f1": 0.12668403693638774,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.12668403693638774,
        "precision": 0.10659154298717277,
        "recall": 0.20958083832335328
      },
      {
        "accuracy": 0.8010645375914837,
        "f1": 0.7584941228653803,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7584941228653803,
        "precision": 0.7403700535437063,
        "recall": 0.8010645375914837
      },
      {
        "accuracy": 0.0658682634730539,
        "f1": 0.04601384715901446,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.04601384715901446,
        "precision": 0.04107927096088704,
        "recall": 0.0658682634730539
      },
      {
        "accuracy": 0.06852960745176315,
        "f1": 0.050517552159241,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.050517552159241,
        "precision": 0.0458957583957584,
        "recall": 0.06852960745176315
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0030556528557901604,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0030556528557901604,
        "precision": 0.0024561117217471173,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01792448954313404,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.01792448954313404,
        "precision": 0.01613941650839632,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.05854956753160346,
        "f1": 0.04462774979585369,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.04462774979585369,
        "precision": 0.04211650739585287,
        "recall": 0.05854956753160346
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.009694413398174041,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.009694413398174041,
        "precision": 0.008819742462389665,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.02598577442694032,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.02598577442694032,
        "precision": 0.024151567204591592,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.04008691950824926,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.04008691950824926,
        "precision": 0.03817991489154018,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.010805872991501734,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.010805872991501734,
        "precision": 0.009856251772419437,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.013092459407502085,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.013092459407502085,
        "precision": 0.012474283147796953,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.10911510312707917,
        "f1": 0.08380824588012452,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.08380824588012452,
        "precision": 0.07741967174619593,
        "recall": 0.10911510312707917
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.021734824111888165,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.021734824111888165,
        "precision": 0.02023758557818098,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001247168321250246,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.001247168321250246,
        "precision": 0.0010039327951927562,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.03063024340180493,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.03063024340180493,
        "precision": 0.02875816130357772,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.10379241516966067,
        "f1": 0.07363585066687633,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.07363585066687633,
        "precision": 0.06549828182337158,
        "recall": 0.10379241516966067
      },
      {
        "accuracy": 0.09314703925482369,
        "f1": 0.06906190379150656,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.06906190379150656,
        "precision": 0.06229660009925566,
        "recall": 0.09314703925482369
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.01545301339913956,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.01545301339913956,
        "precision": 0.014935986153551023,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008812452770038447,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0008812452770038447,
        "precision": 0.0007806669677685563,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.010477504825861952,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.010477504825861952,
        "precision": 0.009862861437193362,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.09780439121756487,
        "f1": 0.0719535676718086,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0719535676718086,
        "precision": 0.0644424462131154,
        "recall": 0.09780439121756487
      },
      {
        "accuracy": 0.1264138389886893,
        "f1": 0.09394029923350786,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.09394029923350786,
        "precision": 0.08492749886672567,
        "recall": 0.1264138389886893
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.028902029868517948,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.028902029868517948,
        "precision": 0.02685509391352364,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.019014777273203214,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.019014777273203214,
        "precision": 0.015813433627804883,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.04856952761144378,
        "f1": 0.03464081437546272,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.03464081437546272,
        "precision": 0.030646007167963254,
        "recall": 0.04856952761144378
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.017288588546073576,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.017288588546073576,
        "precision": 0.015498063701656515,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.05993938049826272,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.05993938049826272,
        "precision": 0.055234433459618676,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.10445775116433799,
        "f1": 0.08665645011091372,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.08665645011091372,
        "precision": 0.0816499815405665,
        "recall": 0.10445775116433799
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.044703112449237845,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.044703112449237845,
        "precision": 0.041878357127697156,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.07385229540918163,
        "f1": 0.05716669840515173,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.05716669840515173,
        "precision": 0.05240427434372877,
        "recall": 0.07385229540918163
      },
      {
        "accuracy": 0.09846972721224219,
        "f1": 0.08181727050068087,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.08181727050068087,
        "precision": 0.07736159679247188,
        "recall": 0.09846972721224219
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.011018364549277591,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.011018364549277591,
        "precision": 0.008747011138446286,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.07850964737192283,
        "f1": 0.0671832155187284,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0671832155187284,
        "precision": 0.06326366396226675,
        "recall": 0.07850964737192283
      },
      {
        "accuracy": 0.04258150365934797,
        "f1": 0.02564247167041578,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.02564247167041578,
        "precision": 0.021472962768942238,
        "recall": 0.04258150365934797
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.06105503746839171,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.06105503746839171,
        "precision": 0.05718340136933608,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0011377563832646181,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0011377563832646181,
        "precision": 0.0006898152240488973,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.07584830339321358,
        "f1": 0.057348922311927154,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.057348922311927154,
        "precision": 0.05289879179976343,
        "recall": 0.07584830339321358
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.023896754029028182,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.023896754029028182,
        "precision": 0.020727988467509423,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.04258445052021833,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.04258445052021833,
        "precision": 0.038181808581010175,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.05788423153692615,
        "f1": 0.04278327842794654,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.04278327842794654,
        "precision": 0.038353895162167674,
        "recall": 0.05788423153692615
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00033549273718644243,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00033549273718644243,
        "precision": 0.00017999968501428303,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.05946874636337815,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.05946874636337815,
        "precision": 0.05427946876209771,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.021560803214316464,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.021560803214316464,
        "precision": 0.01866045446384768,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.029839670075864355,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.029839670075864355,
        "precision": 0.02558370125683317,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.12441783100465735,
        "f1": 0.10442887778646369,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.10442887778646369,
        "precision": 0.09839257154978161,
        "recall": 0.12441783100465735
      },
      {
        "accuracy": 0.07850964737192283,
        "f1": 0.040333801261944975,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.040333801261944975,
        "precision": 0.03204461561169199,
        "recall": 0.07850964737192283
      },
      {
        "accuracy": 0.1497005988023952,
        "f1": 0.10238648761602852,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.10238648761602852,
        "precision": 0.0886715044399675,
        "recall": 0.1497005988023952
      },
      {
        "accuracy": 0.056553559547571526,
        "f1": 0.033413643332041824,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.033413643332041824,
        "precision": 0.0285767618785793,
        "recall": 0.056553559547571526
      },
      {
        "accuracy": 0.28409846972721225,
        "f1": 0.2361187677554943,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2361187677554943,
        "precision": 0.21821357285429144,
        "recall": 0.28409846972721225
      },
      {
        "accuracy": 0.46174318030605455,
        "f1": 0.40552481760399756,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.40552481760399756,
        "precision": 0.38587288979924755,
        "recall": 0.46174318030605455
      },
      {
        "accuracy": 0.19760479041916168,
        "f1": 0.16034133980084184,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.16034133980084184,
        "precision": 0.14719373182447035,
        "recall": 0.19760479041916168
      },
      {
        "accuracy": 0.302727877578177,
        "f1": 0.2514262480330345,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2514262480330345,
        "precision": 0.23357278487019006,
        "recall": 0.302727877578177
      },
      {
        "accuracy": 0.42847638057218895,
        "f1": 0.38340895193268876,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.38340895193268876,
        "precision": 0.36733199858860305,
        "recall": 0.42847638057218895
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.021919459658083163,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.021919459658083163,
        "precision": 0.01687218619060817,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.1051230871590153,
        "f1": 0.07261959043396168,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.07261959043396168,
        "precision": 0.06311534929005869,
        "recall": 0.1051230871590153
      },
      {
        "accuracy": 0.10179640718562874,
        "f1": 0.06311893601725702,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.06311893601725702,
        "precision": 0.05405708296636965,
        "recall": 0.10179640718562874
      },
      {
        "accuracy": 0.36127744510978044,
        "f1": 0.3107689863178885,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3107689863178885,
        "precision": 0.2918316805542355,
        "recall": 0.36127744510978044
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0011740554837121407,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0011740554837121407,
        "precision": 0.0007546146105093784,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.3359946773120426,
        "f1": 0.27540897041895046,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.27540897041895046,
        "precision": 0.2534465460613165,
        "recall": 0.3359946773120426
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.06069225555628004,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.06069225555628004,
        "precision": 0.049416092976031924,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.18030605455755155,
        "f1": 0.12766328814233005,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12766328814233005,
        "precision": 0.11119498295645816,
        "recall": 0.18030605455755155
      },
      {
        "accuracy": 0.20691949434464404,
        "f1": 0.1605746659638875,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.1605746659638875,
        "precision": 0.14434268109743245,
        "recall": 0.20691949434464404
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.0017972576614763384,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0017972576614763384,
        "precision": 0.0011290033966579536,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.2109115103127079,
        "f1": 0.16962331173320958,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.16962331173320958,
        "precision": 0.15538856150133595,
        "recall": 0.2109115103127079
      },
      {
        "accuracy": 0.08183632734530938,
        "f1": 0.0467751330766477,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0467751330766477,
        "precision": 0.039293269032530095,
        "recall": 0.08183632734530938
      },
      {
        "accuracy": 0.10312707917498337,
        "f1": 0.06141936143251321,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.06141936143251321,
        "precision": 0.05148016757923879,
        "recall": 0.10312707917498337
      },
      {
        "accuracy": 0.38988689288090483,
        "f1": 0.3406648315829952,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.3406648315829952,
        "precision": 0.3229128563459901,
        "recall": 0.38988689288090483
      },
      {
        "accuracy": 0.09647371922821024,
        "f1": 0.07073669343541364,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.07073669343541364,
        "precision": 0.06301721952919558,
        "recall": 0.09647371922821024
      },
      {
        "accuracy": 0.14171656686626746,
        "f1": 0.116300756357485,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.116300756357485,
        "precision": 0.10804007603741471,
        "recall": 0.14171656686626746
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0055298117770188554,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.0055298117770188554,
        "precision": 0.005196105395972195,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.03891131923935212,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.03891131923935212,
        "precision": 0.037016700086112,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.16367265469061876,
        "f1": 0.14194742997975202,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.14194742997975202,
        "precision": 0.13612002325548916,
        "recall": 0.16367265469061876
      },
      {
        "accuracy": 0.04125083166999335,
        "f1": 0.035120246395015466,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.035120246395015466,
        "precision": 0.033352311191593334,
        "recall": 0.04125083166999335
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.09908539648151332,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.09908539648151332,
        "precision": 0.09389185972897005,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.104844268156557,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.104844268156557,
        "precision": 0.10248625917845618,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.1437125748502994,
        "f1": 0.11044291975062014,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.11044291975062014,
        "precision": 0.10012050070978726,
        "recall": 0.1437125748502994
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.01574339089650672,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.01574339089650672,
        "precision": 0.014054215256788535,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.05123087159015303,
        "f1": 0.04452794629713518,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.04452794629713518,
        "precision": 0.04282971351689416,
        "recall": 0.05123087159015303
      },
      {
        "accuracy": 0.08915502328675981,
        "f1": 0.07699871823353299,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.07699871823353299,
        "precision": 0.07418289256134142,
        "recall": 0.08915502328675981
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0043272642613498445,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.0043272642613498445,
        "precision": 0.0035562743255554354,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.09846972721224219,
        "f1": 0.07920995554981315,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.07920995554981315,
        "precision": 0.07422461036059926,
        "recall": 0.09846972721224219
      },
      {
        "accuracy": 0.14570858283433133,
        "f1": 0.11442694317606258,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.11442694317606258,
        "precision": 0.10423214417725395,
        "recall": 0.14570858283433133
      },
      {
        "accuracy": 0.12042581503659348,
        "f1": 0.09701956807124283,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.09701956807124283,
        "precision": 0.08926644066364625,
        "recall": 0.12042581503659348
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.0360220345443214,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0360220345443214,
        "precision": 0.03360553045071425,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0004268974013695098,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0004268974013695098,
        "precision": 0.00027106281264631225,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.034597471723220224,
        "f1": 0.026938132185702648,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.026938132185702648,
        "precision": 0.025783060434422703,
        "recall": 0.034597471723220224
      },
      {
        "accuracy": 0.16833000665335995,
        "f1": 0.13681306495677753,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.13681306495677753,
        "precision": 0.12598194664062926,
        "recall": 0.16833000665335995
      },
      {
        "accuracy": 0.22022621423819028,
        "f1": 0.18021158260679218,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.18021158260679218,
        "precision": 0.16634860789884073,
        "recall": 0.22022621423819028
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.10756997831636447,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.10756997831636447,
        "precision": 0.10507127336341922,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.1277445109780439,
        "f1": 0.06891484414858719,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06891484414858719,
        "precision": 0.05529687918038153,
        "recall": 0.1277445109780439
      },
      {
        "accuracy": 0.27877578176979373,
        "f1": 0.1949245956231984,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.1949245956231984,
        "precision": 0.16903195911429444,
        "recall": 0.27877578176979373
      },
      {
        "accuracy": 0.0499001996007984,
        "f1": 0.028120692252064396,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.028120692252064396,
        "precision": 0.023479849859829836,
        "recall": 0.0499001996007984
      },
      {
        "accuracy": 0.3253493013972056,
        "f1": 0.26453451922513793,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.26453451922513793,
        "precision": 0.24310141141478467,
        "recall": 0.3253493013972056
      },
      {
        "accuracy": 0.7624750499001997,
        "f1": 0.7153504955900164,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7153504955900164,
        "precision": 0.695122826242939,
        "recall": 0.7624750499001997
      },
      {
        "accuracy": 0.30073186959414505,
        "f1": 0.24339414125494138,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.24339414125494138,
        "precision": 0.22302024138351484,
        "recall": 0.30073186959414505
      },
      {
        "accuracy": 0.6167664670658682,
        "f1": 0.5533393530399519,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5533393530399519,
        "precision": 0.5265532427209073,
        "recall": 0.6167664670658682
      },
      {
        "accuracy": 0.7351962741184298,
        "f1": 0.6945497893102683,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6945497893102683,
        "precision": 0.6765088869879289,
        "recall": 0.7351962741184298
      },
      {
        "accuracy": 0.08582834331337326,
        "f1": 0.03753832403023825,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.03753832403023825,
        "precision": 0.02942159629769401,
        "recall": 0.08582834331337326
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.06314469589742573,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.06314469589742573,
        "precision": 0.052364026291491055,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.37990685296074517,
        "f1": 0.3174541599930259,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3174541599930259,
        "precision": 0.29471110688675556,
        "recall": 0.37990685296074517
      },
      {
        "accuracy": 0.16966067864271456,
        "f1": 0.09788321005949688,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.09788321005949688,
        "precision": 0.0806527566228752,
        "recall": 0.16966067864271456
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.000491705542245962,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.000491705542245962,
        "precision": 0.0002693780705686482,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.4717232202262142,
        "f1": 0.39566053079027125,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.39566053079027125,
        "precision": 0.3661190439633554,
        "recall": 0.4717232202262142
      },
      {
        "accuracy": 0.20691949434464404,
        "f1": 0.12761158779122853,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.12761158779122853,
        "precision": 0.10536349751340823,
        "recall": 0.20691949434464404
      },
      {
        "accuracy": 0.3366600133067199,
        "f1": 0.24715166568870922,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.24715166568870922,
        "precision": 0.21717530547370867,
        "recall": 0.3366600133067199
      },
      {
        "accuracy": 0.27345309381237526,
        "f1": 0.20845648517147625,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.20845648517147625,
        "precision": 0.1860429933783227,
        "recall": 0.27345309381237526
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0005698574603207631,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0005698574603207631,
        "precision": 0.0003126397506127845,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.24683965402528277,
        "f1": 0.19230728611966139,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.19230728611966139,
        "precision": 0.17458782069560513,
        "recall": 0.24683965402528277
      },
      {
        "accuracy": 0.13972055888223553,
        "f1": 0.07937879730548263,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07937879730548263,
        "precision": 0.06461669014064224,
        "recall": 0.13972055888223553
      },
      {
        "accuracy": 0.1989354624085163,
        "f1": 0.11822499789042407,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11822499789042407,
        "precision": 0.09716679656212357,
        "recall": 0.1989354624085163
      },
      {
        "accuracy": 0.7052561543579507,
        "f1": 0.6557082084028192,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6557082084028192,
        "precision": 0.6342699424998242,
        "recall": 0.7052561543579507
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000311700528056138,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.000311700528056138,
        "precision": 0.00017050435221367642,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00022153276334728784,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.00022153276334728784,
        "precision": 0.00012161204132101048,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008361772531821892,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0008361772531821892,
        "precision": 0.0007559757286468529,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.130032156078536e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 6.130032156078536e-05,
        "precision": 3.170481620790616e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 2.7212106121771458e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.7212106121771458e-06,
        "precision": 1.3633934317158033e-06,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0002370198959371024,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0002370198959371024,
        "precision": 0.00014075529604347554,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 2.7156571211318858e-05,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 2.7156571211318858e-05,
        "precision": 1.3861166555777333e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 9.541720418887503e-06,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 9.541720418887503e-06,
        "precision": 4.783756643345986e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007430655268100718,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0007430655268100718,
        "precision": 0.0007053793647273356,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0002870495645685517,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0002870495645685517,
        "precision": 0.00015389292571769725,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00040752606209926867,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.00040752606209926867,
        "precision": 0.0002613823244131941,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0018951898544595312,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0018951898544595312,
        "precision": 0.0016797781034499188,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00029952682330553106,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.00029952682330553106,
        "precision": 0.000183183087769537,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00113487355889471,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.00113487355889471,
        "precision": 0.0009420304478245624,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 6.721750726957893e-05,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 6.721750726957893e-05,
        "precision": 3.428356669058364e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001106975834858488,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.001106975834858488,
        "precision": 0.0009136588201499783,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001969108702344414,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0001969108702344414,
        "precision": 0.000104208305509514,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.013105206842674699,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.013105206842674699,
        "precision": 0.011284392771418718,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00048289889670414485,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.00048289889670414485,
        "precision": 0.00035272584186556535,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0011626128746257422,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0011626128746257422,
        "precision": 0.0009730264987164852,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0001341872932025959,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0001341872932025959,
        "precision": 7.22394272181691e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009470011113782394,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0009470011113782394,
        "precision": 0.0008394898634702439,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.13639387890884896,
        "f1": 0.08842206437016817,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.08842206437016817,
        "precision": 0.07525502884784323,
        "recall": 0.13639387890884896
      },
      {
        "accuracy": 0.26413838988689287,
        "f1": 0.20056351942579487,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.20056351942579487,
        "precision": 0.17789634775662716,
        "recall": 0.26413838988689287
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.02119389961705331,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.02119389961705331,
        "precision": 0.017966607220857342,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.21490352628077178,
        "f1": 0.17659447819128457,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.17659447819128457,
        "precision": 0.1636378037575642,
        "recall": 0.21490352628077178
      },
      {
        "accuracy": 0.4810379241516966,
        "f1": 0.4323026138277987,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.4323026138277987,
        "precision": 0.41660720372076765,
        "recall": 0.4810379241516966
      },
      {
        "accuracy": 0.17298735861610112,
        "f1": 0.1437432974359122,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.1437432974359122,
        "precision": 0.13369672484131193,
        "recall": 0.17298735861610112
      },
      {
        "accuracy": 0.3260146373918829,
        "f1": 0.27705015825029666,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.27705015825029666,
        "precision": 0.2602004144668816,
        "recall": 0.3260146373918829
      },
      {
        "accuracy": 0.42248835662009315,
        "f1": 0.385497041790769,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.385497041790769,
        "precision": 0.37323156931876705,
        "recall": 0.42248835662009315
      },
      {
        "accuracy": 0.08982035928143713,
        "f1": 0.05268039415974445,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.05268039415974445,
        "precision": 0.04448689067490679,
        "recall": 0.08982035928143713
      },
      {
        "accuracy": 0.0771789753825682,
        "f1": 0.054595903098897114,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.054595903098897114,
        "precision": 0.048964236165154024,
        "recall": 0.0771789753825682
      },
      {
        "accuracy": 0.2721224218230206,
        "f1": 0.2353868218800346,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2353868218800346,
        "precision": 0.22245654438621446,
        "recall": 0.2721224218230206
      },
      {
        "accuracy": 0.14570858283433133,
        "f1": 0.0955157216076554,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0955157216076554,
        "precision": 0.08059829115218337,
        "recall": 0.14570858283433133
      },
      {
        "accuracy": 0.3958749168330007,
        "f1": 0.3532232627219482,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3532232627219482,
        "precision": 0.33870007576499517,
        "recall": 0.3958749168330007
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0015547080491461979,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0015547080491461979,
        "precision": 0.000978199321678766,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.19427811044577512,
        "f1": 0.1332200720365567,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.1332200720365567,
        "precision": 0.11484637771406338,
        "recall": 0.19427811044577512
      },
      {
        "accuracy": 0.2648037258815702,
        "f1": 0.20541397317844423,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.20541397317844423,
        "precision": 0.1860497767184394,
        "recall": 0.2648037258815702
      },
      {
        "accuracy": 0.23087159015302727,
        "f1": 0.18449921945430928,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.18449921945430928,
        "precision": 0.16887740136726037,
        "recall": 0.23087159015302727
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008962636648441509,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008962636648441509,
        "precision": 0.0005092862832203428,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.1643379906852961,
        "f1": 0.13188783568025084,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.13188783568025084,
        "precision": 0.12219100019658323,
        "recall": 0.1643379906852961
      },
      {
        "accuracy": 0.12242182302062542,
        "f1": 0.07773989759430643,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07773989759430643,
        "precision": 0.06564428862333054,
        "recall": 0.12242182302062542
      },
      {
        "accuracy": 0.18562874251497005,
        "f1": 0.1245276740228014,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1245276740228014,
        "precision": 0.1072857993267175,
        "recall": 0.18562874251497005
      },
      {
        "accuracy": 0.4078509647371923,
        "f1": 0.3705647891217927,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.3705647891217927,
        "precision": 0.3577369350635318,
        "recall": 0.4078509647371923
      },
      {
        "accuracy": 0.13040585495675316,
        "f1": 0.09941062116710819,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.09941062116710819,
        "precision": 0.08986287424411178,
        "recall": 0.13040585495675316
      },
      {
        "accuracy": 0.18363273453093812,
        "f1": 0.15135098139090156,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.15135098139090156,
        "precision": 0.14065341748211302,
        "recall": 0.18363273453093812
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004200250561074802,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.004200250561074802,
        "precision": 0.0031789365457513034,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.04507132748863573,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.04507132748863573,
        "precision": 0.042763511842536024,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.17897538256819695,
        "f1": 0.15325807088217228,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.15325807088217228,
        "precision": 0.1458774459555506,
        "recall": 0.17897538256819695
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.038246533579397266,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.038246533579397266,
        "precision": 0.03603159241881797,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.13439787092481703,
        "f1": 0.11311994804851197,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.11311994804851197,
        "precision": 0.1075480434759893,
        "recall": 0.13439787092481703
      },
      {
        "accuracy": 0.15768463073852296,
        "f1": 0.13995039975842022,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.13995039975842022,
        "precision": 0.13421949783801454,
        "recall": 0.15768463073852296
      },
      {
        "accuracy": 0.10179640718562874,
        "f1": 0.07407381005185397,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.07407381005185397,
        "precision": 0.06520847933023581,
        "recall": 0.10179640718562874
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01771877490440365,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.01771877490440365,
        "precision": 0.01627391604001851,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.0591629858847208,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0591629858847208,
        "precision": 0.05589106502857981,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.1264138389886893,
        "f1": 0.09363156303687006,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.09363156303687006,
        "precision": 0.08372779974901817,
        "recall": 0.1264138389886893
      },
      {
        "accuracy": 0.1383898868928809,
        "f1": 0.12194894299979962,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.12194894299979962,
        "precision": 0.1177823876833945,
        "recall": 0.1383898868928809
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.003978592292872823,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.003978592292872823,
        "precision": 0.003181090710318029,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.13639387890884896,
        "f1": 0.1156484562883862,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.1156484562883862,
        "precision": 0.10988257660350458,
        "recall": 0.13639387890884896
      },
      {
        "accuracy": 0.19095143047238855,
        "f1": 0.15678545031931285,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.15678545031931285,
        "precision": 0.14577265034771075,
        "recall": 0.19095143047238855
      },
      {
        "accuracy": 0.059214903526280775,
        "f1": 0.045872948667359845,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.045872948667359845,
        "precision": 0.04222959062635959,
        "recall": 0.059214903526280775
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0023507251160332096,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0023507251160332096,
        "precision": 0.0019364846241680185,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.022757265889296198,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.022757265889296198,
        "precision": 0.021314326134200937,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.11310711909514305,
        "f1": 0.08593957910976048,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.08593957910976048,
        "precision": 0.0772324758851705,
        "recall": 0.11310711909514305
      },
      {
        "accuracy": 0.16766467065868262,
        "f1": 0.13113382601003104,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.13113382601003104,
        "precision": 0.1200869765132544,
        "recall": 0.16766467065868262
      },
      {
        "accuracy": 0.14437791084497673,
        "f1": 0.12867157628671666,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.12867157628671666,
        "precision": 0.12409398321254808,
        "recall": 0.14437791084497673
      },
      {
        "accuracy": 0.12242182302062542,
        "f1": 0.08614575580056384,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.08614575580056384,
        "precision": 0.07560958142001938,
        "recall": 0.12242182302062542
      },
      {
        "accuracy": 0.21423819028609448,
        "f1": 0.1633253977007646,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.1633253977007646,
        "precision": 0.14591863651244888,
        "recall": 0.21423819028609448
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.011544009402030014,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.011544009402030014,
        "precision": 0.010385919354514671,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.1111111111111111,
        "f1": 0.08614575450352774,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.08614575450352774,
        "precision": 0.07864648807625554,
        "recall": 0.1111111111111111
      },
      {
        "accuracy": 0.33399866932801064,
        "f1": 0.29527878862794016,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.29527878862794016,
        "precision": 0.28224465652906644,
        "recall": 0.33399866932801064
      },
      {
        "accuracy": 0.08782435129740519,
        "f1": 0.07083006874215532,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.07083006874215532,
        "precision": 0.06522794681743355,
        "recall": 0.08782435129740519
      },
      {
        "accuracy": 0.26413838988689287,
        "f1": 0.2257591637402474,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.2257591637402474,
        "precision": 0.21251576713468423,
        "recall": 0.26413838988689287
      },
      {
        "accuracy": 0.31869594145043245,
        "f1": 0.2884351560447761,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.2884351560447761,
        "precision": 0.2778878315943918,
        "recall": 0.31869594145043245
      },
      {
        "accuracy": 0.09181636726546906,
        "f1": 0.058128754572667314,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.058128754572667314,
        "precision": 0.04889777950861665,
        "recall": 0.09181636726546906
      },
      {
        "accuracy": 0.046573519627411845,
        "f1": 0.031179867890168217,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.031179867890168217,
        "precision": 0.027646408213240648,
        "recall": 0.046573519627411845
      },
      {
        "accuracy": 0.1330671989354624,
        "f1": 0.11264049885350971,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.11264049885350971,
        "precision": 0.10651139326715005,
        "recall": 0.1330671989354624
      },
      {
        "accuracy": 0.11709913506320692,
        "f1": 0.08231213692259755,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.08231213692259755,
        "precision": 0.07243813516268606,
        "recall": 0.11709913506320692
      },
      {
        "accuracy": 0.2774451097804391,
        "f1": 0.24890743604981796,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.24890743604981796,
        "precision": 0.23927792435351783,
        "recall": 0.2774451097804391
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.002486124437501198,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.002486124437501198,
        "precision": 0.0018653447448436884,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.2268795741849634,
        "f1": 0.18818432715934222,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.18818432715934222,
        "precision": 0.17535794494817622,
        "recall": 0.2268795741849634
      },
      {
        "accuracy": 0.2162341982701264,
        "f1": 0.16644712442528573,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.16644712442528573,
        "precision": 0.1490707737963227,
        "recall": 0.2162341982701264
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.0831129675173935,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0831129675173935,
        "precision": 0.07570370387032072,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007675365958799092,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0007675365958799092,
        "precision": 0.0005188121793620474,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.07784431137724551,
        "f1": 0.05870733430376049,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.05870733430376049,
        "precision": 0.054062508282167604,
        "recall": 0.07784431137724551
      },
      {
        "accuracy": 0.11310711909514305,
        "f1": 0.07141616039310845,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.07141616039310845,
        "precision": 0.06021901258270625,
        "recall": 0.11310711909514305
      },
      {
        "accuracy": 0.15701929474384566,
        "f1": 0.1104761312962759,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.1104761312962759,
        "precision": 0.09692607606779262,
        "recall": 0.15701929474384566
      },
      {
        "accuracy": 0.3120425815036593,
        "f1": 0.28114232282740903,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.28114232282740903,
        "precision": 0.27075418204038154,
        "recall": 0.3120425815036593
      },
      {
        "accuracy": 0.07451763140385895,
        "f1": 0.045871552857580794,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.045871552857580794,
        "precision": 0.03818318149655476,
        "recall": 0.07451763140385895
      },
      {
        "accuracy": 0.11510312707917499,
        "f1": 0.08349134286670978,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.08349134286670978,
        "precision": 0.07372066371567369,
        "recall": 0.11510312707917499
      },
      {
        "accuracy": 0.02927478376580173,
        "f1": 0.01930741691220733,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.01930741691220733,
        "precision": 0.016656479311561303,
        "recall": 0.02927478376580173
      },
      {
        "accuracy": 0.1277445109780439,
        "f1": 0.10086485555547431,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.10086485555547431,
        "precision": 0.0932236056986556,
        "recall": 0.1277445109780439
      },
      {
        "accuracy": 0.24550898203592814,
        "f1": 0.2045880901336656,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.2045880901336656,
        "precision": 0.1914523726912946,
        "recall": 0.24550898203592814
      },
      {
        "accuracy": 0.1051230871590153,
        "f1": 0.08412331352704476,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08412331352704476,
        "precision": 0.07809575192309723,
        "recall": 0.1051230871590153
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.14278962278925839,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.14278962278925839,
        "precision": 0.13493466283806657,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.2268795741849634,
        "f1": 0.1953653779465687,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1953653779465687,
        "precision": 0.18621747351625056,
        "recall": 0.2268795741849634
      },
      {
        "accuracy": 0.049234863606121095,
        "f1": 0.023691646040312552,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.023691646040312552,
        "precision": 0.018328266140003616,
        "recall": 0.049234863606121095
      },
      {
        "accuracy": 0.0552228875582169,
        "f1": 0.037595609520181435,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.037595609520181435,
        "precision": 0.03290737560618851,
        "recall": 0.0552228875582169
      },
      {
        "accuracy": 0.18097139055222888,
        "f1": 0.15299900961404042,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.15299900961404042,
        "precision": 0.14519528301963433,
        "recall": 0.18097139055222888
      },
      {
        "accuracy": 0.08117099135063206,
        "f1": 0.048908714926678996,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.048908714926678996,
        "precision": 0.0407521010814424,
        "recall": 0.08117099135063206
      },
      {
        "accuracy": 0.21756487025948104,
        "f1": 0.18421641168799027,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.18421641168799027,
        "precision": 0.1739988922742463,
        "recall": 0.21756487025948104
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0016752499968088767,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0016752499968088767,
        "precision": 0.001326685217432361,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.21956087824351297,
        "f1": 0.18121324229108662,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.18121324229108662,
        "precision": 0.1680267249311769,
        "recall": 0.21956087824351297
      },
      {
        "accuracy": 0.09181636726546906,
        "f1": 0.06012825239372145,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.06012825239372145,
        "precision": 0.051267042634308105,
        "recall": 0.09181636726546906
      },
      {
        "accuracy": 0.11443779108449767,
        "f1": 0.08250102082437412,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.08250102082437412,
        "precision": 0.07278411657007407,
        "recall": 0.11443779108449767
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0022051135823590914,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0022051135823590914,
        "precision": 0.0017150883418348489,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.10113107119095142,
        "f1": 0.073587183866625,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.073587183866625,
        "precision": 0.06559198143854916,
        "recall": 0.10113107119095142
      },
      {
        "accuracy": 0.07252162341982701,
        "f1": 0.044183410718761064,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.044183410718761064,
        "precision": 0.03745712039125213,
        "recall": 0.07252162341982701
      },
      {
        "accuracy": 0.09048569527611444,
        "f1": 0.06074196795248969,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.06074196795248969,
        "precision": 0.05278840144109605,
        "recall": 0.09048569527611444
      },
      {
        "accuracy": 0.20891550232867598,
        "f1": 0.17530816140669783,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.17530816140669783,
        "precision": 0.16496373409228426,
        "recall": 0.20891550232867598
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0010560840152596437,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0010560840152596437,
        "precision": 0.0008710241784806004,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007338475618921135,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0007338475618921135,
        "precision": 0.0007007456676069177,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 5.079284615450379e-05,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 5.079284615450379e-05,
        "precision": 2.6345051391439887e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00013302224403799104,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.00013302224403799104,
        "precision": 6.952201876725998e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 3.65569227844677e-06,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 3.65569227844677e-06,
        "precision": 1.8328815280366723e-06,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0003874909757725407,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0003874909757725407,
        "precision": 0.00024983904111494046,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 7.536414585017607e-05,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 7.536414585017607e-05,
        "precision": 3.911369180830259e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 1.3454680733027268e-05,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 1.3454680733027268e-05,
        "precision": 6.756855670528875e-06,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00013660450385236578,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.00013660450385236578,
        "precision": 7.03876409702971e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.00011088933244621867,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.00011088933244621867,
        "precision": 6.048509042521019e-05,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0005110434503616644,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0005110434503616644,
        "precision": 0.00031730326584743826,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 8.820742353676485e-05,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 8.820742353676485e-05,
        "precision": 4.583875140633963e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 2.6493613695204923e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 2.6493613695204923e-05,
        "precision": 1.3333765926764113e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.014250969175330976,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.014250969175330976,
        "precision": 0.012264163983079092,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.00021744471524157437,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.00021744471524157437,
        "precision": 0.00012148827850757325,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007591477575005319,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0007591477575005319,
        "precision": 0.0007133592155273615,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.00017106750484501606,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.00017106750484501606,
        "precision": 8.84708937852933e-05,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0004186202856868297,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0004186202856868297,
        "precision": 0.00026599499993019645,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 7.908579384249003e-05,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 7.908579384249003e-05,
        "precision": 4.0502212906520904e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0007577613393789717,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0007577613393789717,
        "precision": 0.0005019578726815416,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0002549019435961664,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0002549019435961664,
        "precision": 0.00013817018166025437,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.00045041646375062013,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.00045041646375062013,
        "precision": 0.0003361153340986421,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.025808546816530848,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.025808546816530848,
        "precision": 0.021214798943551962,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.09381237524950099,
        "f1": 0.06898350965217233,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.06898350965217233,
        "precision": 0.06098750809329651,
        "recall": 0.09381237524950099
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.0338766910623198,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.0338766910623198,
        "precision": 0.029907116982965283,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.21224218230206254,
        "f1": 0.17879901572516343,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.17879901572516343,
        "precision": 0.16743725025582362,
        "recall": 0.21224218230206254
      },
      {
        "accuracy": 0.23419827012641384,
        "f1": 0.1962236266841866,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.1962236266841866,
        "precision": 0.18505080095561607,
        "recall": 0.23419827012641384
      },
      {
        "accuracy": 0.14038589487691283,
        "f1": 0.11569656779237616,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.11569656779237616,
        "precision": 0.10775274847131135,
        "recall": 0.14038589487691283
      },
      {
        "accuracy": 0.15236194278110446,
        "f1": 0.12064338944735677,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.12064338944735677,
        "precision": 0.11025404070950907,
        "recall": 0.15236194278110446
      },
      {
        "accuracy": 0.24151696606786427,
        "f1": 0.20624239447468284,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.20624239447468284,
        "precision": 0.1955542584033748,
        "recall": 0.24151696606786427
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.017087614093602117,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.017087614093602117,
        "precision": 0.013284673390840067,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.08449767132401863,
        "f1": 0.05773423368233747,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.05773423368233747,
        "precision": 0.05022255411476968,
        "recall": 0.08449767132401863
      },
      {
        "accuracy": 0.18363273453093812,
        "f1": 0.15562102900426253,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.15562102900426253,
        "precision": 0.14586382789975602,
        "recall": 0.18363273453093812
      },
      {
        "accuracy": 0.06719893546240852,
        "f1": 0.043955237146466625,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.043955237146466625,
        "precision": 0.03778851010040804,
        "recall": 0.06719893546240852
      },
      {
        "accuracy": 0.1996007984031936,
        "f1": 0.1648764676818622,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.1648764676818622,
        "precision": 0.1542121839997181,
        "recall": 0.1996007984031936
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0004991473114051487,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0004991473114051487,
        "precision": 0.0002915312910127297,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.15236194278110446,
        "f1": 0.12121483767603294,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12121483767603294,
        "precision": 0.11078018326022318,
        "recall": 0.15236194278110446
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.03158374196140768,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.03158374196140768,
        "precision": 0.025465454557270926,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.09780439121756487,
        "f1": 0.07038008532844947,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.07038008532844947,
        "precision": 0.0625033430343862,
        "recall": 0.09780439121756487
      },
      {
        "accuracy": 0.10711909514304724,
        "f1": 0.08312688272768112,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.08312688272768112,
        "precision": 0.07554413317886371,
        "recall": 0.10711909514304724
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0004913176529882843,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0004913176529882843,
        "precision": 0.00030735580837087923,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.032719544446091355,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.032719544446091355,
        "precision": 0.02760218638462151,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.07518296739853626,
        "f1": 0.047844565603166044,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.047844565603166044,
        "precision": 0.04097363384709745,
        "recall": 0.07518296739853626
      },
      {
        "accuracy": 0.20093147039254824,
        "f1": 0.17316849588814429,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.17316849588814429,
        "precision": 0.16460011971735306,
        "recall": 0.20093147039254824
      },
      {
        "accuracy": 0.07917498336660013,
        "f1": 0.05772646441309116,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.05772646441309116,
        "precision": 0.05177623007213825,
        "recall": 0.07917498336660013
      },
      {
        "accuracy": 0.11177644710578842,
        "f1": 0.09024190487107349,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.09024190487107349,
        "precision": 0.08270671259693216,
        "recall": 0.11177644710578842
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.008922860070307969,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.008922860070307969,
        "precision": 0.008086056869070078,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.030509591687236395,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.030509591687236395,
        "precision": 0.02849818833847705,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.10778443113772455,
        "f1": 0.08978811395015851,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.08978811395015851,
        "precision": 0.08511537224198269,
        "recall": 0.10778443113772455
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.02279975634302178,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.02279975634302178,
        "precision": 0.021669429668283755,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.07318695941450433,
        "f1": 0.05836223170627587,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.05836223170627587,
        "precision": 0.05449876867042536,
        "recall": 0.07318695941450433
      },
      {
        "accuracy": 0.08848968729208251,
        "f1": 0.07905926678459602,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.07905926678459602,
        "precision": 0.07604603023682877,
        "recall": 0.08848968729208251
      },
      {
        "accuracy": 0.12441783100465735,
        "f1": 0.08883459631962624,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.08883459631962624,
        "precision": 0.07779595469216229,
        "recall": 0.12441783100465735
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.016604863174263074,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.016604863174263074,
        "precision": 0.015260640335490636,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.03592814371257485,
        "f1": 0.028304952157494418,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.028304952157494418,
        "precision": 0.026414087944642946,
        "recall": 0.03592814371257485
      },
      {
        "accuracy": 0.1437125748502994,
        "f1": 0.11458331671124475,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.11458331671124475,
        "precision": 0.10587284795119127,
        "recall": 0.1437125748502994
      },
      {
        "accuracy": 0.06054557551563539,
        "f1": 0.052075719642391056,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.052075719642391056,
        "precision": 0.0499524576458943,
        "recall": 0.06054557551563539
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.00355081730502878,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.00355081730502878,
        "precision": 0.002654773864792851,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.07119095143047238,
        "f1": 0.057088525401336576,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.057088525401336576,
        "precision": 0.053195816344518934,
        "recall": 0.07119095143047238
      },
      {
        "accuracy": 0.12042581503659348,
        "f1": 0.09277550536584193,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.09277550536584193,
        "precision": 0.08427122638405954,
        "recall": 0.12042581503659348
      },
      {
        "accuracy": 0.10578842315369262,
        "f1": 0.08108843363334381,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.08108843363334381,
        "precision": 0.07345182404697521,
        "recall": 0.10578842315369262
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.034507970433730856,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.034507970433730856,
        "precision": 0.03294713956810816,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0026377593583279822,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0026377593583279822,
        "precision": 0.0021761328790479632,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.01680235251915421,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.01680235251915421,
        "precision": 0.0154960150495359,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.20226214238190285,
        "f1": 0.1616394195735513,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.1616394195735513,
        "precision": 0.14832134672454034,
        "recall": 0.20226214238190285
      },
      {
        "accuracy": 0.0718562874251497,
        "f1": 0.06094828522610529,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.06094828522610529,
        "precision": 0.057949695033056074,
        "recall": 0.0718562874251497
      },
      {
        "accuracy": 0.10113107119095142,
        "f1": 0.07122698781584907,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.07122698781584907,
        "precision": 0.06276297482161616,
        "recall": 0.10113107119095142
      },
      {
        "accuracy": 0.16899534264803726,
        "f1": 0.14041150503226352,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.14041150503226352,
        "precision": 0.1304054409937945,
        "recall": 0.16899534264803726
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.006303818296382464,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.006303818296382464,
        "precision": 0.006179873818704644,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04959410746939545,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.04959410746939545,
        "precision": 0.046513498361950324,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.1823020625415835,
        "f1": 0.161190404553678,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.161190404553678,
        "precision": 0.15557681196874976,
        "recall": 0.1823020625415835
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.0361425269533748,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.0361425269533748,
        "precision": 0.03390523735160132,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.11776447105788423,
        "f1": 0.09656276376169921,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.09656276376169921,
        "precision": 0.09095493639344872,
        "recall": 0.11776447105788423
      },
      {
        "accuracy": 0.1317365269461078,
        "f1": 0.11639850304469385,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.11639850304469385,
        "precision": 0.11192601645932157,
        "recall": 0.1317365269461078
      },
      {
        "accuracy": 0.1709913506320692,
        "f1": 0.13368918248159764,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.13368918248159764,
        "precision": 0.12132794010229615,
        "recall": 0.1709913506320692
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.02173378111501864,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.02173378111501864,
        "precision": 0.019746668648864256,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.05544481142283779,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.05544481142283779,
        "precision": 0.05375908763242077,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.23952095808383234,
        "f1": 0.19825583598038687,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.19825583598038687,
        "precision": 0.18423655334832978,
        "recall": 0.23952095808383234
      },
      {
        "accuracy": 0.10113107119095142,
        "f1": 0.08691923130139721,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.08691923130139721,
        "precision": 0.08354816500609026,
        "recall": 0.10113107119095142
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0015844716042808283,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0015844716042808283,
        "precision": 0.0012609149523699786,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.11842980705256155,
        "f1": 0.09591832642138082,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.09591832642138082,
        "precision": 0.08958076522305561,
        "recall": 0.11842980705256155
      },
      {
        "accuracy": 0.19028609447771125,
        "f1": 0.1473679412551668,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.1473679412551668,
        "precision": 0.13376832458735854,
        "recall": 0.19028609447771125
      },
      {
        "accuracy": 0.14637391882900866,
        "f1": 0.12012396716033077,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.12012396716033077,
        "precision": 0.11243547568023922,
        "recall": 0.14637391882900866
      },
      {
        "accuracy": 0.05588822355289421,
        "f1": 0.04526959327358529,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.04526959327358529,
        "precision": 0.04295834025812666,
        "recall": 0.05588822355289421
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.000589909616137603,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.000589909616137603,
        "precision": 0.0003616574370899055,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.029890782362452843,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.029890782362452843,
        "precision": 0.028122819106311057,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.2275449101796407,
        "f1": 0.18858631942464277,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.18858631942464277,
        "precision": 0.17403394269661737,
        "recall": 0.2275449101796407
      },
      {
        "accuracy": 0.10978043912175649,
        "f1": 0.09814205233921036,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.09814205233921036,
        "precision": 0.09555072958112239,
        "recall": 0.10978043912175649
      },
      {
        "accuracy": 0.1383898868928809,
        "f1": 0.07288816673870095,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.07288816673870095,
        "precision": 0.05897585506018577,
        "recall": 0.1383898868928809
      },
      {
        "accuracy": 0.2860944777112442,
        "f1": 0.1961272888418597,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.1961272888418597,
        "precision": 0.16914320247653583,
        "recall": 0.2860944777112442
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.027907755300029573,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.027907755300029573,
        "precision": 0.02368337177718415,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.34464404524284764,
        "f1": 0.27295356377192703,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.27295356377192703,
        "precision": 0.24859386316178614,
        "recall": 0.34464404524284764
      },
      {
        "accuracy": 0.8483033932135728,
        "f1": 0.8117875360390331,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8117875360390331,
        "precision": 0.7953157177708076,
        "recall": 0.8483033932135728
      },
      {
        "accuracy": 0.2541583499667332,
        "f1": 0.1955544124946497,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.1955544124946497,
        "precision": 0.17632626635541856,
        "recall": 0.2541583499667332
      },
      {
        "accuracy": 0.6227544910179641,
        "f1": 0.5485061622786174,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5485061622786174,
        "precision": 0.5177454614580363,
        "recall": 0.6227544910179641
      },
      {
        "accuracy": 0.8150365934797072,
        "f1": 0.773430915945886,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.773430915945886,
        "precision": 0.7551230871590153,
        "recall": 0.8150365934797072
      },
      {
        "accuracy": 0.08183632734530938,
        "f1": 0.030255704338951226,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.030255704338951226,
        "precision": 0.02240694017482257,
        "recall": 0.08183632734530938
      },
      {
        "accuracy": 0.1543579507651364,
        "f1": 0.10052254208431019,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.10052254208431019,
        "precision": 0.08704844731497308,
        "recall": 0.1543579507651364
      },
      {
        "accuracy": 0.3958749168330007,
        "f1": 0.32641067072204794,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.32641067072204794,
        "precision": 0.30163112927583985,
        "recall": 0.3958749168330007
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.10073672415655116,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.10073672415655116,
        "precision": 0.08408588906299368,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.7065868263473054,
        "f1": 0.6448341412413269,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.6448341412413269,
        "precision": 0.6175537813262365,
        "recall": 0.7065868263473054
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0012306584897846485,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0012306584897846485,
        "precision": 0.0009729130185471761,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.4763805721889554,
        "f1": 0.3836902913749221,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.3836902913749221,
        "precision": 0.34886180020910557,
        "recall": 0.4763805721889554
      },
      {
        "accuracy": 0.22022621423819028,
        "f1": 0.13437095966449025,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.13437095966449025,
        "precision": 0.11130161541544659,
        "recall": 0.22022621423819028
      },
      {
        "accuracy": 0.37059214903526283,
        "f1": 0.2731995512434634,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.2731995512434634,
        "precision": 0.24130001180899385,
        "recall": 0.37059214903526283
      },
      {
        "accuracy": 0.26147704590818366,
        "f1": 0.19297045639361007,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.19297045639361007,
        "precision": 0.1707862053670437,
        "recall": 0.26147704590818366
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00036139765504565315,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00036139765504565315,
        "precision": 0.00019442053957623707,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.25615435795076513,
        "f1": 0.1929575340752985,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.1929575340752985,
        "precision": 0.1725548329839747,
        "recall": 0.25615435795076513
      },
      {
        "accuracy": 0.14504324683965403,
        "f1": 0.0773439996963538,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.0773439996963538,
        "precision": 0.06141802525438051,
        "recall": 0.14504324683965403
      },
      {
        "accuracy": 0.2055888223552894,
        "f1": 0.12132414705739286,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.12132414705739286,
        "precision": 0.10037766716908435,
        "recall": 0.2055888223552894
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}