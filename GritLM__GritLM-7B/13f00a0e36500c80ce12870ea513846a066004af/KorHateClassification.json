{
  "dataset_revision": "bd1a7370caf712125fac1fda375834ca8ddefaca",
  "evaluation_time": 32.805469036102295,
  "kg_co2_emissions": 0.007197130667910869,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.439306640625,
        "f1": 0.426650503784339,
        "f1_weighted": 0.4378174326658004,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.439306640625,
        "scores_per_experiment": [
          {
            "accuracy": 0.455078125,
            "f1": 0.4200629898675669,
            "f1_weighted": 0.44483243581735143
          },
          {
            "accuracy": 0.4365234375,
            "f1": 0.40758640578092403,
            "f1_weighted": 0.42890474019843544
          },
          {
            "accuracy": 0.44189453125,
            "f1": 0.4393693975285698,
            "f1_weighted": 0.4481891281680801
          },
          {
            "accuracy": 0.42529296875,
            "f1": 0.4186905154198554,
            "f1_weighted": 0.4298105382911479
          },
          {
            "accuracy": 0.4794921875,
            "f1": 0.45570763191265623,
            "f1_weighted": 0.47633668733690104
          },
          {
            "accuracy": 0.3447265625,
            "f1": 0.34199762177209864,
            "f1_weighted": 0.3287706354895591
          },
          {
            "accuracy": 0.50341796875,
            "f1": 0.4890430054571353,
            "f1_weighted": 0.508336938100875
          },
          {
            "accuracy": 0.4248046875,
            "f1": 0.42213568150521635,
            "f1_weighted": 0.4239077131681651
          },
          {
            "accuracy": 0.458984375,
            "f1": 0.44506241985186995,
            "f1_weighted": 0.46446620333269073
          },
          {
            "accuracy": 0.4228515625,
            "f1": 0.4268493687474977,
            "f1_weighted": 0.42461930675479803
          }
        ]
      }
    ]
  },
  "task_name": "KorHateClassification"
}