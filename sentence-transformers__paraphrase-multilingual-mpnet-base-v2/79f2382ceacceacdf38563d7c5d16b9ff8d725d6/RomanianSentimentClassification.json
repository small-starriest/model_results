{
  "dataset_revision": "155048684cea7a6d6af1ddbfeb9a04820311ce93",
  "evaluation_time": 11.121857404708862,
  "kg_co2_emissions": 0.0017618944618813484,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.677392578125,
        "ap": 0.6999553942040542,
        "ap_weighted": 0.6999553942040542,
        "f1": 0.6714291637991071,
        "f1_weighted": 0.6698723884067137,
        "hf_subset": "default",
        "languages": [
          "ron-Latn"
        ],
        "main_score": 0.677392578125,
        "scores_per_experiment": [
          {
            "accuracy": 0.71630859375,
            "ap": 0.7299410779517703,
            "ap_weighted": 0.7299410779517703,
            "f1": 0.7161591042187737,
            "f1_weighted": 0.7153575858811347
          },
          {
            "accuracy": 0.7353515625,
            "ap": 0.7758350843655207,
            "ap_weighted": 0.7758350843655207,
            "f1": 0.7325394125204447,
            "f1_weighted": 0.7291648325449785
          },
          {
            "accuracy": 0.6162109375,
            "ap": 0.6863997448495955,
            "ap_weighted": 0.6863997448495955,
            "f1": 0.5950655048197863,
            "f1_weighted": 0.5836795026073636
          },
          {
            "accuracy": 0.73779296875,
            "ap": 0.7397889951415464,
            "ap_weighted": 0.7397889951415464,
            "f1": 0.7376663146703738,
            "f1_weighted": 0.7383755775162806
          },
          {
            "accuracy": 0.62939453125,
            "ap": 0.6637897086448206,
            "ap_weighted": 0.6637897086448206,
            "f1": 0.6262787200357749,
            "f1_weighted": 0.6220798728379957
          },
          {
            "accuracy": 0.6796875,
            "ap": 0.7312859167226954,
            "ap_weighted": 0.7312859167226954,
            "f1": 0.6718756716412078,
            "f1_weighted": 0.6656459857348292
          },
          {
            "accuracy": 0.60009765625,
            "ap": 0.6319242589537545,
            "ap_weighted": 0.6319242589537545,
            "f1": 0.5994711232279536,
            "f1_weighted": 0.5975219093815869
          },
          {
            "accuracy": 0.638671875,
            "ap": 0.6626428795023445,
            "ap_weighted": 0.6626428795023445,
            "f1": 0.6380916901886053,
            "f1_weighted": 0.6363086832072462
          },
          {
            "accuracy": 0.72216796875,
            "ap": 0.7093121433885844,
            "ap_weighted": 0.7093121433885844,
            "f1": 0.7193560451983116,
            "f1_weighted": 0.7228126536618505
          },
          {
            "accuracy": 0.6982421875,
            "ap": 0.6686341325199096,
            "ap_weighted": 0.6686341325199096,
            "f1": 0.6777880514698396,
            "f1_weighted": 0.6877772806938713
          }
        ]
      }
    ]
  },
  "task_name": "RomanianSentimentClassification"
}