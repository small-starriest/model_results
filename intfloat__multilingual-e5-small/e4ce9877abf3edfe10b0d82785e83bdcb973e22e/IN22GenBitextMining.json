{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 17.97861933708191,
  "kg_co2_emissions": 0.002827909616068309,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.99609375,
        "f1": 0.9949544270833333,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9949544270833333,
        "precision": 0.9944661458333334,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.484375,
        "f1": 0.4299740532676388,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.4299740532676388,
        "precision": 0.4107616341991342,
        "recall": 0.484375
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9036458333333333,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9036458333333333,
        "precision": 0.8932291666666666,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9601888020833333,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9601888020833333,
        "precision": 0.9556477864583334,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8963216145833333,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8963216145833333,
        "precision": 0.8864908854166667,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8757161458333333,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.8757161458333333,
        "precision": 0.8633626302083333,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.99267578125,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.99267578125,
        "precision": 0.9920247395833334,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.014445217730671778,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.014445217730671778,
        "precision": 0.01169067206664863,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9912109375,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9912109375,
        "precision": 0.990234375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9560546875,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9560546875,
        "precision": 0.9508463541666667,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.008614736254795507,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.008614736254795507,
        "precision": 0.006290704052508969,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8116396949404762,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8116396949404762,
        "precision": 0.7959309895833333,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9876302083333333,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9876302083333333,
        "precision": 0.986328125,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9728190104166666,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9728190104166666,
        "precision": 0.9695638020833333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.4411553867522388,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.4411553867522388,
        "precision": 0.42534170513476005,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9282877604166666,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9282877604166666,
        "precision": 0.9208170572916667,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.9194010416666667,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.9194010416666667,
        "precision": 0.91162109375,
        "recall": 0.9365234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.863671875,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.863671875,
        "precision": 0.8496907552083333,
        "recall": 0.8935546875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.015538300133026694,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.015538300133026694,
        "precision": 0.012772110693372519,
        "recall": 0.0302734375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666666,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.9791666666666666,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.009925207316492931,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.009925207316492931,
        "precision": 0.007964720973701853,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8554524739583333,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8554524739583333,
        "precision": 0.842831566220238,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9951171875,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9951171875,
        "precision": 0.99462890625,
        "recall": 0.99609375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833333,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9871419270833333,
        "precision": 0.9856770833333333,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.3515625,
        "f1": 0.3176291300636177,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.3176291300636177,
        "precision": 0.30812528378793935,
        "recall": 0.3515625
      },
      {
        "accuracy": 0.3681640625,
        "f1": 0.33392885528595445,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.33392885528595445,
        "precision": 0.323891137978052,
        "recall": 0.3681640625
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.40178608767719826,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.40178608767719826,
        "precision": 0.388848472623892,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.2724609375,
        "f1": 0.25329562364718616,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.25329562364718616,
        "precision": 0.2473604183997397,
        "recall": 0.2724609375
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.3806853140349234,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3806853140349234,
        "precision": 0.3714205449007276,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.3154296875,
        "f1": 0.2887833823679634,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.2887833823679634,
        "precision": 0.282018923103649,
        "recall": 0.3154296875
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.3278135111458871,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3278135111458871,
        "precision": 0.32143793066072945,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.30078125,
        "f1": 0.27461017567775436,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.27461017567775436,
        "precision": 0.2675557555253672,
        "recall": 0.30078125
      },
      {
        "accuracy": 0.380859375,
        "f1": 0.3426709734556701,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3426709734556701,
        "precision": 0.3325791028626848,
        "recall": 0.380859375
      },
      {
        "accuracy": 0.36328125,
        "f1": 0.32681468918529066,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.32681468918529066,
        "precision": 0.31599148832374424,
        "recall": 0.36328125
      },
      {
        "accuracy": 0.345703125,
        "f1": 0.3210069037187503,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3210069037187503,
        "precision": 0.3134018121436187,
        "recall": 0.345703125
      },
      {
        "accuracy": 0.35546875,
        "f1": 0.3214280846147595,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3214280846147595,
        "precision": 0.31227284378782133,
        "recall": 0.35546875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.015325372793483272,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.015325372793483272,
        "precision": 0.013447304377480158,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.3798828125,
        "f1": 0.34253036709091395,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.34253036709091395,
        "precision": 0.33336087356318633,
        "recall": 0.3798828125
      },
      {
        "accuracy": 0.3447265625,
        "f1": 0.3095142540364885,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3095142540364885,
        "precision": 0.29972102667607914,
        "recall": 0.3447265625
      },
      {
        "accuracy": 0.328125,
        "f1": 0.30042612149007186,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.30042612149007186,
        "precision": 0.29322551852817436,
        "recall": 0.328125
      },
      {
        "accuracy": 0.4140625,
        "f1": 0.36033126295936496,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.36033126295936496,
        "precision": 0.34410295348302683,
        "recall": 0.4140625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.0072049307263449295,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0072049307263449295,
        "precision": 0.00555177154362268,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.42981068410755907,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.42981068410755907,
        "precision": 0.4140811615367398,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.3232421875,
        "f1": 0.29405629509025866,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.29405629509025866,
        "precision": 0.2852989619905571,
        "recall": 0.3232421875
      },
      {
        "accuracy": 0.3330078125,
        "f1": 0.31033107979180025,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.31033107979180025,
        "precision": 0.304443958751186,
        "recall": 0.3330078125
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.25926737007499057,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.25926737007499057,
        "precision": 0.2506453368663808,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.9033203125,
        "f1": 0.8837476325757576,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8837476325757576,
        "precision": 0.8758440290178571,
        "recall": 0.9033203125
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.9054998224431818,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9054998224431818,
        "precision": 0.8983077144209957,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.47392566201159947,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.47392566201159947,
        "precision": 0.45816402022456715,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8594815693204365,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8594815693204365,
        "precision": 0.8503445095486111,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8283040364583334,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8283040364583334,
        "precision": 0.8163178943452382,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.913090587797619,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.913090587797619,
        "precision": 0.9063096788194445,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9634588068181817,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9634588068181817,
        "precision": 0.960302734375,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8859197443181818,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8859197443181818,
        "precision": 0.8772569444444445,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7792364211309524,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7792364211309524,
        "precision": 0.764990234375,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9397786458333334,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9397786458333334,
        "precision": 0.9336263020833333,
        "recall": 0.953125
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8855508207070707,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8855508207070707,
        "precision": 0.8777587890625,
        "recall": 0.90625
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9173874627976191,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9173874627976191,
        "precision": 0.9098958333333333,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006970338147095958,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006970338147095958,
        "precision": 0.005880330869918991,
        "recall": 0.015625
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9273949032738095,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9273949032738095,
        "precision": 0.9211697048611112,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9216331845238095,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9216331845238095,
        "precision": 0.9143880208333334,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8792751736111111,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8792751736111111,
        "precision": 0.8708217075892857,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.86435546875,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.86435546875,
        "precision": 0.8520833333333333,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008461740275067707,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008461740275067707,
        "precision": 0.006164354424621315,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8147538442460317,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8147538442460317,
        "precision": 0.8022705078125,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8876222898195554,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8876222898195554,
        "precision": 0.8817313058035714,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8812445746527778,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8812445746527778,
        "precision": 0.8748896818433813,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.890625,
        "f1": 0.8682605561755953,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8682605561755953,
        "precision": 0.8599450842126624,
        "recall": 0.890625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166667,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9806315104166667,
        "precision": 0.9783528645833333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.427734375,
        "f1": 0.37598622297841044,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.37598622297841044,
        "precision": 0.360771469454259,
        "recall": 0.427734375
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9327473958333333,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9327473958333333,
        "precision": 0.9254557291666667,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8846540178571428,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8846540178571428,
        "precision": 0.8740234375,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8078636532738095,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.8078636532738095,
        "precision": 0.7901041666666667,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002070595561594203,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.002070595561594203,
        "precision": 0.001706518308080808,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833333,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9871419270833333,
        "precision": 0.9856770833333333,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.974609375,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.974609375,
        "precision": 0.9718424479166667,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9399088541666667,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9399088541666667,
        "precision": 0.9332682291666666,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0005297146953282064,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0005297146953282064,
        "precision": 0.000277790539657005,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.857421875,
        "f1": 0.8232770647321428,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.8232770647321428,
        "precision": 0.8088743179563491,
        "recall": 0.857421875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.875,
        "f1": 0.8500388229392135,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8500388229392135,
        "precision": 0.8407586960565476,
        "recall": 0.875
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8808326863354037,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8808326863354037,
        "precision": 0.8738399621212121,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.5205078125,
        "f1": 0.46885857740349923,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.46885857740349923,
        "precision": 0.44998065898944806,
        "recall": 0.5205078125
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.846484375,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.846484375,
        "precision": 0.8330403645833333,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.8251953125,
        "f1": 0.7916272933851058,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7916272933851058,
        "precision": 0.7786675347222222,
        "recall": 0.8251953125
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8758734809027777,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8758734809027777,
        "precision": 0.8663504464285714,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.9040396289908008,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9040396289908008,
        "precision": 0.8977143787202381,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8709178841991343,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8709178841991343,
        "precision": 0.861572265625,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.7666015625,
        "f1": 0.7244954427083333,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7244954427083333,
        "precision": 0.7073226686507936,
        "recall": 0.7666015625
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.9013695126488095,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9013695126488095,
        "precision": 0.8930757068452381,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8675618489583332,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8675618489583332,
        "precision": 0.8567313058035715,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9306640625,
        "f1": 0.9136579241071429,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9136579241071429,
        "precision": 0.9069986979166667,
        "recall": 0.9306640625
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.01820757013742997,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01820757013742997,
        "precision": 0.01588931030372158,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.9189453125,
        "f1": 0.89716796875,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.89716796875,
        "precision": 0.8878092447916667,
        "recall": 0.9189453125
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8833356097027971,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8833356097027971,
        "precision": 0.8744466145833333,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8556862019604037,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8556862019604037,
        "precision": 0.8468961377164502,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8377197265625,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8377197265625,
        "precision": 0.8256068638392856,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.008065679031255202,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008065679031255202,
        "precision": 0.006287143671499167,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.81640625,
        "f1": 0.7777018229166667,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7777018229166667,
        "precision": 0.7607259114583333,
        "recall": 0.81640625
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8635145399305555,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8635145399305555,
        "precision": 0.8542329334077381,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8541178385416666,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8541178385416666,
        "precision": 0.84486900313794,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8142655629960317,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8142655629960317,
        "precision": 0.8014970083085318,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.474609375,
        "f1": 0.4169189225169234,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.4169189225169234,
        "precision": 0.39804593278842865,
        "recall": 0.474609375
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9350260416666667,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.9350260416666667,
        "precision": 0.9280598958333334,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9782552083333333,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9782552083333333,
        "precision": 0.975830078125,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.924609375,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.924609375,
        "precision": 0.9161783854166667,
        "recall": 0.9423828125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8826171875,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.8826171875,
        "precision": 0.87060546875,
        "recall": 0.908203125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9977213541666666,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.9977213541666666,
        "precision": 0.99755859375,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.012570884317767178,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.012570884317767178,
        "precision": 0.011019401876335471,
        "recall": 0.021484375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9666341145833333,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.9666341145833333,
        "precision": 0.9627278645833333,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.011753909827241824,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.011753909827241824,
        "precision": 0.009442364728009259,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.873046875,
        "f1": 0.8409830729166666,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.8409830729166666,
        "precision": 0.8264322916666667,
        "recall": 0.873046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.5263671875,
        "f1": 0.4719826332521645,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4719826332521645,
        "precision": 0.45278982627615433,
        "recall": 0.5263671875
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9588216145833333,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9588216145833333,
        "precision": 0.9541015625,
        "recall": 0.96875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9462890625,
        "f1": 0.9296875,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9296875,
        "precision": 0.9215494791666667,
        "recall": 0.9462890625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8732096354166665,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8732096354166665,
        "precision": 0.8605143229166666,
        "recall": 0.900390625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666666,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666666,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.013294463581385503,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.013294463581385503,
        "precision": 0.01121557024661919,
        "recall": 0.025390625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833334,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.9793294270833334,
        "precision": 0.9768880208333334,
        "recall": 0.984375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0065629703778588375,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0065629703778588375,
        "precision": 0.004857389157390599,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8781575520833333,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8781575520833333,
        "precision": 0.866162109375,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.4521484375,
        "f1": 0.3946444920479847,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.3946444920479847,
        "precision": 0.3746796384382476,
        "recall": 0.4521484375
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.92470703125,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.92470703125,
        "precision": 0.9165852864583334,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9037760416666667,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.9037760416666667,
        "precision": 0.8944010416666666,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8634440104166667,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.8634440104166667,
        "precision": 0.84912109375,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.016862302449388845,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.016862302449388845,
        "precision": 0.01401462432654232,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9816080729166667,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9816080729166667,
        "precision": 0.9798177083333333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007969121807012432,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.007969121807012432,
        "precision": 0.005811373556542142,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8305989583333333,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.8305989583333333,
        "precision": 0.8160319010416667,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8464192708333333,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8464192708333333,
        "precision": 0.8338541666666666,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8491117931547618,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.8491117931547618,
        "precision": 0.8380316840277777,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.4423828125,
        "f1": 0.39453236992813473,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.39453236992813473,
        "precision": 0.3794472346230159,
        "recall": 0.4423828125
      },
      {
        "accuracy": 0.7958984375,
        "f1": 0.752099609375,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.752099609375,
        "precision": 0.7336681547619047,
        "recall": 0.7958984375
      },
      {
        "accuracy": 0.791015625,
        "f1": 0.7453931051587301,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7453931051587301,
        "precision": 0.7277150899422269,
        "recall": 0.791015625
      },
      {
        "accuracy": 0.755859375,
        "f1": 0.7118492266197345,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.7118492266197345,
        "precision": 0.694922297754329,
        "recall": 0.755859375
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.8536280776515152,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.8536280776515152,
        "precision": 0.8414062499999999,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.832080078125,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.832080078125,
        "precision": 0.8192224279626623,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.8701171875,
        "f1": 0.8410667782738095,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.8410667782738095,
        "precision": 0.8289271763392857,
        "recall": 0.8701171875
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8432779947916667,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8432779947916667,
        "precision": 0.8315848214285715,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.8740234375,
        "f1": 0.8465657552083332,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8465657552083332,
        "precision": 0.8352794828869048,
        "recall": 0.8740234375
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8610374813988095,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.8610374813988095,
        "precision": 0.8492117745535714,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.013500392977719742,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.013500392977719742,
        "precision": 0.011626113399723234,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8576915922619047,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.8576915922619047,
        "precision": 0.8466796875,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.849467540922619,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.849467540922619,
        "precision": 0.8376232328869048,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8095912388392857,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8095912388392857,
        "precision": 0.7965010737959957,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.8134765625,
        "f1": 0.7747531467013888,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7747531467013888,
        "precision": 0.7582763671875,
        "recall": 0.8134765625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.011849898132785312,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.011849898132785312,
        "precision": 0.009190583621992956,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.7353515625,
        "f1": 0.6902886284722222,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.6902886284722222,
        "precision": 0.6721218532986111,
        "recall": 0.7353515625
      },
      {
        "accuracy": 0.865234375,
        "f1": 0.8322126116071429,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8322126116071429,
        "precision": 0.8180989583333333,
        "recall": 0.865234375
      },
      {
        "accuracy": 0.865234375,
        "f1": 0.836407955109127,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.836407955109127,
        "precision": 0.8247670379750458,
        "recall": 0.865234375
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8356817336309523,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.8356817336309523,
        "precision": 0.8223055752840909,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.4921875,
        "f1": 0.44283855250652127,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.44283855250652127,
        "precision": 0.4259598529916774,
        "recall": 0.4921875
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9650065104166666,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9650065104166666,
        "precision": 0.96142578125,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833334,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9793294270833334,
        "precision": 0.9768880208333334,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.92177734375,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.92177734375,
        "precision": 0.9143391927083333,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.900390625,
        "f1": 0.8740234375,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8740234375,
        "precision": 0.8614908854166667,
        "recall": 0.900390625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.99755859375,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.99755859375,
        "precision": 0.9973958333333333,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.016014603669602476,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.016014603669602476,
        "precision": 0.014248765449237994,
        "recall": 0.0263671875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666667,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9820963541666667,
        "precision": 0.97998046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9758138020833333,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.9758138020833333,
        "precision": 0.9732259114583333,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.006880645128022472,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006880645128022472,
        "precision": 0.005153168243603071,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.890625,
        "f1": 0.862109375,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.862109375,
        "precision": 0.8489583333333333,
        "recall": 0.890625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9899088541666667,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.9899088541666667,
        "precision": 0.98876953125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.4474100525125916,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.4474100525125916,
        "precision": 0.4274525848500458,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9125000000000001,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.9125000000000001,
        "precision": 0.903564453125,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.90615234375,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.90615234375,
        "precision": 0.8960774739583334,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.87841796875,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.87841796875,
        "precision": 0.8660481770833334,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.014934666369049228,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.014934666369049228,
        "precision": 0.011552880755825862,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9689127604166667,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.9689127604166667,
        "precision": 0.9651692708333333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.004470033680169081,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004470033680169081,
        "precision": 0.00307254469521062,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8356956845238095,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.8356956845238095,
        "precision": 0.8206705729166667,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333334,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.9925130208333334,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833333,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.436560780799062,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.436560780799062,
        "precision": 0.41723516555059526,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9488932291666666,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9488932291666666,
        "precision": 0.9431966145833334,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166667,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9845377604166667,
        "precision": 0.9827473958333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9479817708333332,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9479817708333332,
        "precision": 0.9424641927083334,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8889973958333333,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8889973958333333,
        "precision": 0.876953125,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013114041199443868,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.013114041199443868,
        "precision": 0.010575925182382404,
        "recall": 0.02734375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9661458333333334,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.9661458333333334,
        "precision": 0.9625651041666667,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0041418575385966695,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0041418575385966695,
        "precision": 0.0024672756135500178,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.884765625,
        "f1": 0.8566266741071429,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8566266741071429,
        "precision": 0.8442220052083333,
        "recall": 0.884765625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666666,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9938151041666666,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833333,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9871419270833333,
        "precision": 0.9856770833333333,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005679418021761501,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.005679418021761501,
        "precision": 0.004629574407182274,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.007835640804305141,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.007835640804305141,
        "precision": 0.006698903595195655,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008967227542249222,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.008967227542249222,
        "precision": 0.00789635663639342,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004183098727743936,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.004183098727743936,
        "precision": 0.0036858995997451367,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0023664699528464653,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0023664699528464653,
        "precision": 0.001855453459600978,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007070743805069236,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.007070743805069236,
        "precision": 0.005978376487077147,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.002041140187261753,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.002041140187261753,
        "precision": 0.0012594300031082573,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.008315513483447355,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.008315513483447355,
        "precision": 0.006819623671921744,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0047424971800789865,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0047424971800789865,
        "precision": 0.003481555453002269,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.010658214811265066,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.010658214811265066,
        "precision": 0.009664756647731202,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008051586806420844,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.008051586806420844,
        "precision": 0.006969986010734876,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006612425886531905,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.006612425886531905,
        "precision": 0.0049965030037103335,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004323770365183301,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.004323770365183301,
        "precision": 0.0037478170211332727,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.005528449069124664,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.005528449069124664,
        "precision": 0.004651936690891809,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006495221038726997,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.006495221038726997,
        "precision": 0.005953211812897119,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004931211274005653,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.004931211274005653,
        "precision": 0.003956571686358638,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.007204595735947772,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.007204595735947772,
        "precision": 0.005447328102311967,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06631846004236225,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.06631846004236225,
        "precision": 0.05773383421878367,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006066778865319746,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.006066778865319746,
        "precision": 0.004959189370427352,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0062279146751803,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0062279146751803,
        "precision": 0.005195350442129685,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007018209807056248,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.007018209807056248,
        "precision": 0.006030662337044675,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007301499553487021,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.007301499553487021,
        "precision": 0.006724852466965822,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.509765625,
        "f1": 0.4534087386138167,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4534087386138167,
        "precision": 0.4341286046852453,
        "recall": 0.509765625
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9514973958333333,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9514973958333333,
        "precision": 0.9462890625,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833333,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9871419270833333,
        "precision": 0.9856770833333334,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9268880208333333,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9268880208333333,
        "precision": 0.9192708333333334,
        "recall": 0.943359375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.89013671875,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.89013671875,
        "precision": 0.8787434895833333,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.013505280478193719,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.013505280478193719,
        "precision": 0.011673737503815628,
        "recall": 0.0244140625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333333,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9807942708333333,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.006648672681043489,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006648672681043489,
        "precision": 0.004604471254012694,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.884765625,
        "f1": 0.8563151041666667,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8563151041666667,
        "precision": 0.8435384114583333,
        "recall": 0.884765625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9951171875,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9951171875,
        "precision": 0.99462890625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.474609375,
        "f1": 0.4169110817950432,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.4169110817950432,
        "precision": 0.3971235727705454,
        "recall": 0.474609375
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.9317057291666666,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.9317057291666666,
        "precision": 0.9247233072916666,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666666,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9820963541666666,
        "precision": 0.9801432291666667,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9326171875,
        "f1": 0.9136393229166666,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.9136393229166666,
        "precision": 0.905029296875,
        "recall": 0.9326171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8761067708333333,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.8761067708333333,
        "precision": 0.8639322916666667,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333333,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9925130208333333,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.015281282930337207,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.015281282930337207,
        "precision": 0.012817453271554834,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.97705078125,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.97705078125,
        "precision": 0.9744466145833334,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.009299935828028728,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.009299935828028728,
        "precision": 0.006972945132124819,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.8671875,
        "f1": 0.8349283854166667,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.8349283854166667,
        "precision": 0.8203450520833333,
        "recall": 0.8671875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9951171875,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.9951171875,
        "precision": 0.99462890625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9923502604166667,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9923502604166667,
        "precision": 0.9915364583333333,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166666,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.9767252604166666,
        "precision": 0.9739583333333333,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833333,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.4833984375,
        "f1": 0.4305237785218254,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.4305237785218254,
        "precision": 0.41335770387890214,
        "recall": 0.4833984375
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9024088541666666,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.9024088541666666,
        "precision": 0.8931477864583334,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9471028645833333,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9471028645833333,
        "precision": 0.94091796875,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8763020833333334,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.8763020833333334,
        "precision": 0.8653157552083334,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333334,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.9925130208333334,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8572265625,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.8572265625,
        "precision": 0.8439127604166667,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.97802734375,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.97802734375,
        "precision": 0.9754231770833333,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011364049785388984,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.011364049785388984,
        "precision": 0.009528874734527307,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9464518229166666,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.9464518229166666,
        "precision": 0.9404296875,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.0097961461888981,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0097961461888981,
        "precision": 0.008037668375696992,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8034830729166667,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.8034830729166667,
        "precision": 0.7864583333333334,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9837239583333333,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.9837239583333333,
        "precision": 0.98193359375,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166667,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.9806315104166667,
        "precision": 0.9783528645833333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.96875,
        "f1": 0.95888671875,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.95888671875,
        "precision": 0.9541829427083334,
        "recall": 0.96875
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9498697916666666,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9498697916666666,
        "precision": 0.9448567708333333,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.96533203125,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.96533203125,
        "precision": 0.9612630208333334,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.44420638497786935,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.44420638497786935,
        "precision": 0.4268361240730266,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.88671875,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.88671875,
        "precision": 0.8753255208333333,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8638423859126985,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8638423859126985,
        "precision": 0.8523755622632576,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.865234375,
        "f1": 0.83623046875,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.83623046875,
        "precision": 0.8235212053571428,
        "recall": 0.865234375
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9593098958333334,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9593098958333334,
        "precision": 0.9549153645833333,
        "recall": 0.96875
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9631184895833333,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9631184895833333,
        "precision": 0.959228515625,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9694010416666666,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9694010416666666,
        "precision": 0.9661458333333333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.7993815104166666,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7993815104166666,
        "precision": 0.7839192708333333,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9689127604166667,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9689127604166667,
        "precision": 0.9651692708333334,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9645833333333333,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9645833333333333,
        "precision": 0.9608561197916666,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9627278645833333,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9627278645833333,
        "precision": 0.95849609375,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.011869894609152422,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.011869894609152422,
        "precision": 0.009290139241885565,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166666,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9767252604166666,
        "precision": 0.9739583333333333,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9720052083333333,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9720052083333333,
        "precision": 0.9689453125,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9266462053571429,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9266462053571429,
        "precision": 0.919921875,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.009866221446616152,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009866221446616152,
        "precision": 0.007463533916170634,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7816917782738095,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7816917782738095,
        "precision": 0.7654134114583333,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9421549479166667,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9421549479166667,
        "precision": 0.93701171875,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9580078125,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9580078125,
        "precision": 0.9534505208333333,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9057291666666667,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9057291666666667,
        "precision": 0.8956705729166666,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009799241890251283,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.009799241890251283,
        "precision": 0.008792184762601846,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007430855404087556,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.007430855404087556,
        "precision": 0.0067755864681054035,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007371705022107678,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.007371705022107678,
        "precision": 0.006731397485547097,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005147316916251456,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.005147316916251456,
        "precision": 0.004633820096108922,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0023600260416666665,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0023600260416666665,
        "precision": 0.0019298735119047618,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.009152512634278857,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.009152512634278857,
        "precision": 0.008337445712513061,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.007053786406288562,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.007053786406288562,
        "precision": 0.005894581210019506,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0036870595980744974,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0036870595980744974,
        "precision": 0.0031171569274668683,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005129499581500661,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.005129499581500661,
        "precision": 0.004706254058948643,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006883098770515216,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.006883098770515216,
        "precision": 0.006192172091630478,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005916021574636346,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.005916021574636346,
        "precision": 0.0055048838540351155,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.004847635151572228,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.004847635151572228,
        "precision": 0.003737383344928781,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005028025343270523,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.005028025343270523,
        "precision": 0.004602144433081291,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.046446294389466306,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.046446294389466306,
        "precision": 0.03891684166470864,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006800132935492311,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.006800132935492311,
        "precision": 0.006218627547890391,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00672056677339492,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.00672056677339492,
        "precision": 0.006086006448527266,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0070038841003644825,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0070038841003644825,
        "precision": 0.006566739150797342,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007348820000400719,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.007348820000400719,
        "precision": 0.0067170040570576055,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.006068372628071938,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.006068372628071938,
        "precision": 0.0048070060570047455,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0058785123666983425,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0058785123666983425,
        "precision": 0.0054473330913505195,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.005981387824702112,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.005981387824702112,
        "precision": 0.005171363046688328,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007655237054198919,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.007655237054198919,
        "precision": 0.006978435132542498,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.7653075529454205,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7653075529454205,
        "precision": 0.7539339932528408,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.798018656148539,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.798018656148539,
        "precision": 0.7855987437042125,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.5244140625,
        "f1": 0.48301563345508663,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.48301563345508663,
        "precision": 0.46983855716765877,
        "recall": 0.5244140625
      },
      {
        "accuracy": 0.8544921875,
        "f1": 0.8218284970238096,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8218284970238096,
        "precision": 0.8082194010416667,
        "recall": 0.8544921875
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.721108662973661,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.721108662973661,
        "precision": 0.7084242473485516,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.787109375,
        "f1": 0.7549068390376984,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7549068390376984,
        "precision": 0.7425304594494048,
        "recall": 0.787109375
      },
      {
        "accuracy": 0.8125,
        "f1": 0.7782630997474747,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7782630997474747,
        "precision": 0.7659285583314765,
        "recall": 0.8125
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8371345641121032,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8371345641121032,
        "precision": 0.8280773344494048,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.8056640625,
        "f1": 0.7704806857638888,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7704806857638888,
        "precision": 0.7580481503088925,
        "recall": 0.8056640625
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.6890438988095238,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6890438988095238,
        "precision": 0.6720911792200854,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8266499613667583,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8266499613667583,
        "precision": 0.8144047196293289,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.802734375,
        "f1": 0.7701466393849206,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7701466393849206,
        "precision": 0.7587463155334249,
        "recall": 0.802734375
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.8049818996108058,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8049818996108058,
        "precision": 0.7940789841668748,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011483317285247433,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.011483317285247433,
        "precision": 0.009739044321563854,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.805287458851912,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.805287458851912,
        "precision": 0.7950396825396826,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.8251953125,
        "f1": 0.7946431254292582,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7946431254292582,
        "precision": 0.7832058729031385,
        "recall": 0.8251953125
      },
      {
        "accuracy": 0.794921875,
        "f1": 0.7595140861742424,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7595140861742424,
        "precision": 0.7463641806598349,
        "recall": 0.794921875
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7790884571158009,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.7790884571158009,
        "precision": 0.7645554315476191,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011552411361596189,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.011552411361596189,
        "precision": 0.008615292971670541,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.791015625,
        "f1": 0.7553031348757452,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7553031348757452,
        "precision": 0.7426529525162338,
        "recall": 0.791015625
      },
      {
        "accuracy": 0.796875,
        "f1": 0.767164784793611,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.767164784793611,
        "precision": 0.7571955957454004,
        "recall": 0.796875
      },
      {
        "accuracy": 0.7705078125,
        "f1": 0.7312999419200591,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7312999419200591,
        "precision": 0.7181733983247656,
        "recall": 0.7705078125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.4560546875,
        "f1": 0.4068069625686813,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.4068069625686813,
        "precision": 0.3888566468253968,
        "recall": 0.4560546875
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.91943359375,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.91943359375,
        "precision": 0.9104817708333334,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.8985677083333333,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.8985677083333333,
        "precision": 0.88818359375,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.85595703125,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.85595703125,
        "precision": 0.8415039062499999,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.01689741636287689,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.01689741636287689,
        "precision": 0.015096870488069939,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9658203125,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.9658203125,
        "precision": 0.9620768229166666,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.010795512585015045,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.010795512585015045,
        "precision": 0.008624532919304696,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.83203125,
        "f1": 0.7965169270833333,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.7965169270833333,
        "precision": 0.7812174479166667,
        "recall": 0.83203125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666666,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.9791666666666666,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.4390604981339127,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.4390604981339127,
        "precision": 0.42061726386677556,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.931640625,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.931640625,
        "precision": 0.92431640625,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9111328125,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.9111328125,
        "precision": 0.9013671875,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8728515625,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.8728515625,
        "precision": 0.861328125,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.019383397890406162,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.019383397890406162,
        "precision": 0.01594412667410714,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9876302083333333,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.9876302083333333,
        "precision": 0.986328125,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166666,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.9767252604166666,
        "precision": 0.9739583333333333,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.01181206683657664,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.01181206683657664,
        "precision": 0.009610055769716179,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.873046875,
        "f1": 0.8407877604166667,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.8407877604166667,
        "precision": 0.8262044270833333,
        "recall": 0.873046875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9951171875,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.9951171875,
        "precision": 0.99462890625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.484375,
        "f1": 0.43135690806589244,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.43135690806589244,
        "precision": 0.4137149570456096,
        "recall": 0.484375
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9436848958333333,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9436848958333333,
        "precision": 0.9375,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9138997395833333,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.9138997395833333,
        "precision": 0.9049479166666666,
        "recall": 0.93359375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.939453125,
        "f1": 0.9202473958333333,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.9202473958333333,
        "precision": 0.9109700520833333,
        "recall": 0.939453125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.010459271938852599,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.010459271938852599,
        "precision": 0.008760864371790383,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.97607421875,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.97607421875,
        "precision": 0.9734700520833333,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.007203927389127519,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007203927389127519,
        "precision": 0.005619064324113727,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8654622395833333,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.8654622395833333,
        "precision": 0.8533365885416667,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}