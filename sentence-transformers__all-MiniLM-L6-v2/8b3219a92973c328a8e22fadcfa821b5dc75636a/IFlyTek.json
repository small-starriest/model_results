{
  "dataset_revision": "421605374b29664c5fc098418fe20ada9bd55f8a",
  "evaluation_time": 56.58966827392578,
  "kg_co2_emissions": 0.008607952068782907,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "f1_weighted": 0.0,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.0,
        "scores_per_experiment": [
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          },
          {
            "accuracy": 0.0,
            "f1": 0.0,
            "f1_weighted": 0.0
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.16090804155444402,
        "f1": 0.09509489577756677,
        "f1_weighted": 0.14331167067339443,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.16090804155444402,
        "scores_per_experiment": [
          {
            "accuracy": 0.1669873028087726,
            "f1": 0.09909145033417847,
            "f1_weighted": 0.15747748448581064
          },
          {
            "accuracy": 0.16429395921508272,
            "f1": 0.09757036667988453,
            "f1_weighted": 0.1432088545725101
          },
          {
            "accuracy": 0.1550596383224317,
            "f1": 0.09379539249576788,
            "f1_weighted": 0.13316390255118776
          },
          {
            "accuracy": 0.16044632550981147,
            "f1": 0.09272694020991266,
            "f1_weighted": 0.1408971224222408
          },
          {
            "accuracy": 0.15775298191612158,
            "f1": 0.09229032916809025,
            "f1_weighted": 0.14181098933522288
          }
        ]
      }
    ]
  },
  "task_name": "IFlyTek"
}