{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 24.28349208831787,
  "kg_co2_emissions": 0.0036538016344172287,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.8717343091594589,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.8717343091594589,
        "precision": 0.861283781643063,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.14703925482368596,
        "f1": 0.11495032522389573,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.11495032522389573,
        "precision": 0.10544971680201222,
        "recall": 0.14703925482368596
      },
      {
        "accuracy": 0.5888223552894212,
        "f1": 0.5273286427478043,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.5273286427478043,
        "precision": 0.5030584333977547,
        "recall": 0.5888223552894212
      },
      {
        "accuracy": 0.8283433133732535,
        "f1": 0.7964799745238867,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.7964799745238867,
        "precision": 0.7836894586894586,
        "recall": 0.8283433133732535
      },
      {
        "accuracy": 0.5615435795076513,
        "f1": 0.5012152942791664,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.5012152942791664,
        "precision": 0.4790686685367911,
        "recall": 0.5615435795076513
      },
      {
        "accuracy": 0.8622754491017964,
        "f1": 0.8346988562557426,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8346988562557426,
        "precision": 0.8227893419510186,
        "recall": 0.8622754491017964
      },
      {
        "accuracy": 0.8602794411177644,
        "f1": 0.8290086493679308,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.8290086493679308,
        "precision": 0.815513417609226,
        "recall": 0.8602794411177644
      },
      {
        "accuracy": 0.7491683300066534,
        "f1": 0.7025034586910834,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.7025034586910834,
        "precision": 0.6832675918005258,
        "recall": 0.7491683300066534
      },
      {
        "accuracy": 0.5036593479707252,
        "f1": 0.4469268773659991,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.4469268773659991,
        "precision": 0.4258596563486783,
        "recall": 0.5036593479707252
      },
      {
        "accuracy": 0.852960745176314,
        "f1": 0.8232202262142383,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8232202262142383,
        "precision": 0.8104568640496785,
        "recall": 0.852960745176314
      },
      {
        "accuracy": 0.8396540252827678,
        "f1": 0.8068101891455184,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8068101891455184,
        "precision": 0.7926063217480382,
        "recall": 0.8396540252827678
      },
      {
        "accuracy": 0.8755821689953427,
        "f1": 0.8524728321135506,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.8524728321135506,
        "precision": 0.8422044799290308,
        "recall": 0.8755821689953427
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.011138781823713516,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.011138781823713516,
        "precision": 0.009329387019825785,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.8835662009314704,
        "f1": 0.8569749390108672,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.8569749390108672,
        "precision": 0.8449434464404525,
        "recall": 0.8835662009314704
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.8693058327788867,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.8693058327788867,
        "precision": 0.8585828343313373,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.8649367930805056,
        "f1": 0.836473085574882,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.836473085574882,
        "precision": 0.824129518740297,
        "recall": 0.8649367930805056
      },
      {
        "accuracy": 0.7465069860279441,
        "f1": 0.7012815638564142,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.7012815638564142,
        "precision": 0.6815500866399069,
        "recall": 0.7465069860279441
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007713207095528971,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.007713207095528971,
        "precision": 0.006289282319765214,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.4870259481037924,
        "f1": 0.43143603642605644,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.43143603642605644,
        "precision": 0.4118604301738034,
        "recall": 0.4870259481037924
      },
      {
        "accuracy": 0.7504990019960079,
        "f1": 0.706436861726283,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.706436861726283,
        "precision": 0.6871202040363718,
        "recall": 0.7504990019960079
      },
      {
        "accuracy": 0.8256819693945442,
        "f1": 0.7879722037406667,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.7879722037406667,
        "precision": 0.771773120425815,
        "recall": 0.8256819693945442
      },
      {
        "accuracy": 0.8995342648037259,
        "f1": 0.8776779773785762,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.8776779773785762,
        "precision": 0.8679925862560594,
        "recall": 0.8995342648037259
      },
      {
        "accuracy": 0.9028609447771124,
        "f1": 0.8821721636092894,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.8821721636092894,
        "precision": 0.873826421231611,
        "recall": 0.9028609447771124
      },
      {
        "accuracy": 0.15302727877578176,
        "f1": 0.11888785243044464,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.11888785243044464,
        "precision": 0.10882496282651852,
        "recall": 0.15302727877578176
      },
      {
        "accuracy": 0.6493679308050565,
        "f1": 0.594587280465524,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.594587280465524,
        "precision": 0.573173580406174,
        "recall": 0.6493679308050565
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8877504250757743,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.8877504250757743,
        "precision": 0.879369039698381,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.5921490352628077,
        "f1": 0.5306699251809032,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.5306699251809032,
        "precision": 0.5075650766768531,
        "recall": 0.5921490352628077
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8881348414282547,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.8881348414282547,
        "precision": 0.8793191394987803,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.9281437125748503,
        "f1": 0.909558660456864,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.909558660456864,
        "precision": 0.9010534486582391,
        "recall": 0.9281437125748503
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.7817307184572653,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.7817307184572653,
        "precision": 0.7669544748886067,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.5568862275449101,
        "f1": 0.4988731199310042,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.4988731199310042,
        "precision": 0.47637212347791186,
        "recall": 0.5568862275449101
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8656702468079712,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8656702468079712,
        "precision": 0.8549298228938949,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8854069638500774,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.8854069638500774,
        "precision": 0.8749390108671545,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9039603333016507,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9039603333016507,
        "precision": 0.8962852073630516,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008933772293312768,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.008933772293312768,
        "precision": 0.007393581442194742,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.9288090485695276,
        "f1": 0.912375249500998,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.912375249500998,
        "precision": 0.905100909292526,
        "recall": 0.9288090485695276
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9201501758387985,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9201501758387985,
        "precision": 0.9140053226879574,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.9021956087824351,
        "f1": 0.8791638944333554,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.8791638944333554,
        "precision": 0.8689573234483413,
        "recall": 0.9021956087824351
      },
      {
        "accuracy": 0.7970725216234198,
        "f1": 0.7570198707923258,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7570198707923258,
        "precision": 0.7403985679434782,
        "recall": 0.7970725216234198
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005562074428621694,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.005562074428621694,
        "precision": 0.00425504852880639,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.5355954757152362,
        "f1": 0.47636509088604895,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.47636509088604895,
        "precision": 0.4545316773859688,
        "recall": 0.5355954757152362
      },
      {
        "accuracy": 0.8416500332667998,
        "f1": 0.8103718488948031,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.8103718488948031,
        "precision": 0.7965347083610557,
        "recall": 0.8416500332667998
      },
      {
        "accuracy": 0.8835662009314704,
        "f1": 0.8571523619427811,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.8571523619427811,
        "precision": 0.8455866045686404,
        "recall": 0.8835662009314704
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9193295947786966,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9193295947786966,
        "precision": 0.9124196052339766,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.09928181620281293,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.09928181620281293,
        "precision": 0.09218694877562146,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.1277445109780439,
        "f1": 0.09139857829462371,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.09139857829462371,
        "precision": 0.08373690618578222,
        "recall": 0.1277445109780439
      },
      {
        "accuracy": 0.16833000665335995,
        "f1": 0.1355262018454632,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.1355262018454632,
        "precision": 0.1269295667018983,
        "recall": 0.16833000665335995
      },
      {
        "accuracy": 0.08848968729208251,
        "f1": 0.06887908125508624,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06887908125508624,
        "precision": 0.06450351408955157,
        "recall": 0.08848968729208251
      },
      {
        "accuracy": 0.14238190286094476,
        "f1": 0.11468872298537776,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.11468872298537776,
        "precision": 0.10763658172244067,
        "recall": 0.14238190286094476
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.0964763264391569,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0964763264391569,
        "precision": 0.0909285016847523,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.1703260146373919,
        "f1": 0.13087064109469498,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.13087064109469498,
        "precision": 0.12194732854599397,
        "recall": 0.1703260146373919
      },
      {
        "accuracy": 0.11842980705256155,
        "f1": 0.09523964437319886,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.09523964437319886,
        "precision": 0.09007481100969855,
        "recall": 0.11842980705256155
      },
      {
        "accuracy": 0.1277445109780439,
        "f1": 0.09526940179523291,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.09526940179523291,
        "precision": 0.08630368959543942,
        "recall": 0.1277445109780439
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.09862680580414049,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.09862680580414049,
        "precision": 0.0898834792994904,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.13373253493013973,
        "f1": 0.10002597793756896,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.10002597793756896,
        "precision": 0.09314940440158676,
        "recall": 0.13373253493013973
      },
      {
        "accuracy": 0.13439787092481703,
        "f1": 0.09887876549754131,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09887876549754131,
        "precision": 0.09040361440195918,
        "recall": 0.13439787092481703
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.01133760894239936,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01133760894239936,
        "precision": 0.009763365231241423,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.14105123087159016,
        "f1": 0.1023735818386556,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1023735818386556,
        "precision": 0.09334832462956874,
        "recall": 0.14105123087159016
      },
      {
        "accuracy": 0.12907518296739853,
        "f1": 0.09220339481327215,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.09220339481327215,
        "precision": 0.08450146311650286,
        "recall": 0.12907518296739853
      },
      {
        "accuracy": 0.1324018629407851,
        "f1": 0.10307653968159043,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10307653968159043,
        "precision": 0.09574841504109903,
        "recall": 0.1324018629407851
      },
      {
        "accuracy": 0.12375249500998003,
        "f1": 0.0884193823970516,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.0884193823970516,
        "precision": 0.08062491213259902,
        "recall": 0.12375249500998003
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008431243726171113,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008431243726171113,
        "precision": 0.006781382180667236,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.16101131071190952,
        "f1": 0.1304356322320394,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1304356322320394,
        "precision": 0.1221872804989181,
        "recall": 0.16101131071190952
      },
      {
        "accuracy": 0.10645375914836992,
        "f1": 0.08059338314463257,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.08059338314463257,
        "precision": 0.07546416786930904,
        "recall": 0.10645375914836992
      },
      {
        "accuracy": 0.12242182302062542,
        "f1": 0.09154371211220053,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09154371211220053,
        "precision": 0.08528876491796807,
        "recall": 0.12242182302062542
      },
      {
        "accuracy": 0.13439787092481703,
        "f1": 0.10052081946632502,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10052081946632502,
        "precision": 0.09324057449778524,
        "recall": 0.13439787092481703
      },
      {
        "accuracy": 0.6074517631403858,
        "f1": 0.5526630105537508,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5526630105537508,
        "precision": 0.5316609205830763,
        "recall": 0.6074517631403858
      },
      {
        "accuracy": 0.6739853626081171,
        "f1": 0.6158744184258373,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6158744184258373,
        "precision": 0.5930457987344215,
        "recall": 0.6739853626081171
      },
      {
        "accuracy": 0.17564870259481039,
        "f1": 0.14101360087388032,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.14101360087388032,
        "precision": 0.1297854242435668,
        "recall": 0.17564870259481039
      },
      {
        "accuracy": 0.5775116433799069,
        "f1": 0.5257627628852,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5257627628852,
        "precision": 0.5088609258145366,
        "recall": 0.5775116433799069
      },
      {
        "accuracy": 0.4657351962741184,
        "f1": 0.41076897275152935,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.41076897275152935,
        "precision": 0.391336302863249,
        "recall": 0.4657351962741184
      },
      {
        "accuracy": 0.6633399866932801,
        "f1": 0.6096938398335604,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6096938398335604,
        "precision": 0.5900300169262246,
        "recall": 0.6633399866932801
      },
      {
        "accuracy": 0.7039254823685961,
        "f1": 0.6502164982204902,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6502164982204902,
        "precision": 0.6296816660090112,
        "recall": 0.7039254823685961
      },
      {
        "accuracy": 0.5349301397205589,
        "f1": 0.48101865052962856,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.48101865052962856,
        "precision": 0.46139647851224697,
        "recall": 0.5349301397205589
      },
      {
        "accuracy": 0.40652029274783763,
        "f1": 0.3451779461759501,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3451779461759501,
        "precision": 0.3238527828348188,
        "recall": 0.40652029274783763
      },
      {
        "accuracy": 0.6912840984697272,
        "f1": 0.6350805511484154,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6350805511484154,
        "precision": 0.61257194605498,
        "recall": 0.6912840984697272
      },
      {
        "accuracy": 0.6194278110445776,
        "f1": 0.5513517937669634,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5513517937669634,
        "precision": 0.526084363260012,
        "recall": 0.6194278110445776
      },
      {
        "accuracy": 0.6753160345974717,
        "f1": 0.613155353923817,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.613155353923817,
        "precision": 0.5890654791353395,
        "recall": 0.6753160345974717
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.00739067122133806,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00739067122133806,
        "precision": 0.0052234507814524255,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.6819693945442449,
        "f1": 0.6237957946540781,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6237957946540781,
        "precision": 0.6009778810677013,
        "recall": 0.6819693945442449
      },
      {
        "accuracy": 0.654690618762475,
        "f1": 0.5933468572755216,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5933468572755216,
        "precision": 0.5699702160780006,
        "recall": 0.654690618762475
      },
      {
        "accuracy": 0.6979374584165003,
        "f1": 0.6417915491767787,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6417915491767787,
        "precision": 0.6194935525773848,
        "recall": 0.6979374584165003
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.4286923507482389,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.4286923507482389,
        "precision": 0.40120132510352075,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.005477113922821604,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005477113922821604,
        "precision": 0.0037185780448733244,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.5023286759813705,
        "f1": 0.447068297267898,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.447068297267898,
        "precision": 0.4257340057739259,
        "recall": 0.5023286759813705
      },
      {
        "accuracy": 0.5296074517631404,
        "f1": 0.46328106973482885,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.46328106973482885,
        "precision": 0.43796061445762047,
        "recall": 0.5296074517631404
      },
      {
        "accuracy": 0.5721889554224884,
        "f1": 0.5103518120953837,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5103518120953837,
        "precision": 0.48802750439476983,
        "recall": 0.5721889554224884
      },
      {
        "accuracy": 0.6952761144377911,
        "f1": 0.636190053754924,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.636190053754924,
        "precision": 0.6136222504485978,
        "recall": 0.6952761144377911
      },
      {
        "accuracy": 0.8669328010645376,
        "f1": 0.8360431761629366,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8360431761629366,
        "precision": 0.8228432024839211,
        "recall": 0.8669328010645376
      },
      {
        "accuracy": 0.9394544244843646,
        "f1": 0.9253493013972055,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9253493013972055,
        "precision": 0.9189398979818141,
        "recall": 0.9394544244843646
      },
      {
        "accuracy": 0.13905522288755823,
        "f1": 0.10118376346318399,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.10118376346318399,
        "precision": 0.09206974444059257,
        "recall": 0.13905522288755823
      },
      {
        "accuracy": 0.6813040585495675,
        "f1": 0.6166609061818643,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.6166609061818643,
        "precision": 0.5906774234119544,
        "recall": 0.6813040585495675
      },
      {
        "accuracy": 0.5375914836992681,
        "f1": 0.468414952162936,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.468414952162936,
        "precision": 0.44463507370519434,
        "recall": 0.5375914836992681
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.911998801819161,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.911998801819161,
        "precision": 0.9046129962297627,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.9474384564204924,
        "f1": 0.9337895637296835,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9337895637296835,
        "precision": 0.9278886671102239,
        "recall": 0.9474384564204924
      },
      {
        "accuracy": 0.8157019294743846,
        "f1": 0.7747668683796429,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.7747668683796429,
        "precision": 0.7574826537401388,
        "recall": 0.8157019294743846
      },
      {
        "accuracy": 0.4963406520292748,
        "f1": 0.42180402579604176,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.42180402579604176,
        "precision": 0.3948847928887849,
        "recall": 0.4963406520292748
      },
      {
        "accuracy": 0.906187624750499,
        "f1": 0.8822133510756266,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8822133510756266,
        "precision": 0.8718562874251498,
        "recall": 0.906187624750499
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9036498431708013,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9036498431708013,
        "precision": 0.8950876025726324,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9017869023857048,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9017869023857048,
        "precision": 0.8924595253936572,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0011229844438746328,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0011229844438746328,
        "precision": 0.0006878244660853775,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.9261477045908184,
        "f1": 0.9069416722111332,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.9069416722111332,
        "precision": 0.8986915058771348,
        "recall": 0.9261477045908184
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9090042137946329,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9090042137946329,
        "precision": 0.9006616396835957,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.8863753973534413,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8863753973534413,
        "precision": 0.876763140385895,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.7704590818363274,
        "f1": 0.7223563455100381,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7223563455100381,
        "precision": 0.7022782717393495,
        "recall": 0.7704590818363274
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0028267096370489003,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0028267096370489003,
        "precision": 0.00215841100357692,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.49367930805056554,
        "f1": 0.41810631336579446,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.41810631336579446,
        "precision": 0.39191654029803813,
        "recall": 0.49367930805056554
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.7972404397554098,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.7972404397554098,
        "precision": 0.7814149478820138,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.8968729208250167,
        "f1": 0.8727449862180401,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8727449862180401,
        "precision": 0.8623704971010362,
        "recall": 0.8968729208250167
      },
      {
        "accuracy": 0.9481037924151696,
        "f1": 0.9342648037258816,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9342648037258816,
        "precision": 0.9279995564426702,
        "recall": 0.9481037924151696
      },
      {
        "accuracy": 0.5382568196939455,
        "f1": 0.4748098552372358,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4748098552372358,
        "precision": 0.45250425075774375,
        "recall": 0.5382568196939455
      },
      {
        "accuracy": 0.590818363273453,
        "f1": 0.5300523759448016,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5300523759448016,
        "precision": 0.5075869710600249,
        "recall": 0.590818363273453
      },
      {
        "accuracy": 0.17298735861610112,
        "f1": 0.1381015200032338,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1381015200032338,
        "precision": 0.12669502265310648,
        "recall": 0.17298735861610112
      },
      {
        "accuracy": 0.479707252162342,
        "f1": 0.41932106483004683,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.41932106483004683,
        "precision": 0.39626169276867884,
        "recall": 0.479707252162342
      },
      {
        "accuracy": 0.4491017964071856,
        "f1": 0.40694535424279826,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.40694535424279826,
        "precision": 0.3945080616609803,
        "recall": 0.4491017964071856
      },
      {
        "accuracy": 0.5788423153692615,
        "f1": 0.5284141315762284,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5284141315762284,
        "precision": 0.5108938042071774,
        "recall": 0.5788423153692615
      },
      {
        "accuracy": 0.6114437791084497,
        "f1": 0.5513408329930458,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5513408329930458,
        "precision": 0.5306851904656295,
        "recall": 0.6114437791084497
      },
      {
        "accuracy": 0.5029940119760479,
        "f1": 0.45250415898531426,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.45250415898531426,
        "precision": 0.4343821523711743,
        "recall": 0.5029940119760479
      },
      {
        "accuracy": 0.3546240851630073,
        "f1": 0.3048242620098907,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3048242620098907,
        "precision": 0.2863109759317344,
        "recall": 0.3546240851630073
      },
      {
        "accuracy": 0.5848303393213573,
        "f1": 0.5248744546381157,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5248744546381157,
        "precision": 0.5027802610636941,
        "recall": 0.5848303393213573
      },
      {
        "accuracy": 0.5642049234863606,
        "f1": 0.5006331252838239,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5006331252838239,
        "precision": 0.47731349280782376,
        "recall": 0.5642049234863606
      },
      {
        "accuracy": 0.6420492348636061,
        "f1": 0.5825739961967507,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5825739961967507,
        "precision": 0.5601349803445611,
        "recall": 0.6420492348636061
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.010644102531973648,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.010644102531973648,
        "precision": 0.008582066892554994,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.5954757152361942,
        "f1": 0.5287465097410424,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5287465097410424,
        "precision": 0.504608939888381,
        "recall": 0.5954757152361942
      },
      {
        "accuracy": 0.582168995342648,
        "f1": 0.5201165010642829,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5201165010642829,
        "precision": 0.4978990437855317,
        "recall": 0.582168995342648
      },
      {
        "accuracy": 0.5801729873586161,
        "f1": 0.5218250995696105,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5218250995696105,
        "precision": 0.5011458804372976,
        "recall": 0.5801729873586161
      },
      {
        "accuracy": 0.4823685961410512,
        "f1": 0.4155439297155864,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.4155439297155864,
        "precision": 0.39142074012333494,
        "recall": 0.4823685961410512
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005979085466020993,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005979085466020993,
        "precision": 0.004508573998687051,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.4318030605455755,
        "f1": 0.38122965228753647,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.38122965228753647,
        "precision": 0.3615288563862006,
        "recall": 0.4318030605455755
      },
      {
        "accuracy": 0.499001996007984,
        "f1": 0.4379899947764219,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4379899947764219,
        "precision": 0.41649096387952006,
        "recall": 0.499001996007984
      },
      {
        "accuracy": 0.5296074517631404,
        "f1": 0.47076222235315807,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.47076222235315807,
        "precision": 0.45093203867566906,
        "recall": 0.5296074517631404
      },
      {
        "accuracy": 0.5861610113107119,
        "f1": 0.5217857894304999,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5217857894304999,
        "precision": 0.4992367117616618,
        "recall": 0.5861610113107119
      },
      {
        "accuracy": 0.8802395209580839,
        "f1": 0.8531080695751354,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.8531080695751354,
        "precision": 0.8408025219402464,
        "recall": 0.8802395209580839
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.896806387225549,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.896806387225549,
        "precision": 0.8875249500998003,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.15701929474384566,
        "f1": 0.12162092915585929,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.12162092915585929,
        "precision": 0.1114349607662981,
        "recall": 0.15701929474384566
      },
      {
        "accuracy": 0.6533599467731205,
        "f1": 0.592269477399218,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.592269477399218,
        "precision": 0.5679925862560593,
        "recall": 0.6533599467731205
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.8955786839020373,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.8955786839020373,
        "precision": 0.887154262902766,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.6207584830339321,
        "f1": 0.5576355226055825,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.5576355226055825,
        "precision": 0.5336242605546104,
        "recall": 0.6207584830339321
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8978059753508856,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.8978059753508856,
        "precision": 0.8891502708867978,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.8050565535595475,
        "f1": 0.7668477859096621,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.7668477859096621,
        "precision": 0.7507770173937839,
        "recall": 0.8050565535595475
      },
      {
        "accuracy": 0.5695276114437791,
        "f1": 0.5007387341718679,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.5007387341718679,
        "precision": 0.4736677438773247,
        "recall": 0.5695276114437791
      },
      {
        "accuracy": 0.9048569527611444,
        "f1": 0.883166999334664,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.883166999334664,
        "precision": 0.8734641827456199,
        "recall": 0.9048569527611444
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8624861388334442,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.8624861388334442,
        "precision": 0.8498954472008364,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9050597218261888,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.9050597218261888,
        "precision": 0.8970614326901751,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.00664510687591461,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.00664510687591461,
        "precision": 0.005102935064672746,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.899678420935906,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.899678420935906,
        "precision": 0.891312612869499,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.9214903526280772,
        "f1": 0.9018407629186073,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.9018407629186073,
        "precision": 0.8925482368596142,
        "recall": 0.9214903526280772
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8881823654278744,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.8881823654278744,
        "precision": 0.8779662896429364,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.7797737857618097,
        "f1": 0.7364293058903838,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.7364293058903838,
        "precision": 0.7179086271900643,
        "recall": 0.7797737857618097
      },
      {
        "accuracy": 0.023952095808383235,
        "f1": 0.009122422998933543,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.009122422998933543,
        "precision": 0.006907087273657131,
        "recall": 0.023952095808383235
      },
      {
        "accuracy": 0.5708582834331337,
        "f1": 0.5103914345431312,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.5103914345431312,
        "precision": 0.48730977199041065,
        "recall": 0.5708582834331337
      },
      {
        "accuracy": 0.8063872255489022,
        "f1": 0.7671947111068868,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.7671947111068868,
        "precision": 0.7497394100687514,
        "recall": 0.8063872255489022
      },
      {
        "accuracy": 0.8556220891550232,
        "f1": 0.8217248043595349,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.8217248043595349,
        "precision": 0.8069268869668071,
        "recall": 0.8556220891550232
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8900104552799164,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.8900104552799164,
        "precision": 0.8807828786870703,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.864105123087159,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.864105123087159,
        "precision": 0.8524680797135886,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.9341317365269461,
        "f1": 0.9172987358616101,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9172987358616101,
        "precision": 0.9097028165890441,
        "recall": 0.9341317365269461
      },
      {
        "accuracy": 0.20958083832335328,
        "f1": 0.16407847899863864,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.16407847899863864,
        "precision": 0.1497839723541517,
        "recall": 0.20958083832335328
      },
      {
        "accuracy": 0.7232202262142382,
        "f1": 0.6695519494920693,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6695519494920693,
        "precision": 0.6479622765051907,
        "recall": 0.7232202262142382
      },
      {
        "accuracy": 0.9347970725216235,
        "f1": 0.9186626746506986,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9186626746506986,
        "precision": 0.9116829832398694,
        "recall": 0.9347970725216235
      },
      {
        "accuracy": 0.6274118429807053,
        "f1": 0.5695887833612384,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5695887833612384,
        "precision": 0.5473410562232917,
        "recall": 0.6274118429807053
      },
      {
        "accuracy": 0.9181636726546906,
        "f1": 0.9010645375914839,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9010645375914839,
        "precision": 0.8936127744510978,
        "recall": 0.9181636726546906
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.798960808541647,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.798960808541647,
        "precision": 0.7841206475937015,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.5974717232202262,
        "f1": 0.5333839443619883,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5333839443619883,
        "precision": 0.5082425096896155,
        "recall": 0.5974717232202262
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8848873681209011,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8848873681209011,
        "precision": 0.8749944555333777,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.9108449767132402,
        "f1": 0.8900421379463295,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8900421379463295,
        "precision": 0.8804502106897316,
        "recall": 0.9108449767132402
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.91055666444888,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.91055666444888,
        "precision": 0.9029163894433355,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.010139299964033798,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.010139299964033798,
        "precision": 0.007825382645741927,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.9141716566866267,
        "f1": 0.8943446440452428,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8943446440452428,
        "precision": 0.8855289421157684,
        "recall": 0.9141716566866267
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9062763362164561,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9062763362164561,
        "precision": 0.8975604346861832,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.9234863606121091,
        "f1": 0.9040807274340209,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9040807274340209,
        "precision": 0.8951763140385895,
        "recall": 0.9234863606121091
      },
      {
        "accuracy": 0.7850964737192282,
        "f1": 0.7408959858061654,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.7408959858061654,
        "precision": 0.7215637101864646,
        "recall": 0.7850964737192282
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.007129197357794403,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007129197357794403,
        "precision": 0.005262646121688906,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.6127744510978044,
        "f1": 0.5513470561374754,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5513470561374754,
        "precision": 0.5276906504451414,
        "recall": 0.6127744510978044
      },
      {
        "accuracy": 0.8403193612774451,
        "f1": 0.8082073947343408,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8082073947343408,
        "precision": 0.7940294015144316,
        "recall": 0.8403193612774451
      },
      {
        "accuracy": 0.8902195608782435,
        "f1": 0.8671989354624086,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8671989354624086,
        "precision": 0.8568751386116655,
        "recall": 0.8902195608782435
      },
      {
        "accuracy": 0.9401197604790419,
        "f1": 0.9255045464626303,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9255045464626303,
        "precision": 0.9191727655799512,
        "recall": 0.9401197604790419
      },
      {
        "accuracy": 0.7584830339321357,
        "f1": 0.7162246934702025,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.7162246934702025,
        "precision": 0.6978820137502771,
        "recall": 0.7584830339321357
      },
      {
        "accuracy": 0.8290086493679308,
        "f1": 0.7928048664575611,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.7928048664575611,
        "precision": 0.7762253271235307,
        "recall": 0.8290086493679308
      },
      {
        "accuracy": 0.15103127079174983,
        "f1": 0.1115231685590967,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.1115231685590967,
        "precision": 0.09976281725609157,
        "recall": 0.15103127079174983
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.512199986750885,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.512199986750885,
        "precision": 0.49008174127934606,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.7917498336660014,
        "f1": 0.7544278248810361,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.7544278248810361,
        "precision": 0.7403796497359371,
        "recall": 0.7917498336660014
      },
      {
        "accuracy": 0.5269461077844312,
        "f1": 0.4687560572790114,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.4687560572790114,
        "precision": 0.44640797769540286,
        "recall": 0.5269461077844312
      },
      {
        "accuracy": 0.7977378576180971,
        "f1": 0.7666698349333081,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.7666698349333081,
        "precision": 0.7538256819693946,
        "recall": 0.7977378576180971
      },
      {
        "accuracy": 0.8330006653359947,
        "f1": 0.7975509298862592,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.7975509298862592,
        "precision": 0.7819472166777558,
        "recall": 0.8330006653359947
      },
      {
        "accuracy": 0.4524284763805722,
        "f1": 0.39495986382213927,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.39495986382213927,
        "precision": 0.3724624824425224,
        "recall": 0.4524284763805722
      },
      {
        "accuracy": 0.7791084497671324,
        "f1": 0.738692456357127,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.738692456357127,
        "precision": 0.7211640211640211,
        "recall": 0.7791084497671324
      },
      {
        "accuracy": 0.8137059214903526,
        "f1": 0.7729430028831227,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.7729430028831227,
        "precision": 0.7546462630294966,
        "recall": 0.8137059214903526
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7877356398314482,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.7877356398314482,
        "precision": 0.7716677755599911,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.006745896866295456,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.006745896866295456,
        "precision": 0.005234044555265997,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.8150365934797072,
        "f1": 0.7779330228432025,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.7779330228432025,
        "precision": 0.7614105123087159,
        "recall": 0.8150365934797072
      },
      {
        "accuracy": 0.825016633399867,
        "f1": 0.7860501219782657,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.7860501219782657,
        "precision": 0.7686626746506987,
        "recall": 0.825016633399867
      },
      {
        "accuracy": 0.782435129740519,
        "f1": 0.7421157684630739,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.7421157684630739,
        "precision": 0.72507207806609,
        "recall": 0.782435129740519
      },
      {
        "accuracy": 0.6540252827677977,
        "f1": 0.5963422361625955,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.5963422361625955,
        "precision": 0.5721287583563033,
        "recall": 0.6540252827677977
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.006894882794344375,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.006894882794344375,
        "precision": 0.005146762349899934,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.48835662009314706,
        "f1": 0.43362481386433477,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.43362481386433477,
        "precision": 0.4125209897664987,
        "recall": 0.48835662009314706
      },
      {
        "accuracy": 0.7711244178310046,
        "f1": 0.7262364160567754,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.7262364160567754,
        "precision": 0.7065202927478377,
        "recall": 0.7711244178310046
      },
      {
        "accuracy": 0.8223552894211577,
        "f1": 0.7841998542597345,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.7841998542597345,
        "precision": 0.7673061284837731,
        "recall": 0.8223552894211577
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7822186315200287,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.7822186315200287,
        "precision": 0.7647427367487247,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.49567531603459747,
        "f1": 0.4325660035240873,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.4325660035240873,
        "precision": 0.4089677787282578,
        "recall": 0.49567531603459747
      },
      {
        "accuracy": 0.5535595475715236,
        "f1": 0.488640146723979,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.488640146723979,
        "precision": 0.4649619373142914,
        "recall": 0.5535595475715236
      },
      {
        "accuracy": 0.1217564870259481,
        "f1": 0.09412231504301233,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.09412231504301233,
        "precision": 0.0862904975928928,
        "recall": 0.1217564870259481
      },
      {
        "accuracy": 0.3772455089820359,
        "f1": 0.3237049710103602,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.3237049710103602,
        "precision": 0.3042116824551954,
        "recall": 0.3772455089820359
      },
      {
        "accuracy": 0.37258815701929476,
        "f1": 0.3321009707877002,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.3321009707877002,
        "precision": 0.3206061504983521,
        "recall": 0.37258815701929476
      },
      {
        "accuracy": 0.3200266134397871,
        "f1": 0.2784842680052261,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.2784842680052261,
        "precision": 0.2640042379317027,
        "recall": 0.3200266134397871
      },
      {
        "accuracy": 0.5256154357950765,
        "f1": 0.4707115424680295,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.4707115424680295,
        "precision": 0.4503894679776249,
        "recall": 0.5256154357950765
      },
      {
        "accuracy": 0.5475715236194278,
        "f1": 0.4858815945642293,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.4858815945642293,
        "precision": 0.46309713425481885,
        "recall": 0.5475715236194278
      },
      {
        "accuracy": 0.4278110445775116,
        "f1": 0.3775068097423387,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.3775068097423387,
        "precision": 0.35969074107503135,
        "recall": 0.4278110445775116
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.47296839702029325,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.47296839702029325,
        "precision": 0.44895703099295914,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.48902195608782434,
        "f1": 0.4260046980290703,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.4260046980290703,
        "precision": 0.4026071788047836,
        "recall": 0.48902195608782434
      },
      {
        "accuracy": 0.5349301397205589,
        "f1": 0.47050660583594717,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.47050660583594717,
        "precision": 0.44713975740344053,
        "recall": 0.5349301397205589
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.00725049593440263,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.00725049593440263,
        "precision": 0.0052212476961366276,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.4854527412411644,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.4854527412411644,
        "precision": 0.46007903163591785,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.4667988020224723,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.4667988020224723,
        "precision": 0.4443874503846665,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.550232867598137,
        "f1": 0.49280443442120087,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.49280443442120087,
        "precision": 0.47203086823551776,
        "recall": 0.550232867598137
      },
      {
        "accuracy": 0.42248835662009315,
        "f1": 0.3616112172000395,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.3616112172000395,
        "precision": 0.33896096695497896,
        "recall": 0.42248835662009315
      },
      {
        "accuracy": 0.021290751829673986,
        "f1": 0.009292084603495992,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.009292084603495992,
        "precision": 0.007193601643427977,
        "recall": 0.021290751829673986
      },
      {
        "accuracy": 0.34331337325349304,
        "f1": 0.3002893683532406,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.3002893683532406,
        "precision": 0.28456502099216674,
        "recall": 0.34331337325349304
      },
      {
        "accuracy": 0.4364604125083167,
        "f1": 0.3782846192027829,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.3782846192027829,
        "precision": 0.35632209818543037,
        "recall": 0.4364604125083167
      },
      {
        "accuracy": 0.4717232202262142,
        "f1": 0.41235299039690254,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.41235299039690254,
        "precision": 0.39145285417446973,
        "recall": 0.4717232202262142
      },
      {
        "accuracy": 0.6014637391882901,
        "f1": 0.5374975347970534,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.5374975347970534,
        "precision": 0.5138488895225422,
        "recall": 0.6014637391882901
      },
      {
        "accuracy": 0.8562874251497006,
        "f1": 0.8253049456642272,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8253049456642272,
        "precision": 0.8113328897760036,
        "recall": 0.8562874251497006
      },
      {
        "accuracy": 0.8995342648037259,
        "f1": 0.8764914615214017,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8764914615214017,
        "precision": 0.8659902417387448,
        "recall": 0.8995342648037259
      },
      {
        "accuracy": 0.1490352628077179,
        "f1": 0.11722140135313787,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11722140135313787,
        "precision": 0.10780523462991345,
        "recall": 0.1490352628077179
      },
      {
        "accuracy": 0.6773120425815037,
        "f1": 0.62068138854566,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.62068138854566,
        "precision": 0.5980457315287655,
        "recall": 0.6773120425815037
      },
      {
        "accuracy": 0.8842315369261478,
        "f1": 0.8586541203307669,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8586541203307669,
        "precision": 0.848502994011976,
        "recall": 0.8842315369261478
      },
      {
        "accuracy": 0.6014637391882901,
        "f1": 0.5393191638700621,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5393191638700621,
        "precision": 0.5177309402359302,
        "recall": 0.6014637391882901
      },
      {
        "accuracy": 0.8942115768463074,
        "f1": 0.8719449988911067,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8719449988911067,
        "precision": 0.8623435668345847,
        "recall": 0.8942115768463074
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.866379938535627,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.866379938535627,
        "precision": 0.8545195323638437,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.7598137059214903,
        "f1": 0.7155165858758673,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7155165858758673,
        "precision": 0.6969584640243324,
        "recall": 0.7598137059214903
      },
      {
        "accuracy": 0.5209580838323353,
        "f1": 0.4624522627516639,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.4624522627516639,
        "precision": 0.43997402021354115,
        "recall": 0.5209580838323353
      },
      {
        "accuracy": 0.8483033932135728,
        "f1": 0.8147150144156132,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8147150144156132,
        "precision": 0.7996958464024332,
        "recall": 0.8483033932135728
      },
      {
        "accuracy": 0.8908848968729208,
        "f1": 0.8648480816145487,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8648480816145487,
        "precision": 0.8529718341095587,
        "recall": 0.8908848968729208
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007923734548583321,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007923734548583321,
        "precision": 0.006349693857620202,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.889088489687292,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.889088489687292,
        "precision": 0.8795076513639388,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.8948769128409847,
        "f1": 0.8700377023730318,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8700377023730318,
        "precision": 0.859059658460856,
        "recall": 0.8948769128409847
      },
      {
        "accuracy": 0.8789088489687292,
        "f1": 0.8531492570414726,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8531492570414726,
        "precision": 0.8417339923327947,
        "recall": 0.8789088489687292
      },
      {
        "accuracy": 0.7644710578842315,
        "f1": 0.7164076608687386,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7164076608687386,
        "precision": 0.6960475873649526,
        "recall": 0.7644710578842315
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.008913433745915324,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008913433745915324,
        "precision": 0.007343750508370036,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.5409181636726547,
        "f1": 0.4854244040870787,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4854244040870787,
        "precision": 0.46585904669737005,
        "recall": 0.5409181636726547
      },
      {
        "accuracy": 0.7631403858948769,
        "f1": 0.7180084275892659,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7180084275892659,
        "precision": 0.6986411016351136,
        "recall": 0.7631403858948769
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7874504958337293,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.7874504958337293,
        "precision": 0.7713572854291416,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.9068529607451763,
        "f1": 0.8817697937458416,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8817697937458416,
        "precision": 0.8702816589044133,
        "recall": 0.9068529607451763
      },
      {
        "accuracy": 0.8582834331337326,
        "f1": 0.8288312264360167,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.8288312264360167,
        "precision": 0.8155910401419383,
        "recall": 0.8582834331337326
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.9000221778664891,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9000221778664891,
        "precision": 0.8923153692614771,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.1497005988023952,
        "f1": 0.11809139873012127,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.11809139873012127,
        "precision": 0.10871512390826703,
        "recall": 0.1497005988023952
      },
      {
        "accuracy": 0.6107784431137725,
        "f1": 0.5476063745524824,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.5476063745524824,
        "precision": 0.5233624769552914,
        "recall": 0.6107784431137725
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8804612996229763,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.8804612996229763,
        "precision": 0.8710246174318031,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.5675316034597472,
        "f1": 0.5089482410839696,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.5089482410839696,
        "precision": 0.48696967075210584,
        "recall": 0.5675316034597472
      },
      {
        "accuracy": 0.8875582168995343,
        "f1": 0.8655260906757911,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.8655260906757911,
        "precision": 0.8560212907518296,
        "recall": 0.8875582168995343
      },
      {
        "accuracy": 0.9028609447771124,
        "f1": 0.8800969489592244,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.8800969489592244,
        "precision": 0.8704923486360612,
        "recall": 0.9028609447771124
      },
      {
        "accuracy": 0.823020625415835,
        "f1": 0.7869108344158243,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.7869108344158243,
        "precision": 0.771861831891772,
        "recall": 0.823020625415835
      },
      {
        "accuracy": 0.49966733200266134,
        "f1": 0.43896334315495994,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.43896334315495994,
        "precision": 0.41512453688102385,
        "recall": 0.49966733200266134
      },
      {
        "accuracy": 0.8596141051230871,
        "f1": 0.830793967620315,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.830793967620315,
        "precision": 0.818059119855527,
        "recall": 0.8596141051230871
      },
      {
        "accuracy": 0.8995342648037259,
        "f1": 0.8793302284320248,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.8793302284320248,
        "precision": 0.87008205810601,
        "recall": 0.8995342648037259
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004199335875660646,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.004199335875660646,
        "precision": 0.0028773090479464964,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.9041916167664671,
        "f1": 0.8821246396096697,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.8821246396096697,
        "precision": 0.8719671767575958,
        "recall": 0.9041916167664671
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8848240027880746,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.8848240027880746,
        "precision": 0.8759924595253937,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.8669328010645376,
        "f1": 0.8371384215695593,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.8371384215695593,
        "precision": 0.8241738744732755,
        "recall": 0.8669328010645376
      },
      {
        "accuracy": 0.7691284098469727,
        "f1": 0.7252114817983082,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.7252114817983082,
        "precision": 0.7063764246398977,
        "recall": 0.7691284098469727
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.004921171297784397,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004921171297784397,
        "precision": 0.0034532862814036316,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.5083166999334664,
        "f1": 0.45322846370750564,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.45322846370750564,
        "precision": 0.4327516923824309,
        "recall": 0.5083166999334664
      },
      {
        "accuracy": 0.8383233532934131,
        "f1": 0.8061432690175204,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.8061432690175204,
        "precision": 0.7917350484216751,
        "recall": 0.8383233532934131
      },
      {
        "accuracy": 0.8735861610113107,
        "f1": 0.8478725089503534,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.8478725089503534,
        "precision": 0.8367930805056553,
        "recall": 0.8735861610113107
      },
      {
        "accuracy": 0.9101796407185628,
        "f1": 0.8874251497005988,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.8874251497005988,
        "precision": 0.8772676868485252,
        "recall": 0.9101796407185628
      },
      {
        "accuracy": 0.8795741849634066,
        "f1": 0.8530621297088363,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8530621297088363,
        "precision": 0.841173209137281,
        "recall": 0.8795741849634066
      },
      {
        "accuracy": 0.9221556886227545,
        "f1": 0.9037924151696607,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9037924151696607,
        "precision": 0.8951541361721003,
        "recall": 0.9221556886227545
      },
      {
        "accuracy": 0.15236194278110446,
        "f1": 0.12250808798966353,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.12250808798966353,
        "precision": 0.11317560554861814,
        "recall": 0.15236194278110446
      },
      {
        "accuracy": 0.6660013306719893,
        "f1": 0.6079000728701327,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6079000728701327,
        "precision": 0.5846101447897855,
        "recall": 0.6660013306719893
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8961188733643825,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8961188733643825,
        "precision": 0.8876136615657573,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.6606786427145709,
        "f1": 0.6015792996830921,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6015792996830921,
        "precision": 0.5793557573497693,
        "recall": 0.6606786427145709
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.8976935018851186,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8976935018851186,
        "precision": 0.8901308494122866,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.9194943446440452,
        "f1": 0.9003009853309255,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9003009853309255,
        "precision": 0.8916056775338214,
        "recall": 0.9194943446440452
      },
      {
        "accuracy": 0.8110445775116434,
        "f1": 0.7746855495358489,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7746855495358489,
        "precision": 0.7592666518814224,
        "recall": 0.8110445775116434
      },
      {
        "accuracy": 0.5355954757152362,
        "f1": 0.47287440510993406,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.47287440510993406,
        "precision": 0.44842750765904466,
        "recall": 0.5355954757152362
      },
      {
        "accuracy": 0.8888888888888888,
        "f1": 0.8642271013528499,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8642271013528499,
        "precision": 0.853459747172322,
        "recall": 0.8888888888888888
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.870316509837468,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.870316509837468,
        "precision": 0.860467952982923,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.008467662787122339,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008467662787122339,
        "precision": 0.0065289809379545285,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8935272312517821,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8935272312517821,
        "precision": 0.8850853847859835,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9002439565313817,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9002439565313817,
        "precision": 0.890940341539144,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8778664892437348,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8778664892437348,
        "precision": 0.8672654690618763,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.791084497671324,
        "f1": 0.7516807654532206,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.7516807654532206,
        "precision": 0.7348371632802772,
        "recall": 0.791084497671324
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.009438493646200698,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009438493646200698,
        "precision": 0.007756398280700329,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.5482368596141052,
        "f1": 0.49062562705277274,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.49062562705277274,
        "precision": 0.46943733984652153,
        "recall": 0.5482368596141052
      },
      {
        "accuracy": 0.825016633399867,
        "f1": 0.7916747701178841,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7916747701178841,
        "precision": 0.7768241295187402,
        "recall": 0.825016633399867
      },
      {
        "accuracy": 0.8735861610113107,
        "f1": 0.8473053892215567,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8473053892215567,
        "precision": 0.83562874251497,
        "recall": 0.8735861610113107
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.904457751164338,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.904457751164338,
        "precision": 0.8960634286981592,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.003371697790568856,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.003371697790568856,
        "precision": 0.002319086119946282,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.0064123416293539025,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0064123416293539025,
        "precision": 0.005207804921445901,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.008306472308461979,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.008306472308461979,
        "precision": 0.006979528015473521,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003230906931360162,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.003230906931360162,
        "precision": 0.002777164992429636,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006579433725142309,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0006579433725142309,
        "precision": 0.00038391231006001464,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007372096182471117,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.007372096182471117,
        "precision": 0.006223079800719299,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0038421921104127023,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0038421921104127023,
        "precision": 0.0034445544193619144,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.003803206628967617,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.003803206628967617,
        "precision": 0.002924817910014684,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.005091634429573731,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.005091634429573731,
        "precision": 0.0044376415617578035,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.0068098563033806596,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0068098563033806596,
        "precision": 0.005338980357731675,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.004883524978064126,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.004883524978064126,
        "precision": 0.004185872823645999,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0020784962265148724,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0020784962265148724,
        "precision": 0.0018292291520155908,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.0058912418327968395,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0058912418327968395,
        "precision": 0.00504427981090575,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.004666734324627502,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.004666734324627502,
        "precision": 0.0039030453453658006,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0030840282585103116,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0030840282585103116,
        "precision": 0.002608799575107922,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0047226416487322585,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0047226416487322585,
        "precision": 0.0039486345881694605,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.006203696969533716,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.006203696969533716,
        "precision": 0.0052652669790307915,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.028524967425265297,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.028524967425265297,
        "precision": 0.025441997198484227,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.0032919336269890517,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0032919336269890517,
        "precision": 0.002751336157802015,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.00335921431067935,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.00335921431067935,
        "precision": 0.0024007181836708464,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.004596514258723244,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.004596514258723244,
        "precision": 0.004072036691781771,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.005002056702721599,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.005002056702721599,
        "precision": 0.004427316618847026,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.886892880904857,
        "f1": 0.8611776447105788,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8611776447105788,
        "precision": 0.8500174254665273,
        "recall": 0.886892880904857
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9049456642271013,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9049456642271013,
        "precision": 0.8966733200266134,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.1596806387225549,
        "f1": 0.1269779020642511,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.1269779020642511,
        "precision": 0.11695715388330159,
        "recall": 0.1596806387225549
      },
      {
        "accuracy": 0.6773120425815037,
        "f1": 0.6231890715922652,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6231890715922652,
        "precision": 0.6013999079338987,
        "recall": 0.6773120425815037
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8882821658270759,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8882821658270759,
        "precision": 0.8796914108291354,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.6114437791084497,
        "f1": 0.5542131853509099,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5542131853509099,
        "precision": 0.5326078002724709,
        "recall": 0.6114437791084497
      },
      {
        "accuracy": 0.908183632734531,
        "f1": 0.8871811931692172,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8871811931692172,
        "precision": 0.8779773785761809,
        "recall": 0.908183632734531
      },
      {
        "accuracy": 0.9121756487025948,
        "f1": 0.8903304502106898,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8903304502106898,
        "precision": 0.880760700820581,
        "recall": 0.9121756487025948
      },
      {
        "accuracy": 0.801729873586161,
        "f1": 0.7651062953458163,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7651062953458163,
        "precision": 0.7495310965370844,
        "recall": 0.801729873586161
      },
      {
        "accuracy": 0.5429141716566867,
        "f1": 0.48477177439253283,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.48477177439253283,
        "precision": 0.4623229731014162,
        "recall": 0.5429141716566867
      },
      {
        "accuracy": 0.9088489687292083,
        "f1": 0.887447327567088,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.887447327567088,
        "precision": 0.8778997560434685,
        "recall": 0.9088489687292083
      },
      {
        "accuracy": 0.8922155688622755,
        "f1": 0.8666223109336881,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8666223109336881,
        "precision": 0.8550343756930583,
        "recall": 0.8922155688622755
      },
      {
        "accuracy": 0.9241516966067864,
        "f1": 0.9080727434020847,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9080727434020847,
        "precision": 0.9009980039920158,
        "recall": 0.9241516966067864
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.009895484317487544,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009895484317487544,
        "precision": 0.008285492069820946,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9066755378132623,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9066755378132623,
        "precision": 0.898148148148148,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.8942115768463074,
        "f1": 0.8712353071634509,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8712353071634509,
        "precision": 0.8611554668440896,
        "recall": 0.8942115768463074
      },
      {
        "accuracy": 0.812375249500998,
        "f1": 0.7745217745217744,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7745217745217744,
        "precision": 0.757972943002883,
        "recall": 0.812375249500998
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.0050447886600101886,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0050447886600101886,
        "precision": 0.003427837879141769,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.5342648037258816,
        "f1": 0.48160593749416103,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.48160593749416103,
        "precision": 0.4625500562127308,
        "recall": 0.5342648037258816
      },
      {
        "accuracy": 0.8023952095808383,
        "f1": 0.7616671419066628,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7616671419066628,
        "precision": 0.7436127744510979,
        "recall": 0.8023952095808383
      },
      {
        "accuracy": 0.867598137059215,
        "f1": 0.8381586034280645,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8381586034280645,
        "precision": 0.8251497005988023,
        "recall": 0.867598137059215
      },
      {
        "accuracy": 0.9328010645375915,
        "f1": 0.9154690618762474,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9154690618762474,
        "precision": 0.9075579000728702,
        "recall": 0.9328010645375915
      },
      {
        "accuracy": 0.8928809048569527,
        "f1": 0.8683743623863385,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.8683743623863385,
        "precision": 0.8579174983366599,
        "recall": 0.8928809048569527
      },
      {
        "accuracy": 0.9308050565535595,
        "f1": 0.9135063206919495,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9135063206919495,
        "precision": 0.9053005100909293,
        "recall": 0.9308050565535595
      },
      {
        "accuracy": 0.15701929474384566,
        "f1": 0.12142666067228707,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.12142666067228707,
        "precision": 0.11131772074229263,
        "recall": 0.15701929474384566
      },
      {
        "accuracy": 0.6540252827677977,
        "f1": 0.6009386469965312,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.6009386469965312,
        "precision": 0.5798414375730332,
        "recall": 0.6540252827677977
      },
      {
        "accuracy": 0.9015302727877578,
        "f1": 0.8775464943129613,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.8775464943129613,
        "precision": 0.8671213129296962,
        "recall": 0.9015302727877578
      },
      {
        "accuracy": 0.5808383233532934,
        "f1": 0.5203904840631387,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.5203904840631387,
        "precision": 0.496739796390495,
        "recall": 0.5808383233532934
      },
      {
        "accuracy": 0.9128409846972722,
        "f1": 0.8933466400532267,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.8933466400532267,
        "precision": 0.8845309381237524,
        "recall": 0.9128409846972722
      },
      {
        "accuracy": 0.914836992681304,
        "f1": 0.8942559325792858,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.8942559325792858,
        "precision": 0.8847305389221557,
        "recall": 0.914836992681304
      },
      {
        "accuracy": 0.8063872255489022,
        "f1": 0.7665071972457203,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.7665071972457203,
        "precision": 0.7491516966067864,
        "recall": 0.8063872255489022
      },
      {
        "accuracy": 0.543579507651364,
        "f1": 0.48156337637375557,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.48156337637375557,
        "precision": 0.4578269387151622,
        "recall": 0.543579507651364
      },
      {
        "accuracy": 0.8915502328675982,
        "f1": 0.8690396983810158,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.8690396983810158,
        "precision": 0.8593812375249502,
        "recall": 0.8915502328675982
      },
      {
        "accuracy": 0.9021956087824351,
        "f1": 0.8803852612235846,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.8803852612235846,
        "precision": 0.8705921490352628,
        "recall": 0.9021956087824351
      },
      {
        "accuracy": 0.9228210246174318,
        "f1": 0.9049013084941229,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9049013084941229,
        "precision": 0.8967287646928366,
        "recall": 0.9228210246174318
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.009416121049520916,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.009416121049520916,
        "precision": 0.006715722030330908,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.8994899090707474,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.8994899090707474,
        "precision": 0.8901086715457974,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8637170104235973,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.8637170104235973,
        "precision": 0.8521512530494566,
        "recall": 0.8895542248835662
      },
      {
        "accuracy": 0.7797737857618097,
        "f1": 0.7336438234641827,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.7336438234641827,
        "precision": 0.7136776951148209,
        "recall": 0.7797737857618097
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.00872406214242657,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00872406214242657,
        "precision": 0.006789923363960696,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.5249500998003992,
        "f1": 0.47076536238212885,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.47076536238212885,
        "precision": 0.45075193528287344,
        "recall": 0.5249500998003992
      },
      {
        "accuracy": 0.8296739853626082,
        "f1": 0.795645745545945,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.795645745545945,
        "precision": 0.7807884231536927,
        "recall": 0.8296739853626082
      },
      {
        "accuracy": 0.8809048569527611,
        "f1": 0.8540252827677977,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.8540252827677977,
        "precision": 0.8418939897981815,
        "recall": 0.8809048569527611
      },
      {
        "accuracy": 0.9248170326014638,
        "f1": 0.9062763362164561,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9062763362164561,
        "precision": 0.8978709248170326,
        "recall": 0.9248170326014638
      },
      {
        "accuracy": 0.874251497005988,
        "f1": 0.8436143585844184,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.8436143585844184,
        "precision": 0.8296074517631403,
        "recall": 0.874251497005988
      },
      {
        "accuracy": 0.9095143047238856,
        "f1": 0.8870259481037924,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.8870259481037924,
        "precision": 0.8765247283211356,
        "recall": 0.9095143047238856
      },
      {
        "accuracy": 0.1550232867598137,
        "f1": 0.12070627364451482,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.12070627364451482,
        "precision": 0.11112981080252421,
        "recall": 0.1550232867598137
      },
      {
        "accuracy": 0.6872920825016633,
        "f1": 0.630890119712475,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.630890119712475,
        "precision": 0.6074272090739157,
        "recall": 0.6872920825016633
      },
      {
        "accuracy": 0.89354624085163,
        "f1": 0.8675870481259703,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.8675870481259703,
        "precision": 0.8565377182143649,
        "recall": 0.89354624085163
      },
      {
        "accuracy": 0.582168995342648,
        "f1": 0.5178192252044548,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.5178192252044548,
        "precision": 0.4936191349864005,
        "recall": 0.582168995342648
      },
      {
        "accuracy": 0.916833000665336,
        "f1": 0.8982479485473497,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.8982479485473497,
        "precision": 0.889997782213351,
        "recall": 0.916833000665336
      },
      {
        "accuracy": 0.9115103127079175,
        "f1": 0.8891824815976512,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.8891824815976512,
        "precision": 0.8795908183632735,
        "recall": 0.9115103127079175
      },
      {
        "accuracy": 0.7791084497671324,
        "f1": 0.7347305389221557,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.7347305389221557,
        "precision": 0.7162912270696701,
        "recall": 0.7791084497671324
      },
      {
        "accuracy": 0.5622089155023287,
        "f1": 0.49549424479564197,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.49549424479564197,
        "precision": 0.46896920444824636,
        "recall": 0.5622089155023287
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8732091372809936,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.8732091372809936,
        "precision": 0.8621867376358393,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.8662674650698603,
        "f1": 0.83301333840256,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.83301333840256,
        "precision": 0.8180490870111629,
        "recall": 0.8662674650698603
      },
      {
        "accuracy": 0.9075182967398536,
        "f1": 0.8856509203814594,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.8856509203814594,
        "precision": 0.8756043468618319,
        "recall": 0.9075182967398536
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.012056198558137471,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.012056198558137471,
        "precision": 0.009634486462100583,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8827677977378577,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.8827677977378577,
        "precision": 0.8723663783544022,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.8982035928143712,
        "f1": 0.8737857618097139,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.8737857618097139,
        "precision": 0.8625194056331782,
        "recall": 0.8982035928143712
      },
      {
        "accuracy": 0.7504990019960079,
        "f1": 0.7003881126635618,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.7003881126635618,
        "precision": 0.6791087377913726,
        "recall": 0.7504990019960079
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.007286370614616084,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.007286370614616084,
        "precision": 0.0054674864285058425,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.5562208915502329,
        "f1": 0.4951398789722143,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.4951398789722143,
        "precision": 0.4711909514304724,
        "recall": 0.5562208915502329
      },
      {
        "accuracy": 0.7857618097139055,
        "f1": 0.7447924737345895,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.7447924737345895,
        "precision": 0.7270292747837658,
        "recall": 0.7857618097139055
      },
      {
        "accuracy": 0.833666001330672,
        "f1": 0.796362829895764,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.796362829895764,
        "precision": 0.7798403193612774,
        "recall": 0.833666001330672
      },
      {
        "accuracy": 0.9321357285429142,
        "f1": 0.9165225105344865,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.9165225105344865,
        "precision": 0.9097249944555333,
        "recall": 0.9321357285429142
      },
      {
        "accuracy": 0.7518296739853626,
        "f1": 0.7078784230480837,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7078784230480837,
        "precision": 0.6894650093751891,
        "recall": 0.7518296739853626
      },
      {
        "accuracy": 0.803725881570193,
        "f1": 0.7626787938165184,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7626787938165184,
        "precision": 0.7452982923042804,
        "recall": 0.803725881570193
      },
      {
        "accuracy": 0.1317365269461078,
        "f1": 0.10710676854042295,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.10710676854042295,
        "precision": 0.09994927384853415,
        "recall": 0.1317365269461078
      },
      {
        "accuracy": 0.5076513639387891,
        "f1": 0.44607403759100367,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.44607403759100367,
        "precision": 0.4233723030130216,
        "recall": 0.5076513639387891
      },
      {
        "accuracy": 0.6686626746506986,
        "f1": 0.6273525389075273,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6273525389075273,
        "precision": 0.613106874274539,
        "recall": 0.6686626746506986
      },
      {
        "accuracy": 0.47904191616766467,
        "f1": 0.4236070667707394,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4236070667707394,
        "precision": 0.4043649981274732,
        "recall": 0.47904191616766467
      },
      {
        "accuracy": 0.7578176979374585,
        "f1": 0.719661734731595,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.719661734731595,
        "precision": 0.7043310204986853,
        "recall": 0.7578176979374585
      },
      {
        "accuracy": 0.7478376580172987,
        "f1": 0.702173430915946,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.702173430915946,
        "precision": 0.6843828216582707,
        "recall": 0.7478376580172987
      },
      {
        "accuracy": 0.6400532268795742,
        "f1": 0.5908452603063381,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5908452603063381,
        "precision": 0.5717205393852101,
        "recall": 0.6400532268795742
      },
      {
        "accuracy": 0.43446440452428475,
        "f1": 0.38042161505235356,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.38042161505235356,
        "precision": 0.36054003104901305,
        "recall": 0.43446440452428475
      },
      {
        "accuracy": 0.7784431137724551,
        "f1": 0.7352121154516363,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7352121154516363,
        "precision": 0.7167627707547866,
        "recall": 0.7784431137724551
      },
      {
        "accuracy": 0.7491683300066534,
        "f1": 0.7020435319836518,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.7020435319836518,
        "precision": 0.6823685961410512,
        "recall": 0.7491683300066534
      },
      {
        "accuracy": 0.7950765136393879,
        "f1": 0.7579423644293902,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7579423644293902,
        "precision": 0.7424048727940943,
        "recall": 0.7950765136393879
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.008739431661950469,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008739431661950469,
        "precision": 0.007058110040317667,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.8070525615435795,
        "f1": 0.7698507746411938,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7698507746411938,
        "precision": 0.7537480594366821,
        "recall": 0.8070525615435795
      },
      {
        "accuracy": 0.7864271457085829,
        "f1": 0.7427990579687186,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7427990579687186,
        "precision": 0.7238467509425592,
        "recall": 0.7864271457085829
      },
      {
        "accuracy": 0.739853626081171,
        "f1": 0.6963158339405844,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6963158339405844,
        "precision": 0.6791166344559557,
        "recall": 0.739853626081171
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.009174513606753107,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009174513606753107,
        "precision": 0.007153796816576519,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.4231536926147705,
        "f1": 0.37579576297141165,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.37579576297141165,
        "precision": 0.3583501901366173,
        "recall": 0.4231536926147705
      },
      {
        "accuracy": 0.6447105788423154,
        "f1": 0.5871009304143036,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5871009304143036,
        "precision": 0.5634152330260115,
        "recall": 0.6447105788423154
      },
      {
        "accuracy": 0.7225548902195609,
        "f1": 0.6761968127237589,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6761968127237589,
        "precision": 0.6576402750055446,
        "recall": 0.7225548902195609
      },
      {
        "accuracy": 0.7950765136393879,
        "f1": 0.7524543505581429,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7524543505581429,
        "precision": 0.7346869752558375,
        "recall": 0.7950765136393879
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.004093737404456814,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.004093737404456814,
        "precision": 0.0033879834885739493,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.006301097274383019,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.006301097274383019,
        "precision": 0.004860046488619361,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.015968063872255488,
        "f1": 0.007053581517298407,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.007053581517298407,
        "precision": 0.0057602886043313685,
        "recall": 0.015968063872255488
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0038040173010534944,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0038040173010534944,
        "precision": 0.0032601471341638065,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0025282767797737858,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0025282767797737858,
        "precision": 0.002328675981370592,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.005029567964125322,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.005029567964125322,
        "precision": 0.004342436697936436,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.007984031936127744,
        "f1": 0.004100018067905854,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.004100018067905854,
        "precision": 0.0036533237053337792,
        "recall": 0.007984031936127744
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005204727246578317,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.005204727246578317,
        "precision": 0.004562778316779281,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0045222444403823624,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0045222444403823624,
        "precision": 0.003806489685981291,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.009441173904717043,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.009441173904717043,
        "precision": 0.00787715808579713,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.002953150078161753,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.002953150078161753,
        "precision": 0.002813755225726684,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0012129581059232306,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0012129581059232306,
        "precision": 0.000844711209080569,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.007466577573125339,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.007466577573125339,
        "precision": 0.0069103919696143976,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.03992015968063872,
        "f1": 0.0284329929206842,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.0284329929206842,
        "precision": 0.025164489535747018,
        "recall": 0.03992015968063872
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005285041348336678,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.005285041348336678,
        "precision": 0.004667766029383211,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.004884034822299648,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.004884034822299648,
        "precision": 0.004281600344376372,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.005279524343890527,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.005279524343890527,
        "precision": 0.004588060939633969,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.00380815625721832,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.00380815625721832,
        "precision": 0.00288561562564183,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0033174710535848894,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0033174710535848894,
        "precision": 0.0027755631775013673,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.00422495458200231,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.00422495458200231,
        "precision": 0.003497810659942622,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0026465318766623817,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0026465318766623817,
        "precision": 0.002370218056544495,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.00416168821215515,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.00416168821215515,
        "precision": 0.0036373082736917,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.4750499001996008,
        "f1": 0.4157279906150586,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4157279906150586,
        "precision": 0.3949368458849497,
        "recall": 0.4750499001996008
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.46113021049989217,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.46113021049989217,
        "precision": 0.4372452366805765,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.18163672654690619,
        "f1": 0.14868975372967388,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.14868975372967388,
        "precision": 0.13847278986999545,
        "recall": 0.18163672654690619
      },
      {
        "accuracy": 0.5016633399866933,
        "f1": 0.4394719323926128,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4394719323926128,
        "precision": 0.41624120685996935,
        "recall": 0.5016633399866933
      },
      {
        "accuracy": 0.40718562874251496,
        "f1": 0.36436076619517516,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.36436076619517516,
        "precision": 0.3512747024054131,
        "recall": 0.40718562874251496
      },
      {
        "accuracy": 0.42381902860944776,
        "f1": 0.3667229649431912,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3667229649431912,
        "precision": 0.34689268556534025,
        "recall": 0.42381902860944776
      },
      {
        "accuracy": 0.5495675316034597,
        "f1": 0.496693160708551,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.496693160708551,
        "precision": 0.4775204807688228,
        "recall": 0.5495675316034597
      },
      {
        "accuracy": 0.5921490352628077,
        "f1": 0.529355061291189,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.529355061291189,
        "precision": 0.507800239237365,
        "recall": 0.5921490352628077
      },
      {
        "accuracy": 0.4530938123752495,
        "f1": 0.4052455343872509,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4052455343872509,
        "precision": 0.3891667525291917,
        "recall": 0.4530938123752495
      },
      {
        "accuracy": 0.36327345309381237,
        "f1": 0.3098882561956414,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3098882561956414,
        "precision": 0.29044846814307895,
        "recall": 0.36327345309381237
      },
      {
        "accuracy": 0.5229540918163673,
        "f1": 0.4612357283357388,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4612357283357388,
        "precision": 0.4396328508104955,
        "recall": 0.5229540918163673
      },
      {
        "accuracy": 0.499001996007984,
        "f1": 0.4338332701772488,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4338332701772488,
        "precision": 0.41176456979850196,
        "recall": 0.499001996007984
      },
      {
        "accuracy": 0.5362608117099135,
        "f1": 0.4715067103885816,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4715067103885816,
        "precision": 0.44901295293011867,
        "recall": 0.5362608117099135
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.006590705443000852,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006590705443000852,
        "precision": 0.004876348300519449,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.5282767797737857,
        "f1": 0.46602103394482125,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.46602103394482125,
        "precision": 0.4451848135231368,
        "recall": 0.5282767797737857
      },
      {
        "accuracy": 0.5096473719228211,
        "f1": 0.44518699917314447,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.44518699917314447,
        "precision": 0.4238716953948256,
        "recall": 0.5096473719228211
      },
      {
        "accuracy": 0.5469061876247505,
        "f1": 0.4889104574733318,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4889104574733318,
        "precision": 0.4680184844356501,
        "recall": 0.5469061876247505
      },
      {
        "accuracy": 0.41650033266799735,
        "f1": 0.34963081569867993,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.34963081569867993,
        "precision": 0.32679385247669734,
        "recall": 0.41650033266799735
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.0074396245113268235,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0074396245113268235,
        "precision": 0.0060047271060349175,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.437125748502994,
        "f1": 0.3772202012521374,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3772202012521374,
        "precision": 0.3560300994931734,
        "recall": 0.437125748502994
      },
      {
        "accuracy": 0.4703925482368596,
        "f1": 0.40729329428185584,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.40729329428185584,
        "precision": 0.38674828812054357,
        "recall": 0.4703925482368596
      },
      {
        "accuracy": 0.5322687957418496,
        "f1": 0.46867723738601896,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.46867723738601896,
        "precision": 0.44658839607941403,
        "recall": 0.5322687957418496
      },
      {
        "accuracy": 0.7684630738522954,
        "f1": 0.7222560650704363,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.7222560650704363,
        "precision": 0.7024791686468331,
        "recall": 0.7684630738522954
      },
      {
        "accuracy": 0.8403193612774451,
        "f1": 0.8082427737118355,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.8082427737118355,
        "precision": 0.7940225609387286,
        "recall": 0.8403193612774451
      },
      {
        "accuracy": 0.1270791749833666,
        "f1": 0.09428655915681863,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.09428655915681863,
        "precision": 0.08437372166164582,
        "recall": 0.1270791749833666
      },
      {
        "accuracy": 0.5329341317365269,
        "f1": 0.4677459895024765,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.4677459895024765,
        "precision": 0.442130047167032,
        "recall": 0.5329341317365269
      },
      {
        "accuracy": 0.7930805056553559,
        "f1": 0.7532884447555106,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.7532884447555106,
        "precision": 0.7375410794572471,
        "recall": 0.7930805056553559
      },
      {
        "accuracy": 0.4976713240186294,
        "f1": 0.4376709426294466,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.4376709426294466,
        "precision": 0.4148805157288191,
        "recall": 0.4976713240186294
      },
      {
        "accuracy": 0.8010645375914837,
        "f1": 0.7657035136077052,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.7657035136077052,
        "precision": 0.7513560181224851,
        "recall": 0.8010645375914837
      },
      {
        "accuracy": 0.8303393213572854,
        "f1": 0.7964521174102012,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.7964521174102012,
        "precision": 0.7813040585495675,
        "recall": 0.8303393213572854
      },
      {
        "accuracy": 0.7677977378576181,
        "f1": 0.724654394913876,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.724654394913876,
        "precision": 0.7060762313756325,
        "recall": 0.7677977378576181
      },
      {
        "accuracy": 0.4457751164337991,
        "f1": 0.38702705219671285,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.38702705219671285,
        "precision": 0.36445125621772323,
        "recall": 0.4457751164337991
      },
      {
        "accuracy": 0.7711244178310046,
        "f1": 0.7260510724582581,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.7260510724582581,
        "precision": 0.7069960607884761,
        "recall": 0.7711244178310046
      },
      {
        "accuracy": 0.8216899534264803,
        "f1": 0.7863542755758325,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.7863542755758325,
        "precision": 0.7702040363717011,
        "recall": 0.8216899534264803
      },
      {
        "accuracy": 0.8170326014637392,
        "f1": 0.7835662009314704,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.7835662009314704,
        "precision": 0.7689509869150586,
        "recall": 0.8170326014637392
      },
      {
        "accuracy": 0.017964071856287425,
        "f1": 0.006607621190993147,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.006607621190993147,
        "precision": 0.004940117729538887,
        "recall": 0.017964071856287425
      },
      {
        "accuracy": 0.8043912175648703,
        "f1": 0.7628108861641796,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.7628108861641796,
        "precision": 0.7447992903082724,
        "recall": 0.8043912175648703
      },
      {
        "accuracy": 0.8236859614105123,
        "f1": 0.7881902860944777,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.7881902860944777,
        "precision": 0.7726610271520451,
        "recall": 0.8236859614105123
      },
      {
        "accuracy": 0.780439121756487,
        "f1": 0.7393552001336432,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.7393552001336432,
        "precision": 0.7220067800906124,
        "recall": 0.780439121756487
      },
      {
        "accuracy": 0.6713240186294078,
        "f1": 0.6152499714375962,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.6152499714375962,
        "precision": 0.5914068688020783,
        "recall": 0.6713240186294078
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0031485473251531603,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0031485473251531603,
        "precision": 0.00193463564970551,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.4550898203592814,
        "f1": 0.398066349263954,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.398066349263954,
        "precision": 0.37777938591311844,
        "recall": 0.4550898203592814
      },
      {
        "accuracy": 0.83166999334664,
        "f1": 0.7946456293761682,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.7946456293761682,
        "precision": 0.7780217343091596,
        "recall": 0.83166999334664
      },
      {
        "accuracy": 0.8296739853626082,
        "f1": 0.7943709650296477,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.7943709650296477,
        "precision": 0.7792858726990465,
        "recall": 0.8296739853626082
      },
      {
        "accuracy": 0.8483033932135728,
        "f1": 0.8178436777239172,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.8178436777239172,
        "precision": 0.8046795298292305,
        "recall": 0.8483033932135728
      },
      {
        "accuracy": 0.9055222887558216,
        "f1": 0.8852073630516745,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.8852073630516745,
        "precision": 0.8760479041916166,
        "recall": 0.9055222887558216
      },
      {
        "accuracy": 0.1370592149035263,
        "f1": 0.10784368959860083,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.10784368959860083,
        "precision": 0.09904142144367575,
        "recall": 0.1370592149035263
      },
      {
        "accuracy": 0.6061210911510313,
        "f1": 0.5478307934395759,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.5478307934395759,
        "precision": 0.5250994957581784,
        "recall": 0.6061210911510313
      },
      {
        "accuracy": 0.8795741849634066,
        "f1": 0.8566787060799036,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8566787060799036,
        "precision": 0.8474669708202641,
        "recall": 0.8795741849634066
      },
      {
        "accuracy": 0.5482368596141052,
        "f1": 0.49255162415683484,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.49255162415683484,
        "precision": 0.4728107277508475,
        "recall": 0.5482368596141052
      },
      {
        "accuracy": 0.8715901530272788,
        "f1": 0.8482843836137249,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.8482843836137249,
        "precision": 0.8387447327567087,
        "recall": 0.8715901530272788
      },
      {
        "accuracy": 0.884896872920825,
        "f1": 0.8625542565662326,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.8625542565662326,
        "precision": 0.8526502550454647,
        "recall": 0.884896872920825
      },
      {
        "accuracy": 0.8097139055222887,
        "f1": 0.770782245033742,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.770782245033742,
        "precision": 0.7547920032949973,
        "recall": 0.8097139055222887
      },
      {
        "accuracy": 0.499001996007984,
        "f1": 0.44278691294659367,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.44278691294659367,
        "precision": 0.42153154009441435,
        "recall": 0.499001996007984
      },
      {
        "accuracy": 0.850964737192282,
        "f1": 0.8216376770268986,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.8216376770268986,
        "precision": 0.8094651965909451,
        "recall": 0.850964737192282
      },
      {
        "accuracy": 0.8782435129740519,
        "f1": 0.8538827107689382,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.8538827107689382,
        "precision": 0.8432024839210469,
        "recall": 0.8782435129740519
      },
      {
        "accuracy": 0.8829008649367931,
        "f1": 0.8596267781896526,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.8596267781896526,
        "precision": 0.8491350632069194,
        "recall": 0.8829008649367931
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.006436186477140025,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.006436186477140025,
        "precision": 0.005082843739944907,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.8842315369261478,
        "f1": 0.8580521496689162,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.8580521496689162,
        "precision": 0.8467509425593257,
        "recall": 0.8842315369261478
      },
      {
        "accuracy": 0.884896872920825,
        "f1": 0.8575663487839137,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.8575663487839137,
        "precision": 0.8452705699711688,
        "recall": 0.884896872920825
      },
      {
        "accuracy": 0.8429807052561543,
        "f1": 0.8101479580521497,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.8101479580521497,
        "precision": 0.7963184741627857,
        "recall": 0.8429807052561543
      },
      {
        "accuracy": 0.7584830339321357,
        "f1": 0.7146579043784632,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.7146579043784632,
        "precision": 0.6960642207648196,
        "recall": 0.7584830339321357
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.0059949699783200415,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0059949699783200415,
        "precision": 0.004435630247628541,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.4856952761144378,
        "f1": 0.4329773981470588,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.4329773981470588,
        "precision": 0.41377483128980136,
        "recall": 0.4856952761144378
      },
      {
        "accuracy": 0.8423153692614771,
        "f1": 0.8113550676424928,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.8113550676424928,
        "precision": 0.7973164781548016,
        "recall": 0.8423153692614771
      },
      {
        "accuracy": 0.9001996007984032,
        "f1": 0.8781991572410734,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.8781991572410734,
        "precision": 0.8684187181193169,
        "recall": 0.9001996007984032
      },
      {
        "accuracy": 0.9021956087824351,
        "f1": 0.8810157462852073,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8810157462852073,
        "precision": 0.8720743697789605,
        "recall": 0.9021956087824351
      },
      {
        "accuracy": 0.9314703925482368,
        "f1": 0.9153914393435353,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9153914393435353,
        "precision": 0.9082390774007542,
        "recall": 0.9314703925482368
      },
      {
        "accuracy": 0.1490352628077179,
        "f1": 0.11535984351321417,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.11535984351321417,
        "precision": 0.10509460353106394,
        "recall": 0.1490352628077179
      },
      {
        "accuracy": 0.6706586826347305,
        "f1": 0.6143633368184266,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6143633368184266,
        "precision": 0.5921764529548961,
        "recall": 0.6706586826347305
      },
      {
        "accuracy": 0.9367930805056554,
        "f1": 0.9205810601020182,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9205810601020182,
        "precision": 0.9137059214903526,
        "recall": 0.9367930805056554
      },
      {
        "accuracy": 0.5954757152361942,
        "f1": 0.5321886652409817,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5321886652409817,
        "precision": 0.5088864598844639,
        "recall": 0.5954757152361942
      },
      {
        "accuracy": 0.9201596806387226,
        "f1": 0.9015635395874918,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9015635395874918,
        "precision": 0.8936412888508698,
        "recall": 0.9201596806387226
      },
      {
        "accuracy": 0.9387890884896873,
        "f1": 0.9232867598137058,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9232867598137058,
        "precision": 0.9165779552007097,
        "recall": 0.9387890884896873
      },
      {
        "accuracy": 0.803725881570193,
        "f1": 0.7639440695328918,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.7639440695328918,
        "precision": 0.7475947815768175,
        "recall": 0.803725881570193
      },
      {
        "accuracy": 0.6041250831669993,
        "f1": 0.5459604600323164,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.5459604600323164,
        "precision": 0.5232254254210342,
        "recall": 0.6041250831669993
      },
      {
        "accuracy": 0.9161676646706587,
        "f1": 0.8953109653708455,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8953109653708455,
        "precision": 0.8859724994455535,
        "recall": 0.9161676646706587
      },
      {
        "accuracy": 0.8975382568196939,
        "f1": 0.8743845642049234,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8743845642049234,
        "precision": 0.8641273009536482,
        "recall": 0.8975382568196939
      },
      {
        "accuracy": 0.9254823685961411,
        "f1": 0.9090929252605898,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9090929252605898,
        "precision": 0.9019405633178088,
        "recall": 0.9254823685961411
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.008972382085738407,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.008972382085738407,
        "precision": 0.006794319388867136,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.929474384564205,
        "f1": 0.9127966289642937,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9127966289642937,
        "precision": 0.9055444666223109,
        "recall": 0.929474384564205
      },
      {
        "accuracy": 0.927478376580173,
        "f1": 0.9106453759148369,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9106453759148369,
        "precision": 0.9033599467731205,
        "recall": 0.927478376580173
      },
      {
        "accuracy": 0.9155023286759814,
        "f1": 0.8968507429585274,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8968507429585274,
        "precision": 0.8887114659569749,
        "recall": 0.9155023286759814
      },
      {
        "accuracy": 0.801729873586161,
        "f1": 0.762228899953451,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.762228899953451,
        "precision": 0.745331559104014,
        "recall": 0.801729873586161
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.0065797704557409905,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0065797704557409905,
        "precision": 0.005094821529859029,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.5535595475715236,
        "f1": 0.49782711189896817,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.49782711189896817,
        "precision": 0.477413715138266,
        "recall": 0.5535595475715236
      },
      {
        "accuracy": 0.83166999334664,
        "f1": 0.8010217659918258,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8010217659918258,
        "precision": 0.7879415771631341,
        "recall": 0.83166999334664
      },
      {
        "accuracy": 0.8895542248835662,
        "f1": 0.8652821341444096,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8652821341444096,
        "precision": 0.8551119982257706,
        "recall": 0.8895542248835662
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}