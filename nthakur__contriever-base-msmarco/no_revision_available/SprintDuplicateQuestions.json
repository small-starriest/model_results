{
    "test": {
        "cos_sim": {
            "accuracy": 0.9984356435643564,
            "accuracy_threshold": 0.7485564351081848,
            "ap": 0.9554507015913917,
            "f1": 0.9210789210789211,
            "f1_threshold": 0.7485564351081848,
            "precision": 0.9201596806387226,
            "recall": 0.922
        },
        "dot": {
            "accuracy": 0.997950495049505,
            "accuracy_threshold": 1.7159266471862793,
            "ap": 0.9439559714606074,
            "f1": 0.8973723351512147,
            "f1_threshold": 1.7159266471862793,
            "precision": 0.8898721730580138,
            "recall": 0.905
        },
        "euclidean": {
            "accuracy": 0.997990099009901,
            "accuracy_threshold": 1.0682193040847778,
            "ap": 0.9456986031661518,
            "f1": 0.8981435022579027,
            "f1_threshold": 1.0692650079727173,
            "precision": 0.9013091641490433,
            "recall": 0.895
        },
        "evaluation_time": 11.08,
        "manhattan": {
            "accuracy": 0.998009900990099,
            "accuracy_threshold": 23.450923919677734,
            "ap": 0.9453283582657289,
            "f1": 0.8983308042488619,
            "f1_threshold": 23.450923919677734,
            "precision": 0.9089048106448311,
            "recall": 0.888
        },
        "max": {
            "accuracy": 0.9984356435643564,
            "ap": 0.9554507015913917,
            "f1": 0.9210789210789211
        }
    },
    "mteb_version": "0.0.2",
    "mteb_dataset_name": "SprintDuplicateQuestions",
    "dataset_revision": "5a8256d0dff9c4bd3be3ba3e67e4e70173f802ea"
}