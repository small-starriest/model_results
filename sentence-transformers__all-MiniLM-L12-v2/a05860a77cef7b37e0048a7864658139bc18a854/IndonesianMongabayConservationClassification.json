{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 16.404426097869873,
  "kg_co2_emissions": 0.0024331624690539936,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.3156601842374616,
        "f1": 0.3118871610160072,
        "f1_weighted": 0.3180437128589567,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.3118871610160072,
        "scores_per_experiment": [
          {
            "accuracy": 0.300921187308086,
            "f1": 0.30167407933187845,
            "f1_weighted": 0.3046429995444529
          },
          {
            "accuracy": 0.34390992835209827,
            "f1": 0.3375136508677845,
            "f1_weighted": 0.3527047668242105
          },
          {
            "accuracy": 0.3039918116683726,
            "f1": 0.2992563637127958,
            "f1_weighted": 0.310305865391525
          },
          {
            "accuracy": 0.3705220061412487,
            "f1": 0.35246719430566037,
            "f1_weighted": 0.3696825820647594
          },
          {
            "accuracy": 0.2906857727737973,
            "f1": 0.29099169943206643,
            "f1_weighted": 0.290364463928548
          },
          {
            "accuracy": 0.3039918116683726,
            "f1": 0.30364440235757084,
            "f1_weighted": 0.30387766446725484
          },
          {
            "accuracy": 0.33162743091095187,
            "f1": 0.33186010585160963,
            "f1_weighted": 0.3270768594868315
          },
          {
            "accuracy": 0.3039918116683726,
            "f1": 0.3031138747453936,
            "f1_weighted": 0.3104336556605718
          },
          {
            "accuracy": 0.33265097236438074,
            "f1": 0.32566462204761687,
            "f1_weighted": 0.3368787849691262
          },
          {
            "accuracy": 0.2743091095189355,
            "f1": 0.27268561750769565,
            "f1_weighted": 0.274469486252287
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.3282520325203252,
        "f1": 0.3235151123959868,
        "f1_weighted": 0.3299592910962755,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.3235151123959868,
        "scores_per_experiment": [
          {
            "accuracy": 0.3150406504065041,
            "f1": 0.31459419479501044,
            "f1_weighted": 0.32029602170902427
          },
          {
            "accuracy": 0.3231707317073171,
            "f1": 0.3188864595630663,
            "f1_weighted": 0.3323877893463469
          },
          {
            "accuracy": 0.31910569105691056,
            "f1": 0.31373051136672286,
            "f1_weighted": 0.3225440576885883
          },
          {
            "accuracy": 0.40040650406504064,
            "f1": 0.3802996039088305,
            "f1_weighted": 0.3968195373331555
          },
          {
            "accuracy": 0.2845528455284553,
            "f1": 0.2841970484095148,
            "f1_weighted": 0.2827928599943837
          },
          {
            "accuracy": 0.3353658536585366,
            "f1": 0.33368182375751926,
            "f1_weighted": 0.33840256489927917
          },
          {
            "accuracy": 0.3516260162601626,
            "f1": 0.35060599700849143,
            "f1_weighted": 0.34442948988109123
          },
          {
            "accuracy": 0.3089430894308943,
            "f1": 0.3093517979896543,
            "f1_weighted": 0.3118117536282229
          },
          {
            "accuracy": 0.3516260162601626,
            "f1": 0.3412169059547691,
            "f1_weighted": 0.3564682634829779
          },
          {
            "accuracy": 0.2926829268292683,
            "f1": 0.28858678120628917,
            "f1_weighted": 0.29364057299968477
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}