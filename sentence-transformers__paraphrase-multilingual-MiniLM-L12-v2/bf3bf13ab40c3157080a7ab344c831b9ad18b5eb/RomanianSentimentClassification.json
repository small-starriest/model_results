{
  "dataset_revision": "155048684cea7a6d6af1ddbfeb9a04820311ce93",
  "evaluation_time": 10.244195461273193,
  "kg_co2_emissions": 0.0015366425568407553,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.6626953125,
        "ap": 0.681228683146329,
        "ap_weighted": 0.681228683146329,
        "f1": 0.6564935232118015,
        "f1_weighted": 0.6554671213171971,
        "hf_subset": "default",
        "languages": [
          "ron-Latn"
        ],
        "main_score": 0.6626953125,
        "scores_per_experiment": [
          {
            "accuracy": 0.61474609375,
            "ap": 0.6402183864581755,
            "ap_weighted": 0.6402183864581755,
            "f1": 0.6146203077319348,
            "f1_weighted": 0.6137636029602473
          },
          {
            "accuracy": 0.697265625,
            "ap": 0.7437330380783166,
            "ap_weighted": 0.7437330380783166,
            "f1": 0.691748065414199,
            "f1_weighted": 0.6866735215615644
          },
          {
            "accuracy": 0.57763671875,
            "ap": 0.6407470878911659,
            "ap_weighted": 0.6407470878911659,
            "f1": 0.5584419145184105,
            "f1_weighted": 0.5471138333325544
          },
          {
            "accuracy": 0.7470703125,
            "ap": 0.7290042712637077,
            "ap_weighted": 0.7290042712637077,
            "f1": 0.7438961741246451,
            "f1_weighted": 0.7474044323289848
          },
          {
            "accuracy": 0.56005859375,
            "ap": 0.6220161556148701,
            "ap_weighted": 0.6220161556148701,
            "f1": 0.5434162669930863,
            "f1_weighted": 0.5326902661165077
          },
          {
            "accuracy": 0.712890625,
            "ap": 0.7347199543767933,
            "ap_weighted": 0.7347199543767933,
            "f1": 0.7120599569031066,
            "f1_weighted": 0.7101569718084053
          },
          {
            "accuracy": 0.6240234375,
            "ap": 0.6282221137941689,
            "ap_weighted": 0.6282221137941689,
            "f1": 0.6158908780903667,
            "f1_weighted": 0.6227680759803922
          },
          {
            "accuracy": 0.68896484375,
            "ap": 0.6895327400949326,
            "ap_weighted": 0.6895327400949326,
            "f1": 0.6881451129604312,
            "f1_weighted": 0.6901124668553962
          },
          {
            "accuracy": 0.673828125,
            "ap": 0.6774785998614021,
            "ap_weighted": 0.6774785998614021,
            "f1": 0.6730795517002414,
            "f1_weighted": 0.6750044544710493
          },
          {
            "accuracy": 0.73046875,
            "ap": 0.7066144840297577,
            "ap_weighted": 0.7066144840297577,
            "f1": 0.7236370036815936,
            "f1_weighted": 0.7289835877568682
          }
        ]
      }
    ]
  },
  "task_name": "RomanianSentimentClassification"
}