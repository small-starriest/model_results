{
  "dataset_revision": "69e8f12da6e31d59addadda9a9c8a2e601a0e282",
  "evaluation_time": 60.35265874862671,
  "kg_co2_emissions": 0.009017277507172877,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.042,
        "f1": 0.02748326673326673,
        "hf_subset": "gle-eng",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02748326673326673,
        "precision": 0.024478764150011025,
        "recall": 0.042
      },
      {
        "accuracy": 0.003,
        "f1": 0.0010095618895299024,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ],
        "main_score": 0.0010095618895299024,
        "precision": 0.0010047924056154366,
        "recall": 0.003
      },
      {
        "accuracy": 0.006,
        "f1": 0.0022045878957643664,
        "hf_subset": "heb-eng",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0022045878957643664,
        "precision": 0.0021069219027113344,
        "recall": 0.006
      },
      {
        "accuracy": 0.006818181818181818,
        "f1": 0.00382034632034632,
        "hf_subset": "mon-eng",
        "languages": [
          "mon-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.00382034632034632,
        "precision": 0.00342544146500981,
        "recall": 0.006818181818181818
      },
      {
        "accuracy": 0.071,
        "f1": 0.05038894926277371,
        "hf_subset": "lat-eng",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05038894926277371,
        "precision": 0.04662529261301921,
        "recall": 0.071
      },
      {
        "accuracy": 0.05533596837944664,
        "f1": 0.03779807227718013,
        "hf_subset": "csb-eng",
        "languages": [
          "csb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03779807227718013,
        "precision": 0.035751969409464665,
        "recall": 0.05533596837944664
      },
      {
        "accuracy": 0.04384133611691023,
        "f1": 0.029006303286798363,
        "hf_subset": "dsb-eng",
        "languages": [
          "dsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029006303286798363,
        "precision": 0.026444742143965586,
        "recall": 0.04384133611691023
      },
      {
        "accuracy": 0.01282051282051282,
        "f1": 0.00455866982868845,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.00455866982868845,
        "precision": 0.004419612846579139,
        "recall": 0.01282051282051282
      },
      {
        "accuracy": 0.003,
        "f1": 4.803225056760284e-05,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ],
        "main_score": 4.803225056760284e-05,
        "precision": 2.4325838992549614e-05,
        "recall": 0.003
      },
      {
        "accuracy": 0.058,
        "f1": 0.045521305245590955,
        "hf_subset": "lfn-eng",
        "languages": [
          "lfn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.045521305245590955,
        "precision": 0.04317824290125607,
        "recall": 0.058
      },
      {
        "accuracy": 0.004,
        "f1": 0.0020514017197839083,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0020514017197839083,
        "precision": 0.0020263123359580055,
        "recall": 0.004
      },
      {
        "accuracy": 0.07073170731707316,
        "f1": 0.05205897094398836,
        "hf_subset": "kur-eng",
        "languages": [
          "kur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05205897094398836,
        "precision": 0.04831644775216175,
        "recall": 0.07073170731707316
      },
      {
        "accuracy": 0.07251908396946564,
        "f1": 0.053253756456139625,
        "hf_subset": "fao-eng",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.053253756456139625,
        "precision": 0.04907428506323345,
        "recall": 0.07251908396946564
      },
      {
        "accuracy": 0.006702412868632708,
        "f1": 0.003012514183825706,
        "hf_subset": "kat-eng",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ],
        "main_score": 0.003012514183825706,
        "precision": 0.0028654656335621483,
        "recall": 0.006702412868632708
      },
      {
        "accuracy": 0.041407867494824016,
        "f1": 0.026467651288765385,
        "hf_subset": "hsb-eng",
        "languages": [
          "hsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026467651288765385,
        "precision": 0.024398840549441237,
        "recall": 0.041407867494824016
      },
      {
        "accuracy": 0.006514657980456026,
        "f1": 0.003333972025292201,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.003333972025292201,
        "precision": 0.003296106716302156,
        "recall": 0.006514657980456026
      },
      {
        "accuracy": 0.041,
        "f1": 0.030657202759959968,
        "hf_subset": "vie-eng",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030657202759959968,
        "precision": 0.02904730164968851,
        "recall": 0.041
      },
      {
        "accuracy": 0.001,
        "f1": 2.0855057351407717e-06,
        "hf_subset": "pes-eng",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 2.0855057351407717e-06,
        "precision": 1.0438413361169101e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.041,
        "f1": 0.03274170614579707,
        "hf_subset": "slk-eng",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03274170614579707,
        "precision": 0.03108081311769991,
        "recall": 0.041
      },
      {
        "accuracy": 0.07062146892655367,
        "f1": 0.055760388387507034,
        "hf_subset": "bos-eng",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.055760388387507034,
        "precision": 0.05215107471241389,
        "recall": 0.07062146892655367
      },
      {
        "accuracy": 0.004,
        "f1": 0.003002016129032258,
        "hf_subset": "ukr-eng",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.003002016129032258,
        "precision": 0.0030010090817356207,
        "recall": 0.004
      },
      {
        "accuracy": 0.15384615384615385,
        "f1": 0.11327561327561327,
        "hf_subset": "gsw-eng",
        "languages": [
          "gsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11327561327561327,
        "precision": 0.1064359151315673,
        "recall": 0.15384615384615385
      },
      {
        "accuracy": 0.048,
        "f1": 0.03216547242552934,
        "hf_subset": "bre-eng",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03216547242552934,
        "precision": 0.029960273722260247,
        "recall": 0.048
      },
      {
        "accuracy": 0.003,
        "f1": 0.002006734006734007,
        "hf_subset": "uig-eng",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ],
        "main_score": 0.002006734006734007,
        "precision": 0.0020033783783783786,
        "recall": 0.003
      },
      {
        "accuracy": 0.087,
        "f1": 0.07044231306842101,
        "hf_subset": "cbk-eng",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07044231306842101,
        "precision": 0.06731408550928523,
        "recall": 0.087
      },
      {
        "accuracy": 0.161,
        "f1": 0.13544200244448104,
        "hf_subset": "ile-eng",
        "languages": [
          "ile-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13544200244448104,
        "precision": 0.12940418656327143,
        "recall": 0.161
      },
      {
        "accuracy": 0.013,
        "f1": 0.009153338898163605,
        "hf_subset": "lit-eng",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009153338898163605,
        "precision": 0.008512345475613841,
        "recall": 0.013
      },
      {
        "accuracy": 0.001,
        "f1": 4.255319148936171e-06,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 4.255319148936171e-06,
        "precision": 2.132196162046908e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.005474452554744526,
        "f1": 0.00304969503049695,
        "hf_subset": "tha-eng",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 0.00304969503049695,
        "precision": 0.002741402061166881,
        "recall": 0.005474452554744526
      },
      {
        "accuracy": 0.001,
        "f1": 3.2102728731942214e-06,
        "hf_subset": "mhr-eng",
        "languages": [
          "mhr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 3.2102728731942214e-06,
        "precision": 1.607717041800643e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.07746478873239436,
        "f1": 0.06927944478464992,
        "hf_subset": "max-eng",
        "languages": [
          "max-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06927944478464992,
        "precision": 0.06691678455009534,
        "recall": 0.07746478873239436
      },
      {
        "accuracy": 0.003537735849056604,
        "f1": 0.0013787791718545476,
        "hf_subset": "yid-eng",
        "languages": [
          "yid-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0013787791718545476,
        "precision": 0.0009842028082120624,
        "recall": 0.003537735849056604
      },
      {
        "accuracy": 0.00554016620498615,
        "f1": 0.004160556189234697,
        "hf_subset": "khm-eng",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ],
        "main_score": 0.004160556189234697,
        "precision": 0.004157845756983711,
        "recall": 0.00554016620498615
      },
      {
        "accuracy": 0.198,
        "f1": 0.17628451662532246,
        "hf_subset": "ina-eng",
        "languages": [
          "ina-Latn",
          "eng-Latn"
        ],
        "main_score": 0.17628451662532246,
        "precision": 0.17012261904761902,
        "recall": 0.198
      },
      {
        "accuracy": 0.118,
        "f1": 0.09896345214301576,
        "hf_subset": "ita-eng",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09896345214301576,
        "precision": 0.0949094741120795,
        "recall": 0.118
      },
      {
        "accuracy": 0.008,
        "f1": 0.0050372079351407514,
        "hf_subset": "bel-eng",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0050372079351407514,
        "precision": 0.005018771097751173,
        "recall": 0.008
      },
      {
        "accuracy": 0.016,
        "f1": 0.012789365978439613,
        "hf_subset": "srp-eng",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.012789365978439613,
        "precision": 0.012278696741854637,
        "recall": 0.016
      },
      {
        "accuracy": 0.041,
        "f1": 0.02584580986215896,
        "hf_subset": "pol-eng",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02584580986215896,
        "precision": 0.0225673323117259,
        "recall": 0.041
      },
      {
        "accuracy": 0.04738760631834751,
        "f1": 0.032480772061043856,
        "hf_subset": "slv-eng",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.032480772061043856,
        "precision": 0.030963136389206062,
        "recall": 0.04738760631834751
      },
      {
        "accuracy": 0.0673076923076923,
        "f1": 0.04583930562191432,
        "hf_subset": "tzl-eng",
        "languages": [
          "tzl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04583930562191432,
        "precision": 0.04376571141277023,
        "recall": 0.0673076923076923
      },
      {
        "accuracy": 0.035046728971962614,
        "f1": 0.023439255372769065,
        "hf_subset": "uzb-eng",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023439255372769065,
        "precision": 0.021802681352914997,
        "recall": 0.035046728971962614
      },
      {
        "accuracy": 0.088,
        "f1": 0.07476426784138648,
        "hf_subset": "ido-eng",
        "languages": [
          "ido-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07476426784138648,
        "precision": 0.07193788495095264,
        "recall": 0.088
      },
      {
        "accuracy": 0.002,
        "f1": 0.0006687370600414079,
        "hf_subset": "rus-eng",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0006687370600414079,
        "precision": 0.0005010362694300519,
        "recall": 0.002
      },
      {
        "accuracy": 0.17518248175182483,
        "f1": 0.13290348742903488,
        "hf_subset": "cha-eng",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13290348742903488,
        "precision": 0.12565983232391656,
        "recall": 0.17518248175182483
      },
      {
        "accuracy": 0.008,
        "f1": 0.006037037037037036,
        "hf_subset": "wuu-eng",
        "languages": [
          "wuu-Hans",
          "eng-Latn"
        ],
        "main_score": 0.006037037037037036,
        "precision": 0.005518867924528302,
        "recall": 0.008
      },
      {
        "accuracy": 0.002,
        "f1": 0.001002028397565923,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.001002028397565923,
        "precision": 0.001001015228426396,
        "recall": 0.002
      },
      {
        "accuracy": 0.006738544474393531,
        "f1": 0.004120233978053884,
        "hf_subset": "hye-eng",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ],
        "main_score": 0.004120233978053884,
        "precision": 0.004082695493610229,
        "recall": 0.006738544474393531
      },
      {
        "accuracy": 0.062,
        "f1": 0.046883608040296336,
        "hf_subset": "ber-eng",
        "languages": [
          "ber-Tfng",
          "eng-Latn"
        ],
        "main_score": 0.046883608040296336,
        "precision": 0.044644810529744304,
        "recall": 0.062
      },
      {
        "accuracy": 0.099,
        "f1": 0.08285855994553176,
        "hf_subset": "por-eng",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08285855994553176,
        "precision": 0.07962654571661575,
        "recall": 0.099
      },
      {
        "accuracy": 0.16731517509727625,
        "f1": 0.13973117339351177,
        "hf_subset": "nov-eng",
        "languages": [
          "nov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13973117339351177,
        "precision": 0.1329793168502413,
        "recall": 0.16731517509727625
      },
      {
        "accuracy": 0.002911208151382824,
        "f1": 0.00146008285746277,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.00146008285746277,
        "precision": 0.0014578469171023386,
        "recall": 0.002911208151382824
      },
      {
        "accuracy": 0.086,
        "f1": 0.08172449236978181,
        "hf_subset": "fra-eng",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08172449236978181,
        "precision": 0.0804594696969697,
        "recall": 0.086
      },
      {
        "accuracy": 0.001,
        "f1": 2.02020202020202e-06,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 2.02020202020202e-06,
        "precision": 1.0111223458038423e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.118,
        "f1": 0.0956469697297344,
        "hf_subset": "nds-eng",
        "languages": [
          "nds-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0956469697297344,
        "precision": 0.08968811503950716,
        "recall": 0.118
      },
      {
        "accuracy": 0.006,
        "f1": 0.004403424657534247,
        "hf_subset": "tat-eng",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.004403424657534247,
        "precision": 0.004251715265866209,
        "recall": 0.006
      },
      {
        "accuracy": 0.018,
        "f1": 0.009560286410286408,
        "hf_subset": "kab-eng",
        "languages": [
          "kab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009560286410286408,
        "precision": 0.008067895954620093,
        "recall": 0.018
      },
      {
        "accuracy": 0.017,
        "f1": 0.009696282098192566,
        "hf_subset": "jpn-eng",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.009696282098192566,
        "precision": 0.008600958479785578,
        "recall": 0.017
      },
      {
        "accuracy": 0.001,
        "f1": 2.509410288582183e-06,
        "hf_subset": "mkd-eng",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ],
        "main_score": 2.509410288582183e-06,
        "precision": 1.256281407035176e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.016,
        "f1": 0.008634253056884636,
        "hf_subset": "yue-eng",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ],
        "main_score": 0.008634253056884636,
        "precision": 0.007708323655962005,
        "recall": 0.016
      },
      {
        "accuracy": 0.026,
        "f1": 0.018773401640159507,
        "hf_subset": "dtp-eng",
        "languages": [
          "dtp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018773401640159507,
        "precision": 0.017737194401643553,
        "recall": 0.026
      },
      {
        "accuracy": 0.06338028169014084,
        "f1": 0.04009171991010389,
        "hf_subset": "xho-eng",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04009171991010389,
        "precision": 0.0381059081763307,
        "recall": 0.06338028169014084
      },
      {
        "accuracy": 0.048,
        "f1": 0.038628365207928325,
        "hf_subset": "ind-eng",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.038628365207928325,
        "precision": 0.03673333720210461,
        "recall": 0.048
      },
      {
        "accuracy": 0.109,
        "f1": 0.09312591847834814,
        "hf_subset": "glg-eng",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09312591847834814,
        "precision": 0.08975472347570956,
        "recall": 0.109
      },
      {
        "accuracy": 0.056,
        "f1": 0.04235209380344995,
        "hf_subset": "zsm-eng",
        "languages": [
          "zsm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04235209380344995,
        "precision": 0.03999096182753098,
        "recall": 0.056
      },
      {
        "accuracy": 0.08974358974358974,
        "f1": 0.058010318266728526,
        "hf_subset": "swh-eng",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.058010318266728526,
        "precision": 0.05293318117473311,
        "recall": 0.08974358974358974
      },
      {
        "accuracy": 0.07874015748031496,
        "f1": 0.06838463373896445,
        "hf_subset": "ast-eng",
        "languages": [
          "ast-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06838463373896445,
        "precision": 0.06700137253485516,
        "recall": 0.07874015748031496
      },
      {
        "accuracy": 0.061,
        "f1": 0.05626894197952218,
        "hf_subset": "spa-eng",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05626894197952218,
        "precision": 0.055062250063275114,
        "recall": 0.061
      },
      {
        "accuracy": 0.08,
        "f1": 0.06926850438417155,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06926850438417155,
        "precision": 0.06593609742747673,
        "recall": 0.08
      },
      {
        "accuracy": 0.09142857142857143,
        "f1": 0.0762386185243328,
        "hf_subset": "pms-eng",
        "languages": [
          "pms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0762386185243328,
        "precision": 0.07191528545119706,
        "recall": 0.09142857142857143
      },
      {
        "accuracy": 0.044,
        "f1": 0.03536778821074596,
        "hf_subset": "pam-eng",
        "languages": [
          "pam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03536778821074596,
        "precision": 0.033852640795378766,
        "recall": 0.044
      },
      {
        "accuracy": 0.006956521739130435,
        "f1": 0.00421213569039656,
        "hf_subset": "kaz-eng",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.00421213569039656,
        "precision": 0.003932367149758454,
        "recall": 0.006956521739130435
      },
      {
        "accuracy": 0.051,
        "f1": 0.03831996381469697,
        "hf_subset": "hrv-eng",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03831996381469697,
        "precision": 0.03590879912297623,
        "recall": 0.051
      },
      {
        "accuracy": 0.07,
        "f1": 0.054596134420752035,
        "hf_subset": "epo-eng",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.054596134420752035,
        "precision": 0.05219227595955537,
        "recall": 0.07
      },
      {
        "accuracy": 0.0011976047904191617,
        "f1": 2.9791163940775166e-06,
        "hf_subset": "orv-eng",
        "languages": [
          "orv-Cyrl",
          "eng-Latn"
        ],
        "main_score": 2.9791163940775166e-06,
        "precision": 1.4914131885668264e-06,
        "recall": 0.0011976047904191617
      },
      {
        "accuracy": 0.125,
        "f1": 0.08922275641025641,
        "hf_subset": "swg-eng",
        "languages": [
          "swg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08922275641025641,
        "precision": 0.08320690118152523,
        "recall": 0.125
      },
      {
        "accuracy": 0.034,
        "f1": 0.0278366391184573,
        "hf_subset": "kzj-eng",
        "languages": [
          "kzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0278366391184573,
        "precision": 0.02618799103286578,
        "recall": 0.034
      },
      {
        "accuracy": 0.19402985074626866,
        "f1": 0.1563536484245439,
        "hf_subset": "ang-eng",
        "languages": [
          "ang-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1563536484245439,
        "precision": 0.14597633950065345,
        "recall": 0.19402985074626866
      },
      {
        "accuracy": 0.027,
        "f1": 0.019155437048838535,
        "hf_subset": "cmn-eng",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.019155437048838535,
        "precision": 0.0178592911379614,
        "recall": 0.027
      },
      {
        "accuracy": 0.048,
        "f1": 0.04337861471861471,
        "hf_subset": "nob-eng",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04337861471861471,
        "precision": 0.042161470002489425,
        "recall": 0.048
      },
      {
        "accuracy": 0.037,
        "f1": 0.026147389306599832,
        "hf_subset": "lvs-eng",
        "languages": [
          "lvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026147389306599832,
        "precision": 0.023985104434572517,
        "recall": 0.037
      },
      {
        "accuracy": 0.094,
        "f1": 0.07842246216315985,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07842246216315985,
        "precision": 0.07528007031668023,
        "recall": 0.094
      },
      {
        "accuracy": 0.014,
        "f1": 0.010356050677151594,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010356050677151594,
        "precision": 0.009418504901960783,
        "recall": 0.014
      },
      {
        "accuracy": 0.046,
        "f1": 0.03588832233938402,
        "hf_subset": "tur-eng",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03588832233938402,
        "precision": 0.034051046649230386,
        "recall": 0.046
      },
      {
        "accuracy": 0.047,
        "f1": 0.03581412067951196,
        "hf_subset": "sqi-eng",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03581412067951196,
        "precision": 0.03382183448464198,
        "recall": 0.047
      },
      {
        "accuracy": 0.048,
        "f1": 0.035592343930579216,
        "hf_subset": "hun-eng",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.035592343930579216,
        "precision": 0.0326726079031571,
        "recall": 0.048
      },
      {
        "accuracy": 0.017316017316017316,
        "f1": 0.005130430694340468,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.005130430694340468,
        "precision": 0.003450033211937974,
        "recall": 0.017316017316017316
      },
      {
        "accuracy": 0.072,
        "f1": 0.05893418505248173,
        "hf_subset": "afr-eng",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05893418505248173,
        "precision": 0.05636520212867461,
        "recall": 0.072
      },
      {
        "accuracy": 0.054187192118226604,
        "f1": 0.035185708092112036,
        "hf_subset": "tuk-eng",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.035185708092112036,
        "precision": 0.03196496989600438,
        "recall": 0.054187192118226604
      },
      {
        "accuracy": 0.031,
        "f1": 0.023580886952352748,
        "hf_subset": "est-eng",
        "languages": [
          "est-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023580886952352748,
        "precision": 0.02213261579994317,
        "recall": 0.031
      },
      {
        "accuracy": 0.15606936416184972,
        "f1": 0.11218001651527662,
        "hf_subset": "fry-eng",
        "languages": [
          "fry-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11218001651527662,
        "precision": 0.10058053699672197,
        "recall": 0.15606936416184972
      },
      {
        "accuracy": 0.039,
        "f1": 0.02408289746429281,
        "hf_subset": "cor-eng",
        "languages": [
          "cor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02408289746429281,
        "precision": 0.021682958659274446,
        "recall": 0.039
      },
      {
        "accuracy": 0.05,
        "f1": 0.03387887911761758,
        "hf_subset": "ceb-eng",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03387887911761758,
        "precision": 0.03154631564534132,
        "recall": 0.05
      },
      {
        "accuracy": 0.071,
        "f1": 0.055414267628136345,
        "hf_subset": "eus-eng",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.055414267628136345,
        "precision": 0.05200681165812745,
        "recall": 0.071
      },
      {
        "accuracy": 0.011904761904761904,
        "f1": 0.0024965325936199723,
        "hf_subset": "amh-eng",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ],
        "main_score": 0.0024965325936199723,
        "precision": 0.001546451914098973,
        "recall": 0.011904761904761904
      },
      {
        "accuracy": 0.086,
        "f1": 0.0681772023427945,
        "hf_subset": "ron-eng",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0681772023427945,
        "precision": 0.06469236375234111,
        "recall": 0.086
      },
      {
        "accuracy": 0.083,
        "f1": 0.06551650194669062,
        "hf_subset": "oci-eng",
        "languages": [
          "oci-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06551650194669062,
        "precision": 0.0612495280995281,
        "recall": 0.083
      },
      {
        "accuracy": 0.001,
        "f1": 2.797202797202797e-06,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 2.797202797202797e-06,
        "precision": 1.4005602240896359e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.0021953896816684962,
        "f1": 0.0011009520955548246,
        "hf_subset": "arq-eng",
        "languages": [
          "arq-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0011009520955548246,
        "precision": 0.0010993258881460374,
        "recall": 0.0021953896816684962
      },
      {
        "accuracy": 0.082,
        "f1": 0.06062484492284332,
        "hf_subset": "swe-eng",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06062484492284332,
        "precision": 0.056771555519196965,
        "recall": 0.082
      },
      {
        "accuracy": 0.066,
        "f1": 0.05377660693976483,
        "hf_subset": "nno-eng",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05377660693976483,
        "precision": 0.051045845019815184,
        "recall": 0.066
      },
      {
        "accuracy": 0.03618817852834741,
        "f1": 0.02696742536157494,
        "hf_subset": "gla-eng",
        "languages": [
          "gla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02696742536157494,
        "precision": 0.02479251699402089,
        "recall": 0.03618817852834741
      },
      {
        "accuracy": 0.006,
        "f1": 0.0045048076923076925,
        "hf_subset": "kor-eng",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ],
        "main_score": 0.0045048076923076925,
        "precision": 0.00433574297188755,
        "recall": 0.006
      },
      {
        "accuracy": 0.0020964360587002098,
        "f1": 1.2705673083031574e-05,
        "hf_subset": "arz-eng",
        "languages": [
          "arz-Arab",
          "eng-Latn"
        ],
        "main_score": 1.2705673083031574e-05,
        "precision": 6.372146075076625e-06,
        "recall": 0.0020964360587002098
      },
      {
        "accuracy": 0.04,
        "f1": 0.027941267011855245,
        "hf_subset": "fin-eng",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027941267011855245,
        "precision": 0.025908241758241756,
        "recall": 0.04
      },
      {
        "accuracy": 0.041,
        "f1": 0.03039783137216765,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03039783137216765,
        "precision": 0.02809781116463202,
        "recall": 0.041
      },
      {
        "accuracy": 0.086,
        "f1": 0.07891272250150178,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07891272250150178,
        "precision": 0.07657456790123456,
        "recall": 0.086
      },
      {
        "accuracy": 0.08695652173913043,
        "f1": 0.06089151272601483,
        "hf_subset": "cym-eng",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06089151272601483,
        "precision": 0.05612653840762253,
        "recall": 0.08695652173913043
      },
      {
        "accuracy": 0.058,
        "f1": 0.04938314765300059,
        "hf_subset": "war-eng",
        "languages": [
          "war-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04938314765300059,
        "precision": 0.04798601818320365,
        "recall": 0.058
      },
      {
        "accuracy": 0.03,
        "f1": 0.023660966521798672,
        "hf_subset": "isl-eng",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023660966521798672,
        "precision": 0.022616601071302426,
        "recall": 0.03
      },
      {
        "accuracy": 0.115,
        "f1": 0.10156134937066263,
        "hf_subset": "nld-eng",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10156134937066263,
        "precision": 0.09877762813456797,
        "recall": 0.115
      },
      {
        "accuracy": 0.034,
        "f1": 0.02690489479512735,
        "hf_subset": "tgl-eng",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02690489479512735,
        "precision": 0.02540408262146488,
        "recall": 0.034
      },
      {
        "accuracy": 0.05365853658536585,
        "f1": 0.033683834819818785,
        "hf_subset": "jav-eng",
        "languages": [
          "jav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.033683834819818785,
        "precision": 0.0308319783197832,
        "recall": 0.05365853658536585
      }
    ]
  },
  "task_name": "Tatoeba"
}