{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 33.53307604789734,
  "kg_co2_emissions": 0.006361447100979294,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.21156601842374614,
        "f1": 0.20951540121753442,
        "f1_weighted": 0.2135153613184381,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.20951540121753442,
        "scores_per_experiment": [
          {
            "accuracy": 0.19037871033776868,
            "f1": 0.19378105662640435,
            "f1_weighted": 0.18909211382762312
          },
          {
            "accuracy": 0.22313203684749233,
            "f1": 0.22801357295086042,
            "f1_weighted": 0.22366640972204505
          },
          {
            "accuracy": 0.24667349027635618,
            "f1": 0.25100388286924846,
            "f1_weighted": 0.25238528263975424
          },
          {
            "accuracy": 0.18730808597748208,
            "f1": 0.17392372815544152,
            "f1_weighted": 0.18180301413975727
          },
          {
            "accuracy": 0.21903787103377687,
            "f1": 0.22975672786725246,
            "f1_weighted": 0.2262810250373017
          },
          {
            "accuracy": 0.2067553735926305,
            "f1": 0.20633535487623456,
            "f1_weighted": 0.2078072182397566
          },
          {
            "accuracy": 0.24155578300921188,
            "f1": 0.232824443720419,
            "f1_weighted": 0.24930350528680545
          },
          {
            "accuracy": 0.20061412487205732,
            "f1": 0.19118303020037122,
            "f1_weighted": 0.19507609464744968
          },
          {
            "accuracy": 0.2128966223132037,
            "f1": 0.2004076367030311,
            "f1_weighted": 0.2141865430514408
          },
          {
            "accuracy": 0.18730808597748208,
            "f1": 0.18792457820608144,
            "f1_weighted": 0.1955524065924472
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.22073170731707314,
        "f1": 0.21599517399332968,
        "f1_weighted": 0.2264561559516393,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.21599517399332968,
        "scores_per_experiment": [
          {
            "accuracy": 0.21341463414634146,
            "f1": 0.21095469165737998,
            "f1_weighted": 0.21542360035709035
          },
          {
            "accuracy": 0.26422764227642276,
            "f1": 0.2689460663990682,
            "f1_weighted": 0.2673779930210287
          },
          {
            "accuracy": 0.27235772357723576,
            "f1": 0.2699372627742745,
            "f1_weighted": 0.2828898265732646
          },
          {
            "accuracy": 0.17682926829268292,
            "f1": 0.16556985797178472,
            "f1_weighted": 0.16648591413184663
          },
          {
            "accuracy": 0.2073170731707317,
            "f1": 0.2217368060177821,
            "f1_weighted": 0.22971406785062087
          },
          {
            "accuracy": 0.2073170731707317,
            "f1": 0.20539297500674722,
            "f1_weighted": 0.20794604667577313
          },
          {
            "accuracy": 0.23577235772357724,
            "f1": 0.22632744380146944,
            "f1_weighted": 0.24745859213303828
          },
          {
            "accuracy": 0.20528455284552846,
            "f1": 0.18764399196651252,
            "f1_weighted": 0.2047755822432821
          },
          {
            "accuracy": 0.23577235772357724,
            "f1": 0.21716136097812433,
            "f1_weighted": 0.24136799368860107
          },
          {
            "accuracy": 0.18902439024390244,
            "f1": 0.18628128336015384,
            "f1_weighted": 0.20112194284184692
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}