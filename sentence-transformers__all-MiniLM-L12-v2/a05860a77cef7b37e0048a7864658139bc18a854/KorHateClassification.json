{
  "dataset_revision": "bd1a7370caf712125fac1fda375834ca8ddefaca",
  "evaluation_time": 9.909254789352417,
  "kg_co2_emissions": 0.00148165352277888,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.372412109375,
        "f1": 0.3580915669972144,
        "f1_weighted": 0.3733839758775707,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.372412109375,
        "scores_per_experiment": [
          {
            "accuracy": 0.3671875,
            "f1": 0.36147599235874317,
            "f1_weighted": 0.37180001876142865
          },
          {
            "accuracy": 0.34130859375,
            "f1": 0.3295720834512389,
            "f1_weighted": 0.3412472088582788
          },
          {
            "accuracy": 0.40283203125,
            "f1": 0.3794286177454791,
            "f1_weighted": 0.4023173267547919
          },
          {
            "accuracy": 0.3310546875,
            "f1": 0.32037975636401345,
            "f1_weighted": 0.3356982774060545
          },
          {
            "accuracy": 0.3212890625,
            "f1": 0.31066742466974967,
            "f1_weighted": 0.32434893605957366
          },
          {
            "accuracy": 0.40283203125,
            "f1": 0.3886715455992357,
            "f1_weighted": 0.4070611089087536
          },
          {
            "accuracy": 0.40576171875,
            "f1": 0.3923964640669518,
            "f1_weighted": 0.4047213612685122
          },
          {
            "accuracy": 0.37158203125,
            "f1": 0.35644794525725293,
            "f1_weighted": 0.371243582606695
          },
          {
            "accuracy": 0.369140625,
            "f1": 0.35908467625770696,
            "f1_weighted": 0.37060084189216635
          },
          {
            "accuracy": 0.4111328125,
            "f1": 0.38279116420177256,
            "f1_weighted": 0.40480109625945243
          }
        ]
      }
    ]
  },
  "task_name": "KorHateClassification"
}