{
  "dataset_revision": "9abd46cf7fc8b4c64290f26993c540b92aa145ac",
  "evaluation_time": 15.583771705627441,
  "kg_co2_emissions": 0.0025511125054986984,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.871923828125,
        "f1": 0.8633509309154235,
        "f1_weighted": 0.8633756141727931,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.871923828125,
        "scores_per_experiment": [
          {
            "accuracy": 0.87451171875,
            "f1": 0.8642687460044819,
            "f1_weighted": 0.8642860551087385
          },
          {
            "accuracy": 0.880859375,
            "f1": 0.8705402386453747,
            "f1_weighted": 0.8705910209887113
          },
          {
            "accuracy": 0.87939453125,
            "f1": 0.8702753182348324,
            "f1_weighted": 0.8703323655966063
          },
          {
            "accuracy": 0.86962890625,
            "f1": 0.8622417355043008,
            "f1_weighted": 0.862260593070698
          },
          {
            "accuracy": 0.86376953125,
            "f1": 0.8558019718789726,
            "f1_weighted": 0.8558157186386628
          },
          {
            "accuracy": 0.88671875,
            "f1": 0.8799724521152088,
            "f1_weighted": 0.8799880848248236
          },
          {
            "accuracy": 0.86865234375,
            "f1": 0.8611448844655806,
            "f1_weighted": 0.8612074639808027
          },
          {
            "accuracy": 0.85498046875,
            "f1": 0.847777824493017,
            "f1_weighted": 0.8477787196023916
          },
          {
            "accuracy": 0.86669921875,
            "f1": 0.8589710022916786,
            "f1_weighted": 0.8589131850099454
          },
          {
            "accuracy": 0.8740234375,
            "f1": 0.8625151355207875,
            "f1_weighted": 0.86258293490655
          }
        ]
      }
    ]
  },
  "task_name": "DBpediaClassification"
}