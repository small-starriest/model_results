{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 8.495158433914185,
  "kg_co2_emissions": 0.0014239673313778964,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8063431905132298,
        "cosine_spearman": 0.7943047577565244,
        "euclidean_pearson": 0.7907675883200211,
        "euclidean_spearman": 0.7943047577565244,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7943047577565244,
        "manhattan_pearson": 0.7903527116786103,
        "manhattan_spearman": 0.7930022073507282,
        "pearson": 0.8063431905132298,
        "spearman": 0.7943047577565244
      },
      {
        "cosine_pearson": 0.7543786906316923,
        "cosine_spearman": 0.7256326276475369,
        "euclidean_pearson": 0.7530692046299765,
        "euclidean_spearman": 0.7256326276475369,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7256326276475369,
        "manhattan_pearson": 0.7524188049974091,
        "manhattan_spearman": 0.7273275429843192,
        "pearson": 0.7543786906316923,
        "spearman": 0.7256326276475369
      },
      {
        "cosine_pearson": 0.5041551027766978,
        "cosine_spearman": 0.5019991067552446,
        "euclidean_pearson": 0.5138169156486535,
        "euclidean_spearman": 0.5019991067552446,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.5019991067552446,
        "manhattan_pearson": 0.5133993167262495,
        "manhattan_spearman": 0.5025567025097297,
        "pearson": 0.5041551027766978,
        "spearman": 0.5019991067552446
      },
      {
        "cosine_pearson": 0.48270952556373087,
        "cosine_spearman": 0.45324679732323686,
        "euclidean_pearson": 0.49038823515578134,
        "euclidean_spearman": 0.45324679732323686,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.45324679732323686,
        "manhattan_pearson": 0.4883557653726014,
        "manhattan_spearman": 0.4517925066938626,
        "pearson": 0.48270952556373087,
        "spearman": 0.45324679732323686
      },
      {
        "cosine_pearson": 0.4080471358665909,
        "cosine_spearman": 0.40143450894729094,
        "euclidean_pearson": 0.408698248369212,
        "euclidean_spearman": 0.40143450894729094,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.40143450894729094,
        "manhattan_pearson": 0.41584971002737886,
        "manhattan_spearman": 0.40957106273977345,
        "pearson": 0.4080471358665909,
        "spearman": 0.40143450894729094
      },
      {
        "cosine_pearson": 0.8166646129656611,
        "cosine_spearman": 0.8039019258893243,
        "euclidean_pearson": 0.8159936529056973,
        "euclidean_spearman": 0.8039019258893243,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8039019258893243,
        "manhattan_pearson": 0.8176879870926655,
        "manhattan_spearman": 0.807539334441241,
        "pearson": 0.8166646129656611,
        "spearman": 0.8039019258893243
      },
      {
        "cosine_pearson": 0.5360676357160233,
        "cosine_spearman": 0.5123414179162021,
        "euclidean_pearson": 0.5334548394057652,
        "euclidean_spearman": 0.5123414179162021,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.5123414179162021,
        "manhattan_pearson": 0.5259948237410472,
        "manhattan_spearman": 0.5036164335922936,
        "pearson": 0.5360676357160233,
        "spearman": 0.5123414179162021
      },
      {
        "cosine_pearson": 0.7283090951984403,
        "cosine_spearman": 0.7257176943362972,
        "euclidean_pearson": 0.7105961023181209,
        "euclidean_spearman": 0.7257176943362972,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7257176943362972,
        "manhattan_pearson": 0.7093576029783476,
        "manhattan_spearman": 0.7245075624548345,
        "pearson": 0.7283090951984403,
        "spearman": 0.7257176943362972
      },
      {
        "cosine_pearson": 0.28948702540871263,
        "cosine_spearman": 0.39799651795987606,
        "euclidean_pearson": 0.3726375157092498,
        "euclidean_spearman": 0.39799651795987606,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.39799651795987606,
        "manhattan_pearson": 0.3760978464384344,
        "manhattan_spearman": 0.40763658662819646,
        "pearson": 0.28948702540871263,
        "spearman": 0.39799651795987606
      },
      {
        "cosine_pearson": 0.5072765443694224,
        "cosine_spearman": 0.5138349538105524,
        "euclidean_pearson": 0.5105853162300293,
        "euclidean_spearman": 0.5138349538105524,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5138349538105524,
        "manhattan_pearson": 0.5018264938625792,
        "manhattan_spearman": 0.5058186392214556,
        "pearson": 0.5072765443694224,
        "spearman": 0.5138349538105524
      },
      {
        "cosine_pearson": 0.7949406525412015,
        "cosine_spearman": 0.7736960416097961,
        "euclidean_pearson": 0.7868994560409399,
        "euclidean_spearman": 0.7736960416097961,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7736960416097961,
        "manhattan_pearson": 0.7879074671915144,
        "manhattan_spearman": 0.7760698425868396,
        "pearson": 0.7949406525412015,
        "spearman": 0.7736960416097961
      },
      {
        "cosine_pearson": 0.8010373644441682,
        "cosine_spearman": 0.7742685010164576,
        "euclidean_pearson": 0.7806232606534133,
        "euclidean_spearman": 0.7742685010164576,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7742685010164576,
        "manhattan_pearson": 0.780059002818334,
        "manhattan_spearman": 0.7736428819807606,
        "pearson": 0.8010373644441682,
        "spearman": 0.7742685010164576
      }
    ]
  },
  "task_name": "SemRel24STS"
}