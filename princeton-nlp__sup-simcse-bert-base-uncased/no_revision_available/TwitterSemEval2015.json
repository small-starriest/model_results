{
    "mteb_version": "0.0.2",
    "test": {
        "cos_sim": {
            "accuracy": 0.8419264469213804,
            "accuracy_threshold": 0.7157667279243469,
            "ap": 0.6775361224485238,
            "f1": 0.6289014499877119,
            "f1_threshold": 0.6459685564041138,
            "precision": 0.5885464581416743,
            "recall": 0.675197889182058
        },
        "dot": {
            "accuracy": 0.805269118435954,
            "accuracy_threshold": 18.567798614501953,
            "ap": 0.5501751117776821,
            "f1": 0.5522921859759402,
            "f1_threshold": 15.1850004196167,
            "precision": 0.46864079455582125,
            "recall": 0.6722955145118733
        },
        "euclidean": {
            "accuracy": 0.8379924897180664,
            "accuracy_threshold": 3.722175121307373,
            "ap": 0.6590761522134796,
            "f1": 0.6102802563780318,
            "f1_threshold": 4.112122535705566,
            "precision": 0.5826733861291097,
            "recall": 0.6406332453825857
        },
        "evaluation_time": 7.13,
        "manhattan": {
            "accuracy": 0.8377540680693807,
            "accuracy_threshold": 81.08329772949219,
            "ap": 0.6593440872809281,
            "f1": 0.609328309731064,
            "f1_threshold": 89.89747619628906,
            "precision": 0.6002047606859483,
            "recall": 0.6187335092348285
        },
        "max": {
            "accuracy": 0.8419264469213804,
            "ap": 0.6775361224485238,
            "f1": 0.6289014499877119
        }
    },
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}