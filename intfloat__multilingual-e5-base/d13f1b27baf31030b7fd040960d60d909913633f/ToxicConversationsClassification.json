{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 11.504231214523315,
  "kg_co2_emissions": 0.001768267771979686,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.643310546875,
        "ap": 0.11752635743758102,
        "ap_weighted": 0.11752635743758102,
        "f1": 0.4956901897617526,
        "f1_weighted": 0.720707215763922,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.643310546875,
        "scores_per_experiment": [
          {
            "accuracy": 0.6640625,
            "ap": 0.11827260238522903,
            "ap_weighted": 0.11827260238522903,
            "f1": 0.507779673498247,
            "f1_weighted": 0.7412559238353545
          },
          {
            "accuracy": 0.69677734375,
            "ap": 0.12955931907594254,
            "ap_weighted": 0.12955931907594254,
            "f1": 0.5312542500317888,
            "f1_weighted": 0.7657339653729524
          },
          {
            "accuracy": 0.7587890625,
            "ap": 0.1533957868875564,
            "ap_weighted": 0.1533957868875564,
            "f1": 0.5763293310463121,
            "f1_weighted": 0.8103773794288701
          },
          {
            "accuracy": 0.72021484375,
            "ap": 0.12086912212372222,
            "ap_weighted": 0.12086912212372222,
            "f1": 0.5347770326923573,
            "f1_weighted": 0.7820274474358809
          },
          {
            "accuracy": 0.50048828125,
            "ap": 0.0991416060216895,
            "ap_weighted": 0.0991416060216895,
            "f1": 0.41290968533240974,
            "f1_weighted": 0.60378895127669
          },
          {
            "accuracy": 0.4658203125,
            "ap": 0.10173270935954191,
            "ap_weighted": 0.10173270935954191,
            "f1": 0.3956159801462059,
            "f1_weighted": 0.5690146463037146
          },
          {
            "accuracy": 0.74267578125,
            "ap": 0.12449227485823007,
            "ap_weighted": 0.12449227485823007,
            "f1": 0.5475179213836201,
            "f1_weighted": 0.797668219085954
          },
          {
            "accuracy": 0.57080078125,
            "ap": 0.10510392065068448,
            "ap_weighted": 0.10510392065068448,
            "f1": 0.4534443451640904,
            "f1_weighted": 0.666639809665785
          },
          {
            "accuracy": 0.63037109375,
            "ap": 0.10967512559101654,
            "ap_weighted": 0.10967512559101654,
            "f1": 0.4854057857727281,
            "f1_weighted": 0.7153231647541602
          },
          {
            "accuracy": 0.68310546875,
            "ap": 0.11302110742219747,
            "ap_weighted": 0.11302110742219747,
            "f1": 0.5118678925497671,
            "f1_weighted": 0.755242650479859
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}