{
  "dataset_revision": "a4654f4896408912913a62ace89614879a549287",
  "evaluation_time": 21.94180679321289,
  "kg_co2_emissions": 0.003258165918559354,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.568994140625,
        "ap": 0.5202238022522137,
        "ap_weighted": 0.5202238022522137,
        "f1": 0.565554773725769,
        "f1_weighted": 0.5649372653910973,
        "hf_subset": "default",
        "languages": [
          "fra-Latn"
        ],
        "main_score": 0.568994140625,
        "scores_per_experiment": [
          {
            "accuracy": 0.5634765625,
            "ap": 0.5141805108057419,
            "ap_weighted": 0.5141805108057419,
            "f1": 0.559524118837492,
            "f1_weighted": 0.5612354861965161
          },
          {
            "accuracy": 0.59521484375,
            "ap": 0.5364648532493463,
            "ap_weighted": 0.5364648532493463,
            "f1": 0.5948554174920292,
            "f1_weighted": 0.5953503651259563
          },
          {
            "accuracy": 0.5693359375,
            "ap": 0.5213491280549898,
            "ap_weighted": 0.5213491280549898,
            "f1": 0.564581772531233,
            "f1_weighted": 0.562715651702371
          },
          {
            "accuracy": 0.55615234375,
            "ap": 0.512490255757195,
            "ap_weighted": 0.512490255757195,
            "f1": 0.5542725388861554,
            "f1_weighted": 0.5530852937089905
          },
          {
            "accuracy": 0.57080078125,
            "ap": 0.520657351088206,
            "ap_weighted": 0.520657351088206,
            "f1": 0.5707368160510139,
            "f1_weighted": 0.5705218929824207
          },
          {
            "accuracy": 0.5615234375,
            "ap": 0.514945053092396,
            "ap_weighted": 0.514945053092396,
            "f1": 0.5613389496582024,
            "f1_weighted": 0.5609699739746072
          },
          {
            "accuracy": 0.53955078125,
            "ap": 0.5050205271603345,
            "ap_weighted": 0.5050205271603345,
            "f1": 0.5246160340772449,
            "f1_weighted": 0.5211600595248718
          },
          {
            "accuracy": 0.5859375,
            "ap": 0.5315357855811209,
            "ap_weighted": 0.5315357855811209,
            "f1": 0.5833947433063129,
            "f1_weighted": 0.5820597960421272
          },
          {
            "accuracy": 0.55029296875,
            "ap": 0.5061552974694361,
            "ap_weighted": 0.5061552974694361,
            "f1": 0.5474964752519142,
            "f1_weighted": 0.548955515337872
          },
          {
            "accuracy": 0.59765625,
            "ap": 0.5394392602633696,
            "ap_weighted": 0.5394392602633696,
            "f1": 0.594730871166092,
            "f1_weighted": 0.59331861931524
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5779296875,
        "ap": 0.5354013850439461,
        "ap_weighted": 0.5354013850439461,
        "f1": 0.5721050930102015,
        "f1_weighted": 0.5715184721241663,
        "hf_subset": "default",
        "languages": [
          "fra-Latn"
        ],
        "main_score": 0.5779296875,
        "scores_per_experiment": [
          {
            "accuracy": 0.57861328125,
            "ap": 0.5353649953963541,
            "ap_weighted": 0.5353649953963541,
            "f1": 0.5772334931583032,
            "f1_weighted": 0.5777288017040405
          },
          {
            "accuracy": 0.58447265625,
            "ap": 0.5392784715806423,
            "ap_weighted": 0.5392784715806423,
            "f1": 0.5842893960698445,
            "f1_weighted": 0.5844683943853453
          },
          {
            "accuracy": 0.57666015625,
            "ap": 0.5347397033077684,
            "ap_weighted": 0.5347397033077684,
            "f1": 0.5648783858790144,
            "f1_weighted": 0.5634100346755089
          },
          {
            "accuracy": 0.591796875,
            "ap": 0.544171034419118,
            "ap_weighted": 0.544171034419118,
            "f1": 0.5879454164761377,
            "f1_weighted": 0.5871284404256215
          },
          {
            "accuracy": 0.58935546875,
            "ap": 0.5425274762974976,
            "ap_weighted": 0.5425274762974976,
            "f1": 0.5876162873523176,
            "f1_weighted": 0.5870670721741021
          },
          {
            "accuracy": 0.56298828125,
            "ap": 0.5257802565939866,
            "ap_weighted": 0.5257802565939866,
            "f1": 0.5604048776217696,
            "f1_weighted": 0.5597137760142176
          },
          {
            "accuracy": 0.54638671875,
            "ap": 0.5170026471165522,
            "ap_weighted": 0.5170026471165522,
            "f1": 0.5261732714877191,
            "f1_weighted": 0.5241662625396912
          },
          {
            "accuracy": 0.58642578125,
            "ap": 0.540753459742433,
            "ap_weighted": 0.540753459742433,
            "f1": 0.5793834211226312,
            "f1_weighted": 0.578267273479803
          },
          {
            "accuracy": 0.5595703125,
            "ap": 0.5227386649330651,
            "ap_weighted": 0.5227386649330651,
            "f1": 0.5545227863547137,
            "f1_weighted": 0.5554952455203194
          },
          {
            "accuracy": 0.60302734375,
            "ap": 0.5516571410520423,
            "ap_weighted": 0.5516571410520423,
            "f1": 0.5986035945795631,
            "f1_weighted": 0.5977394203230127
          }
        ]
      }
    ]
  },
  "task_name": "MovieReviewSentimentClassification"
}