{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 111.68021607398987,
  "kg_co2_emissions": 0.017624860437299772,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.9973649538866931,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973649538866931,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9868247694334651,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9868247694334651,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733861,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9947299077733861,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034255,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9907773386034255,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9920948616600791,
        "f1": 0.9894598155467721,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9894598155467721,
        "precision": 0.9881422924901185,
        "recall": 0.9920948616600791
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034255,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9907773386034255,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9594861660079052,
        "f1": 0.9471014492753622,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9471014492753622,
        "precision": 0.9413702239789196,
        "recall": 0.9594861660079052
      },
      {
        "accuracy": 0.9812252964426877,
        "f1": 0.9751317523056654,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9751317523056654,
        "precision": 0.9721673254281951,
        "recall": 0.9812252964426877
      },
      {
        "accuracy": 0.974308300395257,
        "f1": 0.9659090909090909,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9659090909090909,
        "precision": 0.9617918313570488,
        "recall": 0.974308300395257
      },
      {
        "accuracy": 0.9802371541501976,
        "f1": 0.9738142292490118,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9738142292490118,
        "precision": 0.9706851119894598,
        "recall": 0.9802371541501976
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9871541501976284,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9871541501976284,
        "precision": 0.9856719367588933,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.991106719367589,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.991106719367589,
        "precision": 0.9901185770750988,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733861,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9947299077733861,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9841897233201581,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9841897233201581,
        "precision": 0.9822134387351779,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9535573122529645,
        "f1": 0.9388998682476944,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9388998682476944,
        "precision": 0.9319828722002635,
        "recall": 0.9535573122529645
      },
      {
        "accuracy": 0.9851778656126482,
        "f1": 0.9804018445322793,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9804018445322793,
        "precision": 0.9780961791831357,
        "recall": 0.9851778656126482
      },
      {
        "accuracy": 0.9199604743083004,
        "f1": 0.8982213438735178,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8982213438735178,
        "precision": 0.8887845849802372,
        "recall": 0.9199604743083004
      },
      {
        "accuracy": 0.9634387351778656,
        "f1": 0.9525691699604744,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9525691699604744,
        "precision": 0.9472990777338604,
        "recall": 0.9634387351778656
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9833662714097496,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9833662714097496,
        "precision": 0.9815546772068512,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9864953886693018,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9864953886693018,
        "precision": 0.9851778656126482,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9733201581027668,
        "f1": 0.9654808959156785,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9654808959156785,
        "precision": 0.9620388669301712,
        "recall": 0.9733201581027668
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9841897233201581,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9841897233201581,
        "precision": 0.9822134387351779,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.05596758838724812,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.05596758838724812,
        "precision": 0.05311527240875067,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.1373517786561265,
        "f1": 0.09211032735199451,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.09211032735199451,
        "precision": 0.08165887046379953,
        "recall": 0.1373517786561265
      },
      {
        "accuracy": 0.25296442687747034,
        "f1": 0.21171844569955714,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.21171844569955714,
        "precision": 0.20204654206136421,
        "recall": 0.25296442687747034
      },
      {
        "accuracy": 0.35276679841897235,
        "f1": 0.2984722421083909,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.2984722421083909,
        "precision": 0.28208891569563505,
        "recall": 0.35276679841897235
      },
      {
        "accuracy": 0.967391304347826,
        "f1": 0.9572463768115942,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9572463768115942,
        "precision": 0.9524868247694335,
        "recall": 0.967391304347826
      },
      {
        "accuracy": 0.9841897233201581,
        "f1": 0.9792490118577075,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9792490118577075,
        "precision": 0.9767786561264822,
        "recall": 0.9841897233201581
      },
      {
        "accuracy": 0.8428853754940712,
        "f1": 0.806764853503984,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.806764853503984,
        "precision": 0.7928653773762468,
        "recall": 0.8428853754940712
      },
      {
        "accuracy": 0.9140316205533597,
        "f1": 0.8890363259928477,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8890363259928477,
        "precision": 0.877635046113307,
        "recall": 0.9140316205533597
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9828722002635045,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9828722002635045,
        "precision": 0.9807312252964426,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.958498023715415,
        "f1": 0.9464756258234519,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9464756258234519,
        "precision": 0.9409090909090909,
        "recall": 0.958498023715415
      },
      {
        "accuracy": 0.9792490118577075,
        "f1": 0.9726613965744401,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9726613965744401,
        "precision": 0.9695322793148881,
        "recall": 0.9792490118577075
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.40711462450592883,
        "f1": 0.35681017734004955,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.35681017734004955,
        "precision": 0.3423822543433267,
        "recall": 0.40711462450592883
      },
      {
        "accuracy": 0.5622529644268774,
        "f1": 0.5002920046027753,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.5002920046027753,
        "precision": 0.4795639980247273,
        "recall": 0.5622529644268774
      },
      {
        "accuracy": 0.983201581027668,
        "f1": 0.9779314888010541,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9779314888010541,
        "precision": 0.9754611330698288,
        "recall": 0.983201581027668
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768115,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9855072463768115,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.974308300395257,
        "f1": 0.9659090909090909,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9659090909090909,
        "precision": 0.9617918313570488,
        "recall": 0.974308300395257
      },
      {
        "accuracy": 0.9812252964426877,
        "f1": 0.9752964426877471,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9752964426877471,
        "precision": 0.9723320158102767,
        "recall": 0.9812252964426877
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.016804744037730808,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.016804744037730808,
        "precision": 0.01563305352135169,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.008341541560560392,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.008341541560560392,
        "precision": 0.006215864175350341,
        "recall": 0.019762845849802372
      }
    ],
    "validation": [
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527916,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9933132731527916,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9852892009361417,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9852892009361417,
        "precision": 0.9834503510531595,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527916,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9933132731527916,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9867937144767636,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9867937144767636,
        "precision": 0.9852892009361417,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9896355733868271,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9896355733868271,
        "precision": 0.9884653961885657,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9648946840521565,
        "f1": 0.9533600802407222,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9533600802407222,
        "precision": 0.947676362420595,
        "recall": 0.9648946840521565
      },
      {
        "accuracy": 0.9849548645937813,
        "f1": 0.9799398194583752,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9799398194583752,
        "precision": 0.977432296890672,
        "recall": 0.9849548645937813
      },
      {
        "accuracy": 0.970912738214644,
        "f1": 0.9617853560682046,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9617853560682046,
        "precision": 0.9574557004346372,
        "recall": 0.970912738214644
      },
      {
        "accuracy": 0.9799398194583752,
        "f1": 0.9735874289535273,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9735874289535273,
        "precision": 0.9704112337011033,
        "recall": 0.9799398194583752
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9872952189903041,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9872952189903041,
        "precision": 0.9859578736208626,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9924774322968907,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9924774322968907,
        "precision": 0.9918087596121699,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444668,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9893012370444668,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139083,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139083,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305584,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9986626546305584,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9348044132397192,
        "f1": 0.9164159144098963,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9164159144098963,
        "precision": 0.9079815203185313,
        "recall": 0.9348044132397192
      },
      {
        "accuracy": 0.9699097291875627,
        "f1": 0.9600468070879306,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9600468070879306,
        "precision": 0.9551989301237044,
        "recall": 0.9699097291875627
      },
      {
        "accuracy": 0.9277833500501504,
        "f1": 0.9057840187228351,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9057840187228351,
        "precision": 0.8956034770979605,
        "recall": 0.9277833500501504
      },
      {
        "accuracy": 0.9628886659979939,
        "f1": 0.950852557673019,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.950852557673019,
        "precision": 0.9450016716817119,
        "recall": 0.9628886659979939
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9862922099632231,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9862922099632231,
        "precision": 0.9849548645937813,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9876295553326646,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9876295553326646,
        "precision": 0.9864593781344032,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9648946840521565,
        "f1": 0.955566700100301,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.955566700100301,
        "precision": 0.9514655076340132,
        "recall": 0.9648946840521565
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9852892009361417,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9852892009361417,
        "precision": 0.9834503510531595,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.05616850551654965,
        "f1": 0.048657878397096045,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.048657878397096045,
        "precision": 0.04703941356961694,
        "recall": 0.05616850551654965
      },
      {
        "accuracy": 0.15245737211634905,
        "f1": 0.10978112654579479,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.10978112654579479,
        "precision": 0.09909557348457718,
        "recall": 0.15245737211634905
      },
      {
        "accuracy": 0.2246740220661986,
        "f1": 0.19572126587848673,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.19572126587848673,
        "precision": 0.1883011535269336,
        "recall": 0.2246740220661986
      },
      {
        "accuracy": 0.36710130391173523,
        "f1": 0.30815763600094853,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.30815763600094853,
        "precision": 0.28993428002956584,
        "recall": 0.36710130391173523
      },
      {
        "accuracy": 0.9638916750250752,
        "f1": 0.9523570712136409,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9523570712136409,
        "precision": 0.9468405215646941,
        "recall": 0.9638916750250752
      },
      {
        "accuracy": 0.9819458375125376,
        "f1": 0.9759277833500501,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9759277833500501,
        "precision": 0.9729187562688064,
        "recall": 0.9819458375125376
      },
      {
        "accuracy": 0.8284854563691073,
        "f1": 0.7900633116280056,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7900633116280056,
        "precision": 0.7743301388236192,
        "recall": 0.8284854563691073
      },
      {
        "accuracy": 0.8976930792377131,
        "f1": 0.8698651510085812,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8698651510085812,
        "precision": 0.8576479438314946,
        "recall": 0.8976930792377131
      },
      {
        "accuracy": 0.9779338014042126,
        "f1": 0.970912738214644,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.970912738214644,
        "precision": 0.9675693747910399,
        "recall": 0.9779338014042126
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9896355733868272,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9896355733868272,
        "precision": 0.9884653961885657,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9638916750250752,
        "f1": 0.9527582748244733,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9527582748244733,
        "precision": 0.947592778335005,
        "recall": 0.9638916750250752
      },
      {
        "accuracy": 0.9779338014042126,
        "f1": 0.970912738214644,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.970912738214644,
        "precision": 0.9675693747910398,
        "recall": 0.9779338014042126
      },
      {
        "accuracy": 0.9869608826479438,
        "f1": 0.9827816783684387,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9827816783684387,
        "precision": 0.9807756603142761,
        "recall": 0.9869608826479438
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444667,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9893012370444667,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.4202607823470411,
        "f1": 0.3694780241609233,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.3694780241609233,
        "precision": 0.35517201810348487,
        "recall": 0.4202607823470411
      },
      {
        "accuracy": 0.5847542627883651,
        "f1": 0.5241438100515332,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.5241438100515332,
        "precision": 0.5021504740662213,
        "recall": 0.5847542627883651
      },
      {
        "accuracy": 0.9769307923771314,
        "f1": 0.9694082246740221,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9694082246740221,
        "precision": 0.9657305249080574,
        "recall": 0.9769307923771314
      },
      {
        "accuracy": 0.9779338014042126,
        "f1": 0.9710799063858242,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9710799063858242,
        "precision": 0.9677365429622199,
        "recall": 0.9779338014042126
      },
      {
        "accuracy": 0.9739217652958877,
        "f1": 0.9656302240053494,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9656302240053494,
        "precision": 0.9616349047141425,
        "recall": 0.9739217652958877
      },
      {
        "accuracy": 0.9789368104312939,
        "f1": 0.9724172517552658,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9724172517552658,
        "precision": 0.9694082246740221,
        "recall": 0.9789368104312939
      },
      {
        "accuracy": 0.013039117352056168,
        "f1": 0.009346079813163344,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.009346079813163344,
        "precision": 0.008941348443405361,
        "recall": 0.013039117352056168
      },
      {
        "accuracy": 0.01805416248746239,
        "f1": 0.005439449391646452,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.005439449391646452,
        "precision": 0.003905965251934591,
        "recall": 0.01805416248746239
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}