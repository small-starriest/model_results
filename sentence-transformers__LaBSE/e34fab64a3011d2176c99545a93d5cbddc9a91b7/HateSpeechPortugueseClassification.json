{
  "dataset_revision": "b0f431acbf8d3865cb7c7b3effb2a9771a618ebc",
  "evaluation_time": 9.809330463409424,
  "kg_co2_emissions": 0.0015028533021403626,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.57080078125,
        "ap": 0.3490869025356049,
        "ap_weighted": 0.3490869025356049,
        "f1": 0.5448712025206316,
        "f1_weighted": 0.5830198889759762,
        "hf_subset": "default",
        "languages": [
          "por-Latn"
        ],
        "main_score": 0.57080078125,
        "scores_per_experiment": [
          {
            "accuracy": 0.61279296875,
            "ap": 0.36423001564607116,
            "ap_weighted": 0.36423001564607116,
            "f1": 0.5781361574238227,
            "f1_weighted": 0.6227708241403305
          },
          {
            "accuracy": 0.55859375,
            "ap": 0.34828231251382136,
            "ap_weighted": 0.34828231251382136,
            "f1": 0.5416289104318125,
            "f1_weighted": 0.574180734577878
          },
          {
            "accuracy": 0.599609375,
            "ap": 0.35117124283176193,
            "ap_weighted": 0.35117124283176193,
            "f1": 0.5606304634708142,
            "f1_weighted": 0.6089387538250183
          },
          {
            "accuracy": 0.666015625,
            "ap": 0.3853331351834762,
            "ap_weighted": 0.3853331351834762,
            "f1": 0.6096895531370681,
            "f1_weighted": 0.6644228569010482
          },
          {
            "accuracy": 0.5966796875,
            "ap": 0.353484470697604,
            "ap_weighted": 0.353484470697604,
            "f1": 0.5622966921166996,
            "f1_weighted": 0.6075816128654368
          },
          {
            "accuracy": 0.51904296875,
            "ap": 0.32643330659305236,
            "ap_weighted": 0.32643330659305236,
            "f1": 0.5029056393527779,
            "f1_weighted": 0.5359674849470867
          },
          {
            "accuracy": 0.49853515625,
            "ap": 0.3177021644641649,
            "ap_weighted": 0.3177021644641649,
            "f1": 0.48388907851462437,
            "f1_weighted": 0.5159830923347517
          },
          {
            "accuracy": 0.55224609375,
            "ap": 0.3329625427894473,
            "ap_weighted": 0.3329625427894473,
            "f1": 0.5247039231838998,
            "f1_weighted": 0.5669389758167025
          },
          {
            "accuracy": 0.537109375,
            "ap": 0.35202147180341886,
            "ap_weighted": 0.35202147180341886,
            "f1": 0.5307724655964966,
            "f1_weighted": 0.5509014719370369
          },
          {
            "accuracy": 0.5673828125,
            "ap": 0.3592483628332309,
            "ap_weighted": 0.3592483628332309,
            "f1": 0.5540591419783003,
            "f1_weighted": 0.5825130824144726
          }
        ]
      }
    ]
  },
  "task_name": "HateSpeechPortugueseClassification"
}