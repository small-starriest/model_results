{
  "dataset_revision": "37c8b42c63d4eb75f549679158a85eb5bd984caa",
  "evaluation_time": 10.067947149276733,
  "kg_co2_emissions": 0.0015301825536374952,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.571337890625,
        "ap": 0.5520302079360373,
        "ap_weighted": 0.5520302079360373,
        "f1": 0.5639758149394524,
        "f1_weighted": 0.5646463662743593,
        "hf_subset": "default",
        "languages": [
          "slv-Latn"
        ],
        "main_score": 0.571337890625,
        "scores_per_experiment": [
          {
            "accuracy": 0.55126953125,
            "ap": 0.538244584040147,
            "ap_weighted": 0.538244584040147,
            "f1": 0.5462690078949798,
            "f1_weighted": 0.5473854038067982
          },
          {
            "accuracy": 0.587890625,
            "ap": 0.5670529292324503,
            "ap_weighted": 0.5670529292324503,
            "f1": 0.5841592352336054,
            "f1_weighted": 0.5832360047759407
          },
          {
            "accuracy": 0.58740234375,
            "ap": 0.563171870252744,
            "ap_weighted": 0.563171870252744,
            "f1": 0.5873998844616679,
            "f1_weighted": 0.5874234936296561
          },
          {
            "accuracy": 0.60546875,
            "ap": 0.575026148708162,
            "ap_weighted": 0.575026148708162,
            "f1": 0.6053181908381798,
            "f1_weighted": 0.605498861832364
          },
          {
            "accuracy": 0.61328125,
            "ap": 0.573875391314379,
            "ap_weighted": 0.573875391314379,
            "f1": 0.592546334209191,
            "f1_weighted": 0.5947006111744699
          },
          {
            "accuracy": 0.560546875,
            "ap": 0.548478059520564,
            "ap_weighted": 0.548478059520564,
            "f1": 0.555603561343682,
            "f1_weighted": 0.5545050471978336
          },
          {
            "accuracy": 0.52734375,
            "ap": 0.5245355594898754,
            "ap_weighted": 0.5245355594898754,
            "f1": 0.519721687897009,
            "f1_weighted": 0.5211397459626818
          },
          {
            "accuracy": 0.55810546875,
            "ap": 0.5434420807506917,
            "ap_weighted": 0.5434420807506917,
            "f1": 0.5573065885469226,
            "f1_weighted": 0.5577473500382757
          },
          {
            "accuracy": 0.5654296875,
            "ap": 0.5474579266540003,
            "ap_weighted": 0.5474579266540003,
            "f1": 0.563616862347015,
            "f1_weighted": 0.5642760714935551
          },
          {
            "accuracy": 0.556640625,
            "ap": 0.5390175293973596,
            "ap_weighted": 0.5390175293973596,
            "f1": 0.5278167966222715,
            "f1_weighted": 0.5305510728320164
          }
        ]
      }
    ]
  },
  "task_name": "FrenkSlClassification"
}