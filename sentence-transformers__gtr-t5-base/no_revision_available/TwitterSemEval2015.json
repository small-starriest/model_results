{
    "test": {
        "cos_sim": {
            "accuracy": 0.853907134767837,
            "accuracy_threshold": 0.8573521375656128,
            "ap": 0.7222675077030647,
            "f1": 0.6806487013778807,
            "f1_threshold": 0.8156364560127258,
            "precision": 0.6327363409657674,
            "recall": 0.7364116094986808
        },
        "dot": {
            "accuracy": 0.853907134767837,
            "accuracy_threshold": 0.8573521375656128,
            "ap": 0.7222675006771236,
            "f1": 0.6806487013778807,
            "f1_threshold": 0.8156364560127258,
            "precision": 0.6327363409657674,
            "recall": 0.7364116094986808
        },
        "euclidean": {
            "accuracy": 0.853907134767837,
            "accuracy_threshold": 0.5341306924819946,
            "ap": 0.7222675376564271,
            "f1": 0.6806487013778807,
            "f1_threshold": 0.6072289943695068,
            "precision": 0.6327363409657674,
            "recall": 0.7364116094986808
        },
        "evaluation_time": 10.5,
        "manhattan": {
            "accuracy": 0.8540859510043511,
            "accuracy_threshold": 12.074257850646973,
            "ap": 0.7220275449321797,
            "f1": 0.6808250945929453,
            "f1_threshold": 13.386808395385742,
            "precision": 0.6334317510788099,
            "recall": 0.7358839050131926
        },
        "max": {
            "accuracy": 0.8540859510043511,
            "ap": 0.7222675376564271,
            "f1": 0.6808250945929453
        }
    },
    "mteb_version": "0.0.2",
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}