{
  "dataset_revision": "c9e9f2c09836bfec57c543ab65983f3398e9657a",
  "evaluation_time": 16.445123195648193,
  "kg_co2_emissions": 0.002495092024343151,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.26294779938587515,
        "f1": 0.2579656012165428,
        "f1_weighted": 0.2629055822234879,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.2579656012165428,
        "scores_per_experiment": [
          {
            "accuracy": 0.2671443193449335,
            "f1": 0.2658039592465822,
            "f1_weighted": 0.25547639545491785
          },
          {
            "accuracy": 0.2804503582395087,
            "f1": 0.27920216630699357,
            "f1_weighted": 0.2785446229804163
          },
          {
            "accuracy": 0.25895598771750256,
            "f1": 0.2608911328552776,
            "f1_weighted": 0.2623982876191525
          },
          {
            "accuracy": 0.25895598771750256,
            "f1": 0.2577312486447392,
            "f1_weighted": 0.26839507246611405
          },
          {
            "accuracy": 0.34186284544524054,
            "f1": 0.3316414168422736,
            "f1_weighted": 0.3451530410650271
          },
          {
            "accuracy": 0.23643807574206754,
            "f1": 0.2306329452417699,
            "f1_weighted": 0.24503934515593095
          },
          {
            "accuracy": 0.25588536335721596,
            "f1": 0.25183697099627084,
            "f1_weighted": 0.2646104870212666
          },
          {
            "accuracy": 0.27635619242579323,
            "f1": 0.2668215022501762,
            "f1_weighted": 0.26828974119834964
          },
          {
            "accuracy": 0.23132036847492324,
            "f1": 0.2186254992296898,
            "f1_weighted": 0.2343962611629792
          },
          {
            "accuracy": 0.22210849539406347,
            "f1": 0.21646917055165507,
            "f1_weighted": 0.2067525681107251
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.26727642276422764,
        "f1": 0.26012111251366654,
        "f1_weighted": 0.26965069415497567,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.26012111251366654,
        "scores_per_experiment": [
          {
            "accuracy": 0.2845528455284553,
            "f1": 0.27652561997389585,
            "f1_weighted": 0.2737140926543786
          },
          {
            "accuracy": 0.2926829268292683,
            "f1": 0.2920910441806705,
            "f1_weighted": 0.29007607493195336
          },
          {
            "accuracy": 0.2804878048780488,
            "f1": 0.2786725252054381,
            "f1_weighted": 0.2832696377284839
          },
          {
            "accuracy": 0.2601626016260163,
            "f1": 0.2596095312261473,
            "f1_weighted": 0.2703674007112497
          },
          {
            "accuracy": 0.3252032520325203,
            "f1": 0.3202673237376446,
            "f1_weighted": 0.3308327382420996
          },
          {
            "accuracy": 0.21951219512195122,
            "f1": 0.21240282803083455,
            "f1_weighted": 0.22743434127375897
          },
          {
            "accuracy": 0.23577235772357724,
            "f1": 0.23155344418399273,
            "f1_weighted": 0.2465645962991024
          },
          {
            "accuracy": 0.2886178861788618,
            "f1": 0.2709224681236744,
            "f1_weighted": 0.28543528333677454
          },
          {
            "accuracy": 0.258130081300813,
            "f1": 0.24085210685471203,
            "f1_weighted": 0.2668939632173923
          },
          {
            "accuracy": 0.22764227642276422,
            "f1": 0.21831423361965574,
            "f1_weighted": 0.2219188131545632
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianMongabayConservationClassification"
}