{
  "dataset_revision": "b108d2c32ee4e1f4176ea233e1a5ac17bceb9ef9",
  "evaluation_time": 34.40301704406738,
  "kg_co2_emissions": 0.009025715509423566,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.53857421875,
        "f1": 0.5269944093114776,
        "f1_weighted": 0.5438678976772924,
        "hf_subset": "default",
        "languages": [
          "ara-Arab"
        ],
        "main_score": 0.53857421875,
        "scores_per_experiment": [
          {
            "accuracy": 0.57421875,
            "f1": 0.5455539950016617,
            "f1_weighted": 0.581156758510033
          },
          {
            "accuracy": 0.47314453125,
            "f1": 0.47190224244228896,
            "f1_weighted": 0.48405009050173076
          },
          {
            "accuracy": 0.47216796875,
            "f1": 0.47522004512733856,
            "f1_weighted": 0.4802206782885647
          },
          {
            "accuracy": 0.5849609375,
            "f1": 0.5563854341632928,
            "f1_weighted": 0.5842849854145746
          },
          {
            "accuracy": 0.52685546875,
            "f1": 0.5300914028862649,
            "f1_weighted": 0.5294431085575573
          },
          {
            "accuracy": 0.56298828125,
            "f1": 0.5524563314633559,
            "f1_weighted": 0.5726065063647563
          },
          {
            "accuracy": 0.5263671875,
            "f1": 0.526461637028902,
            "f1_weighted": 0.5343847518243421
          },
          {
            "accuracy": 0.58349609375,
            "f1": 0.5657387309756418,
            "f1_weighted": 0.5880943465892978
          },
          {
            "accuracy": 0.50439453125,
            "f1": 0.4918096892044143,
            "f1_weighted": 0.5074923234296914
          },
          {
            "accuracy": 0.5771484375,
            "f1": 0.5543245848216156,
            "f1_weighted": 0.5769454272923759
          }
        ]
      }
    ]
  },
  "task_name": "HotelReviewSentimentClassification"
}