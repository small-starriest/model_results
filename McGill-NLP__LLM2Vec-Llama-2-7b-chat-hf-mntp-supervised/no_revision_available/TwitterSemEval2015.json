{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.0.1.dev0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8813256243666925,
      "accuracy_threshold": 0.793980598449707,
      "ap": 0.8069819368353635,
      "f1": 0.7349014621741895,
      "f1_threshold": 0.7790637016296387,
      "precision": 0.7092024539877301,
      "recall": 0.762532981530343
    },
    "dot": {
      "accuracy": 0.8608809679918936,
      "accuracy_threshold": 6335.580078125,
      "ap": 0.7441500765551534,
      "f1": 0.6932043650793651,
      "f1_threshold": 6063.451171875,
      "precision": 0.6539541413196069,
      "recall": 0.737467018469657
    },
    "euclidean": {
      "accuracy": 0.8815640460153782,
      "accuracy_threshold": 55.83635711669922,
      "ap": 0.8031937915172528,
      "f1": 0.7357214428857716,
      "f1_threshold": 59.157386779785156,
      "precision": 0.7002861230329042,
      "recall": 0.774934036939314
    },
    "evaluation_time": 66.5,
    "manhattan": {
      "accuracy": 0.8815044406032068,
      "accuracy_threshold": 2841.29736328125,
      "ap": 0.8030776043635841,
      "f1": 0.7354741971760589,
      "f1_threshold": 3013.926025390625,
      "precision": 0.6985521006408735,
      "recall": 0.7765171503957784
    },
    "max": {
      "accuracy": 0.8815640460153782,
      "ap": 0.8069819368353635,
      "f1": 0.7357214428857716
    }
  }
}