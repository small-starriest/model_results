{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 696.5194683074951,
  "kg_co2_emissions": 0.27093922773158174,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433466,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433466,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9130434782608695,
        "f1": 0.8873847167325428,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.8873847167325428,
        "precision": 0.8756093544137022,
        "recall": 0.9130434782608695
      },
      {
        "accuracy": 0.8982213438735178,
        "f1": 0.870111048371918,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.870111048371918,
        "precision": 0.8575428194993413,
        "recall": 0.8982213438735178
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733859,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9947299077733859,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9664031620553359,
        "f1": 0.9561923583662715,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9561923583662715,
        "precision": 0.9510869565217391,
        "recall": 0.9664031620553359
      },
      {
        "accuracy": 0.9436758893280632,
        "f1": 0.9262187088274044,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9262187088274044,
        "precision": 0.9179841897233202,
        "recall": 0.9436758893280632
      },
      {
        "accuracy": 0.8053359683794467,
        "f1": 0.758883869753435,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.758883869753435,
        "precision": 0.7394927536231884,
        "recall": 0.8053359683794467
      },
      {
        "accuracy": 0.7944664031620553,
        "f1": 0.7487374450319115,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7487374450319115,
        "precision": 0.7311104409424567,
        "recall": 0.7944664031620553
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9962121212121213,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9962121212121213,
        "precision": 0.9958827404479579,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9828722002635046,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9828722002635046,
        "precision": 0.9807312252964426,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.9407114624505929,
        "f1": 0.922266139657444,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.922266139657444,
        "precision": 0.9135375494071146,
        "recall": 0.9407114624505929
      },
      {
        "accuracy": 0.9199604743083004,
        "f1": 0.8962450592885376,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.8962450592885376,
        "precision": 0.8853754940711462,
        "recall": 0.9199604743083004
      },
      {
        "accuracy": 0.9130434782608695,
        "f1": 0.8872529644268775,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8872529644268775,
        "precision": 0.8751152832674571,
        "recall": 0.9130434782608695
      },
      {
        "accuracy": 0.8705533596837944,
        "f1": 0.8367409270571325,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8367409270571325,
        "precision": 0.8221673254281949,
        "recall": 0.8705533596837944
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9922595520421608,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9922595520421608,
        "precision": 0.9914361001317523,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9604743083003953,
        "f1": 0.9486166007905138,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9486166007905138,
        "precision": 0.9430171277997366,
        "recall": 0.9604743083003953
      },
      {
        "accuracy": 0.9288537549407114,
        "f1": 0.9074110671936758,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9074110671936758,
        "precision": 0.8973978919631095,
        "recall": 0.9288537549407114
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9782608695652174,
        "f1": 0.9713438735177866,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9713438735177866,
        "precision": 0.9680500658761529,
        "recall": 0.9782608695652174
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9963768115942028,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9963768115942028,
        "precision": 0.9960474308300395,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9848484848484848,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9848484848484848,
        "precision": 0.983201581027668,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.6847826086956522,
        "f1": 0.6241510008802499,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.6241510008802499,
        "precision": 0.6019272394272394,
        "recall": 0.6847826086956522
      },
      {
        "accuracy": 0.6936758893280632,
        "f1": 0.6314237091411005,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6314237091411005,
        "precision": 0.6074553164227078,
        "recall": 0.6936758893280632
      },
      {
        "accuracy": 0.841897233201581,
        "f1": 0.8046325051759834,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.8046325051759834,
        "precision": 0.7897437103958843,
        "recall": 0.841897233201581
      },
      {
        "accuracy": 0.8438735177865613,
        "f1": 0.8047619047619048,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.8047619047619048,
        "precision": 0.7876811594202898,
        "recall": 0.8438735177865613
      },
      {
        "accuracy": 0.866600790513834,
        "f1": 0.830368906455863,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.830368906455863,
        "precision": 0.8144762845849802,
        "recall": 0.866600790513834
      },
      {
        "accuracy": 0.8191699604743083,
        "f1": 0.7779738377564465,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.7779738377564465,
        "precision": 0.7617471296819123,
        "recall": 0.8191699604743083
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9845191040843214,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9845191040843214,
        "precision": 0.982707509881423,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.989459815546772,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.989459815546772,
        "precision": 0.9886363636363636,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9840250329380764,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9840250329380764,
        "precision": 0.9825428194993413,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9868247694334651,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9868247694334651,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.2865612648221344,
        "f1": 0.23574425513188224,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.23574425513188224,
        "precision": 0.2239191497230677,
        "recall": 0.2865612648221344
      },
      {
        "accuracy": 0.34288537549407117,
        "f1": 0.2750982011846796,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.2750982011846796,
        "precision": 0.25562519642405546,
        "recall": 0.34288537549407117
      },
      {
        "accuracy": 0.45849802371541504,
        "f1": 0.40148383640382096,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.40148383640382096,
        "precision": 0.3827645078862666,
        "recall": 0.45849802371541504
      },
      {
        "accuracy": 0.48221343873517786,
        "f1": 0.41619422599281936,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.41619422599281936,
        "precision": 0.39368196718740195,
        "recall": 0.48221343873517786
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9841897233201581,
        "f1": 0.9789196310935442,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9789196310935442,
        "precision": 0.9762845849802372,
        "recall": 0.9841897233201581
      },
      {
        "accuracy": 0.9337944664031621,
        "f1": 0.9136034255599473,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9136034255599473,
        "precision": 0.9039031620553359,
        "recall": 0.9337944664031621
      },
      {
        "accuracy": 0.9021739130434783,
        "f1": 0.8736495388669302,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8736495388669302,
        "precision": 0.8609025032938077,
        "recall": 0.9021739130434783
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768115,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9855072463768115,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9845191040843215,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9845191040843215,
        "precision": 0.982707509881423,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.9855072463768115,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9855072463768115,
        "precision": 0.9836956521739131,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.5592885375494071,
        "f1": 0.5097816260709369,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.5097816260709369,
        "precision": 0.4926682177145656,
        "recall": 0.5592885375494071
      },
      {
        "accuracy": 0.5810276679841897,
        "f1": 0.5122229672501412,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.5122229672501412,
        "precision": 0.4867664930483686,
        "recall": 0.5810276679841897
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034257,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9907773386034257,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9891304347826086,
        "f1": 0.985836627140975,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.985836627140975,
        "precision": 0.9841897233201581,
        "recall": 0.9891304347826086
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.01714024762671473,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.01714024762671473,
        "precision": 0.01631059329566443,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.010771265057806104,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.010771265057806104,
        "precision": 0.007621750550357269,
        "recall": 0.030632411067193676
      }
    ],
    "validation": [
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222335,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222335,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444667,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9893012370444667,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9327983951855566,
        "f1": 0.9121364092276829,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9121364092276829,
        "precision": 0.9022902039451688,
        "recall": 0.9327983951855566
      },
      {
        "accuracy": 0.8966900702106319,
        "f1": 0.8662177007212112,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.8662177007212112,
        "precision": 0.8522233366766967,
        "recall": 0.8966900702106319
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611167,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9973253092611167,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9658976930792377,
        "f1": 0.9546974256101638,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9546974256101638,
        "precision": 0.9491808759612169,
        "recall": 0.9658976930792377
      },
      {
        "accuracy": 0.9468405215646941,
        "f1": 0.9310264125710465,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9310264125710465,
        "precision": 0.9236877298562354,
        "recall": 0.9468405215646941
      },
      {
        "accuracy": 0.7903711133400201,
        "f1": 0.7381891706866631,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.7381891706866631,
        "precision": 0.7166583082581076,
        "recall": 0.7903711133400201
      },
      {
        "accuracy": 0.7903711133400201,
        "f1": 0.7397318940949834,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.7397318940949834,
        "precision": 0.718547308592444,
        "recall": 0.7903711133400201
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9779338014042126,
        "f1": 0.9707455700434637,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9707455700434637,
        "precision": 0.9672350384486794,
        "recall": 0.9779338014042126
      },
      {
        "accuracy": 0.9468405215646941,
        "f1": 0.9313607489134068,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9313607489134068,
        "precision": 0.924189234369776,
        "recall": 0.9468405215646941
      },
      {
        "accuracy": 0.905717151454363,
        "f1": 0.8791206954195921,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.8791206954195921,
        "precision": 0.8671610068300138,
        "recall": 0.905717151454363
      },
      {
        "accuracy": 0.9137412236710131,
        "f1": 0.8889000334336342,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.8889000334336342,
        "precision": 0.8775493146104982,
        "recall": 0.9137412236710131
      },
      {
        "accuracy": 0.8826479438314945,
        "f1": 0.8507674538767819,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.8507674538767819,
        "precision": 0.8365262454028752,
        "recall": 0.8826479438314945
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527917,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9933132731527917,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.987963891675025,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.987963891675025,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9398194583751254,
        "f1": 0.9213831972106796,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9213831972106796,
        "precision": 0.9125710464727517,
        "recall": 0.9398194583751254
      },
      {
        "accuracy": 0.9167502507522568,
        "f1": 0.8914744232698094,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.8914744232698094,
        "precision": 0.8799732530926112,
        "recall": 0.9167502507522568
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9779338014042126,
        "f1": 0.9707455700434636,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9707455700434636,
        "precision": 0.9672350384486793,
        "recall": 0.9779338014042126
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9909729187562688,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9909729187562688,
        "precision": 0.9899699097291875,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9819458375125376,
        "f1": 0.9764292878635907,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9764292878635907,
        "precision": 0.9737545971247074,
        "recall": 0.9819458375125376
      },
      {
        "accuracy": 0.7191574724172518,
        "f1": 0.662598907834615,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.662598907834615,
        "precision": 0.6400139530203636,
        "recall": 0.7191574724172518
      },
      {
        "accuracy": 0.7211634904714143,
        "f1": 0.6623330308385473,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.6623330308385473,
        "precision": 0.6393004771891432,
        "recall": 0.7211634904714143
      },
      {
        "accuracy": 0.8655967903711134,
        "f1": 0.8301762430147586,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.8301762430147586,
        "precision": 0.8146773654296222,
        "recall": 0.8655967903711134
      },
      {
        "accuracy": 0.8575727181544633,
        "f1": 0.821856840362357,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.821856840362357,
        "precision": 0.8072730095047047,
        "recall": 0.8575727181544633
      },
      {
        "accuracy": 0.876629889669007,
        "f1": 0.8425657926159431,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8425657926159431,
        "precision": 0.827515880976262,
        "recall": 0.876629889669007
      },
      {
        "accuracy": 0.7913741223671013,
        "f1": 0.7409768989508206,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.7409768989508206,
        "precision": 0.7210743341134515,
        "recall": 0.7913741223671013
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9866265463055833,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9866265463055833,
        "precision": 0.9849548645937813,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.9799398194583752,
        "f1": 0.9735874289535272,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9735874289535272,
        "precision": 0.9704112337011033,
        "recall": 0.9799398194583752
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9926446004680708,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9926446004680708,
        "precision": 0.9919759277833501,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.986292209963223,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.986292209963223,
        "precision": 0.9849548645937813,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222335,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222335,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.9812771648278167,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9812771648278167,
        "precision": 0.9789368104312939,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.31795386158475425,
        "f1": 0.2593809992839068,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.2593809992839068,
        "precision": 0.24249535613987186,
        "recall": 0.31795386158475425
      },
      {
        "accuracy": 0.34503510531594783,
        "f1": 0.27759084583676,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.27759084583676,
        "precision": 0.2570105100038942,
        "recall": 0.34503510531594783
      },
      {
        "accuracy": 0.5045135406218656,
        "f1": 0.4394244270947911,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.4394244270947911,
        "precision": 0.418443461698226,
        "recall": 0.5045135406218656
      },
      {
        "accuracy": 0.48144433299899697,
        "f1": 0.4015900440084758,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.4015900440084758,
        "precision": 0.37255002742715876,
        "recall": 0.48144433299899697
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527917,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9933132731527917,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.9839518555667001,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9839518555667001,
        "precision": 0.9819458375125376,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.9317953861584755,
        "f1": 0.9124707455700435,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9124707455700435,
        "precision": 0.9034938147776663,
        "recall": 0.9317953861584755
      },
      {
        "accuracy": 0.8856569709127382,
        "f1": 0.855437741796819,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.855437741796819,
        "precision": 0.8422266800401204,
        "recall": 0.8856569709127382
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444668,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9893012370444668,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9759277833500501,
        "f1": 0.9687395519893012,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9687395519893012,
        "precision": 0.9653961885656971,
        "recall": 0.9759277833500501
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527917,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9933132731527917,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9749247743229689,
        "f1": 0.9672350384486794,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9672350384486794,
        "precision": 0.9635907723169509,
        "recall": 0.9749247743229689
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9899699097291875,
        "f1": 0.9866265463055834,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9866265463055834,
        "precision": 0.9849548645937813,
        "recall": 0.9899699097291875
      },
      {
        "accuracy": 0.5656970912738215,
        "f1": 0.5098769074221747,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.5098769074221747,
        "precision": 0.4911507783615486,
        "recall": 0.5656970912738215
      },
      {
        "accuracy": 0.563691073219659,
        "f1": 0.49435596165786727,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.49435596165786727,
        "precision": 0.46953877006448513,
        "recall": 0.563691073219659
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9849548645937813,
        "f1": 0.9799398194583752,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9799398194583752,
        "precision": 0.977432296890672,
        "recall": 0.9849548645937813
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139085,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139085,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9869608826479438,
        "f1": 0.9827816783684387,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9827816783684387,
        "precision": 0.9807756603142762,
        "recall": 0.9869608826479438
      },
      {
        "accuracy": 0.020060180541624874,
        "f1": 0.014732792492777414,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.014732792492777414,
        "precision": 0.01347467674120901,
        "recall": 0.020060180541624874
      },
      {
        "accuracy": 0.026078234704112337,
        "f1": 0.009233891477060613,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.009233891477060613,
        "precision": 0.006662090927386815,
        "recall": 0.026078234704112337
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}