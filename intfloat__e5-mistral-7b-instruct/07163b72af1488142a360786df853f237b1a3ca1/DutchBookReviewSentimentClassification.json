{
  "dataset_revision": "3f756ab4572e071eb53e887ab629f19fa747d39e",
  "evaluation_time": 34.0067617893219,
  "kg_co2_emissions": 0.009059852798533316,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.8744154676258994,
        "ap": 0.8114128093306341,
        "ap_weighted": 0.8114128093306341,
        "f1": 0.8736396032139803,
        "f1_weighted": 0.8736396032139803,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ],
        "main_score": 0.8744154676258994,
        "scores_per_experiment": [
          {
            "accuracy": 0.8862410071942446,
            "ap": 0.8276626873683535,
            "ap_weighted": 0.8276626873683535,
            "f1": 0.8859032735243693,
            "f1_weighted": 0.8859032735243693
          },
          {
            "accuracy": 0.8835431654676259,
            "ap": 0.8171211306816617,
            "ap_weighted": 0.8171211306816617,
            "f1": 0.8826594895381414,
            "f1_weighted": 0.8826594895381413
          },
          {
            "accuracy": 0.8655575539568345,
            "ap": 0.798061279448125,
            "ap_weighted": 0.798061279448125,
            "f1": 0.8647005695192547,
            "f1_weighted": 0.8647005695192546
          },
          {
            "accuracy": 0.8889388489208633,
            "ap": 0.8261969516008181,
            "ap_weighted": 0.8261969516008181,
            "f1": 0.8883241569188227,
            "f1_weighted": 0.8883241569188227
          },
          {
            "accuracy": 0.8830935251798561,
            "ap": 0.8168907270496966,
            "ap_weighted": 0.8168907270496966,
            "f1": 0.8822340020806195,
            "f1_weighted": 0.8822340020806195
          },
          {
            "accuracy": 0.8633093525179856,
            "ap": 0.8170577928800871,
            "ap_weighted": 0.8170577928800871,
            "f1": 0.8632876827559879,
            "f1_weighted": 0.8632876827559878
          },
          {
            "accuracy": 0.8628597122302158,
            "ap": 0.7924335664144955,
            "ap_weighted": 0.7924335664144955,
            "f1": 0.8616612761090582,
            "f1_weighted": 0.8616612761090582
          },
          {
            "accuracy": 0.8709532374100719,
            "ap": 0.8224669592884332,
            "ap_weighted": 0.8224669592884332,
            "f1": 0.8709525851515654,
            "f1_weighted": 0.8709525851515654
          },
          {
            "accuracy": 0.8637589928057554,
            "ap": 0.7888907782864618,
            "ap_weighted": 0.7888907782864618,
            "f1": 0.8618267310258115,
            "f1_weighted": 0.8618267310258115
          },
          {
            "accuracy": 0.8758992805755396,
            "ap": 0.8073462202882071,
            "ap_weighted": 0.8073462202882071,
            "f1": 0.8748462655161726,
            "f1_weighted": 0.8748462655161727
          }
        ]
      }
    ]
  },
  "task_name": "DutchBookReviewSentimentClassification"
}